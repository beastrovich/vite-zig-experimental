{
  "version": 3,
  "names": [],
  "sources": [
    "/home/beastrovich/repos/labs/vite-zig/zig/src/lib/sys.zig",
    "/home/beastrovich/repos/labs/vite-zig/zig/src/lib/Console.zig",
    "App.zig",
    "/usr/lib/zig/std/mem/Allocator.zig",
    "/usr/lib/zig/std/builtin.zig",
    "/home/beastrovich/repos/labs/vite-zig/zig/src/lib/WebWorkerThread.zig",
    "/usr/lib/zig/std/debug.zig",
    "/usr/lib/zig/std/mem.zig",
    "/usr/lib/zig/std/heap/WasmAllocator.zig",
    "/usr/lib/zig/std/math.zig",
    "/usr/lib/zig/std/math/log2.zig",
    "/usr/lib/zig/std/fmt.zig",
    "/usr/lib/zig/std/io.zig",
    "/usr/lib/zig/std/io/fixed_buffer_stream.zig",
    "/usr/lib/zig/std/meta.zig",
    "/usr/lib/zig/std/io/Writer.zig",
    "/usr/lib/zig/std/unicode.zig"
  ],
  "sourcesContent": [
    "extern \"sys\" fn cpuCount() u32;\n\npub fn declareMain(comptime f: anytype) void {\n    const fn_type = @TypeOf(f);\n    const fn_type_info = @typeInfo(fn_type);\n    // fn_type_info.Fn\n    if (fn_type_info != .Fn) {\n        @compileError(\"main_fn must be a function\");\n    }\n\n    const handle = (switch (@typeInfo(@typeInfo(fn_type).Fn.return_type.?)) {\n        .ErrorUnion => struct {\n            fn handle() callconv(.C) void {\n                @call(.always_inline, f, .{}) catch unreachable;\n            }\n            // @compileError(\"main_fn must not return an error union\");\n        },\n        .Void => struct {\n            fn handle() callconv(.C) void {\n                @call(.always_inline, f, .{});\n            }\n        },\n        else => @compileError(\"main_fn return type is not supported\"),\n    }).handle;\n\n    @export(handle, .{ .name = \"__wasm_mainStart\" });\n}\n",
    "const std = @import(\"std\");\n\nconst __log = @extern(*const fn ([*]const u8, usize) callconv(.C) void, .{\n    .name = \"log\",\n    .library_name = \"console\",\n});\n\npub inline fn log(s: []const u8) void {\n    __log(s.ptr, s.len);\n}\n\npub fn logFmtSmall(comptime bufferSize: usize, comptime fmt: []const u8, args: anytype) void {\n    var buff: [bufferSize]u8 = undefined;\n    const printed = std.fmt.bufPrint(&buff, fmt, args) catch {\n        log(\"Error formatting message\");\n        return;\n    };\n    log(printed);\n}\n",
    "const std = @import(\"std\");\nconst lib = @import(\"./lib.zig\");\n\n/// Asks the host to create a new thread for us.\n/// Newly created thread will call `wasi_tread_start` with the thread ID as well\n/// as the input `arg` that was provided to `spawnWasiThread`\n// const spawnWasiThread = @\"thread-spawn\";\n// extern \"wasi\" fn @\"thread-spawn\"(arg: *Instance) i32;\n\nconst SharedContext = struct {\n    const Self = @This();\n\n    unique: std.atomic.Value(u32) = std.atomic.Value(u32).init(0),\n    thread_count: std.atomic.Value(usize) = std.atomic.Value(usize).init(0),\n    // stack_locations: [32]usize = [_]usize{0} ** 32,\n    thread_idx: u32 = 0,\n};\n\nfn spinWait(iterations: u32) void {\n    var i: u32 = 0;\n    var x: u32 = 1;\n    while (i < iterations) : (i += 1) {\n        x = x *% 31 +% 1;\n    }\n    std.mem.doNotOptimizeAway(x);\n}\n\nfn startFn(ctx: *SharedContext) void {\n    _ = ctx; // autofix\n\n    // // const g = GlobalContext.current();\n    // // _ = g; // autofix\n    // // _ = data;\n    // const id = g.unique.fetchAdd(1, .monotonic);\n\n    // // Create a stack buffer to test\n    // var stack_buffer: [256]u8 = undefined;\n    // var prng = std.rand.DefaultPrng.init(@as(u64, id));\n    // var rand = prng.random();\n\n    // const NUM_ITERATIONS = 100;\n    // var iter: usize = 0;\n    // while (iter < NUM_ITERATIONS) : (iter += 1) {\n    //     // Fill buffer with thread-unique pattern\n    //     for (stack_buffer[0..], 0..) |*b, i| {\n    //         b.* = @truncate(id +% i +% @as(u8, @truncate(iter)));\n    //     }\n\n    //     // Random delay between write and check\n    //     // spinWait(rand.intRangeAtMost(u32, 100, 10000));\n\n    //     // Verify buffer hasn't been corrupted\n    //     var corrupted = false;\n    //     var corrupt_offset: usize = 0;\n    //     var corrupt_value: u8 = 0;\n    //     var expected_value: u8 = 0;\n\n    //     for (stack_buffer[0..], 0..) |b, i| {\n    //         const expected = @as(u8, @truncate(id +% i +% @as(u8, @truncate(iter))));\n    //         if (b != expected) {\n    //             corrupted = true;\n    //             corrupt_offset = i;\n    //             corrupt_value = b;\n    //             expected_value = expected;\n    //             break;\n    //         }\n    //     }\n\n    //     if (corrupted) {\n    //         Env.logFmtSmall(500, \"Thread {d} iter {d} stack corruption at 0x{x} offset {d}: expected {d}, got {d}\", .{\n    //             id,\n    //             iter,\n    //             @intFromPtr(&stack_buffer) + corrupt_offset,\n    //             corrupt_offset,\n    //             expected_value,\n    //             corrupt_value,\n    //         });\n    //         // Continue testing to see if corruption persists\n    //     }\n\n    //     // Random delay before next iteration\n    //     spinWait(rand.intRangeAtMost(u32, 100, 10000));\n    // }\n\n    // Env.logFmtSmall(100, \"Thread {d} completed {d} iterations at stack 0x{x}\", .{ id, NUM_ITERATIONS, @intFromPtr(&stack_buffer) });\n    // // if (id < 20) {\n    // //     Env.startThread(&startFn, null);\n    // //     // Env.log(\"Thread 0 exiting\");\n    // // }\n}\n\npub fn main() !void {\n    lib.Console.log(\"test\");\n\n    const alloc = std.heap.wasm_allocator;\n    const ctx = alloc.create(SharedContext) catch unreachable;\n    ctx.* = .{};\n\n    lib.WebWorkerThread.spawn(.{\n        .allocator = alloc,\n    }, startFn, .{ctx}) catch unreachable;\n}\n",
    "//! The standard memory allocation interface.\n\nconst std = @import(\"../std.zig\");\nconst assert = std.debug.assert;\nconst math = std.math;\nconst mem = std.mem;\nconst Allocator = @This();\nconst builtin = @import(\"builtin\");\n\npub const Error = error{OutOfMemory};\npub const Log2Align = math.Log2Int(usize);\n\n// The type erased pointer to the allocator implementation\nptr: *anyopaque,\nvtable: *const VTable,\n\npub const VTable = struct {\n    /// Attempt to allocate exactly `len` bytes aligned to `1 << ptr_align`.\n    ///\n    /// `ret_addr` is optionally provided as the first return address of the\n    /// allocation call stack. If the value is `0` it means no return address\n    /// has been provided.\n    alloc: *const fn (ctx: *anyopaque, len: usize, ptr_align: u8, ret_addr: usize) ?[*]u8,\n\n    /// Attempt to expand or shrink memory in place. `buf.len` must equal the\n    /// length requested from the most recent successful call to `alloc` or\n    /// `resize`. `buf_align` must equal the same value that was passed as the\n    /// `ptr_align` parameter to the original `alloc` call.\n    ///\n    /// A result of `true` indicates the resize was successful and the\n    /// allocation now has the same address but a size of `new_len`. `false`\n    /// indicates the resize could not be completed without moving the\n    /// allocation to a different address.\n    ///\n    /// `new_len` must be greater than zero.\n    ///\n    /// `ret_addr` is optionally provided as the first return address of the\n    /// allocation call stack. If the value is `0` it means no return address\n    /// has been provided.\n    resize: *const fn (ctx: *anyopaque, buf: []u8, buf_align: u8, new_len: usize, ret_addr: usize) bool,\n\n    /// Free and invalidate a buffer.\n    ///\n    /// `buf.len` must equal the most recent length returned by `alloc` or\n    /// given to a successful `resize` call.\n    ///\n    /// `buf_align` must equal the same value that was passed as the\n    /// `ptr_align` parameter to the original `alloc` call.\n    ///\n    /// `ret_addr` is optionally provided as the first return address of the\n    /// allocation call stack. If the value is `0` it means no return address\n    /// has been provided.\n    free: *const fn (ctx: *anyopaque, buf: []u8, buf_align: u8, ret_addr: usize) void,\n};\n\npub fn noResize(\n    self: *anyopaque,\n    buf: []u8,\n    log2_buf_align: u8,\n    new_len: usize,\n    ret_addr: usize,\n) bool {\n    _ = self;\n    _ = buf;\n    _ = log2_buf_align;\n    _ = new_len;\n    _ = ret_addr;\n    return false;\n}\n\npub fn noFree(\n    self: *anyopaque,\n    buf: []u8,\n    log2_buf_align: u8,\n    ret_addr: usize,\n) void {\n    _ = self;\n    _ = buf;\n    _ = log2_buf_align;\n    _ = ret_addr;\n}\n\n/// This function is not intended to be called except from within the\n/// implementation of an Allocator\npub inline fn rawAlloc(self: Allocator, len: usize, ptr_align: u8, ret_addr: usize) ?[*]u8 {\n    return self.vtable.alloc(self.ptr, len, ptr_align, ret_addr);\n}\n\n/// This function is not intended to be called except from within the\n/// implementation of an Allocator\npub inline fn rawResize(self: Allocator, buf: []u8, log2_buf_align: u8, new_len: usize, ret_addr: usize) bool {\n    return self.vtable.resize(self.ptr, buf, log2_buf_align, new_len, ret_addr);\n}\n\n/// This function is not intended to be called except from within the\n/// implementation of an Allocator\npub inline fn rawFree(self: Allocator, buf: []u8, log2_buf_align: u8, ret_addr: usize) void {\n    return self.vtable.free(self.ptr, buf, log2_buf_align, ret_addr);\n}\n\n/// Returns a pointer to undefined memory.\n/// Call `destroy` with the result to free the memory.\npub fn create(self: Allocator, comptime T: type) Error!*T {\n    if (@sizeOf(T) == 0) return @as(*T, @ptrFromInt(math.maxInt(usize)));\n    const ptr: *T = @ptrCast(try self.allocBytesWithAlignment(@alignOf(T), @sizeOf(T), @returnAddress()));\n    return ptr;\n}\n\n/// `ptr` should be the return value of `create`, or otherwise\n/// have the same address and alignment property.\npub fn destroy(self: Allocator, ptr: anytype) void {\n    const info = @typeInfo(@TypeOf(ptr)).Pointer;\n    if (info.size != .One) @compileError(\"ptr must be a single item pointer\");\n    const T = info.child;\n    if (@sizeOf(T) == 0) return;\n    const non_const_ptr = @as([*]u8, @ptrCast(@constCast(ptr)));\n    self.rawFree(non_const_ptr[0..@sizeOf(T)], log2a(info.alignment), @returnAddress());\n}\n\n/// Allocates an array of `n` items of type `T` and sets all the\n/// items to `undefined`. Depending on the Allocator\n/// implementation, it may be required to call `free` once the\n/// memory is no longer needed, to avoid a resource leak. If the\n/// `Allocator` implementation is unknown, then correct code will\n/// call `free` when done.\n///\n/// For allocating a single item, see `create`.\npub fn alloc(self: Allocator, comptime T: type, n: usize) Error![]T {\n    return self.allocAdvancedWithRetAddr(T, null, n, @returnAddress());\n}\n\npub fn allocWithOptions(\n    self: Allocator,\n    comptime Elem: type,\n    n: usize,\n    /// null means naturally aligned\n    comptime optional_alignment: ?u29,\n    comptime optional_sentinel: ?Elem,\n) Error!AllocWithOptionsPayload(Elem, optional_alignment, optional_sentinel) {\n    return self.allocWithOptionsRetAddr(Elem, n, optional_alignment, optional_sentinel, @returnAddress());\n}\n\npub fn allocWithOptionsRetAddr(\n    self: Allocator,\n    comptime Elem: type,\n    n: usize,\n    /// null means naturally aligned\n    comptime optional_alignment: ?u29,\n    comptime optional_sentinel: ?Elem,\n    return_address: usize,\n) Error!AllocWithOptionsPayload(Elem, optional_alignment, optional_sentinel) {\n    if (optional_sentinel) |sentinel| {\n        const ptr = try self.allocAdvancedWithRetAddr(Elem, optional_alignment, n + 1, return_address);\n        ptr[n] = sentinel;\n        return ptr[0..n :sentinel];\n    } else {\n        return self.allocAdvancedWithRetAddr(Elem, optional_alignment, n, return_address);\n    }\n}\n\nfn AllocWithOptionsPayload(comptime Elem: type, comptime alignment: ?u29, comptime sentinel: ?Elem) type {\n    if (sentinel) |s| {\n        return [:s]align(alignment orelse @alignOf(Elem)) Elem;\n    } else {\n        return []align(alignment orelse @alignOf(Elem)) Elem;\n    }\n}\n\n/// Allocates an array of `n + 1` items of type `T` and sets the first `n`\n/// items to `undefined` and the last item to `sentinel`. Depending on the\n/// Allocator implementation, it may be required to call `free` once the\n/// memory is no longer needed, to avoid a resource leak. If the\n/// `Allocator` implementation is unknown, then correct code will\n/// call `free` when done.\n///\n/// For allocating a single item, see `create`.\npub fn allocSentinel(\n    self: Allocator,\n    comptime Elem: type,\n    n: usize,\n    comptime sentinel: Elem,\n) Error![:sentinel]Elem {\n    return self.allocWithOptionsRetAddr(Elem, n, null, sentinel, @returnAddress());\n}\n\npub fn alignedAlloc(\n    self: Allocator,\n    comptime T: type,\n    /// null means naturally aligned\n    comptime alignment: ?u29,\n    n: usize,\n) Error![]align(alignment orelse @alignOf(T)) T {\n    return self.allocAdvancedWithRetAddr(T, alignment, n, @returnAddress());\n}\n\npub inline fn allocAdvancedWithRetAddr(\n    self: Allocator,\n    comptime T: type,\n    /// null means naturally aligned\n    comptime alignment: ?u29,\n    n: usize,\n    return_address: usize,\n) Error![]align(alignment orelse @alignOf(T)) T {\n    const a = alignment orelse @alignOf(T);\n    const ptr: [*]align(a) T = @ptrCast(try self.allocWithSizeAndAlignment(@sizeOf(T), a, n, return_address));\n    return ptr[0..n];\n}\n\nfn allocWithSizeAndAlignment(self: Allocator, comptime size: usize, comptime alignment: u29, n: usize, return_address: usize) Error![*]align(alignment) u8 {\n    const byte_count = math.mul(usize, size, n) catch return Error.OutOfMemory;\n    return self.allocBytesWithAlignment(alignment, byte_count, return_address);\n}\n\nfn allocBytesWithAlignment(self: Allocator, comptime alignment: u29, byte_count: usize, return_address: usize) Error![*]align(alignment) u8 {\n    // The Zig Allocator interface is not intended to solve alignments beyond\n    // the minimum OS page size. For these use cases, the caller must use OS\n    // APIs directly.\n    comptime assert(alignment <= mem.page_size);\n\n    if (byte_count == 0) {\n        const ptr = comptime std.mem.alignBackward(usize, math.maxInt(usize), alignment);\n        return @as([*]align(alignment) u8, @ptrFromInt(ptr));\n    }\n\n    const byte_ptr = self.rawAlloc(byte_count, log2a(alignment), return_address) orelse return Error.OutOfMemory;\n    // TODO: https://github.com/ziglang/zig/issues/4298\n    @memset(byte_ptr[0..byte_count], undefined);\n    return @as([*]align(alignment) u8, @alignCast(byte_ptr));\n}\n\n/// Requests to modify the size of an allocation. It is guaranteed to not move\n/// the pointer, however the allocator implementation may refuse the resize\n/// request by returning `false`.\npub fn resize(self: Allocator, old_mem: anytype, new_n: usize) bool {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    const T = Slice.child;\n    if (new_n == 0) {\n        self.free(old_mem);\n        return true;\n    }\n    if (old_mem.len == 0) {\n        return false;\n    }\n    const old_byte_slice = mem.sliceAsBytes(old_mem);\n    // I would like to use saturating multiplication here, but LLVM cannot lower it\n    // on WebAssembly: https://github.com/ziglang/zig/issues/9660\n    //const new_byte_count = new_n *| @sizeOf(T);\n    const new_byte_count = math.mul(usize, @sizeOf(T), new_n) catch return false;\n    return self.rawResize(old_byte_slice, log2a(Slice.alignment), new_byte_count, @returnAddress());\n}\n\n/// This function requests a new byte size for an existing allocation, which\n/// can be larger, smaller, or the same size as the old memory allocation.\n/// If `new_n` is 0, this is the same as `free` and it always succeeds.\npub fn realloc(self: Allocator, old_mem: anytype, new_n: usize) t: {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    break :t Error![]align(Slice.alignment) Slice.child;\n} {\n    return self.reallocAdvanced(old_mem, new_n, @returnAddress());\n}\n\npub fn reallocAdvanced(\n    self: Allocator,\n    old_mem: anytype,\n    new_n: usize,\n    return_address: usize,\n) t: {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    break :t Error![]align(Slice.alignment) Slice.child;\n} {\n    const Slice = @typeInfo(@TypeOf(old_mem)).Pointer;\n    const T = Slice.child;\n    if (old_mem.len == 0) {\n        return self.allocAdvancedWithRetAddr(T, Slice.alignment, new_n, return_address);\n    }\n    if (new_n == 0) {\n        self.free(old_mem);\n        const ptr = comptime std.mem.alignBackward(usize, math.maxInt(usize), Slice.alignment);\n        return @as([*]align(Slice.alignment) T, @ptrFromInt(ptr))[0..0];\n    }\n\n    const old_byte_slice = mem.sliceAsBytes(old_mem);\n    const byte_count = math.mul(usize, @sizeOf(T), new_n) catch return Error.OutOfMemory;\n    // Note: can't set shrunk memory to undefined as memory shouldn't be modified on realloc failure\n    if (mem.isAligned(@intFromPtr(old_byte_slice.ptr), Slice.alignment)) {\n        if (self.rawResize(old_byte_slice, log2a(Slice.alignment), byte_count, return_address)) {\n            const new_bytes: []align(Slice.alignment) u8 = @alignCast(old_byte_slice.ptr[0..byte_count]);\n            return mem.bytesAsSlice(T, new_bytes);\n        }\n    }\n\n    const new_mem = self.rawAlloc(byte_count, log2a(Slice.alignment), return_address) orelse\n        return error.OutOfMemory;\n    const copy_len = @min(byte_count, old_byte_slice.len);\n    @memcpy(new_mem[0..copy_len], old_byte_slice[0..copy_len]);\n    // TODO https://github.com/ziglang/zig/issues/4298\n    @memset(old_byte_slice, undefined);\n    self.rawFree(old_byte_slice, log2a(Slice.alignment), return_address);\n\n    const new_bytes: []align(Slice.alignment) u8 = @alignCast(new_mem[0..byte_count]);\n    return mem.bytesAsSlice(T, new_bytes);\n}\n\n/// Free an array allocated with `alloc`. To free a single item,\n/// see `destroy`.\npub fn free(self: Allocator, memory: anytype) void {\n    const Slice = @typeInfo(@TypeOf(memory)).Pointer;\n    const bytes = mem.sliceAsBytes(memory);\n    const bytes_len = bytes.len + if (Slice.sentinel != null) @sizeOf(Slice.child) else 0;\n    if (bytes_len == 0) return;\n    const non_const_ptr = @constCast(bytes.ptr);\n    // TODO: https://github.com/ziglang/zig/issues/4298\n    @memset(non_const_ptr[0..bytes_len], undefined);\n    self.rawFree(non_const_ptr[0..bytes_len], log2a(Slice.alignment), @returnAddress());\n}\n\n/// Copies `m` to newly allocated memory. Caller owns the memory.\npub fn dupe(allocator: Allocator, comptime T: type, m: []const T) Error![]T {\n    const new_buf = try allocator.alloc(T, m.len);\n    @memcpy(new_buf, m);\n    return new_buf;\n}\n\n/// Copies `m` to newly allocated memory, with a null-terminated element. Caller owns the memory.\npub fn dupeZ(allocator: Allocator, comptime T: type, m: []const T) Error![:0]T {\n    const new_buf = try allocator.alloc(T, m.len + 1);\n    @memcpy(new_buf[0..m.len], m);\n    new_buf[m.len] = 0;\n    return new_buf[0..m.len :0];\n}\n\n/// TODO replace callsites with `@log2` after this proposal is implemented:\n/// https://github.com/ziglang/zig/issues/13642\ninline fn log2a(x: anytype) switch (@typeInfo(@TypeOf(x))) {\n    .Int => math.Log2Int(@TypeOf(x)),\n    .ComptimeInt => comptime_int,\n    else => @compileError(\"int please\"),\n} {\n    switch (@typeInfo(@TypeOf(x))) {\n        .Int => return math.log2_int(@TypeOf(x), x),\n        .ComptimeInt => return math.log2(x),\n        else => @compileError(\"bad\"),\n    }\n}\n",
    "//! Types and values provided by the Zig language.\n\nconst builtin = @import(\"builtin\");\n\n/// `explicit_subsystem` is missing when the subsystem is automatically detected,\n/// so Zig standard library has the subsystem detection logic here. This should generally be\n/// used rather than `explicit_subsystem`.\n/// On non-Windows targets, this is `null`.\npub const subsystem: ?std.Target.SubSystem = blk: {\n    if (@hasDecl(builtin, \"explicit_subsystem\")) break :blk builtin.explicit_subsystem;\n    switch (builtin.os.tag) {\n        .windows => {\n            if (builtin.is_test) {\n                break :blk std.Target.SubSystem.Console;\n            }\n            if (@hasDecl(root, \"main\") or\n                @hasDecl(root, \"WinMain\") or\n                @hasDecl(root, \"wWinMain\") or\n                @hasDecl(root, \"WinMainCRTStartup\") or\n                @hasDecl(root, \"wWinMainCRTStartup\"))\n            {\n                break :blk std.Target.SubSystem.Windows;\n            } else {\n                break :blk std.Target.SubSystem.Console;\n            }\n        },\n        else => break :blk null,\n    }\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const StackTrace = struct {\n    index: usize,\n    instruction_addresses: []usize,\n\n    pub fn format(\n        self: StackTrace,\n        comptime fmt: []const u8,\n        options: std.fmt.FormatOptions,\n        writer: anytype,\n    ) !void {\n        if (fmt.len != 0) std.fmt.invalidFmtError(fmt, self);\n\n        // TODO: re-evaluate whether to use format() methods at all.\n        // Until then, avoid an error when using GeneralPurposeAllocator with WebAssembly\n        // where it tries to call detectTTYConfig here.\n        if (builtin.os.tag == .freestanding) return;\n\n        _ = options;\n        var arena = std.heap.ArenaAllocator.init(std.heap.page_allocator);\n        defer arena.deinit();\n        const debug_info = std.debug.getSelfDebugInfo() catch |err| {\n            return writer.print(\"\\nUnable to print stack trace: Unable to open debug info: {s}\\n\", .{@errorName(err)});\n        };\n        const tty_config = std.io.tty.detectConfig(std.io.getStdErr());\n        try writer.writeAll(\"\\n\");\n        std.debug.writeStackTrace(self, writer, arena.allocator(), debug_info, tty_config) catch |err| {\n            try writer.print(\"Unable to print stack trace: {s}\\n\", .{@errorName(err)});\n        };\n    }\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const GlobalLinkage = enum {\n    internal,\n    strong,\n    weak,\n    link_once,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const SymbolVisibility = enum {\n    default,\n    hidden,\n    protected,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const AtomicOrder = enum {\n    unordered,\n    monotonic,\n    acquire,\n    release,\n    acq_rel,\n    seq_cst,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const ReduceOp = enum {\n    And,\n    Or,\n    Xor,\n    Min,\n    Max,\n    Add,\n    Mul,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const AtomicRmwOp = enum {\n    /// Exchange - store the operand unmodified.\n    /// Supports enums, integers, and floats.\n    Xchg,\n    /// Add operand to existing value.\n    /// Supports integers and floats.\n    /// For integers, two's complement wraparound applies.\n    Add,\n    /// Subtract operand from existing value.\n    /// Supports integers and floats.\n    /// For integers, two's complement wraparound applies.\n    Sub,\n    /// Perform bitwise AND on existing value with operand.\n    /// Supports integers.\n    And,\n    /// Perform bitwise NAND on existing value with operand.\n    /// Supports integers.\n    Nand,\n    /// Perform bitwise OR on existing value with operand.\n    /// Supports integers.\n    Or,\n    /// Perform bitwise XOR on existing value with operand.\n    /// Supports integers.\n    Xor,\n    /// Store operand if it is larger than the existing value.\n    /// Supports integers and floats.\n    Max,\n    /// Store operand if it is smaller than the existing value.\n    /// Supports integers and floats.\n    Min,\n};\n\n/// The code model puts constraints on the location of symbols and the size of code and data.\n/// The selection of a code model is a trade off on speed and restrictions that needs to be selected on a per application basis to meet its requirements.\n/// A slightly more detailed explanation can be found in (for example) the [System V Application Binary Interface (x86_64)](https://github.com/hjl-tools/x86-psABI/wiki/x86-64-psABI-1.0.pdf) 3.5.1.\n///\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const CodeModel = enum {\n    default,\n    tiny,\n    small,\n    kernel,\n    medium,\n    large,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const OptimizeMode = enum {\n    Debug,\n    ReleaseSafe,\n    ReleaseFast,\n    ReleaseSmall,\n};\n\n/// Deprecated; use OptimizeMode.\npub const Mode = OptimizeMode;\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const CallingConvention = enum(u8) {\n    /// This is the default Zig calling convention used when not using `export` on `fn`\n    /// and no other calling convention is specified.\n    Unspecified,\n    /// Matches the C ABI for the target.\n    /// This is the default calling convention when using `export` on `fn`\n    /// and no other calling convention is specified.\n    C,\n    /// This makes a function not have any function prologue or epilogue,\n    /// making the function itself uncallable in regular Zig code.\n    /// This can be useful when integrating with assembly.\n    Naked,\n    /// Functions with this calling convention are called asynchronously,\n    /// as if called as `async function()`.\n    Async,\n    /// Functions with this calling convention are inlined at all call sites.\n    Inline,\n    /// x86-only.\n    Interrupt,\n    Signal,\n    /// x86-only.\n    Stdcall,\n    /// x86-only.\n    Fastcall,\n    /// x86-only.\n    Vectorcall,\n    /// x86-only.\n    Thiscall,\n    /// ARM Procedure Call Standard (obsolete)\n    /// ARM-only.\n    APCS,\n    /// ARM Architecture Procedure Call Standard (current standard)\n    /// ARM-only.\n    AAPCS,\n    /// ARM Architecture Procedure Call Standard Vector Floating-Point\n    /// ARM-only.\n    AAPCSVFP,\n    /// x86-64-only.\n    SysV,\n    /// x86-64-only.\n    Win64,\n    /// AMD GPU, NVPTX, or SPIR-V kernel\n    Kernel,\n    // Vulkan-only\n    Fragment,\n    Vertex,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const AddressSpace = enum(u5) {\n    // CPU address spaces.\n    generic,\n    gs,\n    fs,\n    ss,\n\n    // GPU address spaces.\n    global,\n    constant,\n    param,\n    shared,\n    local,\n    input,\n    output,\n    uniform,\n\n    // AVR address spaces.\n    flash,\n    flash1,\n    flash2,\n    flash3,\n    flash4,\n    flash5,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const SourceLocation = struct {\n    file: [:0]const u8,\n    fn_name: [:0]const u8,\n    line: u32,\n    column: u32,\n};\n\npub const TypeId = std.meta.Tag(Type);\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const Type = union(enum) {\n    Type: void,\n    Void: void,\n    Bool: void,\n    NoReturn: void,\n    Int: Int,\n    Float: Float,\n    Pointer: Pointer,\n    Array: Array,\n    Struct: Struct,\n    ComptimeFloat: void,\n    ComptimeInt: void,\n    Undefined: void,\n    Null: void,\n    Optional: Optional,\n    ErrorUnion: ErrorUnion,\n    ErrorSet: ErrorSet,\n    Enum: Enum,\n    Union: Union,\n    Fn: Fn,\n    Opaque: Opaque,\n    Frame: Frame,\n    AnyFrame: AnyFrame,\n    Vector: Vector,\n    EnumLiteral: void,\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Int = struct {\n        signedness: Signedness,\n        bits: u16,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Float = struct {\n        bits: u16,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Pointer = struct {\n        size: Size,\n        is_const: bool,\n        is_volatile: bool,\n        /// TODO make this u16 instead of comptime_int\n        alignment: comptime_int,\n        address_space: AddressSpace,\n        child: type,\n        is_allowzero: bool,\n\n        /// The type of the sentinel is the element type of the pointer, which is\n        /// the value of the `child` field in this struct. However there is no way\n        /// to refer to that type here, so we use pointer to `anyopaque`.\n        sentinel: ?*const anyopaque,\n\n        /// This data structure is used by the Zig language code generation and\n        /// therefore must be kept in sync with the compiler implementation.\n        pub const Size = enum(u2) {\n            One,\n            Many,\n            Slice,\n            C,\n        };\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Array = struct {\n        len: comptime_int,\n        child: type,\n\n        /// The type of the sentinel is the element type of the array, which is\n        /// the value of the `child` field in this struct. However there is no way\n        /// to refer to that type here, so we use pointer to `anyopaque`.\n        sentinel: ?*const anyopaque,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const ContainerLayout = enum(u2) {\n        auto,\n        @\"extern\",\n        @\"packed\",\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const StructField = struct {\n        name: [:0]const u8,\n        type: type,\n        default_value: ?*const anyopaque,\n        is_comptime: bool,\n        alignment: comptime_int,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Struct = struct {\n        layout: ContainerLayout,\n        /// Only valid if layout is .@\"packed\"\n        backing_integer: ?type = null,\n        fields: []const StructField,\n        decls: []const Declaration,\n        is_tuple: bool,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Optional = struct {\n        child: type,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const ErrorUnion = struct {\n        error_set: type,\n        payload: type,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Error = struct {\n        name: [:0]const u8,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const ErrorSet = ?[]const Error;\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const EnumField = struct {\n        name: [:0]const u8,\n        value: comptime_int,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Enum = struct {\n        tag_type: type,\n        fields: []const EnumField,\n        decls: []const Declaration,\n        is_exhaustive: bool,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const UnionField = struct {\n        name: [:0]const u8,\n        type: type,\n        alignment: comptime_int,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Union = struct {\n        layout: ContainerLayout,\n        tag_type: ?type,\n        fields: []const UnionField,\n        decls: []const Declaration,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Fn = struct {\n        calling_convention: CallingConvention,\n        is_generic: bool,\n        is_var_args: bool,\n        /// TODO change the language spec to make this not optional.\n        return_type: ?type,\n        params: []const Param,\n\n        /// This data structure is used by the Zig language code generation and\n        /// therefore must be kept in sync with the compiler implementation.\n        pub const Param = struct {\n            is_generic: bool,\n            is_noalias: bool,\n            type: ?type,\n        };\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Opaque = struct {\n        decls: []const Declaration,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Frame = struct {\n        function: *const anyopaque,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const AnyFrame = struct {\n        child: ?type,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Vector = struct {\n        len: comptime_int,\n        child: type,\n    };\n\n    /// This data structure is used by the Zig language code generation and\n    /// therefore must be kept in sync with the compiler implementation.\n    pub const Declaration = struct {\n        name: [:0]const u8,\n    };\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const FloatMode = enum {\n    strict,\n    optimized,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const Endian = enum {\n    big,\n    little,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const Signedness = enum {\n    signed,\n    unsigned,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const OutputMode = enum {\n    Exe,\n    Lib,\n    Obj,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const LinkMode = enum {\n    static,\n    dynamic,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const WasiExecModel = enum {\n    command,\n    reactor,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const CallModifier = enum {\n    /// Equivalent to function call syntax.\n    auto,\n\n    /// Equivalent to async keyword used with function call syntax.\n    async_kw,\n\n    /// Prevents tail call optimization. This guarantees that the return\n    /// address will point to the callsite, as opposed to the callsite's\n    /// callsite. If the call is otherwise required to be tail-called\n    /// or inlined, a compile error is emitted instead.\n    never_tail,\n\n    /// Guarantees that the call will not be inlined. If the call is\n    /// otherwise required to be inlined, a compile error is emitted instead.\n    never_inline,\n\n    /// Asserts that the function call will not suspend. This allows a\n    /// non-async function to call an async function.\n    no_async,\n\n    /// Guarantees that the call will be generated with tail call optimization.\n    /// If this is not possible, a compile error is emitted instead.\n    always_tail,\n\n    /// Guarantees that the call will be inlined at the callsite.\n    /// If this is not possible, a compile error is emitted instead.\n    always_inline,\n\n    /// Evaluates the call at compile-time. If the call cannot be completed at\n    /// compile-time, a compile error is emitted instead.\n    compile_time,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const VaListAarch64 = extern struct {\n    __stack: *anyopaque,\n    __gr_top: *anyopaque,\n    __vr_top: *anyopaque,\n    __gr_offs: c_int,\n    __vr_offs: c_int,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const VaListHexagon = extern struct {\n    __gpr: c_long,\n    __fpr: c_long,\n    __overflow_arg_area: *anyopaque,\n    __reg_save_area: *anyopaque,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const VaListPowerPc = extern struct {\n    gpr: u8,\n    fpr: u8,\n    reserved: c_ushort,\n    overflow_arg_area: *anyopaque,\n    reg_save_area: *anyopaque,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const VaListS390x = extern struct {\n    __current_saved_reg_area_pointer: *anyopaque,\n    __saved_reg_area_end_pointer: *anyopaque,\n    __overflow_area_pointer: *anyopaque,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const VaListX86_64 = extern struct {\n    gp_offset: c_uint,\n    fp_offset: c_uint,\n    overflow_arg_area: *anyopaque,\n    reg_save_area: *anyopaque,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const VaList = switch (builtin.cpu.arch) {\n    .aarch64, .aarch64_be => switch (builtin.os.tag) {\n        .windows => *u8,\n        .ios, .macos, .tvos, .watchos, .visionos => *u8,\n        else => @compileError(\"disabled due to miscompilations\"), // VaListAarch64,\n    },\n    .arm => switch (builtin.os.tag) {\n        .ios, .macos, .tvos, .watchos, .visionos => *u8,\n        else => *anyopaque,\n    },\n    .amdgcn => *u8,\n    .avr => *anyopaque,\n    .bpfel, .bpfeb => *anyopaque,\n    .hexagon => if (builtin.target.isMusl()) VaListHexagon else *u8,\n    .mips, .mipsel, .mips64, .mips64el => *anyopaque,\n    .riscv32, .riscv64 => *anyopaque,\n    .powerpc, .powerpcle => switch (builtin.os.tag) {\n        .ios, .macos, .tvos, .watchos, .visionos, .aix => *u8,\n        else => VaListPowerPc,\n    },\n    .powerpc64, .powerpc64le => *u8,\n    .sparc, .sparcel, .sparc64 => *anyopaque,\n    .spirv32, .spirv64 => *anyopaque,\n    .s390x => VaListS390x,\n    .wasm32, .wasm64 => *anyopaque,\n    .x86 => *u8,\n    .x86_64 => switch (builtin.os.tag) {\n        .windows => @compileError(\"disabled due to miscompilations\"), // *u8,\n        else => VaListX86_64,\n    },\n    else => @compileError(\"VaList not supported for this target yet\"),\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const PrefetchOptions = struct {\n    /// Whether the prefetch should prepare for a read or a write.\n    rw: Rw = .read,\n    /// The data's locality in an inclusive range from 0 to 3.\n    ///\n    /// 0 means no temporal locality. That is, the data can be immediately\n    /// dropped from the cache after it is accessed.\n    ///\n    /// 3 means high temporal locality. That is, the data should be kept in\n    /// the cache as it is likely to be accessed again soon.\n    locality: u2 = 3,\n    /// The cache that the prefetch should be performed on.\n    cache: Cache = .data,\n\n    pub const Rw = enum(u1) {\n        read,\n        write,\n    };\n\n    pub const Cache = enum(u1) {\n        instruction,\n        data,\n    };\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const ExportOptions = struct {\n    name: []const u8,\n    linkage: GlobalLinkage = .strong,\n    section: ?[]const u8 = null,\n    visibility: SymbolVisibility = .default,\n};\n\n/// This data structure is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const ExternOptions = struct {\n    name: []const u8,\n    library_name: ?[]const u8 = null,\n    linkage: GlobalLinkage = .strong,\n    is_thread_local: bool = false,\n};\n\n/// This enum is set by the compiler and communicates which compiler backend is\n/// used to produce machine code.\n/// Think carefully before deciding to observe this value. Nearly all code should\n/// be agnostic to the backend that implements the language. The use case\n/// to use this value is to **work around problems with compiler implementations.**\n///\n/// Avoid failing the compilation if the compiler backend does not match a\n/// whitelist of backends; rather one should detect that a known problem would\n/// occur in a blacklist of backends.\n///\n/// The enum is nonexhaustive so that alternate Zig language implementations may\n/// choose a number as their tag (please use a random number generator rather\n/// than a \"cute\" number) and codebases can interact with these values even if\n/// this upstream enum does not have a name for the number. Of course, upstream\n/// is happy to accept pull requests to add Zig implementations to this enum.\n///\n/// This data structure is part of the Zig language specification.\npub const CompilerBackend = enum(u64) {\n    /// It is allowed for a compiler implementation to not reveal its identity,\n    /// in which case this value is appropriate. Be cool and make sure your\n    /// code supports `other` Zig compilers!\n    other = 0,\n    /// The original Zig compiler created in 2015 by Andrew Kelley. Implemented\n    /// in C++. Used LLVM. Deleted from the ZSF ziglang/zig codebase on\n    /// December 6th, 2022.\n    stage1 = 1,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// LLVM backend.\n    stage2_llvm = 2,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// backend that generates C source code.\n    /// Note that one can observe whether the compilation will output C code\n    /// directly with `object_format` value rather than the `compiler_backend` value.\n    stage2_c = 3,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// WebAssembly backend.\n    stage2_wasm = 4,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// arm backend.\n    stage2_arm = 5,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// x86_64 backend.\n    stage2_x86_64 = 6,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// aarch64 backend.\n    stage2_aarch64 = 7,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// x86 backend.\n    stage2_x86 = 8,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// riscv64 backend.\n    stage2_riscv64 = 9,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// sparc64 backend.\n    stage2_sparc64 = 10,\n    /// The reference implementation self-hosted compiler of Zig, using the\n    /// spirv backend.\n    stage2_spirv64 = 11,\n\n    _,\n};\n\n/// This function type is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const TestFn = struct {\n    name: []const u8,\n    func: *const fn () anyerror!void,\n};\n\n/// This function type is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const PanicFn = fn ([]const u8, ?*StackTrace, ?usize) noreturn;\n\n/// This function is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub const panic: PanicFn = if (@hasDecl(root, \"panic\"))\n    root.panic\nelse if (@hasDecl(root, \"os\") and @hasDecl(root.os, \"panic\"))\n    root.os.panic\nelse\n    default_panic;\n\n/// This function is used by the Zig language code generation and\n/// therefore must be kept in sync with the compiler implementation.\npub fn default_panic(msg: []const u8, error_return_trace: ?*StackTrace, ret_addr: ?usize) noreturn {\n    @setCold(true);\n\n    // For backends that cannot handle the language features depended on by the\n    // default panic handler, we have a simpler panic handler:\n    if (builtin.zig_backend == .stage2_wasm or\n        builtin.zig_backend == .stage2_arm or\n        builtin.zig_backend == .stage2_aarch64 or\n        builtin.zig_backend == .stage2_x86 or\n        (builtin.zig_backend == .stage2_x86_64 and (builtin.target.ofmt != .elf and builtin.target.ofmt != .macho)) or\n        builtin.zig_backend == .stage2_sparc64 or\n        builtin.zig_backend == .stage2_spirv64)\n    {\n        while (true) {\n            @breakpoint();\n        }\n    }\n\n    if (builtin.zig_backend == .stage2_riscv64) {\n        asm volatile (\"ecall\"\n            :\n            : [number] \"{a7}\" (64),\n              [arg1] \"{a0}\" (1),\n              [arg2] \"{a1}\" (@intFromPtr(msg.ptr)),\n              [arg3] \"{a2}\" (msg.len),\n            : \"memory\"\n        );\n        std.posix.exit(127);\n    }\n\n    switch (builtin.os.tag) {\n        .freestanding => {\n            while (true) {\n                @breakpoint();\n            }\n        },\n        .wasi => {\n            std.debug.print(\"{s}\", .{msg});\n            std.posix.abort();\n        },\n        .uefi => {\n            const uefi = std.os.uefi;\n\n            const ExitData = struct {\n                pub fn create_exit_data(exit_msg: []const u8, exit_size: *usize) ![*:0]u16 {\n                    // Need boot services for pool allocation\n                    if (uefi.system_table.boot_services == null) {\n                        return error.BootServicesUnavailable;\n                    }\n\n                    // ExitData buffer must be allocated using boot_services.allocatePool\n                    var utf16: []u16 = try uefi.raw_pool_allocator.alloc(u16, 256);\n                    errdefer uefi.raw_pool_allocator.free(utf16);\n\n                    if (exit_msg.len > 255) {\n                        return error.MessageTooLong;\n                    }\n\n                    var fmt: [256]u8 = undefined;\n                    const slice = try std.fmt.bufPrint(&fmt, \"\\r\\nerr: {s}\\r\\n\", .{exit_msg});\n                    const len = try std.unicode.utf8ToUtf16Le(utf16, slice);\n\n                    utf16[len] = 0;\n\n                    exit_size.* = 256;\n\n                    return @as([*:0]u16, @ptrCast(utf16.ptr));\n                }\n            };\n\n            var exit_size: usize = 0;\n            const exit_data = ExitData.create_exit_data(msg, &exit_size) catch null;\n\n            if (exit_data) |data| {\n                if (uefi.system_table.std_err) |out| {\n                    _ = out.setAttribute(uefi.protocol.SimpleTextOutput.red);\n                    _ = out.outputString(data);\n                    _ = out.setAttribute(uefi.protocol.SimpleTextOutput.white);\n                }\n            }\n\n            if (uefi.system_table.boot_services) |bs| {\n                _ = bs.exit(uefi.handle, .Aborted, exit_size, exit_data);\n            }\n\n            // Didn't have boot_services, just fallback to whatever.\n            std.posix.abort();\n        },\n        .cuda, .amdhsa => std.posix.abort(),\n        .plan9 => {\n            var status: [std.os.plan9.ERRMAX]u8 = undefined;\n            const len = @min(msg.len, status.len - 1);\n            @memcpy(status[0..len], msg[0..len]);\n            status[len] = 0;\n            std.os.plan9.exits(status[0..len :0]);\n        },\n        else => {\n            const first_trace_addr = ret_addr orelse @returnAddress();\n            std.debug.panicImpl(error_return_trace, first_trace_addr, msg);\n        },\n    }\n}\n\npub fn checkNonScalarSentinel(expected: anytype, actual: @TypeOf(expected)) void {\n    if (!std.meta.eql(expected, actual)) {\n        panicSentinelMismatch(expected, actual);\n    }\n}\n\npub fn panicSentinelMismatch(expected: anytype, actual: @TypeOf(expected)) noreturn {\n    @setCold(true);\n    std.debug.panicExtra(null, @returnAddress(), \"sentinel mismatch: expected {any}, found {any}\", .{ expected, actual });\n}\n\npub fn panicUnwrapError(st: ?*StackTrace, err: anyerror) noreturn {\n    @setCold(true);\n    std.debug.panicExtra(st, @returnAddress(), \"attempt to unwrap error: {s}\", .{@errorName(err)});\n}\n\npub fn panicOutOfBounds(index: usize, len: usize) noreturn {\n    @setCold(true);\n    std.debug.panicExtra(null, @returnAddress(), \"index out of bounds: index {d}, len {d}\", .{ index, len });\n}\n\npub fn panicStartGreaterThanEnd(start: usize, end: usize) noreturn {\n    @setCold(true);\n    std.debug.panicExtra(null, @returnAddress(), \"start index {d} is larger than end index {d}\", .{ start, end });\n}\n\npub fn panicInactiveUnionField(active: anytype, wanted: @TypeOf(active)) noreturn {\n    @setCold(true);\n    std.debug.panicExtra(null, @returnAddress(), \"access of union field '{s}' while field '{s}' is active\", .{ @tagName(wanted), @tagName(active) });\n}\n\npub const panic_messages = struct {\n    pub const unreach = \"reached unreachable code\";\n    pub const unwrap_null = \"attempt to use null value\";\n    pub const cast_to_null = \"cast causes pointer to be null\";\n    pub const incorrect_alignment = \"incorrect alignment\";\n    pub const invalid_error_code = \"invalid error code\";\n    pub const cast_truncated_data = \"integer cast truncated bits\";\n    pub const negative_to_unsigned = \"attempt to cast negative value to unsigned integer\";\n    pub const integer_overflow = \"integer overflow\";\n    pub const shl_overflow = \"left shift overflowed bits\";\n    pub const shr_overflow = \"right shift overflowed bits\";\n    pub const divide_by_zero = \"division by zero\";\n    pub const exact_division_remainder = \"exact division produced remainder\";\n    pub const inactive_union_field = \"access of inactive union field\";\n    pub const integer_part_out_of_bounds = \"integer part of floating point value out of bounds\";\n    pub const corrupt_switch = \"switch on corrupt value\";\n    pub const shift_rhs_too_big = \"shift amount is greater than the type size\";\n    pub const invalid_enum_value = \"invalid enum value\";\n    pub const sentinel_mismatch = \"sentinel mismatch\";\n    pub const unwrap_error = \"attempt to unwrap error\";\n    pub const index_out_of_bounds = \"index out of bounds\";\n    pub const start_index_greater_than_end = \"start index is larger than end index\";\n    pub const for_len_mismatch = \"for loop over objects with non-equal lengths\";\n    pub const memcpy_len_mismatch = \"@memcpy arguments have non-equal lengths\";\n    pub const memcpy_alias = \"@memcpy arguments alias\";\n    pub const noreturn_returned = \"'noreturn' function returned\";\n};\n\npub noinline fn returnError(st: *StackTrace) void {\n    @setCold(true);\n    @setRuntimeSafety(false);\n    addErrRetTraceAddr(st, @returnAddress());\n}\n\npub inline fn addErrRetTraceAddr(st: *StackTrace, addr: usize) void {\n    if (st.index < st.instruction_addresses.len)\n        st.instruction_addresses[st.index] = addr;\n\n    st.index += 1;\n}\n\nconst std = @import(\"std.zig\");\nconst root = @import(\"root\");\n",
    "const std = @import(\"std\");\n\nconst Self = @This();\n// const GlobalContext = @import(\"./GlobalContext.zig\");\n\nconst ThreadInstance = struct {\n    memory: []u8,\n    wrapper_ptr: usize,\n    entry: *const fn (usize) void,\n    original_stack_ptr: [*]u8,\n    stack_offset: usize,\n    allocator: std.mem.Allocator,\n};\n\nconst ThreadConfig = struct {\n    stack_size: usize = 1024 * 1024, // 1MB\n    allocator: std.mem.Allocator,\n};\n\npub const StartThreadError = error{\n    OutOfMemory,\n};\n\npub fn spawn(\n    config: ThreadConfig,\n    comptime start: anytype,\n    args: anytype,\n) StartThreadError!void {\n    comptime {\n        const arg_ti = @typeInfo(@TypeOf(args));\n        switch (arg_ti) {\n            .Struct => {},\n            else => @compileError(\"Unsupported argument type for thread start function\"),\n        }\n    }\n\n    // const g = GlobalContext.current();\n\n    const Wrapper = struct {\n        args: @TypeOf(args),\n        fn entry(ptr: usize) void {\n            const w: *@This() = @ptrFromInt(ptr);\n            switch (@typeInfo(@typeInfo(@TypeOf(start)).Fn.return_type.?)) {\n                .NoReturn, .Void => {\n                    @call(.auto, start, w.args);\n                },\n                else => {\n                    @compileError(\"Unsupported return type for thread start function\");\n                },\n            }\n        }\n    };\n\n    var stack_offset: usize = 0;\n    var wrapper_offset: usize = 0;\n    var instance_offset: usize = 0;\n\n    const map_bytes = blk: {\n        var bytes: usize = std.mem.page_size;\n\n        bytes = std.mem.alignForward(usize, bytes, 16);\n        bytes += @max(std.mem.page_size, config.stack_size);\n        stack_offset = bytes;\n\n        bytes = std.mem.alignForward(usize, bytes, @alignOf(Wrapper));\n        wrapper_offset = bytes;\n        bytes += @sizeOf(Wrapper);\n\n        bytes = std.mem.alignForward(usize, bytes, @alignOf(ThreadInstance));\n        instance_offset = bytes;\n        bytes += @sizeOf(ThreadInstance);\n\n        bytes = std.mem.alignForward(usize, bytes, std.mem.page_size);\n\n        break :blk bytes;\n    };\n\n    const allocator = config.allocator;\n\n    const allocated_memory = try allocator.alloc(u8, map_bytes);\n\n    const wrapper: *Wrapper = @ptrCast(@alignCast(&allocated_memory[wrapper_offset]));\n    wrapper.* = .{\n        .args = args,\n    };\n\n    const instance: *ThreadInstance = @ptrCast(@alignCast(&allocated_memory[instance_offset]));\n    instance.* = .{\n        .allocator = config.allocator,\n        .memory = allocated_memory,\n        .wrapper_ptr = @intFromPtr(wrapper),\n        .entry = &Wrapper.entry,\n        .original_stack_ptr = __get_stack_pointer(),\n        .stack_offset = stack_offset,\n    };\n\n    startWorker.*(instance);\n}\n\nconst lib_name = \"web_worker\";\n\nfn extern_fn(comptime T: type, comptime name: []const u8) T {\n    return @extern(T, .{\n        .library_name = lib_name,\n        .name = name,\n    });\n}\n\nconst startWorker = extern_fn(\n    *const fn (*ThreadInstance) callconv(.C) void,\n    \"start\",\n);\n\nexport fn __wasm_threadStart(instance: *ThreadInstance) void {\n    __set_stack_pointer(instance.memory.ptr + instance.stack_offset);\n    instance.entry(instance.wrapper_ptr);\n    __set_stack_pointer(instance.original_stack_ptr);\n    const alloc = instance.allocator;\n    alloc.free(instance.memory);\n}\n\n/// Initializes the TLS data segment starting at `memory`.\n/// This is a synthetic function, generated by the linker.\n// extern fn __wasm_init_tls(memory: [*]u8) void;\n\n/// Returns a pointer to the base of the TLS data segment for the current thread\ninline fn __tls_base() [*]u8 {\n    return asm (\n        \\\\ .globaltype __tls_base, i32\n        \\\\ global.get __tls_base\n        \\\\ local.set %[ret]\n        : [ret] \"=r\" (-> [*]u8),\n    );\n}\n\n/// Returns the size of the TLS segment\ninline fn __tls_size() u32 {\n    return asm volatile (\n        \\\\ .globaltype __tls_size, i32, immutable\n        \\\\ global.get __tls_size\n        \\\\ local.set %[ret]\n        : [ret] \"=r\" (-> u32),\n    );\n}\n\n/// Returns the alignment of the TLS segment\ninline fn __tls_align() u32 {\n    return asm (\n        \\\\ .globaltype __tls_align, i32, immutable\n        \\\\ global.get __tls_align\n        \\\\ local.set %[ret]\n        : [ret] \"=r\" (-> u32),\n    );\n}\n\n/// Allows for setting the stack pointer in the WebAssembly module.\ninline fn __set_stack_pointer(addr: [*]u8) void {\n    asm volatile (\n        \\\\ local.get %[ptr]\n        \\\\ global.set __stack_pointer\n        :\n        : [ptr] \"r\" (addr),\n    );\n}\n\n/// Returns the current value of the stack pointer\ninline fn __get_stack_pointer() [*]u8 {\n    return asm (\n        \\\\ global.get __stack_pointer\n        \\\\ local.set %[stack_ptr]\n        : [stack_ptr] \"=r\" (-> [*]u8),\n    );\n}\n",
    "const std = @import(\"std.zig\");\nconst builtin = @import(\"builtin\");\nconst math = std.math;\nconst mem = std.mem;\nconst io = std.io;\nconst posix = std.posix;\nconst fs = std.fs;\nconst testing = std.testing;\nconst elf = std.elf;\nconst DW = std.dwarf;\nconst macho = std.macho;\nconst coff = std.coff;\nconst pdb = std.pdb;\nconst root = @import(\"root\");\nconst File = std.fs.File;\nconst windows = std.os.windows;\nconst native_arch = builtin.cpu.arch;\nconst native_os = builtin.os.tag;\nconst native_endian = native_arch.endian();\n\npub const runtime_safety = switch (builtin.mode) {\n    .Debug, .ReleaseSafe => true,\n    .ReleaseFast, .ReleaseSmall => false,\n};\n\npub const sys_can_stack_trace = switch (builtin.cpu.arch) {\n    // Observed to go into an infinite loop.\n    // TODO: Make this work.\n    .mips,\n    .mipsel,\n    => false,\n\n    // `@returnAddress()` in LLVM 10 gives\n    // \"Non-Emscripten WebAssembly hasn't implemented __builtin_return_address\".\n    .wasm32,\n    .wasm64,\n    => native_os == .emscripten,\n\n    // `@returnAddress()` is unsupported in LLVM 13.\n    .bpfel,\n    .bpfeb,\n    => false,\n\n    else => true,\n};\n\npub const LineInfo = struct {\n    line: u64,\n    column: u64,\n    file_name: []const u8,\n\n    pub fn deinit(self: LineInfo, allocator: mem.Allocator) void {\n        allocator.free(self.file_name);\n    }\n};\n\npub const SymbolInfo = struct {\n    symbol_name: []const u8 = \"???\",\n    compile_unit_name: []const u8 = \"???\",\n    line_info: ?LineInfo = null,\n\n    pub fn deinit(self: SymbolInfo, allocator: mem.Allocator) void {\n        if (self.line_info) |li| {\n            li.deinit(allocator);\n        }\n    }\n};\nconst PdbOrDwarf = union(enum) {\n    pdb: pdb.Pdb,\n    dwarf: DW.DwarfInfo,\n\n    fn deinit(self: *PdbOrDwarf, allocator: mem.Allocator) void {\n        switch (self.*) {\n            .pdb => |*inner| inner.deinit(),\n            .dwarf => |*inner| inner.deinit(allocator),\n        }\n    }\n};\n\n/// Allows the caller to freely write to stderr until `unlockStdErr` is called.\n///\n/// During the lock, any `std.Progress` information is cleared from the terminal.\npub fn lockStdErr() void {\n    std.Progress.lockStdErr();\n}\n\npub fn unlockStdErr() void {\n    std.Progress.unlockStdErr();\n}\n\n/// Print to stderr, unbuffered, and silently returning on failure. Intended\n/// for use in \"printf debugging.\" Use `std.log` functions for proper logging.\npub fn print(comptime fmt: []const u8, args: anytype) void {\n    lockStdErr();\n    defer unlockStdErr();\n    const stderr = io.getStdErr().writer();\n    nosuspend stderr.print(fmt, args) catch return;\n}\n\npub fn getStderrMutex() *std.Thread.Mutex {\n    @compileError(\"deprecated. call std.debug.lockStdErr() and std.debug.unlockStdErr() instead which will integrate properly with std.Progress\");\n}\n\n/// TODO multithreaded awareness\nvar self_debug_info: ?DebugInfo = null;\n\npub fn getSelfDebugInfo() !*DebugInfo {\n    if (self_debug_info) |*info| {\n        return info;\n    } else {\n        self_debug_info = try openSelfDebugInfo(getDebugInfoAllocator());\n        return &self_debug_info.?;\n    }\n}\n\n/// Tries to print a hexadecimal view of the bytes, unbuffered, and ignores any error returned.\n/// Obtains the stderr mutex while dumping.\npub fn dump_hex(bytes: []const u8) void {\n    lockStdErr();\n    defer unlockStdErr();\n    dump_hex_fallible(bytes) catch {};\n}\n\n/// Prints a hexadecimal view of the bytes, unbuffered, returning any error that occurs.\npub fn dump_hex_fallible(bytes: []const u8) !void {\n    const stderr = std.io.getStdErr();\n    const ttyconf = std.io.tty.detectConfig(stderr);\n    const writer = stderr.writer();\n    var chunks = mem.window(u8, bytes, 16, 16);\n    while (chunks.next()) |window| {\n        // 1. Print the address.\n        const address = (@intFromPtr(bytes.ptr) + 0x10 * (chunks.index orelse 0) / 16) - 0x10;\n        try ttyconf.setColor(writer, .dim);\n        // We print the address in lowercase and the bytes in uppercase hexadecimal to distinguish them more.\n        // Also, make sure all lines are aligned by padding the address.\n        try writer.print(\"{x:0>[1]}  \", .{ address, @sizeOf(usize) * 2 });\n        try ttyconf.setColor(writer, .reset);\n\n        // 2. Print the bytes.\n        for (window, 0..) |byte, index| {\n            try writer.print(\"{X:0>2} \", .{byte});\n            if (index == 7) try writer.writeByte(' ');\n        }\n        try writer.writeByte(' ');\n        if (window.len < 16) {\n            var missing_columns = (16 - window.len) * 3;\n            if (window.len < 8) missing_columns += 1;\n            try writer.writeByteNTimes(' ', missing_columns);\n        }\n\n        // 3. Print the characters.\n        for (window) |byte| {\n            if (std.ascii.isPrint(byte)) {\n                try writer.writeByte(byte);\n            } else {\n                // Related: https://github.com/ziglang/zig/issues/7600\n                if (ttyconf == .windows_api) {\n                    try writer.writeByte('.');\n                    continue;\n                }\n\n                // Let's print some common control codes as graphical Unicode symbols.\n                // We don't want to do this for all control codes because most control codes apart from\n                // the ones that Zig has escape sequences for are likely not very useful to print as symbols.\n                switch (byte) {\n                    '\\n' => try writer.writeAll(\"\"),\n                    '\\r' => try writer.writeAll(\"\"),\n                    '\\t' => try writer.writeAll(\"\"),\n                    else => try writer.writeByte('.'),\n                }\n            }\n        }\n        try writer.writeByte('\\n');\n    }\n}\n\n/// Tries to print the current stack trace to stderr, unbuffered, and ignores any error returned.\n/// TODO multithreaded awareness\npub fn dumpCurrentStackTrace(start_addr: ?usize) void {\n    nosuspend {\n        if (comptime builtin.target.isWasm()) {\n            if (native_os == .wasi) {\n                const stderr = io.getStdErr().writer();\n                stderr.print(\"Unable to dump stack trace: not implemented for Wasm\\n\", .{}) catch return;\n            }\n            return;\n        }\n        const stderr = io.getStdErr().writer();\n        if (builtin.strip_debug_info) {\n            stderr.print(\"Unable to dump stack trace: debug info stripped\\n\", .{}) catch return;\n            return;\n        }\n        const debug_info = getSelfDebugInfo() catch |err| {\n            stderr.print(\"Unable to dump stack trace: Unable to open debug info: {s}\\n\", .{@errorName(err)}) catch return;\n            return;\n        };\n        writeCurrentStackTrace(stderr, debug_info, io.tty.detectConfig(io.getStdErr()), start_addr) catch |err| {\n            stderr.print(\"Unable to dump stack trace: {s}\\n\", .{@errorName(err)}) catch return;\n            return;\n        };\n    }\n}\n\npub const have_ucontext = @hasDecl(posix.system, \"ucontext_t\") and\n    (native_os != .linux or switch (builtin.cpu.arch) {\n    .mips, .mipsel, .mips64, .mips64el, .riscv64 => false,\n    else => true,\n});\n\n/// Platform-specific thread state. This contains register state, and on some platforms\n/// information about the stack. This is not safe to trivially copy, because some platforms\n/// use internal pointers within this structure. To make a copy, use `copyContext`.\npub const ThreadContext = blk: {\n    if (native_os == .windows) {\n        break :blk windows.CONTEXT;\n    } else if (have_ucontext) {\n        break :blk posix.ucontext_t;\n    } else {\n        break :blk void;\n    }\n};\n\n/// Copies one context to another, updating any internal pointers\npub fn copyContext(source: *const ThreadContext, dest: *ThreadContext) void {\n    if (!have_ucontext) return {};\n    dest.* = source.*;\n    relocateContext(dest);\n}\n\n/// Updates any internal pointers in the context to reflect its current location\npub fn relocateContext(context: *ThreadContext) void {\n    return switch (native_os) {\n        .macos => {\n            context.mcontext = &context.__mcontext_data;\n        },\n        else => {},\n    };\n}\n\npub const have_getcontext = native_os != .openbsd and native_os != .haiku and\n    !builtin.target.isAndroid() and\n    (native_os != .linux or switch (builtin.cpu.arch) {\n    .x86,\n    .x86_64,\n    => true,\n    else => builtin.link_libc and !builtin.target.isMusl(),\n});\n\n/// Capture the current context. The register values in the context will reflect the\n/// state after the platform `getcontext` function returns.\n///\n/// It is valid to call this if the platform doesn't have context capturing support,\n/// in that case false will be returned.\npub inline fn getContext(context: *ThreadContext) bool {\n    if (native_os == .windows) {\n        context.* = std.mem.zeroes(windows.CONTEXT);\n        windows.ntdll.RtlCaptureContext(context);\n        return true;\n    }\n\n    const result = have_getcontext and posix.system.getcontext(context) == 0;\n    if (native_os == .macos) {\n        assert(context.mcsize == @sizeOf(std.c.mcontext_t));\n\n        // On aarch64-macos, the system getcontext doesn't write anything into the pc\n        // register slot, it only writes lr. This makes the context consistent with\n        // other aarch64 getcontext implementations which write the current lr\n        // (where getcontext will return to) into both the lr and pc slot of the context.\n        if (native_arch == .aarch64) context.mcontext.ss.pc = context.mcontext.ss.lr;\n    }\n\n    return result;\n}\n\n/// Tries to print the stack trace starting from the supplied base pointer to stderr,\n/// unbuffered, and ignores any error returned.\n/// TODO multithreaded awareness\npub fn dumpStackTraceFromBase(context: *const ThreadContext) void {\n    nosuspend {\n        if (comptime builtin.target.isWasm()) {\n            if (native_os == .wasi) {\n                const stderr = io.getStdErr().writer();\n                stderr.print(\"Unable to dump stack trace: not implemented for Wasm\\n\", .{}) catch return;\n            }\n            return;\n        }\n        const stderr = io.getStdErr().writer();\n        if (builtin.strip_debug_info) {\n            stderr.print(\"Unable to dump stack trace: debug info stripped\\n\", .{}) catch return;\n            return;\n        }\n        const debug_info = getSelfDebugInfo() catch |err| {\n            stderr.print(\"Unable to dump stack trace: Unable to open debug info: {s}\\n\", .{@errorName(err)}) catch return;\n            return;\n        };\n        const tty_config = io.tty.detectConfig(io.getStdErr());\n        if (native_os == .windows) {\n            // On x86_64 and aarch64, the stack will be unwound using RtlVirtualUnwind using the context\n            // provided by the exception handler. On x86, RtlVirtualUnwind doesn't exist. Instead, a new backtrace\n            // will be captured and frames prior to the exception will be filtered.\n            // The caveat is that RtlCaptureStackBackTrace does not include the KiUserExceptionDispatcher frame,\n            // which is where the IP in `context` points to, so it can't be used as start_addr.\n            // Instead, start_addr is recovered from the stack.\n            const start_addr = if (builtin.cpu.arch == .x86) @as(*const usize, @ptrFromInt(context.getRegs().bp + 4)).* else null;\n            writeStackTraceWindows(stderr, debug_info, tty_config, context, start_addr) catch return;\n            return;\n        }\n\n        var it = StackIterator.initWithContext(null, debug_info, context) catch return;\n        defer it.deinit();\n        printSourceAtAddress(debug_info, stderr, it.unwind_state.?.dwarf_context.pc, tty_config) catch return;\n\n        while (it.next()) |return_address| {\n            printLastUnwindError(&it, debug_info, stderr, tty_config);\n\n            // On arm64 macOS, the address of the last frame is 0x0 rather than 0x1 as on x86_64 macOS,\n            // therefore, we do a check for `return_address == 0` before subtracting 1 from it to avoid\n            // an overflow. We do not need to signal `StackIterator` as it will correctly detect this\n            // condition on the subsequent iteration and return `null` thus terminating the loop.\n            // same behaviour for x86-windows-msvc\n            const address = if (return_address == 0) return_address else return_address - 1;\n            printSourceAtAddress(debug_info, stderr, address, tty_config) catch return;\n        } else printLastUnwindError(&it, debug_info, stderr, tty_config);\n    }\n}\n\n/// Returns a slice with the same pointer as addresses, with a potentially smaller len.\n/// On Windows, when first_address is not null, we ask for at least 32 stack frames,\n/// and then try to find the first address. If addresses.len is more than 32, we\n/// capture that many stack frames exactly, and then look for the first address,\n/// chopping off the irrelevant frames and shifting so that the returned addresses pointer\n/// equals the passed in addresses pointer.\npub fn captureStackTrace(first_address: ?usize, stack_trace: *std.builtin.StackTrace) void {\n    if (native_os == .windows) {\n        const addrs = stack_trace.instruction_addresses;\n        const first_addr = first_address orelse {\n            stack_trace.index = walkStackWindows(addrs[0..], null);\n            return;\n        };\n        var addr_buf_stack: [32]usize = undefined;\n        const addr_buf = if (addr_buf_stack.len > addrs.len) addr_buf_stack[0..] else addrs;\n        const n = walkStackWindows(addr_buf[0..], null);\n        const first_index = for (addr_buf[0..n], 0..) |addr, i| {\n            if (addr == first_addr) {\n                break i;\n            }\n        } else {\n            stack_trace.index = 0;\n            return;\n        };\n        const end_index = @min(first_index + addrs.len, n);\n        const slice = addr_buf[first_index..end_index];\n        // We use a for loop here because slice and addrs may alias.\n        for (slice, 0..) |addr, i| {\n            addrs[i] = addr;\n        }\n        stack_trace.index = slice.len;\n    } else {\n        // TODO: This should use the DWARF unwinder if .eh_frame_hdr is available (so that full debug info parsing isn't required).\n        //       A new path for loading DebugInfo needs to be created which will only attempt to parse in-memory sections, because\n        //       stopping to load other debug info (ie. source line info) from disk here is not required for unwinding.\n        var it = StackIterator.init(first_address, null);\n        defer it.deinit();\n        for (stack_trace.instruction_addresses, 0..) |*addr, i| {\n            addr.* = it.next() orelse {\n                stack_trace.index = i;\n                return;\n            };\n        }\n        stack_trace.index = stack_trace.instruction_addresses.len;\n    }\n}\n\n/// Tries to print a stack trace to stderr, unbuffered, and ignores any error returned.\n/// TODO multithreaded awareness\npub fn dumpStackTrace(stack_trace: std.builtin.StackTrace) void {\n    nosuspend {\n        if (comptime builtin.target.isWasm()) {\n            if (native_os == .wasi) {\n                const stderr = io.getStdErr().writer();\n                stderr.print(\"Unable to dump stack trace: not implemented for Wasm\\n\", .{}) catch return;\n            }\n            return;\n        }\n        const stderr = io.getStdErr().writer();\n        if (builtin.strip_debug_info) {\n            stderr.print(\"Unable to dump stack trace: debug info stripped\\n\", .{}) catch return;\n            return;\n        }\n        const debug_info = getSelfDebugInfo() catch |err| {\n            stderr.print(\"Unable to dump stack trace: Unable to open debug info: {s}\\n\", .{@errorName(err)}) catch return;\n            return;\n        };\n        writeStackTrace(stack_trace, stderr, getDebugInfoAllocator(), debug_info, io.tty.detectConfig(io.getStdErr())) catch |err| {\n            stderr.print(\"Unable to dump stack trace: {s}\\n\", .{@errorName(err)}) catch return;\n            return;\n        };\n    }\n}\n\n/// This function invokes undefined behavior when `ok` is `false`.\n/// In Debug and ReleaseSafe modes, calls to this function are always\n/// generated, and the `unreachable` statement triggers a panic.\n/// In ReleaseFast and ReleaseSmall modes, calls to this function are\n/// optimized away, and in fact the optimizer is able to use the assertion\n/// in its heuristics.\n/// Inside a test block, it is best to use the `std.testing` module rather\n/// than this function, because this function may not detect a test failure\n/// in ReleaseFast and ReleaseSmall mode. Outside of a test block, this assert\n/// function is the correct function to use.\npub fn assert(ok: bool) void {\n    if (!ok) unreachable; // assertion failure\n}\n\npub fn panic(comptime format: []const u8, args: anytype) noreturn {\n    @setCold(true);\n\n    panicExtra(@errorReturnTrace(), @returnAddress(), format, args);\n}\n\n/// `panicExtra` is useful when you want to print out an `@errorReturnTrace`\n/// and also print out some values.\npub fn panicExtra(\n    trace: ?*std.builtin.StackTrace,\n    ret_addr: ?usize,\n    comptime format: []const u8,\n    args: anytype,\n) noreturn {\n    @setCold(true);\n\n    const size = 0x1000;\n    const trunc_msg = \"(msg truncated)\";\n    var buf: [size + trunc_msg.len]u8 = undefined;\n    // a minor annoyance with this is that it will result in the NoSpaceLeft\n    // error being part of the @panic stack trace (but that error should\n    // only happen rarely)\n    const msg = std.fmt.bufPrint(buf[0..size], format, args) catch |err| switch (err) {\n        error.NoSpaceLeft => blk: {\n            @memcpy(buf[size..], trunc_msg);\n            break :blk &buf;\n        },\n    };\n    std.builtin.panic(msg, trace, ret_addr);\n}\n\n/// Non-zero whenever the program triggered a panic.\n/// The counter is incremented/decremented atomically.\nvar panicking = std.atomic.Value(u8).init(0);\n\n// Locked to avoid interleaving panic messages from multiple threads.\nvar panic_mutex = std.Thread.Mutex{};\n\n/// Counts how many times the panic handler is invoked by this thread.\n/// This is used to catch and handle panics triggered by the panic handler.\nthreadlocal var panic_stage: usize = 0;\n\n// `panicImpl` could be useful in implementing a custom panic handler which\n// calls the default handler (on supported platforms)\npub fn panicImpl(trace: ?*const std.builtin.StackTrace, first_trace_addr: ?usize, msg: []const u8) noreturn {\n    @setCold(true);\n\n    if (enable_segfault_handler) {\n        // If a segfault happens while panicking, we want it to actually segfault, not trigger\n        // the handler.\n        resetSegfaultHandler();\n    }\n\n    // Note there is similar logic in handleSegfaultPosix and handleSegfaultWindowsExtra.\n    nosuspend switch (panic_stage) {\n        0 => {\n            panic_stage = 1;\n\n            _ = panicking.fetchAdd(1, .seq_cst);\n\n            // Make sure to release the mutex when done\n            {\n                panic_mutex.lock();\n                defer panic_mutex.unlock();\n\n                const stderr = io.getStdErr().writer();\n                if (builtin.single_threaded) {\n                    stderr.print(\"panic: \", .{}) catch posix.abort();\n                } else {\n                    const current_thread_id = std.Thread.getCurrentId();\n                    stderr.print(\"thread {} panic: \", .{current_thread_id}) catch posix.abort();\n                }\n                stderr.print(\"{s}\\n\", .{msg}) catch posix.abort();\n                if (trace) |t| {\n                    dumpStackTrace(t.*);\n                }\n                dumpCurrentStackTrace(first_trace_addr);\n            }\n\n            waitForOtherThreadToFinishPanicking();\n        },\n        1 => {\n            panic_stage = 2;\n\n            // A panic happened while trying to print a previous panic message,\n            // we're still holding the mutex but that's fine as we're going to\n            // call abort()\n            const stderr = io.getStdErr().writer();\n            stderr.print(\"Panicked during a panic. Aborting.\\n\", .{}) catch posix.abort();\n        },\n        else => {\n            // Panicked while printing \"Panicked during a panic.\"\n        },\n    };\n\n    posix.abort();\n}\n\n/// Must be called only after adding 1 to `panicking`. There are three callsites.\nfn waitForOtherThreadToFinishPanicking() void {\n    if (panicking.fetchSub(1, .seq_cst) != 1) {\n        // Another thread is panicking, wait for the last one to finish\n        // and call abort()\n        if (builtin.single_threaded) unreachable;\n\n        // Sleep forever without hammering the CPU\n        var futex = std.atomic.Value(u32).init(0);\n        while (true) std.Thread.Futex.wait(&futex, 0);\n        unreachable;\n    }\n}\n\npub fn writeStackTrace(\n    stack_trace: std.builtin.StackTrace,\n    out_stream: anytype,\n    allocator: mem.Allocator,\n    debug_info: *DebugInfo,\n    tty_config: io.tty.Config,\n) !void {\n    _ = allocator;\n    if (builtin.strip_debug_info) return error.MissingDebugInfo;\n    var frame_index: usize = 0;\n    var frames_left: usize = @min(stack_trace.index, stack_trace.instruction_addresses.len);\n\n    while (frames_left != 0) : ({\n        frames_left -= 1;\n        frame_index = (frame_index + 1) % stack_trace.instruction_addresses.len;\n    }) {\n        const return_address = stack_trace.instruction_addresses[frame_index];\n        try printSourceAtAddress(debug_info, out_stream, return_address - 1, tty_config);\n    }\n\n    if (stack_trace.index > stack_trace.instruction_addresses.len) {\n        const dropped_frames = stack_trace.index - stack_trace.instruction_addresses.len;\n\n        tty_config.setColor(out_stream, .bold) catch {};\n        try out_stream.print(\"({d} additional stack frames skipped...)\\n\", .{dropped_frames});\n        tty_config.setColor(out_stream, .reset) catch {};\n    }\n}\n\npub const UnwindError = if (have_ucontext)\n    @typeInfo(@typeInfo(@TypeOf(StackIterator.next_unwind)).Fn.return_type.?).ErrorUnion.error_set\nelse\n    void;\n\npub const StackIterator = struct {\n    // Skip every frame before this address is found.\n    first_address: ?usize,\n    // Last known value of the frame pointer register.\n    fp: usize,\n\n    // When DebugInfo and a register context is available, this iterator can unwind\n    // stacks with frames that don't use a frame pointer (ie. -fomit-frame-pointer),\n    // using DWARF and MachO unwind info.\n    unwind_state: if (have_ucontext) ?struct {\n        debug_info: *DebugInfo,\n        dwarf_context: DW.UnwindContext,\n        last_error: ?UnwindError = null,\n        failed: bool = false,\n    } else void = if (have_ucontext) null else {},\n\n    pub fn init(first_address: ?usize, fp: ?usize) StackIterator {\n        if (native_arch == .sparc64) {\n            // Flush all the register windows on stack.\n            asm volatile (\n                \\\\ flushw\n                ::: \"memory\");\n        }\n\n        return StackIterator{\n            .first_address = first_address,\n            // TODO: this is a workaround for #16876\n            //.fp = fp orelse @frameAddress(),\n            .fp = fp orelse blk: {\n                const fa = @frameAddress();\n                break :blk fa;\n            },\n        };\n    }\n\n    pub fn initWithContext(first_address: ?usize, debug_info: *DebugInfo, context: *const posix.ucontext_t) !StackIterator {\n        // The implementation of DWARF unwinding on aarch64-macos is not complete. However, Apple mandates that\n        // the frame pointer register is always used, so on this platform we can safely use the FP-based unwinder.\n        if (comptime builtin.target.isDarwin() and native_arch == .aarch64) {\n            return init(first_address, context.mcontext.ss.fp);\n        } else {\n            var iterator = init(first_address, null);\n            iterator.unwind_state = .{\n                .debug_info = debug_info,\n                .dwarf_context = try DW.UnwindContext.init(debug_info.allocator, context, &isValidMemory),\n            };\n\n            return iterator;\n        }\n    }\n\n    pub fn deinit(self: *StackIterator) void {\n        if (have_ucontext and self.unwind_state != null) self.unwind_state.?.dwarf_context.deinit();\n    }\n\n    pub fn getLastError(self: *StackIterator) ?struct {\n        err: UnwindError,\n        address: usize,\n    } {\n        if (!have_ucontext) return null;\n        if (self.unwind_state) |*unwind_state| {\n            if (unwind_state.last_error) |err| {\n                unwind_state.last_error = null;\n                return .{\n                    .err = err,\n                    .address = unwind_state.dwarf_context.pc,\n                };\n            }\n        }\n\n        return null;\n    }\n\n    // Offset of the saved BP wrt the frame pointer.\n    const fp_offset = if (native_arch.isRISCV())\n        // On RISC-V the frame pointer points to the top of the saved register\n        // area, on pretty much every other architecture it points to the stack\n        // slot where the previous frame pointer is saved.\n        2 * @sizeOf(usize)\n    else if (native_arch.isSPARC())\n        // On SPARC the previous frame pointer is stored at 14 slots past %fp+BIAS.\n        14 * @sizeOf(usize)\n    else\n        0;\n\n    const fp_bias = if (native_arch.isSPARC())\n        // On SPARC frame pointers are biased by a constant.\n        2047\n    else\n        0;\n\n    // Positive offset of the saved PC wrt the frame pointer.\n    const pc_offset = if (native_arch == .powerpc64le)\n        2 * @sizeOf(usize)\n    else\n        @sizeOf(usize);\n\n    pub fn next(self: *StackIterator) ?usize {\n        var address = self.next_internal() orelse return null;\n\n        if (self.first_address) |first_address| {\n            while (address != first_address) {\n                address = self.next_internal() orelse return null;\n            }\n            self.first_address = null;\n        }\n\n        return address;\n    }\n\n    fn isValidMemory(address: usize) bool {\n        // We are unable to determine validity of memory for freestanding targets\n        if (native_os == .freestanding or native_os == .uefi) return true;\n\n        const aligned_address = address & ~@as(usize, @intCast((mem.page_size - 1)));\n        if (aligned_address == 0) return false;\n        const aligned_memory = @as([*]align(mem.page_size) u8, @ptrFromInt(aligned_address))[0..mem.page_size];\n\n        if (native_os == .windows) {\n            var memory_info: windows.MEMORY_BASIC_INFORMATION = undefined;\n\n            // The only error this function can throw is ERROR_INVALID_PARAMETER.\n            // supply an address that invalid i'll be thrown.\n            const rc = windows.VirtualQuery(aligned_memory, &memory_info, aligned_memory.len) catch {\n                return false;\n            };\n\n            // Result code has to be bigger than zero (number of bytes written)\n            if (rc == 0) {\n                return false;\n            }\n\n            // Free pages cannot be read, they are unmapped\n            if (memory_info.State == windows.MEM_FREE) {\n                return false;\n            }\n\n            return true;\n        } else if (@hasDecl(posix.system, \"msync\") and native_os != .wasi and native_os != .emscripten) {\n            posix.msync(aligned_memory, posix.MSF.ASYNC) catch |err| {\n                switch (err) {\n                    error.UnmappedMemory => return false,\n                    else => unreachable,\n                }\n            };\n\n            return true;\n        } else {\n            // We are unable to determine validity of memory on this target.\n            return true;\n        }\n    }\n\n    fn next_unwind(self: *StackIterator) !usize {\n        const unwind_state = &self.unwind_state.?;\n        const module = try unwind_state.debug_info.getModuleForAddress(unwind_state.dwarf_context.pc);\n        switch (native_os) {\n            .macos, .ios, .watchos, .tvos, .visionos => {\n                // __unwind_info is a requirement for unwinding on Darwin. It may fall back to DWARF, but unwinding\n                // via DWARF before attempting to use the compact unwind info will produce incorrect results.\n                if (module.unwind_info) |unwind_info| {\n                    if (DW.unwindFrameMachO(&unwind_state.dwarf_context, unwind_info, module.eh_frame, module.base_address)) |return_address| {\n                        return return_address;\n                    } else |err| {\n                        if (err != error.RequiresDWARFUnwind) return err;\n                    }\n                } else return error.MissingUnwindInfo;\n            },\n            else => {},\n        }\n\n        if (try module.getDwarfInfoForAddress(unwind_state.debug_info.allocator, unwind_state.dwarf_context.pc)) |di| {\n            return di.unwindFrame(&unwind_state.dwarf_context, null);\n        } else return error.MissingDebugInfo;\n    }\n\n    fn next_internal(self: *StackIterator) ?usize {\n        if (have_ucontext) {\n            if (self.unwind_state) |*unwind_state| {\n                if (!unwind_state.failed) {\n                    if (unwind_state.dwarf_context.pc == 0) return null;\n                    defer self.fp = unwind_state.dwarf_context.getFp() catch 0;\n                    if (self.next_unwind()) |return_address| {\n                        return return_address;\n                    } else |err| {\n                        unwind_state.last_error = err;\n                        unwind_state.failed = true;\n\n                        // Fall back to fp-based unwinding on the first failure.\n                        // We can't attempt it again for other modules higher in the\n                        // stack because the full register state won't have been unwound.\n                    }\n                }\n            }\n        }\n\n        const fp = if (comptime native_arch.isSPARC())\n            // On SPARC the offset is positive. (!)\n            math.add(usize, self.fp, fp_offset) catch return null\n        else\n            math.sub(usize, self.fp, fp_offset) catch return null;\n\n        // Sanity check.\n        if (fp == 0 or !mem.isAligned(fp, @alignOf(usize)) or !isValidMemory(fp))\n            return null;\n\n        const new_fp = math.add(usize, @as(*const usize, @ptrFromInt(fp)).*, fp_bias) catch return null;\n\n        // Sanity check: the stack grows down thus all the parent frames must be\n        // be at addresses that are greater (or equal) than the previous one.\n        // A zero frame pointer often signals this is the last frame, that case\n        // is gracefully handled by the next call to next_internal.\n        if (new_fp != 0 and new_fp < self.fp)\n            return null;\n\n        const new_pc = @as(\n            *const usize,\n            @ptrFromInt(math.add(usize, fp, pc_offset) catch return null),\n        ).*;\n\n        self.fp = new_fp;\n\n        return new_pc;\n    }\n};\n\npub fn writeCurrentStackTrace(\n    out_stream: anytype,\n    debug_info: *DebugInfo,\n    tty_config: io.tty.Config,\n    start_addr: ?usize,\n) !void {\n    var context: ThreadContext = undefined;\n    const has_context = getContext(&context);\n    if (native_os == .windows) {\n        return writeStackTraceWindows(out_stream, debug_info, tty_config, &context, start_addr);\n    }\n\n    var it = (if (has_context) blk: {\n        break :blk StackIterator.initWithContext(start_addr, debug_info, &context) catch null;\n    } else null) orelse StackIterator.init(start_addr, null);\n    defer it.deinit();\n\n    while (it.next()) |return_address| {\n        printLastUnwindError(&it, debug_info, out_stream, tty_config);\n\n        // On arm64 macOS, the address of the last frame is 0x0 rather than 0x1 as on x86_64 macOS,\n        // therefore, we do a check for `return_address == 0` before subtracting 1 from it to avoid\n        // an overflow. We do not need to signal `StackIterator` as it will correctly detect this\n        // condition on the subsequent iteration and return `null` thus terminating the loop.\n        // same behaviour for x86-windows-msvc\n        const address = if (return_address == 0) return_address else return_address - 1;\n        try printSourceAtAddress(debug_info, out_stream, address, tty_config);\n    } else printLastUnwindError(&it, debug_info, out_stream, tty_config);\n}\n\npub noinline fn walkStackWindows(addresses: []usize, existing_context: ?*const windows.CONTEXT) usize {\n    if (builtin.cpu.arch == .x86) {\n        // RtlVirtualUnwind doesn't exist on x86\n        return windows.ntdll.RtlCaptureStackBackTrace(0, addresses.len, @as(**anyopaque, @ptrCast(addresses.ptr)), null);\n    }\n\n    const tib = &windows.teb().NtTib;\n\n    var context: windows.CONTEXT = undefined;\n    if (existing_context) |context_ptr| {\n        context = context_ptr.*;\n    } else {\n        context = std.mem.zeroes(windows.CONTEXT);\n        windows.ntdll.RtlCaptureContext(&context);\n    }\n\n    var i: usize = 0;\n    var image_base: usize = undefined;\n    var history_table: windows.UNWIND_HISTORY_TABLE = std.mem.zeroes(windows.UNWIND_HISTORY_TABLE);\n\n    while (i < addresses.len) : (i += 1) {\n        const current_regs = context.getRegs();\n        if (windows.ntdll.RtlLookupFunctionEntry(current_regs.ip, &image_base, &history_table)) |runtime_function| {\n            var handler_data: ?*anyopaque = null;\n            var establisher_frame: u64 = undefined;\n            _ = windows.ntdll.RtlVirtualUnwind(\n                windows.UNW_FLAG_NHANDLER,\n                image_base,\n                current_regs.ip,\n                runtime_function,\n                &context,\n                &handler_data,\n                &establisher_frame,\n                null,\n            );\n        } else {\n            // leaf function\n            context.setIp(@as(*u64, @ptrFromInt(current_regs.sp)).*);\n            context.setSp(current_regs.sp + @sizeOf(usize));\n        }\n\n        const next_regs = context.getRegs();\n        if (next_regs.sp < @intFromPtr(tib.StackLimit) or next_regs.sp > @intFromPtr(tib.StackBase)) {\n            break;\n        }\n\n        if (next_regs.ip == 0) {\n            break;\n        }\n\n        addresses[i] = next_regs.ip;\n    }\n\n    return i;\n}\n\npub fn writeStackTraceWindows(\n    out_stream: anytype,\n    debug_info: *DebugInfo,\n    tty_config: io.tty.Config,\n    context: *const windows.CONTEXT,\n    start_addr: ?usize,\n) !void {\n    var addr_buf: [1024]usize = undefined;\n    const n = walkStackWindows(addr_buf[0..], context);\n    const addrs = addr_buf[0..n];\n    const start_i: usize = if (start_addr) |saddr| blk: {\n        for (addrs, 0..) |addr, i| {\n            if (addr == saddr) break :blk i;\n        }\n        return;\n    } else 0;\n    for (addrs[start_i..]) |addr| {\n        try printSourceAtAddress(debug_info, out_stream, addr - 1, tty_config);\n    }\n}\n\nfn machoSearchSymbols(symbols: []const MachoSymbol, address: usize) ?*const MachoSymbol {\n    var min: usize = 0;\n    var max: usize = symbols.len - 1;\n    while (min < max) {\n        const mid = min + (max - min) / 2;\n        const curr = &symbols[mid];\n        const next = &symbols[mid + 1];\n        if (address >= next.address()) {\n            min = mid + 1;\n        } else if (address < curr.address()) {\n            max = mid;\n        } else {\n            return curr;\n        }\n    }\n\n    const max_sym = &symbols[symbols.len - 1];\n    if (address >= max_sym.address())\n        return max_sym;\n\n    return null;\n}\n\ntest machoSearchSymbols {\n    const symbols = [_]MachoSymbol{\n        .{ .addr = 100, .strx = undefined, .size = undefined, .ofile = undefined },\n        .{ .addr = 200, .strx = undefined, .size = undefined, .ofile = undefined },\n        .{ .addr = 300, .strx = undefined, .size = undefined, .ofile = undefined },\n    };\n\n    try testing.expectEqual(null, machoSearchSymbols(&symbols, 0));\n    try testing.expectEqual(null, machoSearchSymbols(&symbols, 99));\n    try testing.expectEqual(&symbols[0], machoSearchSymbols(&symbols, 100).?);\n    try testing.expectEqual(&symbols[0], machoSearchSymbols(&symbols, 150).?);\n    try testing.expectEqual(&symbols[0], machoSearchSymbols(&symbols, 199).?);\n\n    try testing.expectEqual(&symbols[1], machoSearchSymbols(&symbols, 200).?);\n    try testing.expectEqual(&symbols[1], machoSearchSymbols(&symbols, 250).?);\n    try testing.expectEqual(&symbols[1], machoSearchSymbols(&symbols, 299).?);\n\n    try testing.expectEqual(&symbols[2], machoSearchSymbols(&symbols, 300).?);\n    try testing.expectEqual(&symbols[2], machoSearchSymbols(&symbols, 301).?);\n    try testing.expectEqual(&symbols[2], machoSearchSymbols(&symbols, 5000).?);\n}\n\nfn printUnknownSource(debug_info: *DebugInfo, out_stream: anytype, address: usize, tty_config: io.tty.Config) !void {\n    const module_name = debug_info.getModuleNameForAddress(address);\n    return printLineInfo(\n        out_stream,\n        null,\n        address,\n        \"???\",\n        module_name orelse \"???\",\n        tty_config,\n        printLineFromFileAnyOs,\n    );\n}\n\nfn printLastUnwindError(it: *StackIterator, debug_info: *DebugInfo, out_stream: anytype, tty_config: io.tty.Config) void {\n    if (!have_ucontext) return;\n    if (it.getLastError()) |unwind_error| {\n        printUnwindError(debug_info, out_stream, unwind_error.address, unwind_error.err, tty_config) catch {};\n    }\n}\n\nfn printUnwindError(debug_info: *DebugInfo, out_stream: anytype, address: usize, err: UnwindError, tty_config: io.tty.Config) !void {\n    const module_name = debug_info.getModuleNameForAddress(address) orelse \"???\";\n    try tty_config.setColor(out_stream, .dim);\n    if (err == error.MissingDebugInfo) {\n        try out_stream.print(\"Unwind information for `{s}:0x{x}` was not available, trace may be incomplete\\n\\n\", .{ module_name, address });\n    } else {\n        try out_stream.print(\"Unwind error at address `{s}:0x{x}` ({}), trace may be incomplete\\n\\n\", .{ module_name, address, err });\n    }\n    try tty_config.setColor(out_stream, .reset);\n}\n\npub fn printSourceAtAddress(debug_info: *DebugInfo, out_stream: anytype, address: usize, tty_config: io.tty.Config) !void {\n    const module = debug_info.getModuleForAddress(address) catch |err| switch (err) {\n        error.MissingDebugInfo, error.InvalidDebugInfo => return printUnknownSource(debug_info, out_stream, address, tty_config),\n        else => return err,\n    };\n\n    const symbol_info = module.getSymbolAtAddress(debug_info.allocator, address) catch |err| switch (err) {\n        error.MissingDebugInfo, error.InvalidDebugInfo => return printUnknownSource(debug_info, out_stream, address, tty_config),\n        else => return err,\n    };\n    defer symbol_info.deinit(debug_info.allocator);\n\n    return printLineInfo(\n        out_stream,\n        symbol_info.line_info,\n        address,\n        symbol_info.symbol_name,\n        symbol_info.compile_unit_name,\n        tty_config,\n        printLineFromFileAnyOs,\n    );\n}\n\nfn printLineInfo(\n    out_stream: anytype,\n    line_info: ?LineInfo,\n    address: usize,\n    symbol_name: []const u8,\n    compile_unit_name: []const u8,\n    tty_config: io.tty.Config,\n    comptime printLineFromFile: anytype,\n) !void {\n    nosuspend {\n        try tty_config.setColor(out_stream, .bold);\n\n        if (line_info) |*li| {\n            try out_stream.print(\"{s}:{d}:{d}\", .{ li.file_name, li.line, li.column });\n        } else {\n            try out_stream.writeAll(\"???:?:?\");\n        }\n\n        try tty_config.setColor(out_stream, .reset);\n        try out_stream.writeAll(\": \");\n        try tty_config.setColor(out_stream, .dim);\n        try out_stream.print(\"0x{x} in {s} ({s})\", .{ address, symbol_name, compile_unit_name });\n        try tty_config.setColor(out_stream, .reset);\n        try out_stream.writeAll(\"\\n\");\n\n        // Show the matching source code line if possible\n        if (line_info) |li| {\n            if (printLineFromFile(out_stream, li)) {\n                if (li.column > 0) {\n                    // The caret already takes one char\n                    const space_needed = @as(usize, @intCast(li.column - 1));\n\n                    try out_stream.writeByteNTimes(' ', space_needed);\n                    try tty_config.setColor(out_stream, .green);\n                    try out_stream.writeAll(\"^\");\n                    try tty_config.setColor(out_stream, .reset);\n                }\n                try out_stream.writeAll(\"\\n\");\n            } else |err| switch (err) {\n                error.EndOfFile, error.FileNotFound => {},\n                error.BadPathName => {},\n                error.AccessDenied => {},\n                else => return err,\n            }\n        }\n    }\n}\n\npub const OpenSelfDebugInfoError = error{\n    MissingDebugInfo,\n    UnsupportedOperatingSystem,\n} || @typeInfo(@typeInfo(@TypeOf(DebugInfo.init)).Fn.return_type.?).ErrorUnion.error_set;\n\npub fn openSelfDebugInfo(allocator: mem.Allocator) OpenSelfDebugInfoError!DebugInfo {\n    nosuspend {\n        if (builtin.strip_debug_info)\n            return error.MissingDebugInfo;\n        if (@hasDecl(root, \"os\") and @hasDecl(root.os, \"debug\") and @hasDecl(root.os.debug, \"openSelfDebugInfo\")) {\n            return root.os.debug.openSelfDebugInfo(allocator);\n        }\n        switch (native_os) {\n            .linux,\n            .freebsd,\n            .netbsd,\n            .dragonfly,\n            .openbsd,\n            .macos,\n            .solaris,\n            .illumos,\n            .windows,\n            => return try DebugInfo.init(allocator),\n            else => return error.UnsupportedOperatingSystem,\n        }\n    }\n}\n\nfn readCoffDebugInfo(allocator: mem.Allocator, coff_obj: *coff.Coff) !ModuleDebugInfo {\n    nosuspend {\n        var di = ModuleDebugInfo{\n            .base_address = undefined,\n            .coff_image_base = coff_obj.getImageBase(),\n            .coff_section_headers = undefined,\n        };\n\n        if (coff_obj.getSectionByName(\".debug_info\")) |_| {\n            // This coff file has embedded DWARF debug info\n            var sections: DW.DwarfInfo.SectionArray = DW.DwarfInfo.null_section_array;\n            errdefer for (sections) |section| if (section) |s| if (s.owned) allocator.free(s.data);\n\n            inline for (@typeInfo(DW.DwarfSection).Enum.fields, 0..) |section, i| {\n                sections[i] = if (coff_obj.getSectionByName(\".\" ++ section.name)) |section_header| blk: {\n                    break :blk .{\n                        .data = try coff_obj.getSectionDataAlloc(section_header, allocator),\n                        .virtual_address = section_header.virtual_address,\n                        .owned = true,\n                    };\n                } else null;\n            }\n\n            var dwarf = DW.DwarfInfo{\n                .endian = native_endian,\n                .sections = sections,\n                .is_macho = false,\n            };\n\n            try DW.openDwarfDebugInfo(&dwarf, allocator);\n            di.dwarf = dwarf;\n        }\n\n        const raw_path = try coff_obj.getPdbPath() orelse return di;\n        const path = blk: {\n            if (fs.path.isAbsolute(raw_path)) {\n                break :blk raw_path;\n            } else {\n                const self_dir = try fs.selfExeDirPathAlloc(allocator);\n                defer allocator.free(self_dir);\n                break :blk try fs.path.join(allocator, &.{ self_dir, raw_path });\n            }\n        };\n        defer if (path.ptr != raw_path.ptr) allocator.free(path);\n\n        di.pdb = pdb.Pdb.init(allocator, path) catch |err| switch (err) {\n            error.FileNotFound, error.IsDir => {\n                if (di.dwarf == null) return error.MissingDebugInfo;\n                return di;\n            },\n            else => return err,\n        };\n        try di.pdb.?.parseInfoStream();\n        try di.pdb.?.parseDbiStream();\n\n        if (!mem.eql(u8, &coff_obj.guid, &di.pdb.?.guid) or coff_obj.age != di.pdb.?.age)\n            return error.InvalidDebugInfo;\n\n        // Only used by the pdb path\n        di.coff_section_headers = try coff_obj.getSectionHeadersAlloc(allocator);\n        errdefer allocator.free(di.coff_section_headers);\n\n        return di;\n    }\n}\n\nfn chopSlice(ptr: []const u8, offset: u64, size: u64) error{Overflow}![]const u8 {\n    const start = math.cast(usize, offset) orelse return error.Overflow;\n    const end = start + (math.cast(usize, size) orelse return error.Overflow);\n    return ptr[start..end];\n}\n\n/// Reads debug info from an ELF file, or the current binary if none in specified.\n/// If the required sections aren't present but a reference to external debug info is,\n/// then this this function will recurse to attempt to load the debug sections from\n/// an external file.\npub fn readElfDebugInfo(\n    allocator: mem.Allocator,\n    elf_filename: ?[]const u8,\n    build_id: ?[]const u8,\n    expected_crc: ?u32,\n    parent_sections: *DW.DwarfInfo.SectionArray,\n    parent_mapped_mem: ?[]align(mem.page_size) const u8,\n) !ModuleDebugInfo {\n    nosuspend {\n        const elf_file = (if (elf_filename) |filename| blk: {\n            break :blk fs.cwd().openFile(filename, .{});\n        } else fs.openSelfExe(.{})) catch |err| switch (err) {\n            error.FileNotFound => return error.MissingDebugInfo,\n            else => return err,\n        };\n\n        const mapped_mem = try mapWholeFile(elf_file);\n        if (expected_crc) |crc| if (crc != std.hash.crc.Crc32.hash(mapped_mem)) return error.InvalidDebugInfo;\n\n        const hdr: *const elf.Ehdr = @ptrCast(&mapped_mem[0]);\n        if (!mem.eql(u8, hdr.e_ident[0..4], elf.MAGIC)) return error.InvalidElfMagic;\n        if (hdr.e_ident[elf.EI_VERSION] != 1) return error.InvalidElfVersion;\n\n        const endian: std.builtin.Endian = switch (hdr.e_ident[elf.EI_DATA]) {\n            elf.ELFDATA2LSB => .little,\n            elf.ELFDATA2MSB => .big,\n            else => return error.InvalidElfEndian,\n        };\n        assert(endian == native_endian); // this is our own debug info\n\n        const shoff = hdr.e_shoff;\n        const str_section_off = shoff + @as(u64, hdr.e_shentsize) * @as(u64, hdr.e_shstrndx);\n        const str_shdr: *const elf.Shdr = @ptrCast(@alignCast(&mapped_mem[math.cast(usize, str_section_off) orelse return error.Overflow]));\n        const header_strings = mapped_mem[str_shdr.sh_offset..][0..str_shdr.sh_size];\n        const shdrs = @as(\n            [*]const elf.Shdr,\n            @ptrCast(@alignCast(&mapped_mem[shoff])),\n        )[0..hdr.e_shnum];\n\n        var sections: DW.DwarfInfo.SectionArray = DW.DwarfInfo.null_section_array;\n\n        // Combine section list. This takes ownership over any owned sections from the parent scope.\n        for (parent_sections, &sections) |*parent, *section| {\n            if (parent.*) |*p| {\n                section.* = p.*;\n                p.owned = false;\n            }\n        }\n        errdefer for (sections) |section| if (section) |s| if (s.owned) allocator.free(s.data);\n\n        var separate_debug_filename: ?[]const u8 = null;\n        var separate_debug_crc: ?u32 = null;\n\n        for (shdrs) |*shdr| {\n            if (shdr.sh_type == elf.SHT_NULL or shdr.sh_type == elf.SHT_NOBITS) continue;\n            const name = mem.sliceTo(header_strings[shdr.sh_name..], 0);\n\n            if (mem.eql(u8, name, \".gnu_debuglink\")) {\n                const gnu_debuglink = try chopSlice(mapped_mem, shdr.sh_offset, shdr.sh_size);\n                const debug_filename = mem.sliceTo(@as([*:0]const u8, @ptrCast(gnu_debuglink.ptr)), 0);\n                const crc_offset = mem.alignForward(usize, @intFromPtr(&debug_filename[debug_filename.len]) + 1, 4) - @intFromPtr(gnu_debuglink.ptr);\n                const crc_bytes = gnu_debuglink[crc_offset..][0..4];\n                separate_debug_crc = mem.readInt(u32, crc_bytes, native_endian);\n                separate_debug_filename = debug_filename;\n                continue;\n            }\n\n            var section_index: ?usize = null;\n            inline for (@typeInfo(DW.DwarfSection).Enum.fields, 0..) |section, i| {\n                if (mem.eql(u8, \".\" ++ section.name, name)) section_index = i;\n            }\n            if (section_index == null) continue;\n            if (sections[section_index.?] != null) continue;\n\n            const section_bytes = try chopSlice(mapped_mem, shdr.sh_offset, shdr.sh_size);\n            sections[section_index.?] = if ((shdr.sh_flags & elf.SHF_COMPRESSED) > 0) blk: {\n                var section_stream = io.fixedBufferStream(section_bytes);\n                var section_reader = section_stream.reader();\n                const chdr = section_reader.readStruct(elf.Chdr) catch continue;\n                if (chdr.ch_type != .ZLIB) continue;\n\n                var zlib_stream = std.compress.zlib.decompressor(section_stream.reader());\n\n                const decompressed_section = try allocator.alloc(u8, chdr.ch_size);\n                errdefer allocator.free(decompressed_section);\n\n                const read = zlib_stream.reader().readAll(decompressed_section) catch continue;\n                assert(read == decompressed_section.len);\n\n                break :blk .{\n                    .data = decompressed_section,\n                    .virtual_address = shdr.sh_addr,\n                    .owned = true,\n                };\n            } else .{\n                .data = section_bytes,\n                .virtual_address = shdr.sh_addr,\n                .owned = false,\n            };\n        }\n\n        const missing_debug_info =\n            sections[@intFromEnum(DW.DwarfSection.debug_info)] == null or\n            sections[@intFromEnum(DW.DwarfSection.debug_abbrev)] == null or\n            sections[@intFromEnum(DW.DwarfSection.debug_str)] == null or\n            sections[@intFromEnum(DW.DwarfSection.debug_line)] == null;\n\n        // Attempt to load debug info from an external file\n        // See: https://sourceware.org/gdb/onlinedocs/gdb/Separate-Debug-Files.html\n        if (missing_debug_info) {\n\n            // Only allow one level of debug info nesting\n            if (parent_mapped_mem) |_| {\n                return error.MissingDebugInfo;\n            }\n\n            const global_debug_directories = [_][]const u8{\n                \"/usr/lib/debug\",\n            };\n\n            // <global debug directory>/.build-id/<2-character id prefix>/<id remainder>.debug\n            if (build_id) |id| blk: {\n                if (id.len < 3) break :blk;\n\n                // Either md5 (16 bytes) or sha1 (20 bytes) are used here in practice\n                const extension = \".debug\";\n                var id_prefix_buf: [2]u8 = undefined;\n                var filename_buf: [38 + extension.len]u8 = undefined;\n\n                _ = std.fmt.bufPrint(&id_prefix_buf, \"{s}\", .{std.fmt.fmtSliceHexLower(id[0..1])}) catch unreachable;\n                const filename = std.fmt.bufPrint(\n                    &filename_buf,\n                    \"{s}\" ++ extension,\n                    .{std.fmt.fmtSliceHexLower(id[1..])},\n                ) catch break :blk;\n\n                for (global_debug_directories) |global_directory| {\n                    const path = try fs.path.join(allocator, &.{ global_directory, \".build-id\", &id_prefix_buf, filename });\n                    defer allocator.free(path);\n\n                    return readElfDebugInfo(allocator, path, null, separate_debug_crc, &sections, mapped_mem) catch continue;\n                }\n            }\n\n            // use the path from .gnu_debuglink, in the same search order as gdb\n            if (separate_debug_filename) |separate_filename| blk: {\n                if (elf_filename != null and mem.eql(u8, elf_filename.?, separate_filename)) return error.MissingDebugInfo;\n\n                // <cwd>/<gnu_debuglink>\n                if (readElfDebugInfo(allocator, separate_filename, null, separate_debug_crc, &sections, mapped_mem)) |debug_info| return debug_info else |_| {}\n\n                // <cwd>/.debug/<gnu_debuglink>\n                {\n                    const path = try fs.path.join(allocator, &.{ \".debug\", separate_filename });\n                    defer allocator.free(path);\n\n                    if (readElfDebugInfo(allocator, path, null, separate_debug_crc, &sections, mapped_mem)) |debug_info| return debug_info else |_| {}\n                }\n\n                var cwd_buf: [fs.MAX_PATH_BYTES]u8 = undefined;\n                const cwd_path = posix.realpath(\".\", &cwd_buf) catch break :blk;\n\n                // <global debug directory>/<absolute folder of current binary>/<gnu_debuglink>\n                for (global_debug_directories) |global_directory| {\n                    const path = try fs.path.join(allocator, &.{ global_directory, cwd_path, separate_filename });\n                    defer allocator.free(path);\n                    if (readElfDebugInfo(allocator, path, null, separate_debug_crc, &sections, mapped_mem)) |debug_info| return debug_info else |_| {}\n                }\n            }\n\n            return error.MissingDebugInfo;\n        }\n\n        var di = DW.DwarfInfo{\n            .endian = endian,\n            .sections = sections,\n            .is_macho = false,\n        };\n\n        try DW.openDwarfDebugInfo(&di, allocator);\n\n        return ModuleDebugInfo{\n            .base_address = undefined,\n            .dwarf = di,\n            .mapped_memory = parent_mapped_mem orelse mapped_mem,\n            .external_mapped_memory = if (parent_mapped_mem != null) mapped_mem else null,\n        };\n    }\n}\n\n/// This takes ownership of macho_file: users of this function should not close\n/// it themselves, even on error.\n/// TODO it's weird to take ownership even on error, rework this code.\nfn readMachODebugInfo(allocator: mem.Allocator, macho_file: File) !ModuleDebugInfo {\n    const mapped_mem = try mapWholeFile(macho_file);\n\n    const hdr: *const macho.mach_header_64 = @ptrCast(@alignCast(mapped_mem.ptr));\n    if (hdr.magic != macho.MH_MAGIC_64)\n        return error.InvalidDebugInfo;\n\n    var it = macho.LoadCommandIterator{\n        .ncmds = hdr.ncmds,\n        .buffer = mapped_mem[@sizeOf(macho.mach_header_64)..][0..hdr.sizeofcmds],\n    };\n    const symtab = while (it.next()) |cmd| switch (cmd.cmd()) {\n        .SYMTAB => break cmd.cast(macho.symtab_command).?,\n        else => {},\n    } else return error.MissingDebugInfo;\n\n    const syms = @as(\n        [*]const macho.nlist_64,\n        @ptrCast(@alignCast(&mapped_mem[symtab.symoff])),\n    )[0..symtab.nsyms];\n    const strings = mapped_mem[symtab.stroff..][0 .. symtab.strsize - 1 :0];\n\n    const symbols_buf = try allocator.alloc(MachoSymbol, syms.len);\n\n    var ofile: u32 = undefined;\n    var last_sym: MachoSymbol = undefined;\n    var symbol_index: usize = 0;\n    var state: enum {\n        init,\n        oso_open,\n        oso_close,\n        bnsym,\n        fun_strx,\n        fun_size,\n        ensym,\n    } = .init;\n\n    for (syms) |*sym| {\n        if (!sym.stab()) continue;\n\n        // TODO handle globals N_GSYM, and statics N_STSYM\n        switch (sym.n_type) {\n            macho.N_OSO => {\n                switch (state) {\n                    .init, .oso_close => {\n                        state = .oso_open;\n                        ofile = sym.n_strx;\n                    },\n                    else => return error.InvalidDebugInfo,\n                }\n            },\n            macho.N_BNSYM => {\n                switch (state) {\n                    .oso_open, .ensym => {\n                        state = .bnsym;\n                        last_sym = .{\n                            .strx = 0,\n                            .addr = sym.n_value,\n                            .size = 0,\n                            .ofile = ofile,\n                        };\n                    },\n                    else => return error.InvalidDebugInfo,\n                }\n            },\n            macho.N_FUN => {\n                switch (state) {\n                    .bnsym => {\n                        state = .fun_strx;\n                        last_sym.strx = sym.n_strx;\n                    },\n                    .fun_strx => {\n                        state = .fun_size;\n                        last_sym.size = @as(u32, @intCast(sym.n_value));\n                    },\n                    else => return error.InvalidDebugInfo,\n                }\n            },\n            macho.N_ENSYM => {\n                switch (state) {\n                    .fun_size => {\n                        state = .ensym;\n                        symbols_buf[symbol_index] = last_sym;\n                        symbol_index += 1;\n                    },\n                    else => return error.InvalidDebugInfo,\n                }\n            },\n            macho.N_SO => {\n                switch (state) {\n                    .init, .oso_close => {},\n                    .oso_open, .ensym => {\n                        state = .oso_close;\n                    },\n                    else => return error.InvalidDebugInfo,\n                }\n            },\n            else => {},\n        }\n    }\n\n    switch (state) {\n        .init => return error.MissingDebugInfo,\n        .oso_close => {},\n        else => return error.InvalidDebugInfo,\n    }\n\n    const symbols = try allocator.realloc(symbols_buf, symbol_index);\n\n    // Even though lld emits symbols in ascending order, this debug code\n    // should work for programs linked in any valid way.\n    // This sort is so that we can binary search later.\n    mem.sort(MachoSymbol, symbols, {}, MachoSymbol.addressLessThan);\n\n    return ModuleDebugInfo{\n        .base_address = undefined,\n        .vmaddr_slide = undefined,\n        .mapped_memory = mapped_mem,\n        .ofiles = ModuleDebugInfo.OFileTable.init(allocator),\n        .symbols = symbols,\n        .strings = strings,\n    };\n}\n\nfn printLineFromFileAnyOs(out_stream: anytype, line_info: LineInfo) !void {\n    // Need this to always block even in async I/O mode, because this could potentially\n    // be called from e.g. the event loop code crashing.\n    var f = try fs.cwd().openFile(line_info.file_name, .{});\n    defer f.close();\n    // TODO fstat and make sure that the file has the correct size\n\n    var buf: [mem.page_size]u8 = undefined;\n    var amt_read = try f.read(buf[0..]);\n    const line_start = seek: {\n        var current_line_start: usize = 0;\n        var next_line: usize = 1;\n        while (next_line != line_info.line) {\n            const slice = buf[current_line_start..amt_read];\n            if (mem.indexOfScalar(u8, slice, '\\n')) |pos| {\n                next_line += 1;\n                if (pos == slice.len - 1) {\n                    amt_read = try f.read(buf[0..]);\n                    current_line_start = 0;\n                } else current_line_start += pos + 1;\n            } else if (amt_read < buf.len) {\n                return error.EndOfFile;\n            } else {\n                amt_read = try f.read(buf[0..]);\n                current_line_start = 0;\n            }\n        }\n        break :seek current_line_start;\n    };\n    const slice = buf[line_start..amt_read];\n    if (mem.indexOfScalar(u8, slice, '\\n')) |pos| {\n        const line = slice[0 .. pos + 1];\n        mem.replaceScalar(u8, line, '\\t', ' ');\n        return out_stream.writeAll(line);\n    } else { // Line is the last inside the buffer, and requires another read to find delimiter. Alternatively the file ends.\n        mem.replaceScalar(u8, slice, '\\t', ' ');\n        try out_stream.writeAll(slice);\n        while (amt_read == buf.len) {\n            amt_read = try f.read(buf[0..]);\n            if (mem.indexOfScalar(u8, buf[0..amt_read], '\\n')) |pos| {\n                const line = buf[0 .. pos + 1];\n                mem.replaceScalar(u8, line, '\\t', ' ');\n                return out_stream.writeAll(line);\n            } else {\n                const line = buf[0..amt_read];\n                mem.replaceScalar(u8, line, '\\t', ' ');\n                try out_stream.writeAll(line);\n            }\n        }\n        // Make sure printing last line of file inserts extra newline\n        try out_stream.writeByte('\\n');\n    }\n}\n\ntest printLineFromFileAnyOs {\n    var output = std.ArrayList(u8).init(std.testing.allocator);\n    defer output.deinit();\n    const output_stream = output.writer();\n\n    const allocator = std.testing.allocator;\n    const join = std.fs.path.join;\n    const expectError = std.testing.expectError;\n    const expectEqualStrings = std.testing.expectEqualStrings;\n\n    var test_dir = std.testing.tmpDir(.{});\n    defer test_dir.cleanup();\n    // Relies on testing.tmpDir internals which is not ideal, but LineInfo requires paths.\n    const test_dir_path = try join(allocator, &.{ \".zig-cache\", \"tmp\", test_dir.sub_path[0..] });\n    defer allocator.free(test_dir_path);\n\n    // Cases\n    {\n        const path = try join(allocator, &.{ test_dir_path, \"one_line.zig\" });\n        defer allocator.free(path);\n        try test_dir.dir.writeFile(.{ .sub_path = \"one_line.zig\", .data = \"no new lines in this file, but one is printed anyway\" });\n\n        try expectError(error.EndOfFile, printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 2, .column = 0 }));\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 1, .column = 0 });\n        try expectEqualStrings(\"no new lines in this file, but one is printed anyway\\n\", output.items);\n        output.clearRetainingCapacity();\n    }\n    {\n        const path = try fs.path.join(allocator, &.{ test_dir_path, \"three_lines.zig\" });\n        defer allocator.free(path);\n        try test_dir.dir.writeFile(.{\n            .sub_path = \"three_lines.zig\",\n            .data =\n            \\\\1\n            \\\\2\n            \\\\3\n            ,\n        });\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 1, .column = 0 });\n        try expectEqualStrings(\"1\\n\", output.items);\n        output.clearRetainingCapacity();\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 3, .column = 0 });\n        try expectEqualStrings(\"3\\n\", output.items);\n        output.clearRetainingCapacity();\n    }\n    {\n        const file = try test_dir.dir.createFile(\"line_overlaps_page_boundary.zig\", .{});\n        defer file.close();\n        const path = try fs.path.join(allocator, &.{ test_dir_path, \"line_overlaps_page_boundary.zig\" });\n        defer allocator.free(path);\n\n        const overlap = 10;\n        var writer = file.writer();\n        try writer.writeByteNTimes('a', mem.page_size - overlap);\n        try writer.writeByte('\\n');\n        try writer.writeByteNTimes('a', overlap);\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 2, .column = 0 });\n        try expectEqualStrings((\"a\" ** overlap) ++ \"\\n\", output.items);\n        output.clearRetainingCapacity();\n    }\n    {\n        const file = try test_dir.dir.createFile(\"file_ends_on_page_boundary.zig\", .{});\n        defer file.close();\n        const path = try fs.path.join(allocator, &.{ test_dir_path, \"file_ends_on_page_boundary.zig\" });\n        defer allocator.free(path);\n\n        var writer = file.writer();\n        try writer.writeByteNTimes('a', mem.page_size);\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 1, .column = 0 });\n        try expectEqualStrings((\"a\" ** mem.page_size) ++ \"\\n\", output.items);\n        output.clearRetainingCapacity();\n    }\n    {\n        const file = try test_dir.dir.createFile(\"very_long_first_line_spanning_multiple_pages.zig\", .{});\n        defer file.close();\n        const path = try fs.path.join(allocator, &.{ test_dir_path, \"very_long_first_line_spanning_multiple_pages.zig\" });\n        defer allocator.free(path);\n\n        var writer = file.writer();\n        try writer.writeByteNTimes('a', 3 * mem.page_size);\n\n        try expectError(error.EndOfFile, printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 2, .column = 0 }));\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 1, .column = 0 });\n        try expectEqualStrings((\"a\" ** (3 * mem.page_size)) ++ \"\\n\", output.items);\n        output.clearRetainingCapacity();\n\n        try writer.writeAll(\"a\\na\");\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 1, .column = 0 });\n        try expectEqualStrings((\"a\" ** (3 * mem.page_size)) ++ \"a\\n\", output.items);\n        output.clearRetainingCapacity();\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = 2, .column = 0 });\n        try expectEqualStrings(\"a\\n\", output.items);\n        output.clearRetainingCapacity();\n    }\n    {\n        const file = try test_dir.dir.createFile(\"file_of_newlines.zig\", .{});\n        defer file.close();\n        const path = try fs.path.join(allocator, &.{ test_dir_path, \"file_of_newlines.zig\" });\n        defer allocator.free(path);\n\n        var writer = file.writer();\n        const real_file_start = 3 * mem.page_size;\n        try writer.writeByteNTimes('\\n', real_file_start);\n        try writer.writeAll(\"abc\\ndef\");\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = real_file_start + 1, .column = 0 });\n        try expectEqualStrings(\"abc\\n\", output.items);\n        output.clearRetainingCapacity();\n\n        try printLineFromFileAnyOs(output_stream, .{ .file_name = path, .line = real_file_start + 2, .column = 0 });\n        try expectEqualStrings(\"def\\n\", output.items);\n        output.clearRetainingCapacity();\n    }\n}\n\nconst MachoSymbol = struct {\n    strx: u32,\n    addr: u64,\n    size: u32,\n    ofile: u32,\n\n    /// Returns the address from the macho file\n    fn address(self: MachoSymbol) u64 {\n        return self.addr;\n    }\n\n    fn addressLessThan(context: void, lhs: MachoSymbol, rhs: MachoSymbol) bool {\n        _ = context;\n        return lhs.addr < rhs.addr;\n    }\n};\n\n/// Takes ownership of file, even on error.\n/// TODO it's weird to take ownership even on error, rework this code.\nfn mapWholeFile(file: File) ![]align(mem.page_size) const u8 {\n    nosuspend {\n        defer file.close();\n\n        const file_len = math.cast(usize, try file.getEndPos()) orelse math.maxInt(usize);\n        const mapped_mem = try posix.mmap(\n            null,\n            file_len,\n            posix.PROT.READ,\n            .{ .TYPE = .SHARED },\n            file.handle,\n            0,\n        );\n        errdefer posix.munmap(mapped_mem);\n\n        return mapped_mem;\n    }\n}\n\npub const WindowsModuleInfo = struct {\n    base_address: usize,\n    size: u32,\n    name: []const u8,\n    handle: windows.HMODULE,\n\n    // Set when the image file needed to be mapped from disk\n    mapped_file: ?struct {\n        file: File,\n        section_handle: windows.HANDLE,\n        section_view: []const u8,\n\n        pub fn deinit(self: @This()) void {\n            const process_handle = windows.kernel32.GetCurrentProcess();\n            assert(windows.ntdll.NtUnmapViewOfSection(process_handle, @constCast(@ptrCast(self.section_view.ptr))) == .SUCCESS);\n            windows.CloseHandle(self.section_handle);\n            self.file.close();\n        }\n    } = null,\n};\n\npub const DebugInfo = struct {\n    allocator: mem.Allocator,\n    address_map: std.AutoHashMap(usize, *ModuleDebugInfo),\n    modules: if (native_os == .windows) std.ArrayListUnmanaged(WindowsModuleInfo) else void,\n\n    pub fn init(allocator: mem.Allocator) !DebugInfo {\n        var debug_info = DebugInfo{\n            .allocator = allocator,\n            .address_map = std.AutoHashMap(usize, *ModuleDebugInfo).init(allocator),\n            .modules = if (native_os == .windows) .{} else {},\n        };\n\n        if (native_os == .windows) {\n            errdefer debug_info.modules.deinit(allocator);\n\n            const handle = windows.kernel32.CreateToolhelp32Snapshot(windows.TH32CS_SNAPMODULE | windows.TH32CS_SNAPMODULE32, 0);\n            if (handle == windows.INVALID_HANDLE_VALUE) {\n                switch (windows.kernel32.GetLastError()) {\n                    else => |err| return windows.unexpectedError(err),\n                }\n            }\n            defer windows.CloseHandle(handle);\n\n            var module_entry: windows.MODULEENTRY32 = undefined;\n            module_entry.dwSize = @sizeOf(windows.MODULEENTRY32);\n            if (windows.kernel32.Module32First(handle, &module_entry) == 0) {\n                return error.MissingDebugInfo;\n            }\n\n            var module_valid = true;\n            while (module_valid) {\n                const module_info = try debug_info.modules.addOne(allocator);\n                const name = allocator.dupe(u8, mem.sliceTo(&module_entry.szModule, 0)) catch &.{};\n                errdefer allocator.free(name);\n\n                module_info.* = .{\n                    .base_address = @intFromPtr(module_entry.modBaseAddr),\n                    .size = module_entry.modBaseSize,\n                    .name = name,\n                    .handle = module_entry.hModule,\n                };\n\n                module_valid = windows.kernel32.Module32Next(handle, &module_entry) == 1;\n            }\n        }\n\n        return debug_info;\n    }\n\n    pub fn deinit(self: *DebugInfo) void {\n        var it = self.address_map.iterator();\n        while (it.next()) |entry| {\n            const mdi = entry.value_ptr.*;\n            mdi.deinit(self.allocator);\n            self.allocator.destroy(mdi);\n        }\n        self.address_map.deinit();\n        if (native_os == .windows) {\n            for (self.modules.items) |module| {\n                self.allocator.free(module.name);\n                if (module.mapped_file) |mapped_file| mapped_file.deinit();\n            }\n            self.modules.deinit(self.allocator);\n        }\n    }\n\n    pub fn getModuleForAddress(self: *DebugInfo, address: usize) !*ModuleDebugInfo {\n        if (comptime builtin.target.isDarwin()) {\n            return self.lookupModuleDyld(address);\n        } else if (native_os == .windows) {\n            return self.lookupModuleWin32(address);\n        } else if (native_os == .haiku) {\n            return self.lookupModuleHaiku(address);\n        } else if (comptime builtin.target.isWasm()) {\n            return self.lookupModuleWasm(address);\n        } else {\n            return self.lookupModuleDl(address);\n        }\n    }\n\n    // Returns the module name for a given address.\n    // This can be called when getModuleForAddress fails, so implementations should provide\n    // a path that doesn't rely on any side-effects of a prior successful module lookup.\n    pub fn getModuleNameForAddress(self: *DebugInfo, address: usize) ?[]const u8 {\n        if (comptime builtin.target.isDarwin()) {\n            return self.lookupModuleNameDyld(address);\n        } else if (native_os == .windows) {\n            return self.lookupModuleNameWin32(address);\n        } else if (native_os == .haiku) {\n            return null;\n        } else if (comptime builtin.target.isWasm()) {\n            return null;\n        } else {\n            return self.lookupModuleNameDl(address);\n        }\n    }\n\n    fn lookupModuleDyld(self: *DebugInfo, address: usize) !*ModuleDebugInfo {\n        const image_count = std.c._dyld_image_count();\n\n        var i: u32 = 0;\n        while (i < image_count) : (i += 1) {\n            const header = std.c._dyld_get_image_header(i) orelse continue;\n            const base_address = @intFromPtr(header);\n            if (address < base_address) continue;\n            const vmaddr_slide = std.c._dyld_get_image_vmaddr_slide(i);\n\n            var it = macho.LoadCommandIterator{\n                .ncmds = header.ncmds,\n                .buffer = @alignCast(@as(\n                    [*]u8,\n                    @ptrFromInt(@intFromPtr(header) + @sizeOf(macho.mach_header_64)),\n                )[0..header.sizeofcmds]),\n            };\n\n            var unwind_info: ?[]const u8 = null;\n            var eh_frame: ?[]const u8 = null;\n            while (it.next()) |cmd| switch (cmd.cmd()) {\n                .SEGMENT_64 => {\n                    const segment_cmd = cmd.cast(macho.segment_command_64).?;\n                    if (!mem.eql(u8, \"__TEXT\", segment_cmd.segName())) continue;\n\n                    const seg_start = segment_cmd.vmaddr + vmaddr_slide;\n                    const seg_end = seg_start + segment_cmd.vmsize;\n                    if (address >= seg_start and address < seg_end) {\n                        if (self.address_map.get(base_address)) |obj_di| {\n                            return obj_di;\n                        }\n\n                        for (cmd.getSections()) |sect| {\n                            if (mem.eql(u8, \"__unwind_info\", sect.sectName())) {\n                                unwind_info = @as([*]const u8, @ptrFromInt(sect.addr + vmaddr_slide))[0..sect.size];\n                            } else if (mem.eql(u8, \"__eh_frame\", sect.sectName())) {\n                                eh_frame = @as([*]const u8, @ptrFromInt(sect.addr + vmaddr_slide))[0..sect.size];\n                            }\n                        }\n\n                        const obj_di = try self.allocator.create(ModuleDebugInfo);\n                        errdefer self.allocator.destroy(obj_di);\n\n                        const macho_path = mem.sliceTo(std.c._dyld_get_image_name(i), 0);\n                        const macho_file = fs.cwd().openFile(macho_path, .{}) catch |err| switch (err) {\n                            error.FileNotFound => return error.MissingDebugInfo,\n                            else => return err,\n                        };\n                        obj_di.* = try readMachODebugInfo(self.allocator, macho_file);\n                        obj_di.base_address = base_address;\n                        obj_di.vmaddr_slide = vmaddr_slide;\n                        obj_di.unwind_info = unwind_info;\n                        obj_di.eh_frame = eh_frame;\n\n                        try self.address_map.putNoClobber(base_address, obj_di);\n\n                        return obj_di;\n                    }\n                },\n                else => {},\n            };\n        }\n\n        return error.MissingDebugInfo;\n    }\n\n    fn lookupModuleNameDyld(self: *DebugInfo, address: usize) ?[]const u8 {\n        _ = self;\n        const image_count = std.c._dyld_image_count();\n\n        var i: u32 = 0;\n        while (i < image_count) : (i += 1) {\n            const header = std.c._dyld_get_image_header(i) orelse continue;\n            const base_address = @intFromPtr(header);\n            if (address < base_address) continue;\n            const vmaddr_slide = std.c._dyld_get_image_vmaddr_slide(i);\n\n            var it = macho.LoadCommandIterator{\n                .ncmds = header.ncmds,\n                .buffer = @alignCast(@as(\n                    [*]u8,\n                    @ptrFromInt(@intFromPtr(header) + @sizeOf(macho.mach_header_64)),\n                )[0..header.sizeofcmds]),\n            };\n\n            while (it.next()) |cmd| switch (cmd.cmd()) {\n                .SEGMENT_64 => {\n                    const segment_cmd = cmd.cast(macho.segment_command_64).?;\n                    if (!mem.eql(u8, \"__TEXT\", segment_cmd.segName())) continue;\n\n                    const original_address = address - vmaddr_slide;\n                    const seg_start = segment_cmd.vmaddr;\n                    const seg_end = seg_start + segment_cmd.vmsize;\n                    if (original_address >= seg_start and original_address < seg_end) {\n                        return fs.path.basename(mem.sliceTo(std.c._dyld_get_image_name(i), 0));\n                    }\n                },\n                else => {},\n            };\n        }\n\n        return null;\n    }\n\n    fn lookupModuleWin32(self: *DebugInfo, address: usize) !*ModuleDebugInfo {\n        for (self.modules.items) |*module| {\n            if (address >= module.base_address and address < module.base_address + module.size) {\n                if (self.address_map.get(module.base_address)) |obj_di| {\n                    return obj_di;\n                }\n\n                const obj_di = try self.allocator.create(ModuleDebugInfo);\n                errdefer self.allocator.destroy(obj_di);\n\n                const mapped_module = @as([*]const u8, @ptrFromInt(module.base_address))[0..module.size];\n                var coff_obj = try coff.Coff.init(mapped_module, true);\n\n                // The string table is not mapped into memory by the loader, so if a section name is in the\n                // string table then we have to map the full image file from disk. This can happen when\n                // a binary is produced with -gdwarf, since the section names are longer than 8 bytes.\n                if (coff_obj.strtabRequired()) {\n                    var name_buffer: [windows.PATH_MAX_WIDE + 4:0]u16 = undefined;\n                    // openFileAbsoluteW requires the prefix to be present\n                    @memcpy(name_buffer[0..4], &[_]u16{ '\\\\', '?', '?', '\\\\' });\n\n                    const process_handle = windows.kernel32.GetCurrentProcess();\n                    const len = windows.kernel32.K32GetModuleFileNameExW(\n                        process_handle,\n                        module.handle,\n                        @ptrCast(&name_buffer[4]),\n                        windows.PATH_MAX_WIDE,\n                    );\n\n                    if (len == 0) return error.MissingDebugInfo;\n                    const coff_file = fs.openFileAbsoluteW(name_buffer[0 .. len + 4 :0], .{}) catch |err| switch (err) {\n                        error.FileNotFound => return error.MissingDebugInfo,\n                        else => return err,\n                    };\n                    errdefer coff_file.close();\n\n                    var section_handle: windows.HANDLE = undefined;\n                    const create_section_rc = windows.ntdll.NtCreateSection(\n                        &section_handle,\n                        windows.STANDARD_RIGHTS_REQUIRED | windows.SECTION_QUERY | windows.SECTION_MAP_READ,\n                        null,\n                        null,\n                        windows.PAGE_READONLY,\n                        // The documentation states that if no AllocationAttribute is specified, then SEC_COMMIT is the default.\n                        // In practice, this isn't the case and specifying 0 will result in INVALID_PARAMETER_6.\n                        windows.SEC_COMMIT,\n                        coff_file.handle,\n                    );\n                    if (create_section_rc != .SUCCESS) return error.MissingDebugInfo;\n                    errdefer windows.CloseHandle(section_handle);\n\n                    var coff_len: usize = 0;\n                    var base_ptr: usize = 0;\n                    const map_section_rc = windows.ntdll.NtMapViewOfSection(\n                        section_handle,\n                        process_handle,\n                        @ptrCast(&base_ptr),\n                        null,\n                        0,\n                        null,\n                        &coff_len,\n                        .ViewUnmap,\n                        0,\n                        windows.PAGE_READONLY,\n                    );\n                    if (map_section_rc != .SUCCESS) return error.MissingDebugInfo;\n                    errdefer assert(windows.ntdll.NtUnmapViewOfSection(process_handle, @ptrFromInt(base_ptr)) == .SUCCESS);\n\n                    const section_view = @as([*]const u8, @ptrFromInt(base_ptr))[0..coff_len];\n                    coff_obj = try coff.Coff.init(section_view, false);\n\n                    module.mapped_file = .{\n                        .file = coff_file,\n                        .section_handle = section_handle,\n                        .section_view = section_view,\n                    };\n                }\n                errdefer if (module.mapped_file) |mapped_file| mapped_file.deinit();\n\n                obj_di.* = try readCoffDebugInfo(self.allocator, &coff_obj);\n                obj_di.base_address = module.base_address;\n\n                try self.address_map.putNoClobber(module.base_address, obj_di);\n                return obj_di;\n            }\n        }\n\n        return error.MissingDebugInfo;\n    }\n\n    fn lookupModuleNameWin32(self: *DebugInfo, address: usize) ?[]const u8 {\n        for (self.modules.items) |module| {\n            if (address >= module.base_address and address < module.base_address + module.size) {\n                return module.name;\n            }\n        }\n        return null;\n    }\n\n    fn lookupModuleNameDl(self: *DebugInfo, address: usize) ?[]const u8 {\n        _ = self;\n\n        var ctx: struct {\n            // Input\n            address: usize,\n            // Output\n            name: []const u8 = \"\",\n        } = .{ .address = address };\n        const CtxTy = @TypeOf(ctx);\n\n        if (posix.dl_iterate_phdr(&ctx, error{Found}, struct {\n            fn callback(info: *posix.dl_phdr_info, size: usize, context: *CtxTy) !void {\n                _ = size;\n                if (context.address < info.dlpi_addr) return;\n                const phdrs = info.dlpi_phdr[0..info.dlpi_phnum];\n                for (phdrs) |*phdr| {\n                    if (phdr.p_type != elf.PT_LOAD) continue;\n\n                    const seg_start = info.dlpi_addr +% phdr.p_vaddr;\n                    const seg_end = seg_start + phdr.p_memsz;\n                    if (context.address >= seg_start and context.address < seg_end) {\n                        context.name = mem.sliceTo(info.dlpi_name, 0) orelse \"\";\n                        break;\n                    }\n                } else return;\n\n                return error.Found;\n            }\n        }.callback)) {\n            return null;\n        } else |err| switch (err) {\n            error.Found => return fs.path.basename(ctx.name),\n        }\n\n        return null;\n    }\n\n    fn lookupModuleDl(self: *DebugInfo, address: usize) !*ModuleDebugInfo {\n        var ctx: struct {\n            // Input\n            address: usize,\n            // Output\n            base_address: usize = undefined,\n            name: []const u8 = undefined,\n            build_id: ?[]const u8 = null,\n            gnu_eh_frame: ?[]const u8 = null,\n        } = .{ .address = address };\n        const CtxTy = @TypeOf(ctx);\n\n        if (posix.dl_iterate_phdr(&ctx, error{Found}, struct {\n            fn callback(info: *posix.dl_phdr_info, size: usize, context: *CtxTy) !void {\n                _ = size;\n                // The base address is too high\n                if (context.address < info.dlpi_addr)\n                    return;\n\n                const phdrs = info.dlpi_phdr[0..info.dlpi_phnum];\n                for (phdrs) |*phdr| {\n                    if (phdr.p_type != elf.PT_LOAD) continue;\n\n                    // Overflowing addition is used to handle the case of VSDOs having a p_vaddr = 0xffffffffff700000\n                    const seg_start = info.dlpi_addr +% phdr.p_vaddr;\n                    const seg_end = seg_start + phdr.p_memsz;\n                    if (context.address >= seg_start and context.address < seg_end) {\n                        // Android libc uses NULL instead of an empty string to mark the\n                        // main program\n                        context.name = mem.sliceTo(info.dlpi_name, 0) orelse \"\";\n                        context.base_address = info.dlpi_addr;\n                        break;\n                    }\n                } else return;\n\n                for (info.dlpi_phdr[0..info.dlpi_phnum]) |phdr| {\n                    switch (phdr.p_type) {\n                        elf.PT_NOTE => {\n                            // Look for .note.gnu.build-id\n                            const note_bytes = @as([*]const u8, @ptrFromInt(info.dlpi_addr + phdr.p_vaddr))[0..phdr.p_memsz];\n                            const name_size = mem.readInt(u32, note_bytes[0..4], native_endian);\n                            if (name_size != 4) continue;\n                            const desc_size = mem.readInt(u32, note_bytes[4..8], native_endian);\n                            const note_type = mem.readInt(u32, note_bytes[8..12], native_endian);\n                            if (note_type != elf.NT_GNU_BUILD_ID) continue;\n                            if (!mem.eql(u8, \"GNU\\x00\", note_bytes[12..16])) continue;\n                            context.build_id = note_bytes[16..][0..desc_size];\n                        },\n                        elf.PT_GNU_EH_FRAME => {\n                            context.gnu_eh_frame = @as([*]const u8, @ptrFromInt(info.dlpi_addr + phdr.p_vaddr))[0..phdr.p_memsz];\n                        },\n                        else => {},\n                    }\n                }\n\n                // Stop the iteration\n                return error.Found;\n            }\n        }.callback)) {\n            return error.MissingDebugInfo;\n        } else |err| switch (err) {\n            error.Found => {},\n        }\n\n        if (self.address_map.get(ctx.base_address)) |obj_di| {\n            return obj_di;\n        }\n\n        const obj_di = try self.allocator.create(ModuleDebugInfo);\n        errdefer self.allocator.destroy(obj_di);\n\n        var sections: DW.DwarfInfo.SectionArray = DW.DwarfInfo.null_section_array;\n        if (ctx.gnu_eh_frame) |eh_frame_hdr| {\n            // This is a special case - pointer offsets inside .eh_frame_hdr\n            // are encoded relative to its base address, so we must use the\n            // version that is already memory mapped, and not the one that\n            // will be mapped separately from the ELF file.\n            sections[@intFromEnum(DW.DwarfSection.eh_frame_hdr)] = .{\n                .data = eh_frame_hdr,\n                .owned = false,\n            };\n        }\n\n        obj_di.* = try readElfDebugInfo(self.allocator, if (ctx.name.len > 0) ctx.name else null, ctx.build_id, null, &sections, null);\n        obj_di.base_address = ctx.base_address;\n\n        // Missing unwind info isn't treated as a failure, as the unwinder will fall back to FP-based unwinding\n        obj_di.dwarf.scanAllUnwindInfo(self.allocator, ctx.base_address) catch {};\n\n        try self.address_map.putNoClobber(ctx.base_address, obj_di);\n\n        return obj_di;\n    }\n\n    fn lookupModuleHaiku(self: *DebugInfo, address: usize) !*ModuleDebugInfo {\n        _ = self;\n        _ = address;\n        @panic(\"TODO implement lookup module for Haiku\");\n    }\n\n    fn lookupModuleWasm(self: *DebugInfo, address: usize) !*ModuleDebugInfo {\n        _ = self;\n        _ = address;\n        @panic(\"TODO implement lookup module for Wasm\");\n    }\n};\n\npub const ModuleDebugInfo = switch (native_os) {\n    .macos, .ios, .watchos, .tvos, .visionos => struct {\n        base_address: usize,\n        vmaddr_slide: usize,\n        mapped_memory: []align(mem.page_size) const u8,\n        symbols: []const MachoSymbol,\n        strings: [:0]const u8,\n        ofiles: OFileTable,\n\n        // Backed by the in-memory sections mapped by the loader\n        unwind_info: ?[]const u8 = null,\n        eh_frame: ?[]const u8 = null,\n\n        const OFileTable = std.StringHashMap(OFileInfo);\n        const OFileInfo = struct {\n            di: DW.DwarfInfo,\n            addr_table: std.StringHashMap(u64),\n        };\n\n        pub fn deinit(self: *@This(), allocator: mem.Allocator) void {\n            var it = self.ofiles.iterator();\n            while (it.next()) |entry| {\n                const ofile = entry.value_ptr;\n                ofile.di.deinit(allocator);\n                ofile.addr_table.deinit();\n            }\n            self.ofiles.deinit();\n            allocator.free(self.symbols);\n            posix.munmap(self.mapped_memory);\n        }\n\n        fn loadOFile(self: *@This(), allocator: mem.Allocator, o_file_path: []const u8) !*OFileInfo {\n            const o_file = try fs.cwd().openFile(o_file_path, .{});\n            const mapped_mem = try mapWholeFile(o_file);\n\n            const hdr: *const macho.mach_header_64 = @ptrCast(@alignCast(mapped_mem.ptr));\n            if (hdr.magic != std.macho.MH_MAGIC_64)\n                return error.InvalidDebugInfo;\n\n            var segcmd: ?macho.LoadCommandIterator.LoadCommand = null;\n            var symtabcmd: ?macho.symtab_command = null;\n            var it = macho.LoadCommandIterator{\n                .ncmds = hdr.ncmds,\n                .buffer = mapped_mem[@sizeOf(macho.mach_header_64)..][0..hdr.sizeofcmds],\n            };\n            while (it.next()) |cmd| switch (cmd.cmd()) {\n                .SEGMENT_64 => segcmd = cmd,\n                .SYMTAB => symtabcmd = cmd.cast(macho.symtab_command).?,\n                else => {},\n            };\n\n            if (segcmd == null or symtabcmd == null) return error.MissingDebugInfo;\n\n            // Parse symbols\n            const strtab = @as(\n                [*]const u8,\n                @ptrCast(&mapped_mem[symtabcmd.?.stroff]),\n            )[0 .. symtabcmd.?.strsize - 1 :0];\n            const symtab = @as(\n                [*]const macho.nlist_64,\n                @ptrCast(@alignCast(&mapped_mem[symtabcmd.?.symoff])),\n            )[0..symtabcmd.?.nsyms];\n\n            // TODO handle tentative (common) symbols\n            var addr_table = std.StringHashMap(u64).init(allocator);\n            try addr_table.ensureTotalCapacity(@as(u32, @intCast(symtab.len)));\n            for (symtab) |sym| {\n                if (sym.n_strx == 0) continue;\n                if (sym.undf() or sym.tentative() or sym.abs()) continue;\n                const sym_name = mem.sliceTo(strtab[sym.n_strx..], 0);\n                // TODO is it possible to have a symbol collision?\n                addr_table.putAssumeCapacityNoClobber(sym_name, sym.n_value);\n            }\n\n            var sections: DW.DwarfInfo.SectionArray = DW.DwarfInfo.null_section_array;\n            if (self.eh_frame) |eh_frame| sections[@intFromEnum(DW.DwarfSection.eh_frame)] = .{\n                .data = eh_frame,\n                .owned = false,\n            };\n\n            for (segcmd.?.getSections()) |sect| {\n                if (!std.mem.eql(u8, \"__DWARF\", sect.segName())) continue;\n\n                var section_index: ?usize = null;\n                inline for (@typeInfo(DW.DwarfSection).Enum.fields, 0..) |section, i| {\n                    if (mem.eql(u8, \"__\" ++ section.name, sect.sectName())) section_index = i;\n                }\n                if (section_index == null) continue;\n\n                const section_bytes = try chopSlice(mapped_mem, sect.offset, sect.size);\n                sections[section_index.?] = .{\n                    .data = section_bytes,\n                    .virtual_address = sect.addr,\n                    .owned = false,\n                };\n            }\n\n            const missing_debug_info =\n                sections[@intFromEnum(DW.DwarfSection.debug_info)] == null or\n                sections[@intFromEnum(DW.DwarfSection.debug_abbrev)] == null or\n                sections[@intFromEnum(DW.DwarfSection.debug_str)] == null or\n                sections[@intFromEnum(DW.DwarfSection.debug_line)] == null;\n            if (missing_debug_info) return error.MissingDebugInfo;\n\n            var di = DW.DwarfInfo{\n                .endian = .little,\n                .sections = sections,\n                .is_macho = true,\n            };\n\n            try DW.openDwarfDebugInfo(&di, allocator);\n            const info = OFileInfo{\n                .di = di,\n                .addr_table = addr_table,\n            };\n\n            // Add the debug info to the cache\n            const result = try self.ofiles.getOrPut(o_file_path);\n            assert(!result.found_existing);\n            result.value_ptr.* = info;\n\n            return result.value_ptr;\n        }\n\n        pub fn getSymbolAtAddress(self: *@This(), allocator: mem.Allocator, address: usize) !SymbolInfo {\n            nosuspend {\n                const result = try self.getOFileInfoForAddress(allocator, address);\n                if (result.symbol == null) return .{};\n\n                // Take the symbol name from the N_FUN STAB entry, we're going to\n                // use it if we fail to find the DWARF infos\n                const stab_symbol = mem.sliceTo(self.strings[result.symbol.?.strx..], 0);\n                if (result.o_file_info == null) return .{ .symbol_name = stab_symbol };\n\n                // Translate again the address, this time into an address inside the\n                // .o file\n                const relocated_address_o = result.o_file_info.?.addr_table.get(stab_symbol) orelse return .{\n                    .symbol_name = \"???\",\n                };\n\n                const addr_off = result.relocated_address - result.symbol.?.addr;\n                const o_file_di = &result.o_file_info.?.di;\n                if (o_file_di.findCompileUnit(relocated_address_o)) |compile_unit| {\n                    return SymbolInfo{\n                        .symbol_name = o_file_di.getSymbolName(relocated_address_o) orelse \"???\",\n                        .compile_unit_name = compile_unit.die.getAttrString(\n                            o_file_di,\n                            DW.AT.name,\n                            o_file_di.section(.debug_str),\n                            compile_unit.*,\n                        ) catch |err| switch (err) {\n                            error.MissingDebugInfo, error.InvalidDebugInfo => \"???\",\n                        },\n                        .line_info = o_file_di.getLineNumberInfo(\n                            allocator,\n                            compile_unit.*,\n                            relocated_address_o + addr_off,\n                        ) catch |err| switch (err) {\n                            error.MissingDebugInfo, error.InvalidDebugInfo => null,\n                            else => return err,\n                        },\n                    };\n                } else |err| switch (err) {\n                    error.MissingDebugInfo, error.InvalidDebugInfo => {\n                        return SymbolInfo{ .symbol_name = stab_symbol };\n                    },\n                    else => return err,\n                }\n            }\n        }\n\n        pub fn getOFileInfoForAddress(self: *@This(), allocator: mem.Allocator, address: usize) !struct {\n            relocated_address: usize,\n            symbol: ?*const MachoSymbol = null,\n            o_file_info: ?*OFileInfo = null,\n        } {\n            nosuspend {\n                // Translate the VA into an address into this object\n                const relocated_address = address - self.vmaddr_slide;\n\n                // Find the .o file where this symbol is defined\n                const symbol = machoSearchSymbols(self.symbols, relocated_address) orelse return .{\n                    .relocated_address = relocated_address,\n                };\n\n                // Check if its debug infos are already in the cache\n                const o_file_path = mem.sliceTo(self.strings[symbol.ofile..], 0);\n                const o_file_info = self.ofiles.getPtr(o_file_path) orelse\n                    (self.loadOFile(allocator, o_file_path) catch |err| switch (err) {\n                    error.FileNotFound,\n                    error.MissingDebugInfo,\n                    error.InvalidDebugInfo,\n                    => return .{\n                        .relocated_address = relocated_address,\n                        .symbol = symbol,\n                    },\n                    else => return err,\n                });\n\n                return .{\n                    .relocated_address = relocated_address,\n                    .symbol = symbol,\n                    .o_file_info = o_file_info,\n                };\n            }\n        }\n\n        pub fn getDwarfInfoForAddress(self: *@This(), allocator: mem.Allocator, address: usize) !?*const DW.DwarfInfo {\n            return if ((try self.getOFileInfoForAddress(allocator, address)).o_file_info) |o_file_info| &o_file_info.di else null;\n        }\n    },\n    .uefi, .windows => struct {\n        base_address: usize,\n        pdb: ?pdb.Pdb = null,\n        dwarf: ?DW.DwarfInfo = null,\n        coff_image_base: u64,\n\n        /// Only used if pdb is non-null\n        coff_section_headers: []coff.SectionHeader,\n\n        pub fn deinit(self: *@This(), allocator: mem.Allocator) void {\n            if (self.dwarf) |*dwarf| {\n                dwarf.deinit(allocator);\n            }\n\n            if (self.pdb) |*p| {\n                p.deinit();\n                allocator.free(self.coff_section_headers);\n            }\n        }\n\n        fn getSymbolFromPdb(self: *@This(), relocated_address: usize) !?SymbolInfo {\n            var coff_section: *align(1) const coff.SectionHeader = undefined;\n            const mod_index = for (self.pdb.?.sect_contribs) |sect_contrib| {\n                if (sect_contrib.Section > self.coff_section_headers.len) continue;\n                // Remember that SectionContribEntry.Section is 1-based.\n                coff_section = &self.coff_section_headers[sect_contrib.Section - 1];\n\n                const vaddr_start = coff_section.virtual_address + sect_contrib.Offset;\n                const vaddr_end = vaddr_start + sect_contrib.Size;\n                if (relocated_address >= vaddr_start and relocated_address < vaddr_end) {\n                    break sect_contrib.ModuleIndex;\n                }\n            } else {\n                // we have no information to add to the address\n                return null;\n            };\n\n            const module = (try self.pdb.?.getModule(mod_index)) orelse\n                return error.InvalidDebugInfo;\n            const obj_basename = fs.path.basename(module.obj_file_name);\n\n            const symbol_name = self.pdb.?.getSymbolName(\n                module,\n                relocated_address - coff_section.virtual_address,\n            ) orelse \"???\";\n            const opt_line_info = try self.pdb.?.getLineNumberInfo(\n                module,\n                relocated_address - coff_section.virtual_address,\n            );\n\n            return SymbolInfo{\n                .symbol_name = symbol_name,\n                .compile_unit_name = obj_basename,\n                .line_info = opt_line_info,\n            };\n        }\n\n        pub fn getSymbolAtAddress(self: *@This(), allocator: mem.Allocator, address: usize) !SymbolInfo {\n            // Translate the VA into an address into this object\n            const relocated_address = address - self.base_address;\n\n            if (self.pdb != null) {\n                if (try self.getSymbolFromPdb(relocated_address)) |symbol| return symbol;\n            }\n\n            if (self.dwarf) |*dwarf| {\n                const dwarf_address = relocated_address + self.coff_image_base;\n                return getSymbolFromDwarf(allocator, dwarf_address, dwarf);\n            }\n\n            return SymbolInfo{};\n        }\n\n        pub fn getDwarfInfoForAddress(self: *@This(), allocator: mem.Allocator, address: usize) !?*const DW.DwarfInfo {\n            _ = allocator;\n            _ = address;\n\n            return switch (self.debug_data) {\n                .dwarf => |*dwarf| dwarf,\n                else => null,\n            };\n        }\n    },\n    .linux, .netbsd, .freebsd, .dragonfly, .openbsd, .haiku, .solaris, .illumos => struct {\n        base_address: usize,\n        dwarf: DW.DwarfInfo,\n        mapped_memory: []align(mem.page_size) const u8,\n        external_mapped_memory: ?[]align(mem.page_size) const u8,\n\n        pub fn deinit(self: *@This(), allocator: mem.Allocator) void {\n            self.dwarf.deinit(allocator);\n            posix.munmap(self.mapped_memory);\n            if (self.external_mapped_memory) |m| posix.munmap(m);\n        }\n\n        pub fn getSymbolAtAddress(self: *@This(), allocator: mem.Allocator, address: usize) !SymbolInfo {\n            // Translate the VA into an address into this object\n            const relocated_address = address - self.base_address;\n            return getSymbolFromDwarf(allocator, relocated_address, &self.dwarf);\n        }\n\n        pub fn getDwarfInfoForAddress(self: *@This(), allocator: mem.Allocator, address: usize) !?*const DW.DwarfInfo {\n            _ = allocator;\n            _ = address;\n            return &self.dwarf;\n        }\n    },\n    .wasi, .emscripten => struct {\n        pub fn deinit(self: *@This(), allocator: mem.Allocator) void {\n            _ = self;\n            _ = allocator;\n        }\n\n        pub fn getSymbolAtAddress(self: *@This(), allocator: mem.Allocator, address: usize) !SymbolInfo {\n            _ = self;\n            _ = allocator;\n            _ = address;\n            return SymbolInfo{};\n        }\n\n        pub fn getDwarfInfoForAddress(self: *@This(), allocator: mem.Allocator, address: usize) !?*const DW.DwarfInfo {\n            _ = self;\n            _ = allocator;\n            _ = address;\n            return null;\n        }\n    },\n    else => DW.DwarfInfo,\n};\n\nfn getSymbolFromDwarf(allocator: mem.Allocator, address: u64, di: *DW.DwarfInfo) !SymbolInfo {\n    if (nosuspend di.findCompileUnit(address)) |compile_unit| {\n        return SymbolInfo{\n            .symbol_name = nosuspend di.getSymbolName(address) orelse \"???\",\n            .compile_unit_name = compile_unit.die.getAttrString(di, DW.AT.name, di.section(.debug_str), compile_unit.*) catch |err| switch (err) {\n                error.MissingDebugInfo, error.InvalidDebugInfo => \"???\",\n            },\n            .line_info = nosuspend di.getLineNumberInfo(allocator, compile_unit.*, address) catch |err| switch (err) {\n                error.MissingDebugInfo, error.InvalidDebugInfo => null,\n                else => return err,\n            },\n        };\n    } else |err| switch (err) {\n        error.MissingDebugInfo, error.InvalidDebugInfo => {\n            return SymbolInfo{};\n        },\n        else => return err,\n    }\n}\n\n/// TODO multithreaded awareness\nvar debug_info_allocator: ?mem.Allocator = null;\nvar debug_info_arena_allocator: std.heap.ArenaAllocator = undefined;\nfn getDebugInfoAllocator() mem.Allocator {\n    if (debug_info_allocator) |a| return a;\n\n    debug_info_arena_allocator = std.heap.ArenaAllocator.init(std.heap.page_allocator);\n    const allocator = debug_info_arena_allocator.allocator();\n    debug_info_allocator = allocator;\n    return allocator;\n}\n\n/// Whether or not the current target can print useful debug information when a segfault occurs.\npub const have_segfault_handling_support = switch (native_os) {\n    .linux,\n    .macos,\n    .netbsd,\n    .solaris,\n    .illumos,\n    .windows,\n    => true,\n\n    .freebsd, .openbsd => @hasDecl(std.c, \"ucontext_t\"),\n    else => false,\n};\n\nconst enable_segfault_handler = std.options.enable_segfault_handler;\npub const default_enable_segfault_handler = runtime_safety and have_segfault_handling_support;\n\npub fn maybeEnableSegfaultHandler() void {\n    if (enable_segfault_handler) {\n        std.debug.attachSegfaultHandler();\n    }\n}\n\nvar windows_segfault_handle: ?windows.HANDLE = null;\n\npub fn updateSegfaultHandler(act: ?*const posix.Sigaction) error{OperationNotSupported}!void {\n    try posix.sigaction(posix.SIG.SEGV, act, null);\n    try posix.sigaction(posix.SIG.ILL, act, null);\n    try posix.sigaction(posix.SIG.BUS, act, null);\n    try posix.sigaction(posix.SIG.FPE, act, null);\n}\n\n/// Attaches a global SIGSEGV handler which calls `@panic(\"segmentation fault\");`\npub fn attachSegfaultHandler() void {\n    if (!have_segfault_handling_support) {\n        @compileError(\"segfault handler not supported for this target\");\n    }\n    if (native_os == .windows) {\n        windows_segfault_handle = windows.kernel32.AddVectoredExceptionHandler(0, handleSegfaultWindows);\n        return;\n    }\n    var act = posix.Sigaction{\n        .handler = .{ .sigaction = handleSegfaultPosix },\n        .mask = posix.empty_sigset,\n        .flags = (posix.SA.SIGINFO | posix.SA.RESTART | posix.SA.RESETHAND),\n    };\n\n    updateSegfaultHandler(&act) catch {\n        @panic(\"unable to install segfault handler, maybe adjust have_segfault_handling_support in std/debug.zig\");\n    };\n}\n\nfn resetSegfaultHandler() void {\n    if (native_os == .windows) {\n        if (windows_segfault_handle) |handle| {\n            assert(windows.kernel32.RemoveVectoredExceptionHandler(handle) != 0);\n            windows_segfault_handle = null;\n        }\n        return;\n    }\n    var act = posix.Sigaction{\n        .handler = .{ .handler = posix.SIG.DFL },\n        .mask = posix.empty_sigset,\n        .flags = 0,\n    };\n    // To avoid a double-panic, do nothing if an error happens here.\n    updateSegfaultHandler(&act) catch {};\n}\n\nfn handleSegfaultPosix(sig: i32, info: *const posix.siginfo_t, ctx_ptr: ?*anyopaque) callconv(.C) noreturn {\n    // Reset to the default handler so that if a segfault happens in this handler it will crash\n    // the process. Also when this handler returns, the original instruction will be repeated\n    // and the resulting segfault will crash the process rather than continually dump stack traces.\n    resetSegfaultHandler();\n\n    const addr = switch (native_os) {\n        .linux => @intFromPtr(info.fields.sigfault.addr),\n        .freebsd, .macos => @intFromPtr(info.addr),\n        .netbsd => @intFromPtr(info.info.reason.fault.addr),\n        .openbsd => @intFromPtr(info.data.fault.addr),\n        .solaris, .illumos => @intFromPtr(info.reason.fault.addr),\n        else => unreachable,\n    };\n\n    const code = if (native_os == .netbsd) info.info.code else info.code;\n    nosuspend switch (panic_stage) {\n        0 => {\n            panic_stage = 1;\n            _ = panicking.fetchAdd(1, .seq_cst);\n\n            {\n                panic_mutex.lock();\n                defer panic_mutex.unlock();\n\n                dumpSegfaultInfoPosix(sig, code, addr, ctx_ptr);\n            }\n\n            waitForOtherThreadToFinishPanicking();\n        },\n        else => {\n            // panic mutex already locked\n            dumpSegfaultInfoPosix(sig, code, addr, ctx_ptr);\n        },\n    };\n\n    // We cannot allow the signal handler to return because when it runs the original instruction\n    // again, the memory may be mapped and undefined behavior would occur rather than repeating\n    // the segfault. So we simply abort here.\n    posix.abort();\n}\n\nfn dumpSegfaultInfoPosix(sig: i32, code: i32, addr: usize, ctx_ptr: ?*const anyopaque) void {\n    const stderr = io.getStdErr().writer();\n    _ = switch (sig) {\n        posix.SIG.SEGV => if (native_arch == .x86_64 and native_os == .linux and code == 128) // SI_KERNEL\n            // x86_64 doesn't have a full 64-bit virtual address space.\n            // Addresses outside of that address space are non-canonical\n            // and the CPU won't provide the faulting address to us.\n            // This happens when accessing memory addresses such as 0xaaaaaaaaaaaaaaaa\n            // but can also happen when no addressable memory is involved;\n            // for example when reading/writing model-specific registers\n            // by executing `rdmsr` or `wrmsr` in user-space (unprivileged mode).\n            stderr.print(\"General protection exception (no address available)\\n\", .{})\n        else\n            stderr.print(\"Segmentation fault at address 0x{x}\\n\", .{addr}),\n        posix.SIG.ILL => stderr.print(\"Illegal instruction at address 0x{x}\\n\", .{addr}),\n        posix.SIG.BUS => stderr.print(\"Bus error at address 0x{x}\\n\", .{addr}),\n        posix.SIG.FPE => stderr.print(\"Arithmetic exception at address 0x{x}\\n\", .{addr}),\n        else => unreachable,\n    } catch posix.abort();\n\n    switch (native_arch) {\n        .x86,\n        .x86_64,\n        .arm,\n        .aarch64,\n        => {\n            const ctx: *const posix.ucontext_t = @ptrCast(@alignCast(ctx_ptr));\n            dumpStackTraceFromBase(ctx);\n        },\n        else => {},\n    }\n}\n\nfn handleSegfaultWindows(info: *windows.EXCEPTION_POINTERS) callconv(windows.WINAPI) c_long {\n    switch (info.ExceptionRecord.ExceptionCode) {\n        windows.EXCEPTION_DATATYPE_MISALIGNMENT => handleSegfaultWindowsExtra(info, 0, \"Unaligned Memory Access\"),\n        windows.EXCEPTION_ACCESS_VIOLATION => handleSegfaultWindowsExtra(info, 1, null),\n        windows.EXCEPTION_ILLEGAL_INSTRUCTION => handleSegfaultWindowsExtra(info, 2, null),\n        windows.EXCEPTION_STACK_OVERFLOW => handleSegfaultWindowsExtra(info, 0, \"Stack Overflow\"),\n        else => return windows.EXCEPTION_CONTINUE_SEARCH,\n    }\n}\n\nfn handleSegfaultWindowsExtra(\n    info: *windows.EXCEPTION_POINTERS,\n    msg: u8,\n    label: ?[]const u8,\n) noreturn {\n    const exception_address = @intFromPtr(info.ExceptionRecord.ExceptionAddress);\n    if (@hasDecl(windows, \"CONTEXT\")) {\n        nosuspend switch (panic_stage) {\n            0 => {\n                panic_stage = 1;\n                _ = panicking.fetchAdd(1, .seq_cst);\n\n                {\n                    panic_mutex.lock();\n                    defer panic_mutex.unlock();\n\n                    dumpSegfaultInfoWindows(info, msg, label);\n                }\n\n                waitForOtherThreadToFinishPanicking();\n            },\n            else => {\n                // panic mutex already locked\n                dumpSegfaultInfoWindows(info, msg, label);\n            },\n        };\n        posix.abort();\n    } else {\n        switch (msg) {\n            0 => panicImpl(null, exception_address, \"{s}\", label.?),\n            1 => {\n                const format_item = \"Segmentation fault at address 0x{x}\";\n                var buf: [format_item.len + 64]u8 = undefined; // 64 is arbitrary, but sufficiently large\n                const to_print = std.fmt.bufPrint(buf[0..buf.len], format_item, .{info.ExceptionRecord.ExceptionInformation[1]}) catch unreachable;\n                panicImpl(null, exception_address, to_print);\n            },\n            2 => panicImpl(null, exception_address, \"Illegal Instruction\"),\n            else => unreachable,\n        }\n    }\n}\n\nfn dumpSegfaultInfoWindows(info: *windows.EXCEPTION_POINTERS, msg: u8, label: ?[]const u8) void {\n    const stderr = io.getStdErr().writer();\n    _ = switch (msg) {\n        0 => stderr.print(\"{s}\\n\", .{label.?}),\n        1 => stderr.print(\"Segmentation fault at address 0x{x}\\n\", .{info.ExceptionRecord.ExceptionInformation[1]}),\n        2 => stderr.print(\"Illegal instruction at address 0x{x}\\n\", .{info.ContextRecord.getRegs().ip}),\n        else => unreachable,\n    } catch posix.abort();\n\n    dumpStackTraceFromBase(info.ContextRecord);\n}\n\npub fn dumpStackPointerAddr(prefix: []const u8) void {\n    const sp = asm (\"\"\n        : [argc] \"={rsp}\" (-> usize),\n    );\n    std.debug.print(\"{} sp = 0x{x}\\n\", .{ prefix, sp });\n}\n\ntest \"manage resources correctly\" {\n    if (builtin.strip_debug_info) return error.SkipZigTest;\n\n    if (native_os == .wasi) return error.SkipZigTest;\n\n    if (native_os == .windows) {\n        // https://github.com/ziglang/zig/issues/13963\n        return error.SkipZigTest;\n    }\n\n    const writer = std.io.null_writer;\n    var di = try openSelfDebugInfo(testing.allocator);\n    defer di.deinit();\n    try printSourceAtAddress(&di, writer, showMyTrace(), io.tty.detectConfig(std.io.getStdErr()));\n}\n\nnoinline fn showMyTrace() usize {\n    return @returnAddress();\n}\n\n/// This API helps you track where a value originated and where it was mutated,\n/// or any other points of interest.\n/// In debug mode, it adds a small size penalty (104 bytes on 64-bit architectures)\n/// to the aggregate that you add it to.\n/// In release mode, it is size 0 and all methods are no-ops.\n/// This is a pre-made type with default settings.\n/// For more advanced usage, see `ConfigurableTrace`.\npub const Trace = ConfigurableTrace(2, 4, builtin.mode == .Debug);\n\npub fn ConfigurableTrace(comptime size: usize, comptime stack_frame_count: usize, comptime is_enabled: bool) type {\n    return struct {\n        addrs: [actual_size][stack_frame_count]usize,\n        notes: [actual_size][]const u8,\n        index: Index,\n\n        const actual_size = if (enabled) size else 0;\n        const Index = if (enabled) usize else u0;\n\n        pub const init: @This() = .{\n            .addrs = undefined,\n            .notes = undefined,\n            .index = 0,\n        };\n\n        pub const enabled = is_enabled;\n\n        pub const add = if (enabled) addNoInline else addNoOp;\n\n        pub noinline fn addNoInline(t: *@This(), note: []const u8) void {\n            comptime assert(enabled);\n            return addAddr(t, @returnAddress(), note);\n        }\n\n        pub inline fn addNoOp(t: *@This(), note: []const u8) void {\n            _ = t;\n            _ = note;\n            comptime assert(!enabled);\n        }\n\n        pub fn addAddr(t: *@This(), addr: usize, note: []const u8) void {\n            if (!enabled) return;\n\n            if (t.index < size) {\n                t.notes[t.index] = note;\n                t.addrs[t.index] = [1]usize{0} ** stack_frame_count;\n                var stack_trace: std.builtin.StackTrace = .{\n                    .index = 0,\n                    .instruction_addresses = &t.addrs[t.index],\n                };\n                captureStackTrace(addr, &stack_trace);\n            }\n            // Keep counting even if the end is reached so that the\n            // user can find out how much more size they need.\n            t.index += 1;\n        }\n\n        pub fn dump(t: @This()) void {\n            if (!enabled) return;\n\n            const tty_config = io.tty.detectConfig(std.io.getStdErr());\n            const stderr = io.getStdErr().writer();\n            const end = @min(t.index, size);\n            const debug_info = getSelfDebugInfo() catch |err| {\n                stderr.print(\n                    \"Unable to dump stack trace: Unable to open debug info: {s}\\n\",\n                    .{@errorName(err)},\n                ) catch return;\n                return;\n            };\n            for (t.addrs[0..end], 0..) |frames_array, i| {\n                stderr.print(\"{s}:\\n\", .{t.notes[i]}) catch return;\n                var frames_array_mutable = frames_array;\n                const frames = mem.sliceTo(frames_array_mutable[0..], 0);\n                const stack_trace: std.builtin.StackTrace = .{\n                    .index = frames.len,\n                    .instruction_addresses = frames,\n                };\n                writeStackTrace(stack_trace, stderr, getDebugInfoAllocator(), debug_info, tty_config) catch continue;\n            }\n            if (t.index > end) {\n                stderr.print(\"{d} more traces not shown; consider increasing trace size\\n\", .{\n                    t.index - end,\n                }) catch return;\n            }\n        }\n\n        pub fn format(\n            t: Trace,\n            comptime fmt: []const u8,\n            options: std.fmt.FormatOptions,\n            writer: anytype,\n        ) !void {\n            if (fmt.len != 0) std.fmt.invalidFmtError(fmt, t);\n            _ = options;\n            if (enabled) {\n                try writer.writeAll(\"\\n\");\n                t.dump();\n                try writer.writeAll(\"\\n\");\n            } else {\n                return writer.writeAll(\"(value tracing disabled)\");\n            }\n        }\n    };\n}\n\npub const SafetyLock = struct {\n    state: State = .unlocked,\n\n    pub const State = if (runtime_safety) enum { unlocked, locked } else enum { unlocked };\n\n    pub fn lock(l: *SafetyLock) void {\n        if (!runtime_safety) return;\n        assert(l.state == .unlocked);\n        l.state = .locked;\n    }\n\n    pub fn unlock(l: *SafetyLock) void {\n        if (!runtime_safety) return;\n        assert(l.state == .locked);\n        l.state = .unlocked;\n    }\n\n    pub fn assertUnlocked(l: SafetyLock) void {\n        if (!runtime_safety) return;\n        assert(l.state == .unlocked);\n    }\n};\n\n/// Detect whether the program is being executed in the Valgrind virtual machine.\n///\n/// When Valgrind integrations are disabled, this returns comptime-known false.\n/// Otherwise, the result is runtime-known.\npub inline fn inValgrind() bool {\n    if (@inComptime()) return false;\n    if (!builtin.valgrind_support) return false;\n    return std.valgrind.runningOnValgrind() > 0;\n}\n\ntest {\n    _ = &dump_hex;\n}\n",
    "const std = @import(\"std.zig\");\nconst builtin = @import(\"builtin\");\nconst debug = std.debug;\nconst assert = debug.assert;\nconst math = std.math;\nconst mem = @This();\nconst testing = std.testing;\nconst Endian = std.builtin.Endian;\nconst native_endian = builtin.cpu.arch.endian();\n\n/// Compile time known minimum page size.\n/// https://github.com/ziglang/zig/issues/4082\npub const page_size = switch (builtin.cpu.arch) {\n    .wasm32, .wasm64 => 64 * 1024,\n    .aarch64 => switch (builtin.os.tag) {\n        .macos, .ios, .watchos, .tvos, .visionos => 16 * 1024,\n        else => 4 * 1024,\n    },\n    .sparc64 => 8 * 1024,\n    else => 4 * 1024,\n};\n\n/// The standard library currently thoroughly depends on byte size\n/// being 8 bits.  (see the use of u8 throughout allocation code as\n/// the \"byte\" type.)  Code which depends on this can reference this\n/// declaration.  If we ever try to port the standard library to a\n/// non-8-bit-byte platform, this will allow us to search for things\n/// which need to be updated.\npub const byte_size_in_bits = 8;\n\npub const Allocator = @import(\"mem/Allocator.zig\");\n\n/// Detects and asserts if the std.mem.Allocator interface is violated by the caller\n/// or the allocator.\npub fn ValidationAllocator(comptime T: type) type {\n    return struct {\n        const Self = @This();\n\n        underlying_allocator: T,\n\n        pub fn init(underlying_allocator: T) @This() {\n            return .{\n                .underlying_allocator = underlying_allocator,\n            };\n        }\n\n        pub fn allocator(self: *Self) Allocator {\n            return .{\n                .ptr = self,\n                .vtable = &.{\n                    .alloc = alloc,\n                    .resize = resize,\n                    .free = free,\n                },\n            };\n        }\n\n        fn getUnderlyingAllocatorPtr(self: *Self) Allocator {\n            if (T == Allocator) return self.underlying_allocator;\n            return self.underlying_allocator.allocator();\n        }\n\n        pub fn alloc(\n            ctx: *anyopaque,\n            n: usize,\n            log2_ptr_align: u8,\n            ret_addr: usize,\n        ) ?[*]u8 {\n            assert(n > 0);\n            const self: *Self = @ptrCast(@alignCast(ctx));\n            const underlying = self.getUnderlyingAllocatorPtr();\n            const result = underlying.rawAlloc(n, log2_ptr_align, ret_addr) orelse\n                return null;\n            assert(mem.isAlignedLog2(@intFromPtr(result), log2_ptr_align));\n            return result;\n        }\n\n        pub fn resize(\n            ctx: *anyopaque,\n            buf: []u8,\n            log2_buf_align: u8,\n            new_len: usize,\n            ret_addr: usize,\n        ) bool {\n            const self: *Self = @ptrCast(@alignCast(ctx));\n            assert(buf.len > 0);\n            const underlying = self.getUnderlyingAllocatorPtr();\n            return underlying.rawResize(buf, log2_buf_align, new_len, ret_addr);\n        }\n\n        pub fn free(\n            ctx: *anyopaque,\n            buf: []u8,\n            log2_buf_align: u8,\n            ret_addr: usize,\n        ) void {\n            const self: *Self = @ptrCast(@alignCast(ctx));\n            assert(buf.len > 0);\n            const underlying = self.getUnderlyingAllocatorPtr();\n            underlying.rawFree(buf, log2_buf_align, ret_addr);\n        }\n\n        pub fn reset(self: *Self) void {\n            self.underlying_allocator.reset();\n        }\n    };\n}\n\npub fn validationWrap(allocator: anytype) ValidationAllocator(@TypeOf(allocator)) {\n    return ValidationAllocator(@TypeOf(allocator)).init(allocator);\n}\n\n/// An allocator helper function.  Adjusts an allocation length satisfy `len_align`.\n/// `full_len` should be the full capacity of the allocation which may be greater\n/// than the `len` that was requested.  This function should only be used by allocators\n/// that are unaffected by `len_align`.\npub fn alignAllocLen(full_len: usize, alloc_len: usize, len_align: u29) usize {\n    assert(alloc_len > 0);\n    assert(alloc_len >= len_align);\n    assert(full_len >= alloc_len);\n    if (len_align == 0)\n        return alloc_len;\n    const adjusted = alignBackwardAnyAlign(full_len, len_align);\n    assert(adjusted >= alloc_len);\n    return adjusted;\n}\n\nconst fail_allocator = Allocator{\n    .ptr = undefined,\n    .vtable = &failAllocator_vtable,\n};\n\nconst failAllocator_vtable = Allocator.VTable{\n    .alloc = failAllocatorAlloc,\n    .resize = Allocator.noResize,\n    .free = Allocator.noFree,\n};\n\nfn failAllocatorAlloc(_: *anyopaque, n: usize, log2_alignment: u8, ra: usize) ?[*]u8 {\n    _ = n;\n    _ = log2_alignment;\n    _ = ra;\n    return null;\n}\n\ntest \"Allocator basics\" {\n    try testing.expectError(error.OutOfMemory, fail_allocator.alloc(u8, 1));\n    try testing.expectError(error.OutOfMemory, fail_allocator.allocSentinel(u8, 1, 0));\n}\n\ntest \"Allocator.resize\" {\n    const primitiveIntTypes = .{\n        i8,\n        u8,\n        i16,\n        u16,\n        i32,\n        u32,\n        i64,\n        u64,\n        i128,\n        u128,\n        isize,\n        usize,\n    };\n    inline for (primitiveIntTypes) |T| {\n        var values = try testing.allocator.alloc(T, 100);\n        defer testing.allocator.free(values);\n\n        for (values, 0..) |*v, i| v.* = @as(T, @intCast(i));\n        if (!testing.allocator.resize(values, values.len + 10)) return error.OutOfMemory;\n        values = values.ptr[0 .. values.len + 10];\n        try testing.expect(values.len == 110);\n    }\n\n    const primitiveFloatTypes = .{\n        f16,\n        f32,\n        f64,\n        f128,\n    };\n    inline for (primitiveFloatTypes) |T| {\n        var values = try testing.allocator.alloc(T, 100);\n        defer testing.allocator.free(values);\n\n        for (values, 0..) |*v, i| v.* = @as(T, @floatFromInt(i));\n        if (!testing.allocator.resize(values, values.len + 10)) return error.OutOfMemory;\n        values = values.ptr[0 .. values.len + 10];\n        try testing.expect(values.len == 110);\n    }\n}\n\n/// Copy all of source into dest at position 0.\n/// dest.len must be >= source.len.\n/// If the slices overlap, dest.ptr must be <= src.ptr.\npub fn copyForwards(comptime T: type, dest: []T, source: []const T) void {\n    for (dest[0..source.len], source) |*d, s| d.* = s;\n}\n\n/// Copy all of source into dest at position 0.\n/// dest.len must be >= source.len.\n/// If the slices overlap, dest.ptr must be >= src.ptr.\npub fn copyBackwards(comptime T: type, dest: []T, source: []const T) void {\n    // TODO instead of manually doing this check for the whole array\n    // and turning off runtime safety, the compiler should detect loops like\n    // this and automatically omit safety checks for loops\n    @setRuntimeSafety(false);\n    assert(dest.len >= source.len);\n    var i = source.len;\n    while (i > 0) {\n        i -= 1;\n        dest[i] = source[i];\n    }\n}\n\n/// Generally, Zig users are encouraged to explicitly initialize all fields of a struct explicitly rather than using this function.\n/// However, it is recognized that there are sometimes use cases for initializing all fields to a \"zero\" value. For example, when\n/// interfacing with a C API where this practice is more common and relied upon. If you are performing code review and see this\n/// function used, examine closely - it may be a code smell.\n/// Zero initializes the type.\n/// This can be used to zero-initialize any type for which it makes sense. Structs will be initialized recursively.\npub fn zeroes(comptime T: type) T {\n    switch (@typeInfo(T)) {\n        .ComptimeInt, .Int, .ComptimeFloat, .Float => {\n            return @as(T, 0);\n        },\n        .Enum, .EnumLiteral => {\n            return @as(T, @enumFromInt(0));\n        },\n        .Void => {\n            return {};\n        },\n        .Bool => {\n            return false;\n        },\n        .Optional, .Null => {\n            return null;\n        },\n        .Struct => |struct_info| {\n            if (@sizeOf(T) == 0) return undefined;\n            if (struct_info.layout == .@\"extern\") {\n                var item: T = undefined;\n                @memset(asBytes(&item), 0);\n                return item;\n            } else {\n                var structure: T = undefined;\n                inline for (struct_info.fields) |field| {\n                    if (!field.is_comptime) {\n                        @field(structure, field.name) = zeroes(field.type);\n                    }\n                }\n                return structure;\n            }\n        },\n        .Pointer => |ptr_info| {\n            switch (ptr_info.size) {\n                .Slice => {\n                    if (ptr_info.sentinel) |sentinel| {\n                        if (ptr_info.child == u8 and @as(*const u8, @ptrCast(sentinel)).* == 0) {\n                            return \"\"; // A special case for the most common use-case: null-terminated strings.\n                        }\n                        @compileError(\"Can't set a sentinel slice to zero. This would require allocating memory.\");\n                    } else {\n                        return &[_]ptr_info.child{};\n                    }\n                },\n                .C => {\n                    return null;\n                },\n                .One, .Many => {\n                    if (ptr_info.is_allowzero) return @ptrFromInt(0);\n                    @compileError(\"Only nullable and allowzero pointers can be set to zero.\");\n                },\n            }\n        },\n        .Array => |info| {\n            if (info.sentinel) |sentinel_ptr| {\n                const sentinel = @as(*align(1) const info.child, @ptrCast(sentinel_ptr)).*;\n                return [_:sentinel]info.child{zeroes(info.child)} ** info.len;\n            }\n            return [_]info.child{zeroes(info.child)} ** info.len;\n        },\n        .Vector => |info| {\n            return @splat(zeroes(info.child));\n        },\n        .Union => |info| {\n            if (info.layout == .@\"extern\") {\n                var item: T = undefined;\n                @memset(asBytes(&item), 0);\n                return item;\n            }\n            @compileError(\"Can't set a \" ++ @typeName(T) ++ \" to zero.\");\n        },\n        .ErrorUnion,\n        .ErrorSet,\n        .Fn,\n        .Type,\n        .NoReturn,\n        .Undefined,\n        .Opaque,\n        .Frame,\n        .AnyFrame,\n        => {\n            @compileError(\"Can't set a \" ++ @typeName(T) ++ \" to zero.\");\n        },\n    }\n}\n\ntest zeroes {\n    const C_struct = extern struct {\n        x: u32,\n        y: u32 align(128),\n    };\n\n    var a = zeroes(C_struct);\n\n    // Extern structs should have padding zeroed out.\n    try testing.expectEqualSlices(u8, &[_]u8{0} ** @sizeOf(@TypeOf(a)), asBytes(&a));\n\n    a.y += 10;\n\n    try testing.expect(a.x == 0);\n    try testing.expect(a.y == 10);\n\n    const ZigStruct = struct {\n        comptime comptime_field: u8 = 5,\n\n        integral_types: struct {\n            integer_0: i0,\n            integer_8: i8,\n            integer_16: i16,\n            integer_32: i32,\n            integer_64: i64,\n            integer_128: i128,\n            unsigned_0: u0,\n            unsigned_8: u8,\n            unsigned_16: u16,\n            unsigned_32: u32,\n            unsigned_64: u64,\n            unsigned_128: u128,\n\n            float_32: f32,\n            float_64: f64,\n        },\n\n        pointers: struct {\n            optional: ?*u8,\n            c_pointer: [*c]u8,\n            slice: []u8,\n            nullTerminatedString: [:0]const u8,\n        },\n\n        array: [2]u32,\n        vector_u32: @Vector(2, u32),\n        vector_f32: @Vector(2, f32),\n        vector_bool: @Vector(2, bool),\n        optional_int: ?u8,\n        empty: void,\n        sentinel: [3:0]u8,\n    };\n\n    const b = zeroes(ZigStruct);\n    try testing.expectEqual(@as(u8, 5), b.comptime_field);\n    try testing.expectEqual(@as(i8, 0), b.integral_types.integer_0);\n    try testing.expectEqual(@as(i8, 0), b.integral_types.integer_8);\n    try testing.expectEqual(@as(i16, 0), b.integral_types.integer_16);\n    try testing.expectEqual(@as(i32, 0), b.integral_types.integer_32);\n    try testing.expectEqual(@as(i64, 0), b.integral_types.integer_64);\n    try testing.expectEqual(@as(i128, 0), b.integral_types.integer_128);\n    try testing.expectEqual(@as(u8, 0), b.integral_types.unsigned_0);\n    try testing.expectEqual(@as(u8, 0), b.integral_types.unsigned_8);\n    try testing.expectEqual(@as(u16, 0), b.integral_types.unsigned_16);\n    try testing.expectEqual(@as(u32, 0), b.integral_types.unsigned_32);\n    try testing.expectEqual(@as(u64, 0), b.integral_types.unsigned_64);\n    try testing.expectEqual(@as(u128, 0), b.integral_types.unsigned_128);\n    try testing.expectEqual(@as(f32, 0), b.integral_types.float_32);\n    try testing.expectEqual(@as(f64, 0), b.integral_types.float_64);\n    try testing.expectEqual(@as(?*u8, null), b.pointers.optional);\n    try testing.expectEqual(@as([*c]u8, null), b.pointers.c_pointer);\n    try testing.expectEqual(@as([]u8, &[_]u8{}), b.pointers.slice);\n    try testing.expectEqual(@as([:0]const u8, \"\"), b.pointers.nullTerminatedString);\n    for (b.array) |e| {\n        try testing.expectEqual(@as(u32, 0), e);\n    }\n    try testing.expectEqual(@as(@TypeOf(b.vector_u32), @splat(0)), b.vector_u32);\n    try testing.expectEqual(@as(@TypeOf(b.vector_f32), @splat(0.0)), b.vector_f32);\n    try testing.expectEqual(@as(@TypeOf(b.vector_bool), @splat(false)), b.vector_bool);\n    try testing.expectEqual(@as(?u8, null), b.optional_int);\n    for (b.sentinel) |e| {\n        try testing.expectEqual(@as(u8, 0), e);\n    }\n\n    const C_union = extern union {\n        a: u8,\n        b: u32,\n    };\n\n    const c = zeroes(C_union);\n    try testing.expectEqual(@as(u8, 0), c.a);\n    try testing.expectEqual(@as(u32, 0), c.b);\n\n    const comptime_union = comptime zeroes(C_union);\n    try testing.expectEqual(@as(u8, 0), comptime_union.a);\n    try testing.expectEqual(@as(u32, 0), comptime_union.b);\n\n    // Ensure zero sized struct with fields is initialized correctly.\n    _ = zeroes(struct { handle: void });\n}\n\n/// Initializes all fields of the struct with their default value, or zero values if no default value is present.\n/// If the field is present in the provided initial values, it will have that value instead.\n/// Structs are initialized recursively.\npub fn zeroInit(comptime T: type, init: anytype) T {\n    const Init = @TypeOf(init);\n\n    switch (@typeInfo(T)) {\n        .Struct => |struct_info| {\n            switch (@typeInfo(Init)) {\n                .Struct => |init_info| {\n                    if (init_info.is_tuple) {\n                        if (init_info.fields.len > struct_info.fields.len) {\n                            @compileError(\"Tuple initializer has more elements than there are fields in `\" ++ @typeName(T) ++ \"`\");\n                        }\n                    } else {\n                        inline for (init_info.fields) |field| {\n                            if (!@hasField(T, field.name)) {\n                                @compileError(\"Encountered an initializer for `\" ++ field.name ++ \"`, but it is not a field of \" ++ @typeName(T));\n                            }\n                        }\n                    }\n\n                    var value: T = if (struct_info.layout == .@\"extern\") zeroes(T) else undefined;\n\n                    inline for (struct_info.fields, 0..) |field, i| {\n                        if (field.is_comptime) {\n                            continue;\n                        }\n\n                        if (init_info.is_tuple and init_info.fields.len > i) {\n                            @field(value, field.name) = @field(init, init_info.fields[i].name);\n                        } else if (@hasField(@TypeOf(init), field.name)) {\n                            switch (@typeInfo(field.type)) {\n                                .Struct => {\n                                    @field(value, field.name) = zeroInit(field.type, @field(init, field.name));\n                                },\n                                else => {\n                                    @field(value, field.name) = @field(init, field.name);\n                                },\n                            }\n                        } else if (field.default_value) |default_value_ptr| {\n                            const default_value = @as(*align(1) const field.type, @ptrCast(default_value_ptr)).*;\n                            @field(value, field.name) = default_value;\n                        } else {\n                            switch (@typeInfo(field.type)) {\n                                .Struct => {\n                                    @field(value, field.name) = std.mem.zeroInit(field.type, .{});\n                                },\n                                else => {\n                                    @field(value, field.name) = std.mem.zeroes(@TypeOf(@field(value, field.name)));\n                                },\n                            }\n                        }\n                    }\n\n                    return value;\n                },\n                else => {\n                    @compileError(\"The initializer must be a struct\");\n                },\n            }\n        },\n        else => {\n            @compileError(\"Can't default init a \" ++ @typeName(T));\n        },\n    }\n}\n\ntest zeroInit {\n    const I = struct {\n        d: f64,\n    };\n\n    const S = struct {\n        a: u32,\n        b: ?bool,\n        c: I,\n        e: [3]u8,\n        f: i64 = -1,\n    };\n\n    const s = zeroInit(S, .{\n        .a = 42,\n    });\n\n    try testing.expectEqual(S{\n        .a = 42,\n        .b = null,\n        .c = .{\n            .d = 0,\n        },\n        .e = [3]u8{ 0, 0, 0 },\n        .f = -1,\n    }, s);\n\n    const Color = struct {\n        r: u8,\n        g: u8,\n        b: u8,\n        a: u8,\n    };\n\n    const c = zeroInit(Color, .{ 255, 255 });\n    try testing.expectEqual(Color{\n        .r = 255,\n        .g = 255,\n        .b = 0,\n        .a = 0,\n    }, c);\n\n    const Foo = struct {\n        foo: u8 = 69,\n        bar: u8,\n    };\n\n    const f = zeroInit(Foo, .{});\n    try testing.expectEqual(Foo{\n        .foo = 69,\n        .bar = 0,\n    }, f);\n\n    const Bar = struct {\n        foo: u32 = 666,\n        bar: u32 = 420,\n    };\n\n    const b = zeroInit(Bar, .{69});\n    try testing.expectEqual(Bar{\n        .foo = 69,\n        .bar = 420,\n    }, b);\n\n    const Baz = struct {\n        foo: [:0]const u8 = \"bar\",\n    };\n\n    const baz1 = zeroInit(Baz, .{});\n    try testing.expectEqual(Baz{}, baz1);\n\n    const baz2 = zeroInit(Baz, .{ .foo = \"zab\" });\n    try testing.expectEqualSlices(u8, \"zab\", baz2.foo);\n\n    const NestedBaz = struct {\n        bbb: Baz,\n    };\n    const nested_baz = zeroInit(NestedBaz, .{});\n    try testing.expectEqual(NestedBaz{\n        .bbb = Baz{},\n    }, nested_baz);\n}\n\npub fn sort(\n    comptime T: type,\n    items: []T,\n    context: anytype,\n    comptime lessThanFn: fn (@TypeOf(context), lhs: T, rhs: T) bool,\n) void {\n    std.sort.block(T, items, context, lessThanFn);\n}\n\npub fn sortUnstable(\n    comptime T: type,\n    items: []T,\n    context: anytype,\n    comptime lessThanFn: fn (@TypeOf(context), lhs: T, rhs: T) bool,\n) void {\n    std.sort.pdq(T, items, context, lessThanFn);\n}\n\n/// TODO: currently this just calls `insertionSortContext`. The block sort implementation\n/// in this file needs to be adapted to use the sort context.\npub fn sortContext(a: usize, b: usize, context: anytype) void {\n    std.sort.insertionContext(a, b, context);\n}\n\npub fn sortUnstableContext(a: usize, b: usize, context: anytype) void {\n    std.sort.pdqContext(a, b, context);\n}\n\n/// Compares two slices of numbers lexicographically. O(n).\npub fn order(comptime T: type, lhs: []const T, rhs: []const T) math.Order {\n    const n = @min(lhs.len, rhs.len);\n    for (lhs[0..n], rhs[0..n]) |lhs_elem, rhs_elem| {\n        switch (math.order(lhs_elem, rhs_elem)) {\n            .eq => continue,\n            .lt => return .lt,\n            .gt => return .gt,\n        }\n    }\n    return math.order(lhs.len, rhs.len);\n}\n\n/// Compares two many-item pointers with NUL-termination lexicographically.\npub fn orderZ(comptime T: type, lhs: [*:0]const T, rhs: [*:0]const T) math.Order {\n    var i: usize = 0;\n    while (lhs[i] == rhs[i] and lhs[i] != 0) : (i += 1) {}\n    return math.order(lhs[i], rhs[i]);\n}\n\ntest order {\n    try testing.expect(order(u8, \"abcd\", \"bee\") == .lt);\n    try testing.expect(order(u8, \"abc\", \"abc\") == .eq);\n    try testing.expect(order(u8, \"abc\", \"abc0\") == .lt);\n    try testing.expect(order(u8, \"\", \"\") == .eq);\n    try testing.expect(order(u8, \"\", \"a\") == .lt);\n}\n\ntest orderZ {\n    try testing.expect(orderZ(u8, \"abcd\", \"bee\") == .lt);\n    try testing.expect(orderZ(u8, \"abc\", \"abc\") == .eq);\n    try testing.expect(orderZ(u8, \"abc\", \"abc0\") == .lt);\n    try testing.expect(orderZ(u8, \"\", \"\") == .eq);\n    try testing.expect(orderZ(u8, \"\", \"a\") == .lt);\n}\n\n/// Returns true if lhs < rhs, false otherwise\npub fn lessThan(comptime T: type, lhs: []const T, rhs: []const T) bool {\n    return order(T, lhs, rhs) == .lt;\n}\n\ntest lessThan {\n    try testing.expect(lessThan(u8, \"abcd\", \"bee\"));\n    try testing.expect(!lessThan(u8, \"abc\", \"abc\"));\n    try testing.expect(lessThan(u8, \"abc\", \"abc0\"));\n    try testing.expect(!lessThan(u8, \"\", \"\"));\n    try testing.expect(lessThan(u8, \"\", \"a\"));\n}\n\nconst backend_can_use_eql_bytes = switch (builtin.zig_backend) {\n    // The SPIR-V backend does not support the optimized path yet.\n    .stage2_spirv64 => false,\n    // The RISC-V does not support vectors.\n    .stage2_riscv64 => false,\n    else => true,\n};\n\n/// Compares two slices and returns whether they are equal.\npub fn eql(comptime T: type, a: []const T, b: []const T) bool {\n    if (@sizeOf(T) == 0) return true;\n    if (!@inComptime() and std.meta.hasUniqueRepresentation(T) and backend_can_use_eql_bytes) return eqlBytes(sliceAsBytes(a), sliceAsBytes(b));\n\n    if (a.len != b.len) return false;\n    if (a.len == 0 or a.ptr == b.ptr) return true;\n\n    for (a, b) |a_elem, b_elem| {\n        if (a_elem != b_elem) return false;\n    }\n    return true;\n}\n\n/// std.mem.eql heavily optimized for slices of bytes.\nfn eqlBytes(a: []const u8, b: []const u8) bool {\n    if (!backend_can_use_eql_bytes) {\n        return eql(u8, a, b);\n    }\n\n    if (a.len != b.len) return false;\n    if (a.len == 0 or a.ptr == b.ptr) return true;\n\n    if (a.len <= 16) {\n        if (a.len < 4) {\n            const x = (a[0] ^ b[0]) | (a[a.len - 1] ^ b[a.len - 1]) | (a[a.len / 2] ^ b[a.len / 2]);\n            return x == 0;\n        }\n        var x: u32 = 0;\n        for ([_]usize{ 0, a.len - 4, (a.len / 8) * 4, a.len - 4 - ((a.len / 8) * 4) }) |n| {\n            x |= @as(u32, @bitCast(a[n..][0..4].*)) ^ @as(u32, @bitCast(b[n..][0..4].*));\n        }\n        return x == 0;\n    }\n\n    // Figure out the fastest way to scan through the input in chunks.\n    // Uses vectors when supported and falls back to usize/words when not.\n    const Scan = if (std.simd.suggestVectorLength(u8)) |vec_size|\n        struct {\n            pub const size = vec_size;\n            pub const Chunk = @Vector(size, u8);\n            pub inline fn isNotEqual(chunk_a: Chunk, chunk_b: Chunk) bool {\n                return @reduce(.Or, chunk_a != chunk_b);\n            }\n        }\n    else\n        struct {\n            pub const size = @sizeOf(usize);\n            pub const Chunk = usize;\n            pub inline fn isNotEqual(chunk_a: Chunk, chunk_b: Chunk) bool {\n                return chunk_a != chunk_b;\n            }\n        };\n\n    inline for (1..6) |s| {\n        const n = 16 << s;\n        if (n <= Scan.size and a.len <= n) {\n            const V = @Vector(n / 2, u8);\n            var x = @as(V, a[0 .. n / 2].*) ^ @as(V, b[0 .. n / 2].*);\n            x |= @as(V, a[a.len - n / 2 ..][0 .. n / 2].*) ^ @as(V, b[a.len - n / 2 ..][0 .. n / 2].*);\n            const zero: V = @splat(0);\n            return !@reduce(.Or, x != zero);\n        }\n    }\n    // Compare inputs in chunks at a time (excluding the last chunk).\n    for (0..(a.len - 1) / Scan.size) |i| {\n        const a_chunk: Scan.Chunk = @bitCast(a[i * Scan.size ..][0..Scan.size].*);\n        const b_chunk: Scan.Chunk = @bitCast(b[i * Scan.size ..][0..Scan.size].*);\n        if (Scan.isNotEqual(a_chunk, b_chunk)) return false;\n    }\n\n    // Compare the last chunk using an overlapping read (similar to the previous size strategies).\n    const last_a_chunk: Scan.Chunk = @bitCast(a[a.len - Scan.size ..][0..Scan.size].*);\n    const last_b_chunk: Scan.Chunk = @bitCast(b[a.len - Scan.size ..][0..Scan.size].*);\n    return !Scan.isNotEqual(last_a_chunk, last_b_chunk);\n}\n\n/// Compares two slices and returns the index of the first inequality.\n/// Returns null if the slices are equal.\npub fn indexOfDiff(comptime T: type, a: []const T, b: []const T) ?usize {\n    const shortest = @min(a.len, b.len);\n    if (a.ptr == b.ptr)\n        return if (a.len == b.len) null else shortest;\n    var index: usize = 0;\n    while (index < shortest) : (index += 1) if (a[index] != b[index]) return index;\n    return if (a.len == b.len) null else shortest;\n}\n\ntest indexOfDiff {\n    try testing.expectEqual(indexOfDiff(u8, \"one\", \"one\"), null);\n    try testing.expectEqual(indexOfDiff(u8, \"one two\", \"one\"), 3);\n    try testing.expectEqual(indexOfDiff(u8, \"one\", \"one two\"), 3);\n    try testing.expectEqual(indexOfDiff(u8, \"one twx\", \"one two\"), 6);\n    try testing.expectEqual(indexOfDiff(u8, \"xne\", \"one\"), 0);\n}\n\n/// Takes a sentinel-terminated pointer and returns a slice preserving pointer attributes.\n/// `[*c]` pointers are assumed to be 0-terminated and assumed to not be allowzero.\nfn Span(comptime T: type) type {\n    switch (@typeInfo(T)) {\n        .Optional => |optional_info| {\n            return ?Span(optional_info.child);\n        },\n        .Pointer => |ptr_info| {\n            var new_ptr_info = ptr_info;\n            switch (ptr_info.size) {\n                .C => {\n                    new_ptr_info.sentinel = &@as(ptr_info.child, 0);\n                    new_ptr_info.is_allowzero = false;\n                },\n                .Many => if (ptr_info.sentinel == null) @compileError(\"invalid type given to std.mem.span: \" ++ @typeName(T)),\n                .One, .Slice => @compileError(\"invalid type given to std.mem.span: \" ++ @typeName(T)),\n            }\n            new_ptr_info.size = .Slice;\n            return @Type(.{ .Pointer = new_ptr_info });\n        },\n        else => {},\n    }\n    @compileError(\"invalid type given to std.mem.span: \" ++ @typeName(T));\n}\n\ntest Span {\n    try testing.expect(Span([*:1]u16) == [:1]u16);\n    try testing.expect(Span(?[*:1]u16) == ?[:1]u16);\n    try testing.expect(Span([*:1]const u8) == [:1]const u8);\n    try testing.expect(Span(?[*:1]const u8) == ?[:1]const u8);\n    try testing.expect(Span([*c]u16) == [:0]u16);\n    try testing.expect(Span(?[*c]u16) == ?[:0]u16);\n    try testing.expect(Span([*c]const u8) == [:0]const u8);\n    try testing.expect(Span(?[*c]const u8) == ?[:0]const u8);\n}\n\n/// Takes a sentinel-terminated pointer and returns a slice, iterating over the\n/// memory to find the sentinel and determine the length.\n/// Pointer attributes such as const are preserved.\n/// `[*c]` pointers are assumed to be non-null and 0-terminated.\npub fn span(ptr: anytype) Span(@TypeOf(ptr)) {\n    if (@typeInfo(@TypeOf(ptr)) == .Optional) {\n        if (ptr) |non_null| {\n            return span(non_null);\n        } else {\n            return null;\n        }\n    }\n    const Result = Span(@TypeOf(ptr));\n    const l = len(ptr);\n    const ptr_info = @typeInfo(Result).Pointer;\n    if (ptr_info.sentinel) |s_ptr| {\n        const s = @as(*align(1) const ptr_info.child, @ptrCast(s_ptr)).*;\n        return ptr[0..l :s];\n    } else {\n        return ptr[0..l];\n    }\n}\n\ntest span {\n    var array: [5]u16 = [_]u16{ 1, 2, 3, 4, 5 };\n    const ptr = @as([*:3]u16, array[0..2 :3]);\n    try testing.expect(eql(u16, span(ptr), &[_]u16{ 1, 2 }));\n    try testing.expectEqual(@as(?[:0]u16, null), span(@as(?[*:0]u16, null)));\n}\n\n/// Helper for the return type of sliceTo()\nfn SliceTo(comptime T: type, comptime end: std.meta.Elem(T)) type {\n    switch (@typeInfo(T)) {\n        .Optional => |optional_info| {\n            return ?SliceTo(optional_info.child, end);\n        },\n        .Pointer => |ptr_info| {\n            var new_ptr_info = ptr_info;\n            new_ptr_info.size = .Slice;\n            switch (ptr_info.size) {\n                .One => switch (@typeInfo(ptr_info.child)) {\n                    .Array => |array_info| {\n                        new_ptr_info.child = array_info.child;\n                        // The return type must only be sentinel terminated if we are guaranteed\n                        // to find the value searched for, which is only the case if it matches\n                        // the sentinel of the type passed.\n                        if (array_info.sentinel) |sentinel_ptr| {\n                            const sentinel = @as(*align(1) const array_info.child, @ptrCast(sentinel_ptr)).*;\n                            if (end == sentinel) {\n                                new_ptr_info.sentinel = &end;\n                            } else {\n                                new_ptr_info.sentinel = null;\n                            }\n                        }\n                    },\n                    else => {},\n                },\n                .Many, .Slice => {\n                    // The return type must only be sentinel terminated if we are guaranteed\n                    // to find the value searched for, which is only the case if it matches\n                    // the sentinel of the type passed.\n                    if (ptr_info.sentinel) |sentinel_ptr| {\n                        const sentinel = @as(*align(1) const ptr_info.child, @ptrCast(sentinel_ptr)).*;\n                        if (end == sentinel) {\n                            new_ptr_info.sentinel = &end;\n                        } else {\n                            new_ptr_info.sentinel = null;\n                        }\n                    }\n                },\n                .C => {\n                    new_ptr_info.sentinel = &end;\n                    // C pointers are always allowzero, but we don't want the return type to be.\n                    assert(new_ptr_info.is_allowzero);\n                    new_ptr_info.is_allowzero = false;\n                },\n            }\n            return @Type(.{ .Pointer = new_ptr_info });\n        },\n        else => {},\n    }\n    @compileError(\"invalid type given to std.mem.sliceTo: \" ++ @typeName(T));\n}\n\n/// Takes an array, a pointer to an array, a sentinel-terminated pointer, or a slice and\n/// iterates searching for the first occurrence of `end`, returning the scanned slice.\n/// If `end` is not found, the full length of the array/slice/sentinel terminated pointer is returned.\n/// If the pointer type is sentinel terminated and `end` matches that terminator, the\n/// resulting slice is also sentinel terminated.\n/// Pointer properties such as mutability and alignment are preserved.\n/// C pointers are assumed to be non-null.\npub fn sliceTo(ptr: anytype, comptime end: std.meta.Elem(@TypeOf(ptr))) SliceTo(@TypeOf(ptr), end) {\n    if (@typeInfo(@TypeOf(ptr)) == .Optional) {\n        const non_null = ptr orelse return null;\n        return sliceTo(non_null, end);\n    }\n    const Result = SliceTo(@TypeOf(ptr), end);\n    const length = lenSliceTo(ptr, end);\n    const ptr_info = @typeInfo(Result).Pointer;\n    if (ptr_info.sentinel) |s_ptr| {\n        const s = @as(*align(1) const ptr_info.child, @ptrCast(s_ptr)).*;\n        return ptr[0..length :s];\n    } else {\n        return ptr[0..length];\n    }\n}\n\ntest sliceTo {\n    try testing.expectEqualSlices(u8, \"aoeu\", sliceTo(\"aoeu\", 0));\n\n    {\n        var array: [5]u16 = [_]u16{ 1, 2, 3, 4, 5 };\n        try testing.expectEqualSlices(u16, &array, sliceTo(&array, 0));\n        try testing.expectEqualSlices(u16, array[0..3], sliceTo(array[0..3], 0));\n        try testing.expectEqualSlices(u16, array[0..2], sliceTo(&array, 3));\n        try testing.expectEqualSlices(u16, array[0..2], sliceTo(array[0..3], 3));\n\n        const sentinel_ptr = @as([*:5]u16, @ptrCast(&array));\n        try testing.expectEqualSlices(u16, array[0..2], sliceTo(sentinel_ptr, 3));\n        try testing.expectEqualSlices(u16, array[0..4], sliceTo(sentinel_ptr, 99));\n\n        const optional_sentinel_ptr = @as(?[*:5]u16, @ptrCast(&array));\n        try testing.expectEqualSlices(u16, array[0..2], sliceTo(optional_sentinel_ptr, 3).?);\n        try testing.expectEqualSlices(u16, array[0..4], sliceTo(optional_sentinel_ptr, 99).?);\n\n        const c_ptr = @as([*c]u16, &array);\n        try testing.expectEqualSlices(u16, array[0..2], sliceTo(c_ptr, 3));\n\n        const slice: []u16 = &array;\n        try testing.expectEqualSlices(u16, array[0..2], sliceTo(slice, 3));\n        try testing.expectEqualSlices(u16, &array, sliceTo(slice, 99));\n\n        const sentinel_slice: [:5]u16 = array[0..4 :5];\n        try testing.expectEqualSlices(u16, array[0..2], sliceTo(sentinel_slice, 3));\n        try testing.expectEqualSlices(u16, array[0..4], sliceTo(sentinel_slice, 99));\n    }\n    {\n        var sentinel_array: [5:0]u16 = [_:0]u16{ 1, 2, 3, 4, 5 };\n        try testing.expectEqualSlices(u16, sentinel_array[0..2], sliceTo(&sentinel_array, 3));\n        try testing.expectEqualSlices(u16, &sentinel_array, sliceTo(&sentinel_array, 0));\n        try testing.expectEqualSlices(u16, &sentinel_array, sliceTo(&sentinel_array, 99));\n    }\n\n    try testing.expectEqual(@as(?[]u8, null), sliceTo(@as(?[]u8, null), 0));\n}\n\n/// Private helper for sliceTo(). If you want the length, use sliceTo(foo, x).len\nfn lenSliceTo(ptr: anytype, comptime end: std.meta.Elem(@TypeOf(ptr))) usize {\n    switch (@typeInfo(@TypeOf(ptr))) {\n        .Pointer => |ptr_info| switch (ptr_info.size) {\n            .One => switch (@typeInfo(ptr_info.child)) {\n                .Array => |array_info| {\n                    if (array_info.sentinel) |sentinel_ptr| {\n                        const sentinel = @as(*align(1) const array_info.child, @ptrCast(sentinel_ptr)).*;\n                        if (sentinel == end) {\n                            return indexOfSentinel(array_info.child, end, ptr);\n                        }\n                    }\n                    return indexOfScalar(array_info.child, ptr, end) orelse array_info.len;\n                },\n                else => {},\n            },\n            .Many => if (ptr_info.sentinel) |sentinel_ptr| {\n                const sentinel = @as(*align(1) const ptr_info.child, @ptrCast(sentinel_ptr)).*;\n                if (sentinel == end) {\n                    return indexOfSentinel(ptr_info.child, end, ptr);\n                }\n                // We're looking for something other than the sentinel,\n                // but iterating past the sentinel would be a bug so we need\n                // to check for both.\n                var i: usize = 0;\n                while (ptr[i] != end and ptr[i] != sentinel) i += 1;\n                return i;\n            },\n            .C => {\n                assert(ptr != null);\n                return indexOfSentinel(ptr_info.child, end, ptr);\n            },\n            .Slice => {\n                if (ptr_info.sentinel) |sentinel_ptr| {\n                    const sentinel = @as(*align(1) const ptr_info.child, @ptrCast(sentinel_ptr)).*;\n                    if (sentinel == end) {\n                        return indexOfSentinel(ptr_info.child, sentinel, ptr);\n                    }\n                }\n                return indexOfScalar(ptr_info.child, ptr, end) orelse ptr.len;\n            },\n        },\n        else => {},\n    }\n    @compileError(\"invalid type given to std.mem.sliceTo: \" ++ @typeName(@TypeOf(ptr)));\n}\n\ntest lenSliceTo {\n    try testing.expect(lenSliceTo(\"aoeu\", 0) == 4);\n\n    {\n        var array: [5]u16 = [_]u16{ 1, 2, 3, 4, 5 };\n        try testing.expectEqual(@as(usize, 5), lenSliceTo(&array, 0));\n        try testing.expectEqual(@as(usize, 3), lenSliceTo(array[0..3], 0));\n        try testing.expectEqual(@as(usize, 2), lenSliceTo(&array, 3));\n        try testing.expectEqual(@as(usize, 2), lenSliceTo(array[0..3], 3));\n\n        const sentinel_ptr = @as([*:5]u16, @ptrCast(&array));\n        try testing.expectEqual(@as(usize, 2), lenSliceTo(sentinel_ptr, 3));\n        try testing.expectEqual(@as(usize, 4), lenSliceTo(sentinel_ptr, 99));\n\n        const c_ptr = @as([*c]u16, &array);\n        try testing.expectEqual(@as(usize, 2), lenSliceTo(c_ptr, 3));\n\n        const slice: []u16 = &array;\n        try testing.expectEqual(@as(usize, 2), lenSliceTo(slice, 3));\n        try testing.expectEqual(@as(usize, 5), lenSliceTo(slice, 99));\n\n        const sentinel_slice: [:5]u16 = array[0..4 :5];\n        try testing.expectEqual(@as(usize, 2), lenSliceTo(sentinel_slice, 3));\n        try testing.expectEqual(@as(usize, 4), lenSliceTo(sentinel_slice, 99));\n    }\n    {\n        var sentinel_array: [5:0]u16 = [_:0]u16{ 1, 2, 3, 4, 5 };\n        try testing.expectEqual(@as(usize, 2), lenSliceTo(&sentinel_array, 3));\n        try testing.expectEqual(@as(usize, 5), lenSliceTo(&sentinel_array, 0));\n        try testing.expectEqual(@as(usize, 5), lenSliceTo(&sentinel_array, 99));\n    }\n}\n\n/// Takes a sentinel-terminated pointer and iterates over the memory to find the\n/// sentinel and determine the length.\n/// `[*c]` pointers are assumed to be non-null and 0-terminated.\npub fn len(value: anytype) usize {\n    switch (@typeInfo(@TypeOf(value))) {\n        .Pointer => |info| switch (info.size) {\n            .Many => {\n                const sentinel_ptr = info.sentinel orelse\n                    @compileError(\"invalid type given to std.mem.len: \" ++ @typeName(@TypeOf(value)));\n                const sentinel = @as(*align(1) const info.child, @ptrCast(sentinel_ptr)).*;\n                return indexOfSentinel(info.child, sentinel, value);\n            },\n            .C => {\n                assert(value != null);\n                return indexOfSentinel(info.child, 0, value);\n            },\n            else => @compileError(\"invalid type given to std.mem.len: \" ++ @typeName(@TypeOf(value))),\n        },\n        else => @compileError(\"invalid type given to std.mem.len: \" ++ @typeName(@TypeOf(value))),\n    }\n}\n\ntest len {\n    var array: [5]u16 = [_]u16{ 1, 2, 0, 4, 5 };\n    const ptr = @as([*:4]u16, array[0..3 :4]);\n    try testing.expect(len(ptr) == 3);\n    const c_ptr = @as([*c]u16, ptr);\n    try testing.expect(len(c_ptr) == 2);\n}\n\nconst backend_supports_vectors = switch (builtin.zig_backend) {\n    .stage2_llvm, .stage2_c => true,\n    else => false,\n};\n\npub fn indexOfSentinel(comptime T: type, comptime sentinel: T, p: [*:sentinel]const T) usize {\n    var i: usize = 0;\n\n    if (backend_supports_vectors and\n        !std.debug.inValgrind() and // https://github.com/ziglang/zig/issues/17717\n        !@inComptime() and\n        (@typeInfo(T) == .Int or @typeInfo(T) == .Float) and std.math.isPowerOfTwo(@bitSizeOf(T)))\n    {\n        switch (@import(\"builtin\").cpu.arch) {\n            // The below branch assumes that reading past the end of the buffer is valid, as long\n            // as we don't read into a new page. This should be the case for most architectures\n            // which use paged memory, however should be confirmed before adding a new arch below.\n            .aarch64, .x86, .x86_64 => if (std.simd.suggestVectorLength(T)) |block_len| {\n                const Block = @Vector(block_len, T);\n                const mask: Block = @splat(sentinel);\n\n                comptime std.debug.assert(std.mem.page_size % @sizeOf(Block) == 0);\n\n                // First block may be unaligned\n                const start_addr = @intFromPtr(&p[i]);\n                const offset_in_page = start_addr & (std.mem.page_size - 1);\n                if (offset_in_page <= std.mem.page_size - @sizeOf(Block)) {\n                    // Will not read past the end of a page, full block.\n                    const block: Block = p[i..][0..block_len].*;\n                    const matches = block == mask;\n                    if (@reduce(.Or, matches)) {\n                        return i + std.simd.firstTrue(matches).?;\n                    }\n\n                    i += (std.mem.alignForward(usize, start_addr, @alignOf(Block)) - start_addr) / @sizeOf(T);\n                } else {\n                    // Would read over a page boundary. Per-byte at a time until aligned or found.\n                    // 0.39% chance this branch is taken for 4K pages at 16b block length.\n                    //\n                    // An alternate strategy is to do read a full block (the last in the page) and\n                    // mask the entries before the pointer.\n                    while ((@intFromPtr(&p[i]) & (@alignOf(Block) - 1)) != 0) : (i += 1) {\n                        if (p[i] == sentinel) return i;\n                    }\n                }\n\n                std.debug.assert(std.mem.isAligned(@intFromPtr(&p[i]), @alignOf(Block)));\n                while (true) {\n                    const block: *const Block = @ptrCast(@alignCast(p[i..][0..block_len]));\n                    const matches = block.* == mask;\n                    if (@reduce(.Or, matches)) {\n                        return i + std.simd.firstTrue(matches).?;\n                    }\n                    i += block_len;\n                }\n            },\n            else => {},\n        }\n    }\n\n    while (p[i] != sentinel) {\n        i += 1;\n    }\n    return i;\n}\n\ntest \"indexOfSentinel vector paths\" {\n    const Types = [_]type{ u8, u16, u32, u64 };\n    const allocator = std.testing.allocator;\n\n    inline for (Types) |T| {\n        const block_len = std.simd.suggestVectorLength(T) orelse continue;\n\n        // Allocate three pages so we guarantee a page-crossing address with a full page after\n        const memory = try allocator.alloc(T, 3 * std.mem.page_size / @sizeOf(T));\n        defer allocator.free(memory);\n        @memset(memory, 0xaa);\n\n        // Find starting page-alignment = 0\n        var start: usize = 0;\n        const start_addr = @intFromPtr(&memory);\n        start += (std.mem.alignForward(usize, start_addr, std.mem.page_size) - start_addr) / @sizeOf(T);\n        try testing.expect(start < std.mem.page_size / @sizeOf(T));\n\n        // Validate all sub-block alignments\n        const search_len = std.mem.page_size / @sizeOf(T);\n        memory[start + search_len] = 0;\n        for (0..block_len) |offset| {\n            try testing.expectEqual(search_len - offset, indexOfSentinel(T, 0, @ptrCast(&memory[start + offset])));\n        }\n        memory[start + search_len] = 0xaa;\n\n        // Validate page boundary crossing\n        const start_page_boundary = start + (std.mem.page_size / @sizeOf(T));\n        memory[start_page_boundary + block_len] = 0;\n        for (0..block_len) |offset| {\n            try testing.expectEqual(2 * block_len - offset, indexOfSentinel(T, 0, @ptrCast(&memory[start_page_boundary - block_len + offset])));\n        }\n    }\n}\n\n/// Returns true if all elements in a slice are equal to the scalar value provided\npub fn allEqual(comptime T: type, slice: []const T, scalar: T) bool {\n    for (slice) |item| {\n        if (item != scalar) return false;\n    }\n    return true;\n}\n\n/// Remove a set of values from the beginning of a slice.\npub fn trimLeft(comptime T: type, slice: []const T, values_to_strip: []const T) []const T {\n    var begin: usize = 0;\n    while (begin < slice.len and indexOfScalar(T, values_to_strip, slice[begin]) != null) : (begin += 1) {}\n    return slice[begin..];\n}\n\n/// Remove a set of values from the end of a slice.\npub fn trimRight(comptime T: type, slice: []const T, values_to_strip: []const T) []const T {\n    var end: usize = slice.len;\n    while (end > 0 and indexOfScalar(T, values_to_strip, slice[end - 1]) != null) : (end -= 1) {}\n    return slice[0..end];\n}\n\n/// Remove a set of values from the beginning and end of a slice.\npub fn trim(comptime T: type, slice: []const T, values_to_strip: []const T) []const T {\n    var begin: usize = 0;\n    var end: usize = slice.len;\n    while (begin < end and indexOfScalar(T, values_to_strip, slice[begin]) != null) : (begin += 1) {}\n    while (end > begin and indexOfScalar(T, values_to_strip, slice[end - 1]) != null) : (end -= 1) {}\n    return slice[begin..end];\n}\n\ntest trim {\n    try testing.expectEqualSlices(u8, \"foo\\n \", trimLeft(u8, \" foo\\n \", \" \\n\"));\n    try testing.expectEqualSlices(u8, \" foo\", trimRight(u8, \" foo\\n \", \" \\n\"));\n    try testing.expectEqualSlices(u8, \"foo\", trim(u8, \" foo\\n \", \" \\n\"));\n    try testing.expectEqualSlices(u8, \"foo\", trim(u8, \"foo\", \" \\n\"));\n}\n\n/// Linear search for the index of a scalar value inside a slice.\npub fn indexOfScalar(comptime T: type, slice: []const T, value: T) ?usize {\n    return indexOfScalarPos(T, slice, 0, value);\n}\n\n/// Linear search for the last index of a scalar value inside a slice.\npub fn lastIndexOfScalar(comptime T: type, slice: []const T, value: T) ?usize {\n    var i: usize = slice.len;\n    while (i != 0) {\n        i -= 1;\n        if (slice[i] == value) return i;\n    }\n    return null;\n}\n\npub fn indexOfScalarPos(comptime T: type, slice: []const T, start_index: usize, value: T) ?usize {\n    if (start_index >= slice.len) return null;\n\n    var i: usize = start_index;\n    if (backend_supports_vectors and\n        !std.debug.inValgrind() and // https://github.com/ziglang/zig/issues/17717\n        !@inComptime() and\n        (@typeInfo(T) == .Int or @typeInfo(T) == .Float) and std.math.isPowerOfTwo(@bitSizeOf(T)))\n    {\n        if (std.simd.suggestVectorLength(T)) |block_len| {\n            // For Intel Nehalem (2009) and AMD Bulldozer (2012) or later, unaligned loads on aligned data result\n            // in the same execution as aligned loads. We ignore older arch's here and don't bother pre-aligning.\n            //\n            // Use `std.simd.suggestVectorLength(T)` to get the same alignment as used in this function\n            // however this usually isn't necessary unless your arch has a performance penalty due to this.\n            //\n            // This may differ for other arch's. Arm for example costs a cycle when loading across a cache\n            // line so explicit alignment prologues may be worth exploration.\n\n            // Unrolling here is ~10% improvement. We can then do one bounds check every 2 blocks\n            // instead of one which adds up.\n            const Block = @Vector(block_len, T);\n            if (i + 2 * block_len < slice.len) {\n                const mask: Block = @splat(value);\n                while (true) {\n                    inline for (0..2) |_| {\n                        const block: Block = slice[i..][0..block_len].*;\n                        const matches = block == mask;\n                        if (@reduce(.Or, matches)) {\n                            return i + std.simd.firstTrue(matches).?;\n                        }\n                        i += block_len;\n                    }\n                    if (i + 2 * block_len >= slice.len) break;\n                }\n            }\n\n            // {block_len, block_len / 2} check\n            inline for (0..2) |j| {\n                const block_x_len = block_len / (1 << j);\n                comptime if (block_x_len < 4) break;\n\n                const BlockX = @Vector(block_x_len, T);\n                if (i + block_x_len < slice.len) {\n                    const mask: BlockX = @splat(value);\n                    const block: BlockX = slice[i..][0..block_x_len].*;\n                    const matches = block == mask;\n                    if (@reduce(.Or, matches)) {\n                        return i + std.simd.firstTrue(matches).?;\n                    }\n                    i += block_x_len;\n                }\n            }\n        }\n    }\n\n    for (slice[i..], i..) |c, j| {\n        if (c == value) return j;\n    }\n    return null;\n}\n\ntest indexOfScalarPos {\n    const Types = [_]type{ u8, u16, u32, u64 };\n\n    inline for (Types) |T| {\n        var memory: [64 / @sizeOf(T)]T = undefined;\n        @memset(&memory, 0xaa);\n        memory[memory.len - 1] = 0;\n\n        for (0..memory.len) |i| {\n            try testing.expectEqual(memory.len - i - 1, indexOfScalarPos(T, memory[i..], 0, 0).?);\n        }\n    }\n}\n\npub fn indexOfAny(comptime T: type, slice: []const T, values: []const T) ?usize {\n    return indexOfAnyPos(T, slice, 0, values);\n}\n\npub fn lastIndexOfAny(comptime T: type, slice: []const T, values: []const T) ?usize {\n    var i: usize = slice.len;\n    while (i != 0) {\n        i -= 1;\n        for (values) |value| {\n            if (slice[i] == value) return i;\n        }\n    }\n    return null;\n}\n\npub fn indexOfAnyPos(comptime T: type, slice: []const T, start_index: usize, values: []const T) ?usize {\n    if (start_index >= slice.len) return null;\n    for (slice[start_index..], start_index..) |c, i| {\n        for (values) |value| {\n            if (c == value) return i;\n        }\n    }\n    return null;\n}\n\n/// Find the first item in `slice` which is not contained in `values`.\n///\n/// Comparable to `strspn` in the C standard library.\npub fn indexOfNone(comptime T: type, slice: []const T, values: []const T) ?usize {\n    return indexOfNonePos(T, slice, 0, values);\n}\n\n/// Find the last item in `slice` which is not contained in `values`.\n///\n/// Like `strspn` in the C standard library, but searches from the end.\npub fn lastIndexOfNone(comptime T: type, slice: []const T, values: []const T) ?usize {\n    var i: usize = slice.len;\n    outer: while (i != 0) {\n        i -= 1;\n        for (values) |value| {\n            if (slice[i] == value) continue :outer;\n        }\n        return i;\n    }\n    return null;\n}\n\n/// Find the first item in `slice[start_index..]` which is not contained in `values`.\n/// The returned index will be relative to the start of `slice`, and never less than `start_index`.\n///\n/// Comparable to `strspn` in the C standard library.\npub fn indexOfNonePos(comptime T: type, slice: []const T, start_index: usize, values: []const T) ?usize {\n    if (start_index >= slice.len) return null;\n    outer: for (slice[start_index..], start_index..) |c, i| {\n        for (values) |value| {\n            if (c == value) continue :outer;\n        }\n        return i;\n    }\n    return null;\n}\n\ntest indexOfNone {\n    try testing.expect(indexOfNone(u8, \"abc123\", \"123\").? == 0);\n    try testing.expect(lastIndexOfNone(u8, \"abc123\", \"123\").? == 2);\n    try testing.expect(indexOfNone(u8, \"123abc\", \"123\").? == 3);\n    try testing.expect(lastIndexOfNone(u8, \"123abc\", \"123\").? == 5);\n    try testing.expect(indexOfNone(u8, \"123123\", \"123\") == null);\n    try testing.expect(indexOfNone(u8, \"333333\", \"123\") == null);\n\n    try testing.expect(indexOfNonePos(u8, \"abc123\", 3, \"321\") == null);\n}\n\npub fn indexOf(comptime T: type, haystack: []const T, needle: []const T) ?usize {\n    return indexOfPos(T, haystack, 0, needle);\n}\n\n/// Find the index in a slice of a sub-slice, searching from the end backwards.\n/// To start looking at a different index, slice the haystack first.\n/// Consider using `lastIndexOf` instead of this, which will automatically use a\n/// more sophisticated algorithm on larger inputs.\npub fn lastIndexOfLinear(comptime T: type, haystack: []const T, needle: []const T) ?usize {\n    var i: usize = haystack.len - needle.len;\n    while (true) : (i -= 1) {\n        if (mem.eql(T, haystack[i..][0..needle.len], needle)) return i;\n        if (i == 0) return null;\n    }\n}\n\n/// Consider using `indexOfPos` instead of this, which will automatically use a\n/// more sophisticated algorithm on larger inputs.\npub fn indexOfPosLinear(comptime T: type, haystack: []const T, start_index: usize, needle: []const T) ?usize {\n    if (needle.len > haystack.len) return null;\n    var i: usize = start_index;\n    const end = haystack.len - needle.len;\n    while (i <= end) : (i += 1) {\n        if (eql(T, haystack[i..][0..needle.len], needle)) return i;\n    }\n    return null;\n}\n\ntest indexOfPosLinear {\n    try testing.expectEqual(0, indexOfPosLinear(u8, \"\", 0, \"\"));\n    try testing.expectEqual(0, indexOfPosLinear(u8, \"123\", 0, \"\"));\n\n    try testing.expectEqual(null, indexOfPosLinear(u8, \"\", 0, \"1\"));\n    try testing.expectEqual(0, indexOfPosLinear(u8, \"1\", 0, \"1\"));\n    try testing.expectEqual(null, indexOfPosLinear(u8, \"2\", 0, \"1\"));\n    try testing.expectEqual(1, indexOfPosLinear(u8, \"21\", 0, \"1\"));\n    try testing.expectEqual(null, indexOfPosLinear(u8, \"222\", 0, \"1\"));\n\n    try testing.expectEqual(null, indexOfPosLinear(u8, \"\", 0, \"12\"));\n    try testing.expectEqual(null, indexOfPosLinear(u8, \"1\", 0, \"12\"));\n    try testing.expectEqual(null, indexOfPosLinear(u8, \"2\", 0, \"12\"));\n    try testing.expectEqual(0, indexOfPosLinear(u8, \"12\", 0, \"12\"));\n    try testing.expectEqual(null, indexOfPosLinear(u8, \"21\", 0, \"12\"));\n    try testing.expectEqual(1, indexOfPosLinear(u8, \"212\", 0, \"12\"));\n    try testing.expectEqual(0, indexOfPosLinear(u8, \"122\", 0, \"12\"));\n    try testing.expectEqual(1, indexOfPosLinear(u8, \"212112\", 0, \"12\"));\n}\n\nfn boyerMooreHorspoolPreprocessReverse(pattern: []const u8, table: *[256]usize) void {\n    for (table) |*c| {\n        c.* = pattern.len;\n    }\n\n    var i: usize = pattern.len - 1;\n    // The first item is intentionally ignored and the skip size will be pattern.len.\n    // This is the standard way Boyer-Moore-Horspool is implemented.\n    while (i > 0) : (i -= 1) {\n        table[pattern[i]] = i;\n    }\n}\n\nfn boyerMooreHorspoolPreprocess(pattern: []const u8, table: *[256]usize) void {\n    for (table) |*c| {\n        c.* = pattern.len;\n    }\n\n    var i: usize = 0;\n    // The last item is intentionally ignored and the skip size will be pattern.len.\n    // This is the standard way Boyer-Moore-Horspool is implemented.\n    while (i < pattern.len - 1) : (i += 1) {\n        table[pattern[i]] = pattern.len - 1 - i;\n    }\n}\n\n/// Find the index in a slice of a sub-slice, searching from the end backwards.\n/// To start looking at a different index, slice the haystack first.\n/// Uses the Reverse Boyer-Moore-Horspool algorithm on large inputs;\n/// `lastIndexOfLinear` on small inputs.\npub fn lastIndexOf(comptime T: type, haystack: []const T, needle: []const T) ?usize {\n    if (needle.len > haystack.len) return null;\n    if (needle.len == 0) return haystack.len;\n\n    if (!std.meta.hasUniqueRepresentation(T) or haystack.len < 52 or needle.len <= 4)\n        return lastIndexOfLinear(T, haystack, needle);\n\n    const haystack_bytes = sliceAsBytes(haystack);\n    const needle_bytes = sliceAsBytes(needle);\n\n    var skip_table: [256]usize = undefined;\n    boyerMooreHorspoolPreprocessReverse(needle_bytes, skip_table[0..]);\n\n    var i: usize = haystack_bytes.len - needle_bytes.len;\n    while (true) {\n        if (i % @sizeOf(T) == 0 and mem.eql(u8, haystack_bytes[i .. i + needle_bytes.len], needle_bytes)) {\n            return @divExact(i, @sizeOf(T));\n        }\n        const skip = skip_table[haystack_bytes[i]];\n        if (skip > i) break;\n        i -= skip;\n    }\n\n    return null;\n}\n\n/// Uses Boyer-Moore-Horspool algorithm on large inputs; `indexOfPosLinear` on small inputs.\npub fn indexOfPos(comptime T: type, haystack: []const T, start_index: usize, needle: []const T) ?usize {\n    if (needle.len > haystack.len) return null;\n    if (needle.len < 2) {\n        if (needle.len == 0) return start_index;\n        // indexOfScalarPos is significantly faster than indexOfPosLinear\n        return indexOfScalarPos(T, haystack, start_index, needle[0]);\n    }\n\n    if (!std.meta.hasUniqueRepresentation(T) or haystack.len < 52 or needle.len <= 4)\n        return indexOfPosLinear(T, haystack, start_index, needle);\n\n    const haystack_bytes = sliceAsBytes(haystack);\n    const needle_bytes = sliceAsBytes(needle);\n\n    var skip_table: [256]usize = undefined;\n    boyerMooreHorspoolPreprocess(needle_bytes, skip_table[0..]);\n\n    var i: usize = start_index * @sizeOf(T);\n    while (i <= haystack_bytes.len - needle_bytes.len) {\n        if (i % @sizeOf(T) == 0 and mem.eql(u8, haystack_bytes[i .. i + needle_bytes.len], needle_bytes)) {\n            return @divExact(i, @sizeOf(T));\n        }\n        i += skip_table[haystack_bytes[i + needle_bytes.len - 1]];\n    }\n\n    return null;\n}\n\ntest indexOf {\n    try testing.expect(indexOf(u8, \"one two three four five six seven eight nine ten eleven\", \"three four\").? == 8);\n    try testing.expect(lastIndexOf(u8, \"one two three four five six seven eight nine ten eleven\", \"three four\").? == 8);\n    try testing.expect(indexOf(u8, \"one two three four five six seven eight nine ten eleven\", \"two two\") == null);\n    try testing.expect(lastIndexOf(u8, \"one two three four five six seven eight nine ten eleven\", \"two two\") == null);\n\n    try testing.expect(indexOf(u8, \"one two three four five six seven eight nine ten\", \"\").? == 0);\n    try testing.expect(lastIndexOf(u8, \"one two three four five six seven eight nine ten\", \"\").? == 48);\n\n    try testing.expect(indexOf(u8, \"one two three four\", \"four\").? == 14);\n    try testing.expect(lastIndexOf(u8, \"one two three two four\", \"two\").? == 14);\n    try testing.expect(indexOf(u8, \"one two three four\", \"gour\") == null);\n    try testing.expect(lastIndexOf(u8, \"one two three four\", \"gour\") == null);\n    try testing.expect(indexOf(u8, \"foo\", \"foo\").? == 0);\n    try testing.expect(lastIndexOf(u8, \"foo\", \"foo\").? == 0);\n    try testing.expect(indexOf(u8, \"foo\", \"fool\") == null);\n    try testing.expect(lastIndexOf(u8, \"foo\", \"lfoo\") == null);\n    try testing.expect(lastIndexOf(u8, \"foo\", \"fool\") == null);\n\n    try testing.expect(indexOf(u8, \"foo foo\", \"foo\").? == 0);\n    try testing.expect(lastIndexOf(u8, \"foo foo\", \"foo\").? == 4);\n    try testing.expect(lastIndexOfAny(u8, \"boo, cat\", \"abo\").? == 6);\n    try testing.expect(lastIndexOfScalar(u8, \"boo\", 'o').? == 2);\n}\n\ntest \"indexOf multibyte\" {\n    {\n        // make haystack and needle long enough to trigger Boyer-Moore-Horspool algorithm\n        const haystack = [1]u16{0} ** 100 ++ [_]u16{ 0xbbaa, 0xccbb, 0xddcc, 0xeedd, 0xffee, 0x00ff };\n        const needle = [_]u16{ 0xbbaa, 0xccbb, 0xddcc, 0xeedd, 0xffee };\n        try testing.expectEqual(indexOfPos(u16, &haystack, 0, &needle), 100);\n\n        // check for misaligned false positives (little and big endian)\n        const needleLE = [_]u16{ 0xbbbb, 0xcccc, 0xdddd, 0xeeee, 0xffff };\n        try testing.expectEqual(indexOfPos(u16, &haystack, 0, &needleLE), null);\n        const needleBE = [_]u16{ 0xaacc, 0xbbdd, 0xccee, 0xddff, 0xee00 };\n        try testing.expectEqual(indexOfPos(u16, &haystack, 0, &needleBE), null);\n    }\n\n    {\n        // make haystack and needle long enough to trigger Boyer-Moore-Horspool algorithm\n        const haystack = [_]u16{ 0xbbaa, 0xccbb, 0xddcc, 0xeedd, 0xffee, 0x00ff } ++ [1]u16{0} ** 100;\n        const needle = [_]u16{ 0xbbaa, 0xccbb, 0xddcc, 0xeedd, 0xffee };\n        try testing.expectEqual(lastIndexOf(u16, &haystack, &needle), 0);\n\n        // check for misaligned false positives (little and big endian)\n        const needleLE = [_]u16{ 0xbbbb, 0xcccc, 0xdddd, 0xeeee, 0xffff };\n        try testing.expectEqual(lastIndexOf(u16, &haystack, &needleLE), null);\n        const needleBE = [_]u16{ 0xaacc, 0xbbdd, 0xccee, 0xddff, 0xee00 };\n        try testing.expectEqual(lastIndexOf(u16, &haystack, &needleBE), null);\n    }\n}\n\ntest \"indexOfPos empty needle\" {\n    try testing.expectEqual(indexOfPos(u8, \"abracadabra\", 5, \"\"), 5);\n}\n\n/// Returns the number of needles inside the haystack\n/// needle.len must be > 0\n/// does not count overlapping needles\npub fn count(comptime T: type, haystack: []const T, needle: []const T) usize {\n    assert(needle.len > 0);\n    var i: usize = 0;\n    var found: usize = 0;\n\n    while (indexOfPos(T, haystack, i, needle)) |idx| {\n        i = idx + needle.len;\n        found += 1;\n    }\n\n    return found;\n}\n\ntest count {\n    try testing.expect(count(u8, \"\", \"h\") == 0);\n    try testing.expect(count(u8, \"h\", \"h\") == 1);\n    try testing.expect(count(u8, \"hh\", \"h\") == 2);\n    try testing.expect(count(u8, \"world!\", \"hello\") == 0);\n    try testing.expect(count(u8, \"hello world!\", \"hello\") == 1);\n    try testing.expect(count(u8, \"   abcabc   abc\", \"abc\") == 3);\n    try testing.expect(count(u8, \"udexdcbvbruhasdrw\", \"bruh\") == 1);\n    try testing.expect(count(u8, \"foo bar\", \"o bar\") == 1);\n    try testing.expect(count(u8, \"foofoofoo\", \"foo\") == 3);\n    try testing.expect(count(u8, \"fffffff\", \"ff\") == 3);\n    try testing.expect(count(u8, \"owowowu\", \"owowu\") == 1);\n}\n\n/// Returns true if the haystack contains expected_count or more needles\n/// needle.len must be > 0\n/// does not count overlapping needles\npub fn containsAtLeast(comptime T: type, haystack: []const T, expected_count: usize, needle: []const T) bool {\n    assert(needle.len > 0);\n    if (expected_count == 0) return true;\n\n    var i: usize = 0;\n    var found: usize = 0;\n\n    while (indexOfPos(T, haystack, i, needle)) |idx| {\n        i = idx + needle.len;\n        found += 1;\n        if (found == expected_count) return true;\n    }\n    return false;\n}\n\ntest containsAtLeast {\n    try testing.expect(containsAtLeast(u8, \"aa\", 0, \"a\"));\n    try testing.expect(containsAtLeast(u8, \"aa\", 1, \"a\"));\n    try testing.expect(containsAtLeast(u8, \"aa\", 2, \"a\"));\n    try testing.expect(!containsAtLeast(u8, \"aa\", 3, \"a\"));\n\n    try testing.expect(containsAtLeast(u8, \"radaradar\", 1, \"radar\"));\n    try testing.expect(!containsAtLeast(u8, \"radaradar\", 2, \"radar\"));\n\n    try testing.expect(containsAtLeast(u8, \"radarradaradarradar\", 3, \"radar\"));\n    try testing.expect(!containsAtLeast(u8, \"radarradaradarradar\", 4, \"radar\"));\n\n    try testing.expect(containsAtLeast(u8, \"   radar      radar   \", 2, \"radar\"));\n    try testing.expect(!containsAtLeast(u8, \"   radar      radar   \", 3, \"radar\"));\n}\n\n/// Reads an integer from memory with size equal to bytes.len.\n/// T specifies the return type, which must be large enough to store\n/// the result.\npub fn readVarInt(comptime ReturnType: type, bytes: []const u8, endian: Endian) ReturnType {\n    var result: ReturnType = 0;\n    switch (endian) {\n        .big => {\n            for (bytes) |b| {\n                result = (result << 8) | b;\n            }\n        },\n        .little => {\n            const ShiftType = math.Log2Int(ReturnType);\n            for (bytes, 0..) |b, index| {\n                result = result | (@as(ReturnType, b) << @as(ShiftType, @intCast(index * 8)));\n            }\n        },\n    }\n    return result;\n}\n\n/// Loads an integer from packed memory with provided bit_count, bit_offset, and signedness.\n/// Asserts that T is large enough to store the read value.\n///\n/// Example:\n///     const T = packed struct(u16){ a: u3, b: u7, c: u6 };\n///     var st = T{ .a = 1, .b = 2, .c = 4 };\n///     const b_field = readVarPackedInt(u64, std.mem.asBytes(&st), @bitOffsetOf(T, \"b\"), 7, builtin.cpu.arch.endian(), .unsigned);\n///\npub fn readVarPackedInt(\n    comptime T: type,\n    bytes: []const u8,\n    bit_offset: usize,\n    bit_count: usize,\n    endian: std.builtin.Endian,\n    signedness: std.builtin.Signedness,\n) T {\n    const uN = std.meta.Int(.unsigned, @bitSizeOf(T));\n    const iN = std.meta.Int(.signed, @bitSizeOf(T));\n    const Log2N = std.math.Log2Int(T);\n\n    const read_size = (bit_count + (bit_offset % 8) + 7) / 8;\n    const bit_shift = @as(u3, @intCast(bit_offset % 8));\n    const pad = @as(Log2N, @intCast(@bitSizeOf(T) - bit_count));\n\n    const lowest_byte = switch (endian) {\n        .big => bytes.len - (bit_offset / 8) - read_size,\n        .little => bit_offset / 8,\n    };\n    const read_bytes = bytes[lowest_byte..][0..read_size];\n\n    if (@bitSizeOf(T) <= 8) {\n        // These are the same shifts/masks we perform below, but adds `@truncate`/`@intCast`\n        // where needed since int is smaller than a byte.\n        const value = if (read_size == 1) b: {\n            break :b @as(uN, @truncate(read_bytes[0] >> bit_shift));\n        } else b: {\n            const i: u1 = @intFromBool(endian == .big);\n            const head = @as(uN, @truncate(read_bytes[i] >> bit_shift));\n            const tail_shift = @as(Log2N, @intCast(@as(u4, 8) - bit_shift));\n            const tail = @as(uN, @truncate(read_bytes[1 - i]));\n            break :b (tail << tail_shift) | head;\n        };\n        switch (signedness) {\n            .signed => return @as(T, @intCast((@as(iN, @bitCast(value)) << pad) >> pad)),\n            .unsigned => return @as(T, @intCast((@as(uN, @bitCast(value)) << pad) >> pad)),\n        }\n    }\n\n    // Copy the value out (respecting endianness), accounting for bit_shift\n    var int: uN = 0;\n    switch (endian) {\n        .big => {\n            for (read_bytes[0 .. read_size - 1]) |elem| {\n                int = elem | (int << 8);\n            }\n            int = (read_bytes[read_size - 1] >> bit_shift) | (int << (@as(u4, 8) - bit_shift));\n        },\n        .little => {\n            int = read_bytes[0] >> bit_shift;\n            for (read_bytes[1..], 0..) |elem, i| {\n                int |= (@as(uN, elem) << @as(Log2N, @intCast((8 * (i + 1) - bit_shift))));\n            }\n        },\n    }\n    switch (signedness) {\n        .signed => return @as(T, @intCast((@as(iN, @bitCast(int)) << pad) >> pad)),\n        .unsigned => return @as(T, @intCast((@as(uN, @bitCast(int)) << pad) >> pad)),\n    }\n}\n\n/// Reads an integer from memory with bit count specified by T.\n/// The bit count of T must be evenly divisible by 8.\n/// This function cannot fail and cannot cause undefined behavior.\npub inline fn readInt(comptime T: type, buffer: *const [@divExact(@typeInfo(T).Int.bits, 8)]u8, endian: Endian) T {\n    const value: T = @bitCast(buffer.*);\n    return if (endian == native_endian) value else @byteSwap(value);\n}\n\ntest readInt {\n    try testing.expect(readInt(u0, &[_]u8{}, .big) == 0x0);\n    try testing.expect(readInt(u0, &[_]u8{}, .little) == 0x0);\n\n    try testing.expect(readInt(u8, &[_]u8{0x32}, .big) == 0x32);\n    try testing.expect(readInt(u8, &[_]u8{0x12}, .little) == 0x12);\n\n    try testing.expect(readInt(u16, &[_]u8{ 0x12, 0x34 }, .big) == 0x1234);\n    try testing.expect(readInt(u16, &[_]u8{ 0x12, 0x34 }, .little) == 0x3412);\n\n    try testing.expect(readInt(u72, &[_]u8{ 0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0, 0x24 }, .big) == 0x123456789abcdef024);\n    try testing.expect(readInt(u72, &[_]u8{ 0xec, 0x10, 0x32, 0x54, 0x76, 0x98, 0xba, 0xdc, 0xfe }, .little) == 0xfedcba9876543210ec);\n\n    try testing.expect(readInt(i8, &[_]u8{0xff}, .big) == -1);\n    try testing.expect(readInt(i8, &[_]u8{0xfe}, .little) == -2);\n\n    try testing.expect(readInt(i16, &[_]u8{ 0xff, 0xfd }, .big) == -3);\n    try testing.expect(readInt(i16, &[_]u8{ 0xfc, 0xff }, .little) == -4);\n\n    try moreReadIntTests();\n    try comptime moreReadIntTests();\n}\n\nfn readPackedIntLittle(comptime T: type, bytes: []const u8, bit_offset: usize) T {\n    const uN = std.meta.Int(.unsigned, @bitSizeOf(T));\n    const Log2N = std.math.Log2Int(T);\n\n    const bit_count = @as(usize, @bitSizeOf(T));\n    const bit_shift = @as(u3, @intCast(bit_offset % 8));\n\n    const load_size = (bit_count + 7) / 8;\n    const load_tail_bits = @as(u3, @intCast((load_size * 8) - bit_count));\n    const LoadInt = std.meta.Int(.unsigned, load_size * 8);\n\n    if (bit_count == 0)\n        return 0;\n\n    // Read by loading a LoadInt, and then follow it up with a 1-byte read\n    // of the tail if bit_offset pushed us over a byte boundary.\n    const read_bytes = bytes[bit_offset / 8 ..];\n    const val = @as(uN, @truncate(readInt(LoadInt, read_bytes[0..load_size], .little) >> bit_shift));\n    if (bit_shift > load_tail_bits) {\n        const tail_bits = @as(Log2N, @intCast(bit_shift - load_tail_bits));\n        const tail_byte = read_bytes[load_size];\n        const tail_truncated = if (bit_count < 8) @as(uN, @truncate(tail_byte)) else @as(uN, tail_byte);\n        return @as(T, @bitCast(val | (tail_truncated << (@as(Log2N, @truncate(bit_count)) -% tail_bits))));\n    } else return @as(T, @bitCast(val));\n}\n\nfn readPackedIntBig(comptime T: type, bytes: []const u8, bit_offset: usize) T {\n    const uN = std.meta.Int(.unsigned, @bitSizeOf(T));\n    const Log2N = std.math.Log2Int(T);\n\n    const bit_count = @as(usize, @bitSizeOf(T));\n    const bit_shift = @as(u3, @intCast(bit_offset % 8));\n    const byte_count = (@as(usize, bit_shift) + bit_count + 7) / 8;\n\n    const load_size = (bit_count + 7) / 8;\n    const load_tail_bits = @as(u3, @intCast((load_size * 8) - bit_count));\n    const LoadInt = std.meta.Int(.unsigned, load_size * 8);\n\n    if (bit_count == 0)\n        return 0;\n\n    // Read by loading a LoadInt, and then follow it up with a 1-byte read\n    // of the tail if bit_offset pushed us over a byte boundary.\n    const end = bytes.len - (bit_offset / 8);\n    const read_bytes = bytes[(end - byte_count)..end];\n    const val = @as(uN, @truncate(readInt(LoadInt, bytes[(end - load_size)..end][0..load_size], .big) >> bit_shift));\n    if (bit_shift > load_tail_bits) {\n        const tail_bits = @as(Log2N, @intCast(bit_shift - load_tail_bits));\n        const tail_byte = if (bit_count < 8) @as(uN, @truncate(read_bytes[0])) else @as(uN, read_bytes[0]);\n        return @as(T, @bitCast(val | (tail_byte << (@as(Log2N, @truncate(bit_count)) -% tail_bits))));\n    } else return @as(T, @bitCast(val));\n}\n\npub const readPackedIntNative = switch (native_endian) {\n    .little => readPackedIntLittle,\n    .big => readPackedIntBig,\n};\n\npub const readPackedIntForeign = switch (native_endian) {\n    .little => readPackedIntBig,\n    .big => readPackedIntLittle,\n};\n\n/// Loads an integer from packed memory.\n/// Asserts that buffer contains at least bit_offset + @bitSizeOf(T) bits.\n///\n/// Example:\n///     const T = packed struct(u16){ a: u3, b: u7, c: u6 };\n///     var st = T{ .a = 1, .b = 2, .c = 4 };\n///     const b_field = readPackedInt(u7, std.mem.asBytes(&st), @bitOffsetOf(T, \"b\"), builtin.cpu.arch.endian());\n///\npub fn readPackedInt(comptime T: type, bytes: []const u8, bit_offset: usize, endian: Endian) T {\n    switch (endian) {\n        .little => return readPackedIntLittle(T, bytes, bit_offset),\n        .big => return readPackedIntBig(T, bytes, bit_offset),\n    }\n}\n\ntest \"comptime read/write int\" {\n    comptime {\n        var bytes: [2]u8 = undefined;\n        writeInt(u16, &bytes, 0x1234, .little);\n        const result = readInt(u16, &bytes, .big);\n        try testing.expect(result == 0x3412);\n    }\n    comptime {\n        var bytes: [2]u8 = undefined;\n        writeInt(u16, &bytes, 0x1234, .big);\n        const result = readInt(u16, &bytes, .little);\n        try testing.expect(result == 0x3412);\n    }\n}\n\n/// Writes an integer to memory, storing it in twos-complement.\n/// This function always succeeds, has defined behavior for all inputs, but\n/// the integer bit width must be divisible by 8.\npub inline fn writeInt(comptime T: type, buffer: *[@divExact(@typeInfo(T).Int.bits, 8)]u8, value: T, endian: Endian) void {\n    buffer.* = @bitCast(if (endian == native_endian) value else @byteSwap(value));\n}\n\ntest writeInt {\n    var buf0: [0]u8 = undefined;\n    var buf1: [1]u8 = undefined;\n    var buf2: [2]u8 = undefined;\n    var buf9: [9]u8 = undefined;\n\n    writeInt(u0, &buf0, 0x0, .big);\n    try testing.expect(eql(u8, buf0[0..], &[_]u8{}));\n    writeInt(u0, &buf0, 0x0, .little);\n    try testing.expect(eql(u8, buf0[0..], &[_]u8{}));\n\n    writeInt(u8, &buf1, 0x12, .big);\n    try testing.expect(eql(u8, buf1[0..], &[_]u8{0x12}));\n    writeInt(u8, &buf1, 0x34, .little);\n    try testing.expect(eql(u8, buf1[0..], &[_]u8{0x34}));\n\n    writeInt(u16, &buf2, 0x1234, .big);\n    try testing.expect(eql(u8, buf2[0..], &[_]u8{ 0x12, 0x34 }));\n    writeInt(u16, &buf2, 0x5678, .little);\n    try testing.expect(eql(u8, buf2[0..], &[_]u8{ 0x78, 0x56 }));\n\n    writeInt(u72, &buf9, 0x123456789abcdef024, .big);\n    try testing.expect(eql(u8, buf9[0..], &[_]u8{ 0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0, 0x24 }));\n    writeInt(u72, &buf9, 0xfedcba9876543210ec, .little);\n    try testing.expect(eql(u8, buf9[0..], &[_]u8{ 0xec, 0x10, 0x32, 0x54, 0x76, 0x98, 0xba, 0xdc, 0xfe }));\n\n    writeInt(i8, &buf1, -1, .big);\n    try testing.expect(eql(u8, buf1[0..], &[_]u8{0xff}));\n    writeInt(i8, &buf1, -2, .little);\n    try testing.expect(eql(u8, buf1[0..], &[_]u8{0xfe}));\n\n    writeInt(i16, &buf2, -3, .big);\n    try testing.expect(eql(u8, buf2[0..], &[_]u8{ 0xff, 0xfd }));\n    writeInt(i16, &buf2, -4, .little);\n    try testing.expect(eql(u8, buf2[0..], &[_]u8{ 0xfc, 0xff }));\n}\n\nfn writePackedIntLittle(comptime T: type, bytes: []u8, bit_offset: usize, value: T) void {\n    const uN = std.meta.Int(.unsigned, @bitSizeOf(T));\n    const Log2N = std.math.Log2Int(T);\n\n    const bit_count = @as(usize, @bitSizeOf(T));\n    const bit_shift = @as(u3, @intCast(bit_offset % 8));\n\n    const store_size = (@bitSizeOf(T) + 7) / 8;\n    const store_tail_bits = @as(u3, @intCast((store_size * 8) - bit_count));\n    const StoreInt = std.meta.Int(.unsigned, store_size * 8);\n\n    if (bit_count == 0)\n        return;\n\n    // Write by storing a StoreInt, and then follow it up with a 1-byte tail\n    // if bit_offset pushed us over a byte boundary.\n    const write_bytes = bytes[bit_offset / 8 ..];\n    const head = write_bytes[0] & ((@as(u8, 1) << bit_shift) - 1);\n\n    var write_value = (@as(StoreInt, @as(uN, @bitCast(value))) << bit_shift) | @as(StoreInt, @intCast(head));\n    if (bit_shift > store_tail_bits) {\n        const tail_len = @as(Log2N, @intCast(bit_shift - store_tail_bits));\n        write_bytes[store_size] &= ~((@as(u8, 1) << @as(u3, @intCast(tail_len))) - 1);\n        write_bytes[store_size] |= @as(u8, @intCast((@as(uN, @bitCast(value)) >> (@as(Log2N, @truncate(bit_count)) -% tail_len))));\n    } else if (bit_shift < store_tail_bits) {\n        const tail_len = store_tail_bits - bit_shift;\n        const tail = write_bytes[store_size - 1] & (@as(u8, 0xfe) << (7 - tail_len));\n        write_value |= @as(StoreInt, tail) << (8 * (store_size - 1));\n    }\n\n    writeInt(StoreInt, write_bytes[0..store_size], write_value, .little);\n}\n\nfn writePackedIntBig(comptime T: type, bytes: []u8, bit_offset: usize, value: T) void {\n    const uN = std.meta.Int(.unsigned, @bitSizeOf(T));\n    const Log2N = std.math.Log2Int(T);\n\n    const bit_count = @as(usize, @bitSizeOf(T));\n    const bit_shift = @as(u3, @intCast(bit_offset % 8));\n    const byte_count = (bit_shift + bit_count + 7) / 8;\n\n    const store_size = (@bitSizeOf(T) + 7) / 8;\n    const store_tail_bits = @as(u3, @intCast((store_size * 8) - bit_count));\n    const StoreInt = std.meta.Int(.unsigned, store_size * 8);\n\n    if (bit_count == 0)\n        return;\n\n    // Write by storing a StoreInt, and then follow it up with a 1-byte tail\n    // if bit_offset pushed us over a byte boundary.\n    const end = bytes.len - (bit_offset / 8);\n    const write_bytes = bytes[(end - byte_count)..end];\n    const head = write_bytes[byte_count - 1] & ((@as(u8, 1) << bit_shift) - 1);\n\n    var write_value = (@as(StoreInt, @as(uN, @bitCast(value))) << bit_shift) | @as(StoreInt, @intCast(head));\n    if (bit_shift > store_tail_bits) {\n        const tail_len = @as(Log2N, @intCast(bit_shift - store_tail_bits));\n        write_bytes[0] &= ~((@as(u8, 1) << @as(u3, @intCast(tail_len))) - 1);\n        write_bytes[0] |= @as(u8, @intCast((@as(uN, @bitCast(value)) >> (@as(Log2N, @truncate(bit_count)) -% tail_len))));\n    } else if (bit_shift < store_tail_bits) {\n        const tail_len = store_tail_bits - bit_shift;\n        const tail = write_bytes[0] & (@as(u8, 0xfe) << (7 - tail_len));\n        write_value |= @as(StoreInt, tail) << (8 * (store_size - 1));\n    }\n\n    writeInt(StoreInt, write_bytes[(byte_count - store_size)..][0..store_size], write_value, .big);\n}\n\npub const writePackedIntNative = switch (native_endian) {\n    .little => writePackedIntLittle,\n    .big => writePackedIntBig,\n};\n\npub const writePackedIntForeign = switch (native_endian) {\n    .little => writePackedIntBig,\n    .big => writePackedIntLittle,\n};\n\n/// Stores an integer to packed memory.\n/// Asserts that buffer contains at least bit_offset + @bitSizeOf(T) bits.\n///\n/// Example:\n///     const T = packed struct(u16){ a: u3, b: u7, c: u6 };\n///     var st = T{ .a = 1, .b = 2, .c = 4 };\n///     // st.b = 0x7f;\n///     writePackedInt(u7, std.mem.asBytes(&st), @bitOffsetOf(T, \"b\"), 0x7f, builtin.cpu.arch.endian());\n///\npub fn writePackedInt(comptime T: type, bytes: []u8, bit_offset: usize, value: T, endian: Endian) void {\n    switch (endian) {\n        .little => writePackedIntLittle(T, bytes, bit_offset, value),\n        .big => writePackedIntBig(T, bytes, bit_offset, value),\n    }\n}\n\n/// Stores an integer to packed memory with provided bit_count, bit_offset, and signedness.\n/// If negative, the written value is sign-extended.\n///\n/// Example:\n///     const T = packed struct(u16){ a: u3, b: u7, c: u6 };\n///     var st = T{ .a = 1, .b = 2, .c = 4 };\n///     // st.b = 0x7f;\n///     var value: u64 = 0x7f;\n///     writeVarPackedInt(std.mem.asBytes(&st), @bitOffsetOf(T, \"b\"), 7, value, builtin.cpu.arch.endian());\n///\npub fn writeVarPackedInt(bytes: []u8, bit_offset: usize, bit_count: usize, value: anytype, endian: std.builtin.Endian) void {\n    const T = @TypeOf(value);\n    const uN = std.meta.Int(.unsigned, @bitSizeOf(T));\n\n    const bit_shift = @as(u3, @intCast(bit_offset % 8));\n    const write_size = (bit_count + bit_shift + 7) / 8;\n    const lowest_byte = switch (endian) {\n        .big => bytes.len - (bit_offset / 8) - write_size,\n        .little => bit_offset / 8,\n    };\n    const write_bytes = bytes[lowest_byte..][0..write_size];\n\n    if (write_size == 1) {\n        // Single byte writes are handled specially, since we need to mask bits\n        // on both ends of the byte.\n        const mask = (@as(u8, 0xff) >> @as(u3, @intCast(8 - bit_count)));\n        const new_bits = @as(u8, @intCast(@as(uN, @bitCast(value)) & mask)) << bit_shift;\n        write_bytes[0] = (write_bytes[0] & ~(mask << bit_shift)) | new_bits;\n        return;\n    }\n\n    var remaining: T = value;\n\n    // Iterate bytes forward for Little-endian, backward for Big-endian\n    const delta: i2 = if (endian == .big) -1 else 1;\n    const start = if (endian == .big) @as(isize, @intCast(write_bytes.len - 1)) else 0;\n\n    var i: isize = start; // isize for signed index arithmetic\n\n    // Write first byte, using a mask to protects bits preceding bit_offset\n    const head_mask = @as(u8, 0xff) >> bit_shift;\n    write_bytes[@intCast(i)] &= ~(head_mask << bit_shift);\n    write_bytes[@intCast(i)] |= @as(u8, @intCast(@as(uN, @bitCast(remaining)) & head_mask)) << bit_shift;\n    remaining = math.shr(T, remaining, @as(u4, 8) - bit_shift);\n    i += delta;\n\n    // Write bytes[1..bytes.len - 1]\n    if (@bitSizeOf(T) > 8) {\n        const loop_end = start + delta * (@as(isize, @intCast(write_size)) - 1);\n        while (i != loop_end) : (i += delta) {\n            write_bytes[@as(usize, @intCast(i))] = @as(u8, @truncate(@as(uN, @bitCast(remaining))));\n            remaining >>= 8;\n        }\n    }\n\n    // Write last byte, using a mask to protect bits following bit_offset + bit_count\n    const following_bits = -%@as(u3, @truncate(bit_shift + bit_count));\n    const tail_mask = (@as(u8, 0xff) << following_bits) >> following_bits;\n    write_bytes[@as(usize, @intCast(i))] &= ~tail_mask;\n    write_bytes[@as(usize, @intCast(i))] |= @as(u8, @intCast(@as(uN, @bitCast(remaining)) & tail_mask));\n}\n\n/// Swap the byte order of all the members of the fields of a struct\n/// (Changing their endianness)\npub fn byteSwapAllFields(comptime S: type, ptr: *S) void {\n    switch (@typeInfo(S)) {\n        .Struct => {\n            inline for (std.meta.fields(S)) |f| {\n                switch (@typeInfo(f.type)) {\n                    .Struct => |struct_info| if (struct_info.backing_integer) |Int| {\n                        @field(ptr, f.name) = @bitCast(@byteSwap(@as(Int, @bitCast(@field(ptr, f.name)))));\n                    } else {\n                        byteSwapAllFields(f.type, &@field(ptr, f.name));\n                    },\n                    .Array => byteSwapAllFields(f.type, &@field(ptr, f.name)),\n                    .Enum => {\n                        @field(ptr, f.name) = @enumFromInt(@byteSwap(@intFromEnum(@field(ptr, f.name))));\n                    },\n                    else => {\n                        @field(ptr, f.name) = @byteSwap(@field(ptr, f.name));\n                    },\n                }\n            }\n        },\n        .Array => {\n            for (ptr) |*item| {\n                switch (@typeInfo(@TypeOf(item.*))) {\n                    .Struct, .Array => byteSwapAllFields(@TypeOf(item.*), item),\n                    .Enum => {\n                        item.* = @enumFromInt(@byteSwap(@intFromEnum(item.*)));\n                    },\n                    else => {\n                        item.* = @byteSwap(item.*);\n                    },\n                }\n            }\n        },\n        else => @compileError(\"byteSwapAllFields expects a struct or array as the first argument\"),\n    }\n}\n\ntest byteSwapAllFields {\n    const T = extern struct {\n        f0: u8,\n        f1: u16,\n        f2: u32,\n        f3: [1]u8,\n    };\n    const K = extern struct {\n        f0: u8,\n        f1: T,\n        f2: u16,\n        f3: [1]u8,\n    };\n    var s = T{\n        .f0 = 0x12,\n        .f1 = 0x1234,\n        .f2 = 0x12345678,\n        .f3 = .{0x12},\n    };\n    var k = K{\n        .f0 = 0x12,\n        .f1 = s,\n        .f2 = 0x1234,\n        .f3 = .{0x12},\n    };\n    byteSwapAllFields(T, &s);\n    byteSwapAllFields(K, &k);\n    try std.testing.expectEqual(T{\n        .f0 = 0x12,\n        .f1 = 0x3412,\n        .f2 = 0x78563412,\n        .f3 = .{0x12},\n    }, s);\n    try std.testing.expectEqual(K{\n        .f0 = 0x12,\n        .f1 = s,\n        .f2 = 0x3412,\n        .f3 = .{0x12},\n    }, k);\n}\n\n/// Deprecated: use `tokenizeAny`, `tokenizeSequence`, or `tokenizeScalar`\npub const tokenize = tokenizeAny;\n\n/// Returns an iterator that iterates over the slices of `buffer` that are not\n/// any of the items in `delimiters`.\n///\n/// `tokenizeAny(u8, \"   abc|def ||  ghi  \", \" |\")` will return slices\n/// for \"abc\", \"def\", \"ghi\", null, in that order.\n///\n/// If `buffer` is empty, the iterator will return null.\n/// If none of `delimiters` exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n///\n/// See also: `tokenizeSequence`, `tokenizeScalar`,\n///           `splitSequence`,`splitAny`, `splitScalar`,\n///           `splitBackwardsSequence`, `splitBackwardsAny`, and `splitBackwardsScalar`\npub fn tokenizeAny(comptime T: type, buffer: []const T, delimiters: []const T) TokenIterator(T, .any) {\n    return .{\n        .index = 0,\n        .buffer = buffer,\n        .delimiter = delimiters,\n    };\n}\n\n/// Returns an iterator that iterates over the slices of `buffer` that are not\n/// the sequence in `delimiter`.\n///\n/// `tokenizeSequence(u8, \"<>abc><def<><>ghi\", \"<>\")` will return slices\n/// for \"abc><def\", \"ghi\", null, in that order.\n///\n/// If `buffer` is empty, the iterator will return null.\n/// If `delimiter` does not exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n/// The delimiter length must not be zero.\n///\n/// See also: `tokenizeAny`, `tokenizeScalar`,\n///           `splitSequence`,`splitAny`, and `splitScalar`\n///           `splitBackwardsSequence`, `splitBackwardsAny`, and `splitBackwardsScalar`\npub fn tokenizeSequence(comptime T: type, buffer: []const T, delimiter: []const T) TokenIterator(T, .sequence) {\n    assert(delimiter.len != 0);\n    return .{\n        .index = 0,\n        .buffer = buffer,\n        .delimiter = delimiter,\n    };\n}\n\n/// Returns an iterator that iterates over the slices of `buffer` that are not\n/// `delimiter`.\n///\n/// `tokenizeScalar(u8, \"   abc def     ghi  \", ' ')` will return slices\n/// for \"abc\", \"def\", \"ghi\", null, in that order.\n///\n/// If `buffer` is empty, the iterator will return null.\n/// If `delimiter` does not exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n///\n/// See also: `tokenizeAny`, `tokenizeSequence`,\n///           `splitSequence`,`splitAny`, and `splitScalar`\n///           `splitBackwardsSequence`, `splitBackwardsAny`, and `splitBackwardsScalar`\npub fn tokenizeScalar(comptime T: type, buffer: []const T, delimiter: T) TokenIterator(T, .scalar) {\n    return .{\n        .index = 0,\n        .buffer = buffer,\n        .delimiter = delimiter,\n    };\n}\n\ntest tokenizeScalar {\n    var it = tokenizeScalar(u8, \"   abc def   ghi  \", ' ');\n    try testing.expect(eql(u8, it.next().?, \"abc\"));\n    try testing.expect(eql(u8, it.peek().?, \"def\"));\n    try testing.expect(eql(u8, it.next().?, \"def\"));\n    try testing.expect(eql(u8, it.next().?, \"ghi\"));\n    try testing.expect(it.next() == null);\n\n    it = tokenizeScalar(u8, \"..\\\\bob\", '\\\\');\n    try testing.expect(eql(u8, it.next().?, \"..\"));\n    try testing.expect(eql(u8, \"..\", \"..\\\\bob\"[0..it.index]));\n    try testing.expect(eql(u8, it.next().?, \"bob\"));\n    try testing.expect(it.next() == null);\n\n    it = tokenizeScalar(u8, \"//a/b\", '/');\n    try testing.expect(eql(u8, it.next().?, \"a\"));\n    try testing.expect(eql(u8, it.next().?, \"b\"));\n    try testing.expect(eql(u8, \"//a/b\", \"//a/b\"[0..it.index]));\n    try testing.expect(it.next() == null);\n\n    it = tokenizeScalar(u8, \"|\", '|');\n    try testing.expect(it.next() == null);\n    try testing.expect(it.peek() == null);\n\n    it = tokenizeScalar(u8, \"\", '|');\n    try testing.expect(it.next() == null);\n    try testing.expect(it.peek() == null);\n\n    it = tokenizeScalar(u8, \"hello\", ' ');\n    try testing.expect(eql(u8, it.next().?, \"hello\"));\n    try testing.expect(it.next() == null);\n\n    var it16 = tokenizeScalar(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"hello\"),\n        ' ',\n    );\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"hello\")));\n    try testing.expect(it16.next() == null);\n}\n\ntest tokenizeAny {\n    var it = tokenizeAny(u8, \"a|b,c/d e\", \" /,|\");\n    try testing.expect(eql(u8, it.next().?, \"a\"));\n    try testing.expect(eql(u8, it.peek().?, \"b\"));\n    try testing.expect(eql(u8, it.next().?, \"b\"));\n    try testing.expect(eql(u8, it.next().?, \"c\"));\n    try testing.expect(eql(u8, it.next().?, \"d\"));\n    try testing.expect(eql(u8, it.next().?, \"e\"));\n    try testing.expect(it.next() == null);\n    try testing.expect(it.peek() == null);\n\n    it = tokenizeAny(u8, \"hello\", \"\");\n    try testing.expect(eql(u8, it.next().?, \"hello\"));\n    try testing.expect(it.next() == null);\n\n    var it16 = tokenizeAny(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"a|b,c/d e\"),\n        std.unicode.utf8ToUtf16LeStringLiteral(\" /,|\"),\n    );\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"a\")));\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"b\")));\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"c\")));\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"d\")));\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"e\")));\n    try testing.expect(it16.next() == null);\n}\n\ntest tokenizeSequence {\n    var it = tokenizeSequence(u8, \"a<>b<><>c><>d><\", \"<>\");\n    try testing.expectEqualStrings(\"a\", it.next().?);\n    try testing.expectEqualStrings(\"b\", it.peek().?);\n    try testing.expectEqualStrings(\"b\", it.next().?);\n    try testing.expectEqualStrings(\"c>\", it.next().?);\n    try testing.expectEqualStrings(\"d><\", it.next().?);\n    try testing.expect(it.next() == null);\n    try testing.expect(it.peek() == null);\n\n    var it16 = tokenizeSequence(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"a<>b<><>c><>d><\"),\n        std.unicode.utf8ToUtf16LeStringLiteral(\"<>\"),\n    );\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"a\")));\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"b\")));\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"c>\")));\n    try testing.expect(eql(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"d><\")));\n    try testing.expect(it16.next() == null);\n}\n\ntest \"tokenize (reset)\" {\n    {\n        var it = tokenizeAny(u8, \"   abc def   ghi  \", \" \");\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n        try testing.expect(it.next() == null);\n    }\n    {\n        var it = tokenizeSequence(u8, \"<><>abc<>def<><>ghi<>\", \"<>\");\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n        try testing.expect(it.next() == null);\n    }\n    {\n        var it = tokenizeScalar(u8, \"   abc def   ghi  \", ' ');\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n        try testing.expect(it.next() == null);\n    }\n}\n\n/// Deprecated: use `splitSequence`, `splitAny`, or `splitScalar`\npub const split = splitSequence;\n\n/// Returns an iterator that iterates over the slices of `buffer` that\n/// are separated by the byte sequence in `delimiter`.\n///\n/// `splitSequence(u8, \"abc||def||||ghi\", \"||\")` will return slices\n/// for \"abc\", \"def\", \"\", \"ghi\", null, in that order.\n///\n/// If `delimiter` does not exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n/// The delimiter length must not be zero.\n///\n/// See also: `splitAny`, `splitScalar`, `splitBackwardsSequence`,\n///           `splitBackwardsAny`,`splitBackwardsScalar`,\n///           `tokenizeAny`, `tokenizeSequence`, and `tokenizeScalar`.\npub fn splitSequence(comptime T: type, buffer: []const T, delimiter: []const T) SplitIterator(T, .sequence) {\n    assert(delimiter.len != 0);\n    return .{\n        .index = 0,\n        .buffer = buffer,\n        .delimiter = delimiter,\n    };\n}\n\n/// Returns an iterator that iterates over the slices of `buffer` that\n/// are separated by any item in `delimiters`.\n///\n/// `splitAny(u8, \"abc,def||ghi\", \"|,\")` will return slices\n/// for \"abc\", \"def\", \"\", \"ghi\", null, in that order.\n///\n/// If none of `delimiters` exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n///\n/// See also: `splitSequence`, `splitScalar`, `splitBackwardsSequence`,\n///           `splitBackwardsAny`,`splitBackwardsScalar`,\n///           `tokenizeAny`, `tokenizeSequence`, and `tokenizeScalar`.\npub fn splitAny(comptime T: type, buffer: []const T, delimiters: []const T) SplitIterator(T, .any) {\n    return .{\n        .index = 0,\n        .buffer = buffer,\n        .delimiter = delimiters,\n    };\n}\n\n/// Returns an iterator that iterates over the slices of `buffer` that\n/// are separated by `delimiter`.\n///\n/// `splitScalar(u8, \"abc|def||ghi\", '|')` will return slices\n/// for \"abc\", \"def\", \"\", \"ghi\", null, in that order.\n///\n/// If `delimiter` does not exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n///\n/// See also: `splitSequence`, `splitAny`, `splitBackwardsSequence`,\n///           `splitBackwardsAny`,`splitBackwardsScalar`,\n///           `tokenizeAny`, `tokenizeSequence`, and `tokenizeScalar`.\npub fn splitScalar(comptime T: type, buffer: []const T, delimiter: T) SplitIterator(T, .scalar) {\n    return .{\n        .index = 0,\n        .buffer = buffer,\n        .delimiter = delimiter,\n    };\n}\n\ntest splitScalar {\n    var it = splitScalar(u8, \"abc|def||ghi\", '|');\n    try testing.expectEqualSlices(u8, it.rest(), \"abc|def||ghi\");\n    try testing.expectEqualSlices(u8, it.first(), \"abc\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"def||ghi\");\n    try testing.expectEqualSlices(u8, it.peek().?, \"def\");\n    try testing.expectEqualSlices(u8, it.next().?, \"def\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"|ghi\");\n    try testing.expectEqualSlices(u8, it.next().?, \"\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"ghi\");\n    try testing.expectEqualSlices(u8, it.peek().?, \"ghi\");\n    try testing.expectEqualSlices(u8, it.next().?, \"ghi\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"\");\n    try testing.expect(it.peek() == null);\n    try testing.expect(it.next() == null);\n\n    it = splitScalar(u8, \"\", '|');\n    try testing.expectEqualSlices(u8, it.first(), \"\");\n    try testing.expect(it.next() == null);\n\n    it = splitScalar(u8, \"|\", '|');\n    try testing.expectEqualSlices(u8, it.first(), \"\");\n    try testing.expectEqualSlices(u8, it.next().?, \"\");\n    try testing.expect(it.peek() == null);\n    try testing.expect(it.next() == null);\n\n    it = splitScalar(u8, \"hello\", ' ');\n    try testing.expectEqualSlices(u8, it.first(), \"hello\");\n    try testing.expect(it.next() == null);\n\n    var it16 = splitScalar(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"hello\"),\n        ' ',\n    );\n    try testing.expectEqualSlices(u16, it16.first(), std.unicode.utf8ToUtf16LeStringLiteral(\"hello\"));\n    try testing.expect(it16.next() == null);\n}\n\ntest splitSequence {\n    var it = splitSequence(u8, \"a, b ,, c, d, e\", \", \");\n    try testing.expectEqualSlices(u8, it.first(), \"a\");\n    try testing.expectEqualSlices(u8, it.rest(), \"b ,, c, d, e\");\n    try testing.expectEqualSlices(u8, it.next().?, \"b ,\");\n    try testing.expectEqualSlices(u8, it.next().?, \"c\");\n    try testing.expectEqualSlices(u8, it.next().?, \"d\");\n    try testing.expectEqualSlices(u8, it.next().?, \"e\");\n    try testing.expect(it.next() == null);\n\n    var it16 = splitSequence(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"a, b ,, c, d, e\"),\n        std.unicode.utf8ToUtf16LeStringLiteral(\", \"),\n    );\n    try testing.expectEqualSlices(u16, it16.first(), std.unicode.utf8ToUtf16LeStringLiteral(\"a\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"b ,\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"c\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"d\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"e\"));\n    try testing.expect(it16.next() == null);\n}\n\ntest splitAny {\n    var it = splitAny(u8, \"a,b, c d e\", \", \");\n    try testing.expectEqualSlices(u8, it.first(), \"a\");\n    try testing.expectEqualSlices(u8, it.rest(), \"b, c d e\");\n    try testing.expectEqualSlices(u8, it.next().?, \"b\");\n    try testing.expectEqualSlices(u8, it.next().?, \"\");\n    try testing.expectEqualSlices(u8, it.next().?, \"c\");\n    try testing.expectEqualSlices(u8, it.next().?, \"d\");\n    try testing.expectEqualSlices(u8, it.next().?, \"e\");\n    try testing.expect(it.next() == null);\n\n    it = splitAny(u8, \"hello\", \"\");\n    try testing.expect(eql(u8, it.next().?, \"hello\"));\n    try testing.expect(it.next() == null);\n\n    var it16 = splitAny(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"a,b, c d e\"),\n        std.unicode.utf8ToUtf16LeStringLiteral(\", \"),\n    );\n    try testing.expectEqualSlices(u16, it16.first(), std.unicode.utf8ToUtf16LeStringLiteral(\"a\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"b\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"c\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"d\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"e\"));\n    try testing.expect(it16.next() == null);\n}\n\ntest \"split (reset)\" {\n    {\n        var it = splitSequence(u8, \"abc def ghi\", \" \");\n        try testing.expect(eql(u8, it.first(), \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.first(), \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n        try testing.expect(it.next() == null);\n    }\n    {\n        var it = splitAny(u8, \"abc def,ghi\", \" ,\");\n        try testing.expect(eql(u8, it.first(), \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.first(), \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n        try testing.expect(it.next() == null);\n    }\n    {\n        var it = splitScalar(u8, \"abc def ghi\", ' ');\n        try testing.expect(eql(u8, it.first(), \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.first(), \"abc\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"ghi\"));\n        try testing.expect(it.next() == null);\n    }\n}\n\n/// Deprecated: use `splitBackwardsSequence`, `splitBackwardsAny`, or `splitBackwardsScalar`\npub const splitBackwards = splitBackwardsSequence;\n\n/// Returns an iterator that iterates backwards over the slices of `buffer` that\n/// are separated by the sequence in `delimiter`.\n///\n/// `splitBackwardsSequence(u8, \"abc||def||||ghi\", \"||\")` will return slices\n/// for \"ghi\", \"\", \"def\", \"abc\", null, in that order.\n///\n/// If `delimiter` does not exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n/// The delimiter length must not be zero.\n///\n/// See also: `splitBackwardsAny`, `splitBackwardsScalar`,\n///           `splitSequence`, `splitAny`,`splitScalar`,\n///           `tokenizeAny`, `tokenizeSequence`, and `tokenizeScalar`.\npub fn splitBackwardsSequence(comptime T: type, buffer: []const T, delimiter: []const T) SplitBackwardsIterator(T, .sequence) {\n    assert(delimiter.len != 0);\n    return .{\n        .index = buffer.len,\n        .buffer = buffer,\n        .delimiter = delimiter,\n    };\n}\n\n/// Returns an iterator that iterates backwards over the slices of `buffer` that\n/// are separated by any item in `delimiters`.\n///\n/// `splitBackwardsAny(u8, \"abc,def||ghi\", \"|,\")` will return slices\n/// for \"ghi\", \"\", \"def\", \"abc\", null, in that order.\n///\n/// If none of `delimiters` exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n///\n/// See also: `splitBackwardsSequence`, `splitBackwardsScalar`,\n///           `splitSequence`, `splitAny`,`splitScalar`,\n///           `tokenizeAny`, `tokenizeSequence`, and `tokenizeScalar`.\npub fn splitBackwardsAny(comptime T: type, buffer: []const T, delimiters: []const T) SplitBackwardsIterator(T, .any) {\n    return .{\n        .index = buffer.len,\n        .buffer = buffer,\n        .delimiter = delimiters,\n    };\n}\n\n/// Returns an iterator that iterates backwards over the slices of `buffer` that\n/// are separated by `delimiter`.\n///\n/// `splitBackwardsScalar(u8, \"abc|def||ghi\", '|')` will return slices\n/// for \"ghi\", \"\", \"def\", \"abc\", null, in that order.\n///\n/// If `delimiter` does not exist in buffer,\n/// the iterator will return `buffer`, null, in that order.\n///\n/// See also: `splitBackwardsSequence`, `splitBackwardsAny`,\n///           `splitSequence`, `splitAny`,`splitScalar`,\n///           `tokenizeAny`, `tokenizeSequence`, and `tokenizeScalar`.\npub fn splitBackwardsScalar(comptime T: type, buffer: []const T, delimiter: T) SplitBackwardsIterator(T, .scalar) {\n    return .{\n        .index = buffer.len,\n        .buffer = buffer,\n        .delimiter = delimiter,\n    };\n}\n\ntest splitBackwardsScalar {\n    var it = splitBackwardsScalar(u8, \"abc|def||ghi\", '|');\n    try testing.expectEqualSlices(u8, it.rest(), \"abc|def||ghi\");\n    try testing.expectEqualSlices(u8, it.first(), \"ghi\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"abc|def|\");\n    try testing.expectEqualSlices(u8, it.next().?, \"\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"abc|def\");\n    try testing.expectEqualSlices(u8, it.next().?, \"def\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"abc\");\n    try testing.expectEqualSlices(u8, it.next().?, \"abc\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"\");\n    try testing.expect(it.next() == null);\n\n    it = splitBackwardsScalar(u8, \"\", '|');\n    try testing.expectEqualSlices(u8, it.first(), \"\");\n    try testing.expect(it.next() == null);\n\n    it = splitBackwardsScalar(u8, \"|\", '|');\n    try testing.expectEqualSlices(u8, it.first(), \"\");\n    try testing.expectEqualSlices(u8, it.next().?, \"\");\n    try testing.expect(it.next() == null);\n\n    it = splitBackwardsScalar(u8, \"hello\", ' ');\n    try testing.expectEqualSlices(u8, it.first(), \"hello\");\n    try testing.expect(it.next() == null);\n\n    var it16 = splitBackwardsScalar(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"hello\"),\n        ' ',\n    );\n    try testing.expectEqualSlices(u16, it16.first(), std.unicode.utf8ToUtf16LeStringLiteral(\"hello\"));\n    try testing.expect(it16.next() == null);\n}\n\ntest splitBackwardsSequence {\n    var it = splitBackwardsSequence(u8, \"a, b ,, c, d, e\", \", \");\n    try testing.expectEqualSlices(u8, it.rest(), \"a, b ,, c, d, e\");\n    try testing.expectEqualSlices(u8, it.first(), \"e\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a, b ,, c, d\");\n    try testing.expectEqualSlices(u8, it.next().?, \"d\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a, b ,, c\");\n    try testing.expectEqualSlices(u8, it.next().?, \"c\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a, b ,\");\n    try testing.expectEqualSlices(u8, it.next().?, \"b ,\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a\");\n    try testing.expectEqualSlices(u8, it.next().?, \"a\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"\");\n    try testing.expect(it.next() == null);\n\n    var it16 = splitBackwardsSequence(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"a, b ,, c, d, e\"),\n        std.unicode.utf8ToUtf16LeStringLiteral(\", \"),\n    );\n    try testing.expectEqualSlices(u16, it16.first(), std.unicode.utf8ToUtf16LeStringLiteral(\"e\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"d\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"c\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"b ,\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"a\"));\n    try testing.expect(it16.next() == null);\n}\n\ntest splitBackwardsAny {\n    var it = splitBackwardsAny(u8, \"a,b, c d e\", \", \");\n    try testing.expectEqualSlices(u8, it.rest(), \"a,b, c d e\");\n    try testing.expectEqualSlices(u8, it.first(), \"e\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a,b, c d\");\n    try testing.expectEqualSlices(u8, it.next().?, \"d\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a,b, c\");\n    try testing.expectEqualSlices(u8, it.next().?, \"c\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a,b,\");\n    try testing.expectEqualSlices(u8, it.next().?, \"\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a,b\");\n    try testing.expectEqualSlices(u8, it.next().?, \"b\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"a\");\n    try testing.expectEqualSlices(u8, it.next().?, \"a\");\n\n    try testing.expectEqualSlices(u8, it.rest(), \"\");\n    try testing.expect(it.next() == null);\n\n    var it16 = splitBackwardsAny(\n        u16,\n        std.unicode.utf8ToUtf16LeStringLiteral(\"a,b, c d e\"),\n        std.unicode.utf8ToUtf16LeStringLiteral(\", \"),\n    );\n    try testing.expectEqualSlices(u16, it16.first(), std.unicode.utf8ToUtf16LeStringLiteral(\"e\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"d\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"c\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"b\"));\n    try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"a\"));\n    try testing.expect(it16.next() == null);\n}\n\ntest \"splitBackwards (reset)\" {\n    {\n        var it = splitBackwardsSequence(u8, \"abc def ghi\", \" \");\n        try testing.expect(eql(u8, it.first(), \"ghi\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.first(), \"ghi\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(it.next() == null);\n    }\n    {\n        var it = splitBackwardsAny(u8, \"abc def,ghi\", \" ,\");\n        try testing.expect(eql(u8, it.first(), \"ghi\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.first(), \"ghi\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(it.next() == null);\n    }\n    {\n        var it = splitBackwardsScalar(u8, \"abc def ghi\", ' ');\n        try testing.expect(eql(u8, it.first(), \"ghi\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n\n        it.reset();\n\n        try testing.expect(eql(u8, it.first(), \"ghi\"));\n        try testing.expect(eql(u8, it.next().?, \"def\"));\n        try testing.expect(eql(u8, it.next().?, \"abc\"));\n        try testing.expect(it.next() == null);\n    }\n}\n\n/// Returns an iterator with a sliding window of slices for `buffer`.\n/// The sliding window has length `size` and on every iteration moves\n/// forward by `advance`.\n///\n/// Extract data for moving average with:\n/// `window(u8, \"abcdefg\", 3, 1)` will return slices\n/// \"abc\", \"bcd\", \"cde\", \"def\", \"efg\", null, in that order.\n///\n/// Chunk or split every N items with:\n/// `window(u8, \"abcdefg\", 3, 3)` will return slices\n/// \"abc\", \"def\", \"g\", null, in that order.\n///\n/// Pick every even index with:\n/// `window(u8, \"abcdefg\", 1, 2)` will return slices\n/// \"a\", \"c\", \"e\", \"g\" null, in that order.\n///\n/// The `size` and `advance` must be not be zero.\npub fn window(comptime T: type, buffer: []const T, size: usize, advance: usize) WindowIterator(T) {\n    assert(size != 0);\n    assert(advance != 0);\n    return .{\n        .index = 0,\n        .buffer = buffer,\n        .size = size,\n        .advance = advance,\n    };\n}\n\ntest window {\n    {\n        // moving average size 3\n        var it = window(u8, \"abcdefg\", 3, 1);\n        try testing.expectEqualSlices(u8, it.next().?, \"abc\");\n        try testing.expectEqualSlices(u8, it.next().?, \"bcd\");\n        try testing.expectEqualSlices(u8, it.next().?, \"cde\");\n        try testing.expectEqualSlices(u8, it.next().?, \"def\");\n        try testing.expectEqualSlices(u8, it.next().?, \"efg\");\n        try testing.expectEqual(it.next(), null);\n\n        // multibyte\n        var it16 = window(u16, std.unicode.utf8ToUtf16LeStringLiteral(\"abcdefg\"), 3, 1);\n        try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"abc\"));\n        try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"bcd\"));\n        try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"cde\"));\n        try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"def\"));\n        try testing.expectEqualSlices(u16, it16.next().?, std.unicode.utf8ToUtf16LeStringLiteral(\"efg\"));\n        try testing.expectEqual(it16.next(), null);\n    }\n\n    {\n        // chunk/split every 3\n        var it = window(u8, \"abcdefg\", 3, 3);\n        try testing.expectEqualSlices(u8, it.next().?, \"abc\");\n        try testing.expectEqualSlices(u8, it.next().?, \"def\");\n        try testing.expectEqualSlices(u8, it.next().?, \"g\");\n        try testing.expectEqual(it.next(), null);\n    }\n\n    {\n        // pick even\n        var it = window(u8, \"abcdefg\", 1, 2);\n        try testing.expectEqualSlices(u8, it.next().?, \"a\");\n        try testing.expectEqualSlices(u8, it.next().?, \"c\");\n        try testing.expectEqualSlices(u8, it.next().?, \"e\");\n        try testing.expectEqualSlices(u8, it.next().?, \"g\");\n        try testing.expectEqual(it.next(), null);\n    }\n\n    {\n        // empty\n        var it = window(u8, \"\", 1, 1);\n        try testing.expectEqualSlices(u8, it.next().?, \"\");\n        try testing.expectEqual(it.next(), null);\n\n        it = window(u8, \"\", 10, 1);\n        try testing.expectEqualSlices(u8, it.next().?, \"\");\n        try testing.expectEqual(it.next(), null);\n\n        it = window(u8, \"\", 1, 10);\n        try testing.expectEqualSlices(u8, it.next().?, \"\");\n        try testing.expectEqual(it.next(), null);\n\n        it = window(u8, \"\", 10, 10);\n        try testing.expectEqualSlices(u8, it.next().?, \"\");\n        try testing.expectEqual(it.next(), null);\n    }\n\n    {\n        // first\n        var it = window(u8, \"abcdefg\", 3, 3);\n        try testing.expectEqualSlices(u8, it.first(), \"abc\");\n        it.reset();\n        try testing.expectEqualSlices(u8, it.next().?, \"abc\");\n    }\n\n    {\n        // reset\n        var it = window(u8, \"abcdefg\", 3, 3);\n        try testing.expectEqualSlices(u8, it.next().?, \"abc\");\n        try testing.expectEqualSlices(u8, it.next().?, \"def\");\n        try testing.expectEqualSlices(u8, it.next().?, \"g\");\n        try testing.expectEqual(it.next(), null);\n\n        it.reset();\n        try testing.expectEqualSlices(u8, it.next().?, \"abc\");\n        try testing.expectEqualSlices(u8, it.next().?, \"def\");\n        try testing.expectEqualSlices(u8, it.next().?, \"g\");\n        try testing.expectEqual(it.next(), null);\n    }\n}\n\npub fn WindowIterator(comptime T: type) type {\n    return struct {\n        buffer: []const T,\n        index: ?usize,\n        size: usize,\n        advance: usize,\n\n        const Self = @This();\n\n        /// Returns a slice of the first window. This never fails.\n        /// Call this only to get the first window and then use `next` to get\n        /// all subsequent windows.\n        pub fn first(self: *Self) []const T {\n            assert(self.index.? == 0);\n            return self.next().?;\n        }\n\n        /// Returns a slice of the next window, or null if window is at end.\n        pub fn next(self: *Self) ?[]const T {\n            const start = self.index orelse return null;\n            const next_index = start + self.advance;\n            const end = if (start + self.size < self.buffer.len and next_index < self.buffer.len) blk: {\n                self.index = next_index;\n                break :blk start + self.size;\n            } else blk: {\n                self.index = null;\n                break :blk self.buffer.len;\n            };\n\n            return self.buffer[start..end];\n        }\n\n        /// Resets the iterator to the initial window.\n        pub fn reset(self: *Self) void {\n            self.index = 0;\n        }\n    };\n}\n\npub fn startsWith(comptime T: type, haystack: []const T, needle: []const T) bool {\n    return if (needle.len > haystack.len) false else eql(T, haystack[0..needle.len], needle);\n}\n\ntest startsWith {\n    try testing.expect(startsWith(u8, \"Bob\", \"Bo\"));\n    try testing.expect(!startsWith(u8, \"Needle in haystack\", \"haystack\"));\n}\n\npub fn endsWith(comptime T: type, haystack: []const T, needle: []const T) bool {\n    return if (needle.len > haystack.len) false else eql(T, haystack[haystack.len - needle.len ..], needle);\n}\n\ntest endsWith {\n    try testing.expect(endsWith(u8, \"Needle in haystack\", \"haystack\"));\n    try testing.expect(!endsWith(u8, \"Bob\", \"Bo\"));\n}\n\npub const DelimiterType = enum { sequence, any, scalar };\n\npub fn TokenIterator(comptime T: type, comptime delimiter_type: DelimiterType) type {\n    return struct {\n        buffer: []const T,\n        delimiter: switch (delimiter_type) {\n            .sequence, .any => []const T,\n            .scalar => T,\n        },\n        index: usize,\n\n        const Self = @This();\n\n        /// Returns a slice of the current token, or null if tokenization is\n        /// complete, and advances to the next token.\n        pub fn next(self: *Self) ?[]const T {\n            const result = self.peek() orelse return null;\n            self.index += result.len;\n            return result;\n        }\n\n        /// Returns a slice of the current token, or null if tokenization is\n        /// complete. Does not advance to the next token.\n        pub fn peek(self: *Self) ?[]const T {\n            // move to beginning of token\n            while (self.index < self.buffer.len and self.isDelimiter(self.index)) : (self.index += switch (delimiter_type) {\n                .sequence => self.delimiter.len,\n                .any, .scalar => 1,\n            }) {}\n            const start = self.index;\n            if (start == self.buffer.len) {\n                return null;\n            }\n\n            // move to end of token\n            var end = start;\n            while (end < self.buffer.len and !self.isDelimiter(end)) : (end += 1) {}\n\n            return self.buffer[start..end];\n        }\n\n        /// Returns a slice of the remaining bytes. Does not affect iterator state.\n        pub fn rest(self: Self) []const T {\n            // move to beginning of token\n            var index: usize = self.index;\n            while (index < self.buffer.len and self.isDelimiter(index)) : (index += switch (delimiter_type) {\n                .sequence => self.delimiter.len,\n                .any, .scalar => 1,\n            }) {}\n            return self.buffer[index..];\n        }\n\n        /// Resets the iterator to the initial token.\n        pub fn reset(self: *Self) void {\n            self.index = 0;\n        }\n\n        fn isDelimiter(self: Self, index: usize) bool {\n            switch (delimiter_type) {\n                .sequence => return startsWith(T, self.buffer[index..], self.delimiter),\n                .any => {\n                    const item = self.buffer[index];\n                    for (self.delimiter) |delimiter_item| {\n                        if (item == delimiter_item) {\n                            return true;\n                        }\n                    }\n                    return false;\n                },\n                .scalar => return self.buffer[index] == self.delimiter,\n            }\n        }\n    };\n}\n\npub fn SplitIterator(comptime T: type, comptime delimiter_type: DelimiterType) type {\n    return struct {\n        buffer: []const T,\n        index: ?usize,\n        delimiter: switch (delimiter_type) {\n            .sequence, .any => []const T,\n            .scalar => T,\n        },\n\n        const Self = @This();\n\n        /// Returns a slice of the first field. This never fails.\n        /// Call this only to get the first field and then use `next` to get all subsequent fields.\n        pub fn first(self: *Self) []const T {\n            assert(self.index.? == 0);\n            return self.next().?;\n        }\n\n        /// Returns a slice of the next field, or null if splitting is complete.\n        pub fn next(self: *Self) ?[]const T {\n            const start = self.index orelse return null;\n            const end = if (switch (delimiter_type) {\n                .sequence => indexOfPos(T, self.buffer, start, self.delimiter),\n                .any => indexOfAnyPos(T, self.buffer, start, self.delimiter),\n                .scalar => indexOfScalarPos(T, self.buffer, start, self.delimiter),\n            }) |delim_start| blk: {\n                self.index = delim_start + switch (delimiter_type) {\n                    .sequence => self.delimiter.len,\n                    .any, .scalar => 1,\n                };\n                break :blk delim_start;\n            } else blk: {\n                self.index = null;\n                break :blk self.buffer.len;\n            };\n            return self.buffer[start..end];\n        }\n\n        /// Returns a slice of the next field, or null if splitting is complete.\n        /// This method does not alter self.index.\n        pub fn peek(self: *Self) ?[]const T {\n            const start = self.index orelse return null;\n            const end = if (switch (delimiter_type) {\n                .sequence => indexOfPos(T, self.buffer, start, self.delimiter),\n                .any => indexOfAnyPos(T, self.buffer, start, self.delimiter),\n                .scalar => indexOfScalarPos(T, self.buffer, start, self.delimiter),\n            }) |delim_start| delim_start else self.buffer.len;\n            return self.buffer[start..end];\n        }\n\n        /// Returns a slice of the remaining bytes. Does not affect iterator state.\n        pub fn rest(self: Self) []const T {\n            const end = self.buffer.len;\n            const start = self.index orelse end;\n            return self.buffer[start..end];\n        }\n\n        /// Resets the iterator to the initial slice.\n        pub fn reset(self: *Self) void {\n            self.index = 0;\n        }\n    };\n}\n\npub fn SplitBackwardsIterator(comptime T: type, comptime delimiter_type: DelimiterType) type {\n    return struct {\n        buffer: []const T,\n        index: ?usize,\n        delimiter: switch (delimiter_type) {\n            .sequence, .any => []const T,\n            .scalar => T,\n        },\n\n        const Self = @This();\n\n        /// Returns a slice of the first field. This never fails.\n        /// Call this only to get the first field and then use `next` to get all subsequent fields.\n        pub fn first(self: *Self) []const T {\n            assert(self.index.? == self.buffer.len);\n            return self.next().?;\n        }\n\n        /// Returns a slice of the next field, or null if splitting is complete.\n        pub fn next(self: *Self) ?[]const T {\n            const end = self.index orelse return null;\n            const start = if (switch (delimiter_type) {\n                .sequence => lastIndexOf(T, self.buffer[0..end], self.delimiter),\n                .any => lastIndexOfAny(T, self.buffer[0..end], self.delimiter),\n                .scalar => lastIndexOfScalar(T, self.buffer[0..end], self.delimiter),\n            }) |delim_start| blk: {\n                self.index = delim_start;\n                break :blk delim_start + switch (delimiter_type) {\n                    .sequence => self.delimiter.len,\n                    .any, .scalar => 1,\n                };\n            } else blk: {\n                self.index = null;\n                break :blk 0;\n            };\n            return self.buffer[start..end];\n        }\n\n        /// Returns a slice of the remaining bytes. Does not affect iterator state.\n        pub fn rest(self: Self) []const T {\n            const end = self.index orelse 0;\n            return self.buffer[0..end];\n        }\n\n        /// Resets the iterator to the initial slice.\n        pub fn reset(self: *Self) void {\n            self.index = self.buffer.len;\n        }\n    };\n}\n\n/// Naively combines a series of slices with a separator.\n/// Allocates memory for the result, which must be freed by the caller.\npub fn join(allocator: Allocator, separator: []const u8, slices: []const []const u8) Allocator.Error![]u8 {\n    return joinMaybeZ(allocator, separator, slices, false);\n}\n\n/// Naively combines a series of slices with a separator and null terminator.\n/// Allocates memory for the result, which must be freed by the caller.\npub fn joinZ(allocator: Allocator, separator: []const u8, slices: []const []const u8) Allocator.Error![:0]u8 {\n    const out = try joinMaybeZ(allocator, separator, slices, true);\n    return out[0 .. out.len - 1 :0];\n}\n\nfn joinMaybeZ(allocator: Allocator, separator: []const u8, slices: []const []const u8, zero: bool) Allocator.Error![]u8 {\n    if (slices.len == 0) return if (zero) try allocator.dupe(u8, &[1]u8{0}) else &[0]u8{};\n\n    const total_len = blk: {\n        var sum: usize = separator.len * (slices.len - 1);\n        for (slices) |slice| sum += slice.len;\n        if (zero) sum += 1;\n        break :blk sum;\n    };\n\n    const buf = try allocator.alloc(u8, total_len);\n    errdefer allocator.free(buf);\n\n    @memcpy(buf[0..slices[0].len], slices[0]);\n    var buf_index: usize = slices[0].len;\n    for (slices[1..]) |slice| {\n        @memcpy(buf[buf_index .. buf_index + separator.len], separator);\n        buf_index += separator.len;\n        @memcpy(buf[buf_index .. buf_index + slice.len], slice);\n        buf_index += slice.len;\n    }\n\n    if (zero) buf[buf.len - 1] = 0;\n\n    // No need for shrink since buf is exactly the correct size.\n    return buf;\n}\n\ntest join {\n    {\n        const str = try join(testing.allocator, \",\", &[_][]const u8{});\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"\"));\n    }\n    {\n        const str = try join(testing.allocator, \",\", &[_][]const u8{ \"a\", \"b\", \"c\" });\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"a,b,c\"));\n    }\n    {\n        const str = try join(testing.allocator, \",\", &[_][]const u8{\"a\"});\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"a\"));\n    }\n    {\n        const str = try join(testing.allocator, \",\", &[_][]const u8{ \"a\", \"\", \"b\", \"\", \"c\" });\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"a,,b,,c\"));\n    }\n}\n\ntest joinZ {\n    {\n        const str = try joinZ(testing.allocator, \",\", &[_][]const u8{});\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"\"));\n        try testing.expectEqual(str[str.len], 0);\n    }\n    {\n        const str = try joinZ(testing.allocator, \",\", &[_][]const u8{ \"a\", \"b\", \"c\" });\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"a,b,c\"));\n        try testing.expectEqual(str[str.len], 0);\n    }\n    {\n        const str = try joinZ(testing.allocator, \",\", &[_][]const u8{\"a\"});\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"a\"));\n        try testing.expectEqual(str[str.len], 0);\n    }\n    {\n        const str = try joinZ(testing.allocator, \",\", &[_][]const u8{ \"a\", \"\", \"b\", \"\", \"c\" });\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"a,,b,,c\"));\n        try testing.expectEqual(str[str.len], 0);\n    }\n}\n\n/// Copies each T from slices into a new slice that exactly holds all the elements.\npub fn concat(allocator: Allocator, comptime T: type, slices: []const []const T) Allocator.Error![]T {\n    return concatMaybeSentinel(allocator, T, slices, null);\n}\n\n/// Copies each T from slices into a new slice that exactly holds all the elements.\npub fn concatWithSentinel(allocator: Allocator, comptime T: type, slices: []const []const T, comptime s: T) Allocator.Error![:s]T {\n    const ret = try concatMaybeSentinel(allocator, T, slices, s);\n    return ret[0 .. ret.len - 1 :s];\n}\n\n/// Copies each T from slices into a new slice that exactly holds all the elements as well as the sentinel.\npub fn concatMaybeSentinel(allocator: Allocator, comptime T: type, slices: []const []const T, comptime s: ?T) Allocator.Error![]T {\n    if (slices.len == 0) return if (s) |sentinel| try allocator.dupe(T, &[1]T{sentinel}) else &[0]T{};\n\n    const total_len = blk: {\n        var sum: usize = 0;\n        for (slices) |slice| {\n            sum += slice.len;\n        }\n\n        if (s) |_| {\n            sum += 1;\n        }\n\n        break :blk sum;\n    };\n\n    const buf = try allocator.alloc(T, total_len);\n    errdefer allocator.free(buf);\n\n    var buf_index: usize = 0;\n    for (slices) |slice| {\n        @memcpy(buf[buf_index .. buf_index + slice.len], slice);\n        buf_index += slice.len;\n    }\n\n    if (s) |sentinel| {\n        buf[buf.len - 1] = sentinel;\n    }\n\n    // No need for shrink since buf is exactly the correct size.\n    return buf;\n}\n\ntest concat {\n    {\n        const str = try concat(testing.allocator, u8, &[_][]const u8{ \"abc\", \"def\", \"ghi\" });\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u8, str, \"abcdefghi\"));\n    }\n    {\n        const str = try concat(testing.allocator, u32, &[_][]const u32{\n            &[_]u32{ 0, 1 },\n            &[_]u32{ 2, 3, 4 },\n            &[_]u32{},\n            &[_]u32{5},\n        });\n        defer testing.allocator.free(str);\n        try testing.expect(eql(u32, str, &[_]u32{ 0, 1, 2, 3, 4, 5 }));\n    }\n    {\n        const str = try concatWithSentinel(testing.allocator, u8, &[_][]const u8{ \"abc\", \"def\", \"ghi\" }, 0);\n        defer testing.allocator.free(str);\n        try testing.expectEqualSentinel(u8, 0, str, \"abcdefghi\");\n    }\n    {\n        const slice = try concatWithSentinel(testing.allocator, u8, &[_][]const u8{}, 0);\n        defer testing.allocator.free(slice);\n        try testing.expectEqualSentinel(u8, 0, slice, &[_:0]u8{});\n    }\n    {\n        const slice = try concatWithSentinel(testing.allocator, u32, &[_][]const u32{\n            &[_]u32{ 0, 1 },\n            &[_]u32{ 2, 3, 4 },\n            &[_]u32{},\n            &[_]u32{5},\n        }, 2);\n        defer testing.allocator.free(slice);\n        try testing.expectEqualSentinel(u32, 2, slice, &[_:2]u32{ 0, 1, 2, 3, 4, 5 });\n    }\n}\n\ntest eql {\n    try testing.expect(eql(u8, \"abcd\", \"abcd\"));\n    try testing.expect(!eql(u8, \"abcdef\", \"abZdef\"));\n    try testing.expect(!eql(u8, \"abcdefg\", \"abcdef\"));\n}\n\nfn moreReadIntTests() !void {\n    {\n        const bytes = [_]u8{\n            0x12,\n            0x34,\n            0x56,\n            0x78,\n        };\n        try testing.expect(readInt(u32, &bytes, .big) == 0x12345678);\n        try testing.expect(readInt(u32, &bytes, .big) == 0x12345678);\n        try testing.expect(readInt(i32, &bytes, .big) == 0x12345678);\n        try testing.expect(readInt(u32, &bytes, .little) == 0x78563412);\n        try testing.expect(readInt(u32, &bytes, .little) == 0x78563412);\n        try testing.expect(readInt(i32, &bytes, .little) == 0x78563412);\n    }\n    {\n        const buf = [_]u8{\n            0x00,\n            0x00,\n            0x12,\n            0x34,\n        };\n        const answer = readInt(u32, &buf, .big);\n        try testing.expect(answer == 0x00001234);\n    }\n    {\n        const buf = [_]u8{\n            0x12,\n            0x34,\n            0x00,\n            0x00,\n        };\n        const answer = readInt(u32, &buf, .little);\n        try testing.expect(answer == 0x00003412);\n    }\n    {\n        const bytes = [_]u8{\n            0xff,\n            0xfe,\n        };\n        try testing.expect(readInt(u16, &bytes, .big) == 0xfffe);\n        try testing.expect(readInt(i16, &bytes, .big) == -0x0002);\n        try testing.expect(readInt(u16, &bytes, .little) == 0xfeff);\n        try testing.expect(readInt(i16, &bytes, .little) == -0x0101);\n    }\n}\n\n/// Returns the smallest number in a slice. O(n).\n/// `slice` must not be empty.\npub fn min(comptime T: type, slice: []const T) T {\n    assert(slice.len > 0);\n    var best = slice[0];\n    for (slice[1..]) |item| {\n        best = @min(best, item);\n    }\n    return best;\n}\n\ntest min {\n    try testing.expectEqual(min(u8, \"abcdefg\"), 'a');\n    try testing.expectEqual(min(u8, \"bcdefga\"), 'a');\n    try testing.expectEqual(min(u8, \"a\"), 'a');\n}\n\n/// Returns the largest number in a slice. O(n).\n/// `slice` must not be empty.\npub fn max(comptime T: type, slice: []const T) T {\n    assert(slice.len > 0);\n    var best = slice[0];\n    for (slice[1..]) |item| {\n        best = @max(best, item);\n    }\n    return best;\n}\n\ntest max {\n    try testing.expectEqual(max(u8, \"abcdefg\"), 'g');\n    try testing.expectEqual(max(u8, \"gabcdef\"), 'g');\n    try testing.expectEqual(max(u8, \"g\"), 'g');\n}\n\n/// Finds the smallest and largest number in a slice. O(n).\n/// Returns an anonymous struct with the fields `min` and `max`.\n/// `slice` must not be empty.\npub fn minMax(comptime T: type, slice: []const T) struct { T, T } {\n    assert(slice.len > 0);\n    var running_minimum = slice[0];\n    var running_maximum = slice[0];\n    for (slice[1..]) |item| {\n        running_minimum = @min(running_minimum, item);\n        running_maximum = @max(running_maximum, item);\n    }\n    return .{ running_minimum, running_maximum };\n}\n\ntest minMax {\n    {\n        const actual_min, const actual_max = minMax(u8, \"abcdefg\");\n        try testing.expectEqual(@as(u8, 'a'), actual_min);\n        try testing.expectEqual(@as(u8, 'g'), actual_max);\n    }\n    {\n        const actual_min, const actual_max = minMax(u8, \"bcdefga\");\n        try testing.expectEqual(@as(u8, 'a'), actual_min);\n        try testing.expectEqual(@as(u8, 'g'), actual_max);\n    }\n    {\n        const actual_min, const actual_max = minMax(u8, \"a\");\n        try testing.expectEqual(@as(u8, 'a'), actual_min);\n        try testing.expectEqual(@as(u8, 'a'), actual_max);\n    }\n}\n\n/// Returns the index of the smallest number in a slice. O(n).\n/// `slice` must not be empty.\npub fn indexOfMin(comptime T: type, slice: []const T) usize {\n    assert(slice.len > 0);\n    var best = slice[0];\n    var index: usize = 0;\n    for (slice[1..], 0..) |item, i| {\n        if (item < best) {\n            best = item;\n            index = i + 1;\n        }\n    }\n    return index;\n}\n\ntest indexOfMin {\n    try testing.expectEqual(indexOfMin(u8, \"abcdefg\"), 0);\n    try testing.expectEqual(indexOfMin(u8, \"bcdefga\"), 6);\n    try testing.expectEqual(indexOfMin(u8, \"a\"), 0);\n}\n\n/// Returns the index of the largest number in a slice. O(n).\n/// `slice` must not be empty.\npub fn indexOfMax(comptime T: type, slice: []const T) usize {\n    assert(slice.len > 0);\n    var best = slice[0];\n    var index: usize = 0;\n    for (slice[1..], 0..) |item, i| {\n        if (item > best) {\n            best = item;\n            index = i + 1;\n        }\n    }\n    return index;\n}\n\ntest indexOfMax {\n    try testing.expectEqual(indexOfMax(u8, \"abcdefg\"), 6);\n    try testing.expectEqual(indexOfMax(u8, \"gabcdef\"), 0);\n    try testing.expectEqual(indexOfMax(u8, \"a\"), 0);\n}\n\n/// Finds the indices of the smallest and largest number in a slice. O(n).\n/// Returns the indices of the smallest and largest numbers in that order.\n/// `slice` must not be empty.\npub fn indexOfMinMax(comptime T: type, slice: []const T) struct { usize, usize } {\n    assert(slice.len > 0);\n    var minVal = slice[0];\n    var maxVal = slice[0];\n    var minIdx: usize = 0;\n    var maxIdx: usize = 0;\n    for (slice[1..], 0..) |item, i| {\n        if (item < minVal) {\n            minVal = item;\n            minIdx = i + 1;\n        }\n        if (item > maxVal) {\n            maxVal = item;\n            maxIdx = i + 1;\n        }\n    }\n    return .{ minIdx, maxIdx };\n}\n\ntest indexOfMinMax {\n    try testing.expectEqual(.{ 0, 6 }, indexOfMinMax(u8, \"abcdefg\"));\n    try testing.expectEqual(.{ 1, 0 }, indexOfMinMax(u8, \"gabcdef\"));\n    try testing.expectEqual(.{ 0, 0 }, indexOfMinMax(u8, \"a\"));\n}\n\npub fn swap(comptime T: type, a: *T, b: *T) void {\n    const tmp = a.*;\n    a.* = b.*;\n    b.* = tmp;\n}\n\n/// In-place order reversal of a slice\npub fn reverse(comptime T: type, items: []T) void {\n    var i: usize = 0;\n    const end = items.len / 2;\n    while (i < end) : (i += 1) {\n        swap(T, &items[i], &items[items.len - i - 1]);\n    }\n}\n\ntest reverse {\n    var arr = [_]i32{ 5, 3, 1, 2, 4 };\n    reverse(i32, arr[0..]);\n\n    try testing.expect(eql(i32, &arr, &[_]i32{ 4, 2, 1, 3, 5 }));\n}\n\nfn ReverseIterator(comptime T: type) type {\n    const Pointer = blk: {\n        switch (@typeInfo(T)) {\n            .Pointer => |ptr_info| switch (ptr_info.size) {\n                .One => switch (@typeInfo(ptr_info.child)) {\n                    .Array => |array_info| {\n                        var new_ptr_info = ptr_info;\n                        new_ptr_info.size = .Many;\n                        new_ptr_info.child = array_info.child;\n                        new_ptr_info.sentinel = array_info.sentinel;\n                        break :blk @Type(.{ .Pointer = new_ptr_info });\n                    },\n                    else => {},\n                },\n                .Slice => {\n                    var new_ptr_info = ptr_info;\n                    new_ptr_info.size = .Many;\n                    break :blk @Type(.{ .Pointer = new_ptr_info });\n                },\n                else => {},\n            },\n            else => {},\n        }\n        @compileError(\"expected slice or pointer to array, found '\" ++ @typeName(T) ++ \"'\");\n    };\n    const Element = std.meta.Elem(Pointer);\n    const ElementPointer = @Type(.{ .Pointer = ptr: {\n        var ptr = @typeInfo(Pointer).Pointer;\n        ptr.size = .One;\n        ptr.child = Element;\n        ptr.sentinel = null;\n        break :ptr ptr;\n    } });\n    return struct {\n        ptr: Pointer,\n        index: usize,\n        pub fn next(self: *@This()) ?Element {\n            if (self.index == 0) return null;\n            self.index -= 1;\n            return self.ptr[self.index];\n        }\n        pub fn nextPtr(self: *@This()) ?ElementPointer {\n            if (self.index == 0) return null;\n            self.index -= 1;\n            return &self.ptr[self.index];\n        }\n    };\n}\n\n/// Iterates over a slice in reverse.\npub fn reverseIterator(slice: anytype) ReverseIterator(@TypeOf(slice)) {\n    return .{ .ptr = slice.ptr, .index = slice.len };\n}\n\ntest reverseIterator {\n    {\n        var it = reverseIterator(\"abc\");\n        try testing.expectEqual(@as(?u8, 'c'), it.next());\n        try testing.expectEqual(@as(?u8, 'b'), it.next());\n        try testing.expectEqual(@as(?u8, 'a'), it.next());\n        try testing.expectEqual(@as(?u8, null), it.next());\n    }\n    {\n        var array = [2]i32{ 3, 7 };\n        const slice: []const i32 = &array;\n        var it = reverseIterator(slice);\n        try testing.expectEqual(@as(?i32, 7), it.next());\n        try testing.expectEqual(@as(?i32, 3), it.next());\n        try testing.expectEqual(@as(?i32, null), it.next());\n\n        it = reverseIterator(slice);\n        try testing.expect(*const i32 == @TypeOf(it.nextPtr().?));\n        try testing.expectEqual(@as(?i32, 7), it.nextPtr().?.*);\n        try testing.expectEqual(@as(?i32, 3), it.nextPtr().?.*);\n        try testing.expectEqual(@as(?*const i32, null), it.nextPtr());\n\n        const mut_slice: []i32 = &array;\n        var mut_it = reverseIterator(mut_slice);\n        mut_it.nextPtr().?.* += 1;\n        mut_it.nextPtr().?.* += 2;\n        try testing.expectEqual([2]i32{ 5, 8 }, array);\n    }\n    {\n        var array = [2]i32{ 3, 7 };\n        const ptr_to_array: *const [2]i32 = &array;\n        var it = reverseIterator(ptr_to_array);\n        try testing.expectEqual(@as(?i32, 7), it.next());\n        try testing.expectEqual(@as(?i32, 3), it.next());\n        try testing.expectEqual(@as(?i32, null), it.next());\n\n        it = reverseIterator(ptr_to_array);\n        try testing.expect(*const i32 == @TypeOf(it.nextPtr().?));\n        try testing.expectEqual(@as(?i32, 7), it.nextPtr().?.*);\n        try testing.expectEqual(@as(?i32, 3), it.nextPtr().?.*);\n        try testing.expectEqual(@as(?*const i32, null), it.nextPtr());\n\n        const mut_ptr_to_array: *[2]i32 = &array;\n        var mut_it = reverseIterator(mut_ptr_to_array);\n        mut_it.nextPtr().?.* += 1;\n        mut_it.nextPtr().?.* += 2;\n        try testing.expectEqual([2]i32{ 5, 8 }, array);\n    }\n}\n\n/// In-place rotation of the values in an array ([0 1 2 3] becomes [1 2 3 0] if we rotate by 1)\n/// Assumes 0 <= amount <= items.len\npub fn rotate(comptime T: type, items: []T, amount: usize) void {\n    reverse(T, items[0..amount]);\n    reverse(T, items[amount..]);\n    reverse(T, items);\n}\n\ntest rotate {\n    var arr = [_]i32{ 5, 3, 1, 2, 4 };\n    rotate(i32, arr[0..], 2);\n\n    try testing.expect(eql(i32, &arr, &[_]i32{ 1, 2, 4, 5, 3 }));\n}\n\n/// Replace needle with replacement as many times as possible, writing to an output buffer which is assumed to be of\n/// appropriate size. Use replacementSize to calculate an appropriate buffer size.\n/// The needle must not be empty.\n/// Returns the number of replacements made.\npub fn replace(comptime T: type, input: []const T, needle: []const T, replacement: []const T, output: []T) usize {\n    // Empty needle will loop until output buffer overflows.\n    assert(needle.len > 0);\n\n    var i: usize = 0;\n    var slide: usize = 0;\n    var replacements: usize = 0;\n    while (slide < input.len) {\n        if (mem.startsWith(T, input[slide..], needle)) {\n            @memcpy(output[i..][0..replacement.len], replacement);\n            i += replacement.len;\n            slide += needle.len;\n            replacements += 1;\n        } else {\n            output[i] = input[slide];\n            i += 1;\n            slide += 1;\n        }\n    }\n\n    return replacements;\n}\n\ntest replace {\n    var output: [29]u8 = undefined;\n    var replacements = replace(u8, \"All your base are belong to us\", \"base\", \"Zig\", output[0..]);\n    var expected: []const u8 = \"All your Zig are belong to us\";\n    try testing.expect(replacements == 1);\n    try testing.expectEqualStrings(expected, output[0..expected.len]);\n\n    replacements = replace(u8, \"Favor reading code over writing code.\", \"code\", \"\", output[0..]);\n    expected = \"Favor reading  over writing .\";\n    try testing.expect(replacements == 2);\n    try testing.expectEqualStrings(expected, output[0..expected.len]);\n\n    // Empty needle is not allowed but input may be empty.\n    replacements = replace(u8, \"\", \"x\", \"y\", output[0..0]);\n    expected = \"\";\n    try testing.expect(replacements == 0);\n    try testing.expectEqualStrings(expected, output[0..expected.len]);\n\n    // Adjacent replacements.\n\n    replacements = replace(u8, \"\\\\n\\\\n\", \"\\\\n\", \"\\n\", output[0..]);\n    expected = \"\\n\\n\";\n    try testing.expect(replacements == 2);\n    try testing.expectEqualStrings(expected, output[0..expected.len]);\n\n    replacements = replace(u8, \"abbba\", \"b\", \"cd\", output[0..]);\n    expected = \"acdcdcda\";\n    try testing.expect(replacements == 3);\n    try testing.expectEqualStrings(expected, output[0..expected.len]);\n}\n\n/// Replace all occurrences of `match` with `replacement`.\npub fn replaceScalar(comptime T: type, slice: []T, match: T, replacement: T) void {\n    for (slice) |*e| {\n        if (e.* == match)\n            e.* = replacement;\n    }\n}\n\n/// Collapse consecutive duplicate elements into one entry.\npub fn collapseRepeatsLen(comptime T: type, slice: []T, elem: T) usize {\n    if (slice.len == 0) return 0;\n    var write_idx: usize = 1;\n    var read_idx: usize = 1;\n    while (read_idx < slice.len) : (read_idx += 1) {\n        if (slice[read_idx - 1] != elem or slice[read_idx] != elem) {\n            slice[write_idx] = slice[read_idx];\n            write_idx += 1;\n        }\n    }\n    return write_idx;\n}\n\n/// Collapse consecutive duplicate elements into one entry.\npub fn collapseRepeats(comptime T: type, slice: []T, elem: T) []T {\n    return slice[0..collapseRepeatsLen(T, slice, elem)];\n}\n\nfn testCollapseRepeats(str: []const u8, elem: u8, expected: []const u8) !void {\n    const mutable = try std.testing.allocator.dupe(u8, str);\n    defer std.testing.allocator.free(mutable);\n    try testing.expect(std.mem.eql(u8, collapseRepeats(u8, mutable, elem), expected));\n}\ntest collapseRepeats {\n    try testCollapseRepeats(\"\", '/', \"\");\n    try testCollapseRepeats(\"a\", '/', \"a\");\n    try testCollapseRepeats(\"/\", '/', \"/\");\n    try testCollapseRepeats(\"//\", '/', \"/\");\n    try testCollapseRepeats(\"/a\", '/', \"/a\");\n    try testCollapseRepeats(\"//a\", '/', \"/a\");\n    try testCollapseRepeats(\"a/\", '/', \"a/\");\n    try testCollapseRepeats(\"a//\", '/', \"a/\");\n    try testCollapseRepeats(\"a/a\", '/', \"a/a\");\n    try testCollapseRepeats(\"a//a\", '/', \"a/a\");\n    try testCollapseRepeats(\"//a///a////\", '/', \"/a/a/\");\n}\n\n/// Calculate the size needed in an output buffer to perform a replacement.\n/// The needle must not be empty.\npub fn replacementSize(comptime T: type, input: []const T, needle: []const T, replacement: []const T) usize {\n    // Empty needle will loop forever.\n    assert(needle.len > 0);\n\n    var i: usize = 0;\n    var size: usize = input.len;\n    while (i < input.len) {\n        if (mem.startsWith(T, input[i..], needle)) {\n            size = size - needle.len + replacement.len;\n            i += needle.len;\n        } else {\n            i += 1;\n        }\n    }\n\n    return size;\n}\n\ntest replacementSize {\n    try testing.expect(replacementSize(u8, \"All your base are belong to us\", \"base\", \"Zig\") == 29);\n    try testing.expect(replacementSize(u8, \"Favor reading code over writing code.\", \"code\", \"\") == 29);\n    try testing.expect(replacementSize(u8, \"Only one obvious way to do things.\", \"things.\", \"things in Zig.\") == 41);\n\n    // Empty needle is not allowed but input may be empty.\n    try testing.expect(replacementSize(u8, \"\", \"x\", \"y\") == 0);\n\n    // Adjacent replacements.\n    try testing.expect(replacementSize(u8, \"\\\\n\\\\n\", \"\\\\n\", \"\\n\") == 2);\n    try testing.expect(replacementSize(u8, \"abbba\", \"b\", \"cd\") == 8);\n}\n\n/// Perform a replacement on an allocated buffer of pre-determined size. Caller must free returned memory.\npub fn replaceOwned(comptime T: type, allocator: Allocator, input: []const T, needle: []const T, replacement: []const T) Allocator.Error![]T {\n    const output = try allocator.alloc(T, replacementSize(T, input, needle, replacement));\n    _ = replace(T, input, needle, replacement, output);\n    return output;\n}\n\ntest replaceOwned {\n    const gpa = std.testing.allocator;\n\n    const base_replace = replaceOwned(u8, gpa, \"All your base are belong to us\", \"base\", \"Zig\") catch @panic(\"out of memory\");\n    defer gpa.free(base_replace);\n    try testing.expect(eql(u8, base_replace, \"All your Zig are belong to us\"));\n\n    const zen_replace = replaceOwned(u8, gpa, \"Favor reading code over writing code.\", \" code\", \"\") catch @panic(\"out of memory\");\n    defer gpa.free(zen_replace);\n    try testing.expect(eql(u8, zen_replace, \"Favor reading over writing.\"));\n}\n\n/// Converts a little-endian integer to host endianness.\npub fn littleToNative(comptime T: type, x: T) T {\n    return switch (native_endian) {\n        .little => x,\n        .big => @byteSwap(x),\n    };\n}\n\n/// Converts a big-endian integer to host endianness.\npub fn bigToNative(comptime T: type, x: T) T {\n    return switch (native_endian) {\n        .little => @byteSwap(x),\n        .big => x,\n    };\n}\n\n/// Converts an integer from specified endianness to host endianness.\npub fn toNative(comptime T: type, x: T, endianness_of_x: Endian) T {\n    return switch (endianness_of_x) {\n        .little => littleToNative(T, x),\n        .big => bigToNative(T, x),\n    };\n}\n\n/// Converts an integer which has host endianness to the desired endianness.\npub fn nativeTo(comptime T: type, x: T, desired_endianness: Endian) T {\n    return switch (desired_endianness) {\n        .little => nativeToLittle(T, x),\n        .big => nativeToBig(T, x),\n    };\n}\n\n/// Converts an integer which has host endianness to little endian.\npub fn nativeToLittle(comptime T: type, x: T) T {\n    return switch (native_endian) {\n        .little => x,\n        .big => @byteSwap(x),\n    };\n}\n\n/// Converts an integer which has host endianness to big endian.\npub fn nativeToBig(comptime T: type, x: T) T {\n    return switch (native_endian) {\n        .little => @byteSwap(x),\n        .big => x,\n    };\n}\n\n/// Returns the number of elements that, if added to the given pointer, align it\n/// to a multiple of the given quantity, or `null` if one of the following\n/// conditions is met:\n/// - The aligned pointer would not fit the address space,\n/// - The delta required to align the pointer is not a multiple of the pointee's\n///   type.\npub fn alignPointerOffset(ptr: anytype, align_to: usize) ?usize {\n    assert(isValidAlign(align_to));\n\n    const T = @TypeOf(ptr);\n    const info = @typeInfo(T);\n    if (info != .Pointer or info.Pointer.size != .Many)\n        @compileError(\"expected many item pointer, got \" ++ @typeName(T));\n\n    // Do nothing if the pointer is already well-aligned.\n    if (align_to <= info.Pointer.alignment)\n        return 0;\n\n    // Calculate the aligned base address with an eye out for overflow.\n    const addr = @intFromPtr(ptr);\n    var ov = @addWithOverflow(addr, align_to - 1);\n    if (ov[1] != 0) return null;\n    ov[0] &= ~@as(usize, align_to - 1);\n\n    // The delta is expressed in terms of bytes, turn it into a number of child\n    // type elements.\n    const delta = ov[0] - addr;\n    const pointee_size = @sizeOf(info.Pointer.child);\n    if (delta % pointee_size != 0) return null;\n    return delta / pointee_size;\n}\n\n/// Aligns a given pointer value to a specified alignment factor.\n/// Returns an aligned pointer or null if one of the following conditions is\n/// met:\n/// - The aligned pointer would not fit the address space,\n/// - The delta required to align the pointer is not a multiple of the pointee's\n///   type.\npub fn alignPointer(ptr: anytype, align_to: usize) ?@TypeOf(ptr) {\n    const adjust_off = alignPointerOffset(ptr, align_to) orelse return null;\n    // Avoid the use of ptrFromInt to avoid losing the pointer provenance info.\n    return @alignCast(ptr + adjust_off);\n}\n\ntest alignPointer {\n    const S = struct {\n        fn checkAlign(comptime T: type, base: usize, align_to: usize, expected: usize) !void {\n            const ptr: T = @ptrFromInt(base);\n            const aligned = alignPointer(ptr, align_to);\n            try testing.expectEqual(expected, @intFromPtr(aligned));\n        }\n    };\n\n    try S.checkAlign([*]u8, 0x123, 0x200, 0x200);\n    try S.checkAlign([*]align(4) u8, 0x10, 2, 0x10);\n    try S.checkAlign([*]u32, 0x10, 2, 0x10);\n    try S.checkAlign([*]u32, 0x4, 16, 0x10);\n    // Misaligned.\n    try S.checkAlign([*]align(1) u32, 0x3, 2, 0);\n    // Overflow.\n    try S.checkAlign([*]u32, math.maxInt(usize) - 3, 8, 0);\n}\n\nfn CopyPtrAttrs(\n    comptime source: type,\n    comptime size: std.builtin.Type.Pointer.Size,\n    comptime child: type,\n) type {\n    const info = @typeInfo(source).Pointer;\n    return @Type(.{\n        .Pointer = .{\n            .size = size,\n            .is_const = info.is_const,\n            .is_volatile = info.is_volatile,\n            .is_allowzero = info.is_allowzero,\n            .alignment = info.alignment,\n            .address_space = info.address_space,\n            .child = child,\n            .sentinel = null,\n        },\n    });\n}\n\nfn AsBytesReturnType(comptime P: type) type {\n    const size = @sizeOf(std.meta.Child(P));\n    return CopyPtrAttrs(P, .One, [size]u8);\n}\n\n/// Given a pointer to a single item, returns a slice of the underlying bytes, preserving pointer attributes.\npub fn asBytes(ptr: anytype) AsBytesReturnType(@TypeOf(ptr)) {\n    return @ptrCast(@alignCast(ptr));\n}\n\ntest asBytes {\n    const deadbeef = @as(u32, 0xDEADBEEF);\n    const deadbeef_bytes = switch (native_endian) {\n        .big => \"\\xDE\\xAD\\xBE\\xEF\",\n        .little => \"\\xEF\\xBE\\xAD\\xDE\",\n    };\n\n    try testing.expect(eql(u8, asBytes(&deadbeef), deadbeef_bytes));\n\n    var codeface = @as(u32, 0xC0DEFACE);\n    for (asBytes(&codeface)) |*b|\n        b.* = 0;\n    try testing.expect(codeface == 0);\n\n    const S = packed struct {\n        a: u8,\n        b: u8,\n        c: u8,\n        d: u8,\n    };\n\n    const inst = S{\n        .a = 0xBE,\n        .b = 0xEF,\n        .c = 0xDE,\n        .d = 0xA1,\n    };\n    switch (native_endian) {\n        .little => {\n            try testing.expect(eql(u8, asBytes(&inst), \"\\xBE\\xEF\\xDE\\xA1\"));\n        },\n        .big => {\n            try testing.expect(eql(u8, asBytes(&inst), \"\\xA1\\xDE\\xEF\\xBE\"));\n        },\n    }\n\n    const ZST = struct {};\n    const zero = ZST{};\n    try testing.expect(eql(u8, asBytes(&zero), \"\"));\n}\n\ntest \"asBytes preserves pointer attributes\" {\n    const inArr: u32 align(16) = 0xDEADBEEF;\n    const inPtr = @as(*align(16) const volatile u32, @ptrCast(&inArr));\n    const outSlice = asBytes(inPtr);\n\n    const in = @typeInfo(@TypeOf(inPtr)).Pointer;\n    const out = @typeInfo(@TypeOf(outSlice)).Pointer;\n\n    try testing.expectEqual(in.is_const, out.is_const);\n    try testing.expectEqual(in.is_volatile, out.is_volatile);\n    try testing.expectEqual(in.is_allowzero, out.is_allowzero);\n    try testing.expectEqual(in.alignment, out.alignment);\n}\n\n/// Given any value, returns a copy of its bytes in an array.\npub fn toBytes(value: anytype) [@sizeOf(@TypeOf(value))]u8 {\n    return asBytes(&value).*;\n}\n\ntest toBytes {\n    var my_bytes = toBytes(@as(u32, 0x12345678));\n    switch (native_endian) {\n        .big => try testing.expect(eql(u8, &my_bytes, \"\\x12\\x34\\x56\\x78\")),\n        .little => try testing.expect(eql(u8, &my_bytes, \"\\x78\\x56\\x34\\x12\")),\n    }\n\n    my_bytes[0] = '\\x99';\n    switch (native_endian) {\n        .big => try testing.expect(eql(u8, &my_bytes, \"\\x99\\x34\\x56\\x78\")),\n        .little => try testing.expect(eql(u8, &my_bytes, \"\\x99\\x56\\x34\\x12\")),\n    }\n}\n\nfn BytesAsValueReturnType(comptime T: type, comptime B: type) type {\n    return CopyPtrAttrs(B, .One, T);\n}\n\n/// Given a pointer to an array of bytes, returns a pointer to a value of the specified type\n/// backed by those bytes, preserving pointer attributes.\npub fn bytesAsValue(comptime T: type, bytes: anytype) BytesAsValueReturnType(T, @TypeOf(bytes)) {\n    return @ptrCast(bytes);\n}\n\ntest bytesAsValue {\n    const deadbeef = @as(u32, 0xDEADBEEF);\n    const deadbeef_bytes = switch (native_endian) {\n        .big => \"\\xDE\\xAD\\xBE\\xEF\",\n        .little => \"\\xEF\\xBE\\xAD\\xDE\",\n    };\n\n    try testing.expect(deadbeef == bytesAsValue(u32, deadbeef_bytes).*);\n\n    var codeface_bytes: [4]u8 = switch (native_endian) {\n        .big => \"\\xC0\\xDE\\xFA\\xCE\",\n        .little => \"\\xCE\\xFA\\xDE\\xC0\",\n    }.*;\n    const codeface = bytesAsValue(u32, &codeface_bytes);\n    try testing.expect(codeface.* == 0xC0DEFACE);\n    codeface.* = 0;\n    for (codeface_bytes) |b|\n        try testing.expect(b == 0);\n\n    const S = packed struct {\n        a: u8,\n        b: u8,\n        c: u8,\n        d: u8,\n    };\n\n    const inst = S{\n        .a = 0xBE,\n        .b = 0xEF,\n        .c = 0xDE,\n        .d = 0xA1,\n    };\n    const inst_bytes = switch (native_endian) {\n        .little => \"\\xBE\\xEF\\xDE\\xA1\",\n        .big => \"\\xA1\\xDE\\xEF\\xBE\",\n    };\n    const inst2 = bytesAsValue(S, inst_bytes);\n    try testing.expect(std.meta.eql(inst, inst2.*));\n}\n\ntest \"bytesAsValue preserves pointer attributes\" {\n    const inArr align(16) = [4]u8{ 0xDE, 0xAD, 0xBE, 0xEF };\n    const inSlice = @as(*align(16) const volatile [4]u8, @ptrCast(&inArr))[0..];\n    const outPtr = bytesAsValue(u32, inSlice);\n\n    const in = @typeInfo(@TypeOf(inSlice)).Pointer;\n    const out = @typeInfo(@TypeOf(outPtr)).Pointer;\n\n    try testing.expectEqual(in.is_const, out.is_const);\n    try testing.expectEqual(in.is_volatile, out.is_volatile);\n    try testing.expectEqual(in.is_allowzero, out.is_allowzero);\n    try testing.expectEqual(in.alignment, out.alignment);\n}\n\n/// Given a pointer to an array of bytes, returns a value of the specified type backed by a\n/// copy of those bytes.\npub fn bytesToValue(comptime T: type, bytes: anytype) T {\n    return bytesAsValue(T, bytes).*;\n}\ntest bytesToValue {\n    const deadbeef_bytes = switch (native_endian) {\n        .big => \"\\xDE\\xAD\\xBE\\xEF\",\n        .little => \"\\xEF\\xBE\\xAD\\xDE\",\n    };\n\n    const deadbeef = bytesToValue(u32, deadbeef_bytes);\n    try testing.expect(deadbeef == @as(u32, 0xDEADBEEF));\n}\n\nfn BytesAsSliceReturnType(comptime T: type, comptime bytesType: type) type {\n    return CopyPtrAttrs(bytesType, .Slice, T);\n}\n\n/// Given a slice of bytes, returns a slice of the specified type\n/// backed by those bytes, preserving pointer attributes.\npub fn bytesAsSlice(comptime T: type, bytes: anytype) BytesAsSliceReturnType(T, @TypeOf(bytes)) {\n    // let's not give an undefined pointer to @ptrCast\n    // it may be equal to zero and fail a null check\n    if (bytes.len == 0) {\n        return &[0]T{};\n    }\n\n    const cast_target = CopyPtrAttrs(@TypeOf(bytes), .Many, T);\n\n    return @as(cast_target, @ptrCast(bytes))[0..@divExact(bytes.len, @sizeOf(T))];\n}\n\ntest bytesAsSlice {\n    {\n        const bytes = [_]u8{ 0xDE, 0xAD, 0xBE, 0xEF };\n        const slice = bytesAsSlice(u16, bytes[0..]);\n        try testing.expect(slice.len == 2);\n        try testing.expect(bigToNative(u16, slice[0]) == 0xDEAD);\n        try testing.expect(bigToNative(u16, slice[1]) == 0xBEEF);\n    }\n    {\n        const bytes = [_]u8{ 0xDE, 0xAD, 0xBE, 0xEF };\n        var runtime_zero: usize = 0;\n        _ = &runtime_zero;\n        const slice = bytesAsSlice(u16, bytes[runtime_zero..]);\n        try testing.expect(slice.len == 2);\n        try testing.expect(bigToNative(u16, slice[0]) == 0xDEAD);\n        try testing.expect(bigToNative(u16, slice[1]) == 0xBEEF);\n    }\n}\n\ntest \"bytesAsSlice keeps pointer alignment\" {\n    {\n        var bytes = [_]u8{ 0x01, 0x02, 0x03, 0x04 };\n        const numbers = bytesAsSlice(u32, bytes[0..]);\n        try comptime testing.expect(@TypeOf(numbers) == []align(@alignOf(@TypeOf(bytes))) u32);\n    }\n    {\n        var bytes = [_]u8{ 0x01, 0x02, 0x03, 0x04 };\n        var runtime_zero: usize = 0;\n        _ = &runtime_zero;\n        const numbers = bytesAsSlice(u32, bytes[runtime_zero..]);\n        try comptime testing.expect(@TypeOf(numbers) == []align(@alignOf(@TypeOf(bytes))) u32);\n    }\n}\n\ntest \"bytesAsSlice on a packed struct\" {\n    const F = packed struct {\n        a: u8,\n    };\n\n    const b: [1]u8 = .{9};\n    const f = bytesAsSlice(F, &b);\n    try testing.expect(f[0].a == 9);\n}\n\ntest \"bytesAsSlice with specified alignment\" {\n    var bytes align(4) = [_]u8{\n        0x33,\n        0x33,\n        0x33,\n        0x33,\n    };\n    const slice: []u32 = std.mem.bytesAsSlice(u32, bytes[0..]);\n    try testing.expect(slice[0] == 0x33333333);\n}\n\ntest \"bytesAsSlice preserves pointer attributes\" {\n    const inArr align(16) = [4]u8{ 0xDE, 0xAD, 0xBE, 0xEF };\n    const inSlice = @as(*align(16) const volatile [4]u8, @ptrCast(&inArr))[0..];\n    const outSlice = bytesAsSlice(u16, inSlice);\n\n    const in = @typeInfo(@TypeOf(inSlice)).Pointer;\n    const out = @typeInfo(@TypeOf(outSlice)).Pointer;\n\n    try testing.expectEqual(in.is_const, out.is_const);\n    try testing.expectEqual(in.is_volatile, out.is_volatile);\n    try testing.expectEqual(in.is_allowzero, out.is_allowzero);\n    try testing.expectEqual(in.alignment, out.alignment);\n}\n\nfn SliceAsBytesReturnType(comptime Slice: type) type {\n    return CopyPtrAttrs(Slice, .Slice, u8);\n}\n\n/// Given a slice, returns a slice of the underlying bytes, preserving pointer attributes.\npub fn sliceAsBytes(slice: anytype) SliceAsBytesReturnType(@TypeOf(slice)) {\n    const Slice = @TypeOf(slice);\n\n    // a slice of zero-bit values always occupies zero bytes\n    if (@sizeOf(std.meta.Elem(Slice)) == 0) return &[0]u8{};\n\n    // let's not give an undefined pointer to @ptrCast\n    // it may be equal to zero and fail a null check\n    if (slice.len == 0 and std.meta.sentinel(Slice) == null) return &[0]u8{};\n\n    const cast_target = CopyPtrAttrs(Slice, .Many, u8);\n\n    return @as(cast_target, @ptrCast(slice))[0 .. slice.len * @sizeOf(std.meta.Elem(Slice))];\n}\n\ntest sliceAsBytes {\n    const bytes = [_]u16{ 0xDEAD, 0xBEEF };\n    const slice = sliceAsBytes(bytes[0..]);\n    try testing.expect(slice.len == 4);\n    try testing.expect(eql(u8, slice, switch (native_endian) {\n        .big => \"\\xDE\\xAD\\xBE\\xEF\",\n        .little => \"\\xAD\\xDE\\xEF\\xBE\",\n    }));\n}\n\ntest \"sliceAsBytes with sentinel slice\" {\n    const empty_string: [:0]const u8 = \"\";\n    const bytes = sliceAsBytes(empty_string);\n    try testing.expect(bytes.len == 0);\n}\n\ntest \"sliceAsBytes with zero-bit element type\" {\n    const lots_of_nothing = [1]void{{}} ** 10_000;\n    const bytes = sliceAsBytes(&lots_of_nothing);\n    try testing.expect(bytes.len == 0);\n}\n\ntest \"sliceAsBytes packed struct at runtime and comptime\" {\n    const Foo = packed struct {\n        a: u4,\n        b: u4,\n    };\n    const S = struct {\n        fn doTheTest() !void {\n            var foo: Foo = undefined;\n            var slice = sliceAsBytes(@as(*[1]Foo, &foo)[0..1]);\n            slice[0] = 0x13;\n            try testing.expect(foo.a == 0x3);\n            try testing.expect(foo.b == 0x1);\n        }\n    };\n    try S.doTheTest();\n    try comptime S.doTheTest();\n}\n\ntest \"sliceAsBytes and bytesAsSlice back\" {\n    try testing.expect(@sizeOf(i32) == 4);\n\n    var big_thing_array = [_]i32{ 1, 2, 3, 4 };\n    const big_thing_slice: []i32 = big_thing_array[0..];\n\n    const bytes = sliceAsBytes(big_thing_slice);\n    try testing.expect(bytes.len == 4 * 4);\n\n    bytes[4] = 0;\n    bytes[5] = 0;\n    bytes[6] = 0;\n    bytes[7] = 0;\n    try testing.expect(big_thing_slice[1] == 0);\n\n    const big_thing_again = bytesAsSlice(i32, bytes);\n    try testing.expect(big_thing_again[2] == 3);\n\n    big_thing_again[2] = -1;\n    try testing.expect(bytes[8] == math.maxInt(u8));\n    try testing.expect(bytes[9] == math.maxInt(u8));\n    try testing.expect(bytes[10] == math.maxInt(u8));\n    try testing.expect(bytes[11] == math.maxInt(u8));\n}\n\ntest \"sliceAsBytes preserves pointer attributes\" {\n    const inArr align(16) = [2]u16{ 0xDEAD, 0xBEEF };\n    const inSlice = @as(*align(16) const volatile [2]u16, @ptrCast(&inArr))[0..];\n    const outSlice = sliceAsBytes(inSlice);\n\n    const in = @typeInfo(@TypeOf(inSlice)).Pointer;\n    const out = @typeInfo(@TypeOf(outSlice)).Pointer;\n\n    try testing.expectEqual(in.is_const, out.is_const);\n    try testing.expectEqual(in.is_volatile, out.is_volatile);\n    try testing.expectEqual(in.is_allowzero, out.is_allowzero);\n    try testing.expectEqual(in.alignment, out.alignment);\n}\n\n/// Round an address up to the next (or current) aligned address.\n/// The alignment must be a power of 2 and greater than 0.\n/// Asserts that rounding up the address does not cause integer overflow.\npub fn alignForward(comptime T: type, addr: T, alignment: T) T {\n    assert(isValidAlignGeneric(T, alignment));\n    return alignBackward(T, addr + (alignment - 1), alignment);\n}\n\npub fn alignForwardLog2(addr: usize, log2_alignment: u8) usize {\n    const alignment = @as(usize, 1) << @as(math.Log2Int(usize), @intCast(log2_alignment));\n    return alignForward(usize, addr, alignment);\n}\n\npub const alignForwardGeneric = @compileError(\"renamed to alignForward\");\n\n/// Force an evaluation of the expression; this tries to prevent\n/// the compiler from optimizing the computation away even if the\n/// result eventually gets discarded.\n// TODO: use @declareSideEffect() when it is available - https://github.com/ziglang/zig/issues/6168\npub fn doNotOptimizeAway(val: anytype) void {\n    if (@inComptime()) return;\n\n    const max_gp_register_bits = @bitSizeOf(c_long);\n    const t = @typeInfo(@TypeOf(val));\n    switch (t) {\n        .Void, .Null, .ComptimeInt, .ComptimeFloat => return,\n        .Enum => doNotOptimizeAway(@intFromEnum(val)),\n        .Bool => doNotOptimizeAway(@intFromBool(val)),\n        .Int => {\n            const bits = t.Int.bits;\n            if (bits <= max_gp_register_bits and builtin.zig_backend != .stage2_c) {\n                const val2 = @as(\n                    std.meta.Int(t.Int.signedness, @max(8, std.math.ceilPowerOfTwoAssert(u16, bits))),\n                    val,\n                );\n                asm volatile (\"\"\n                    :\n                    : [val2] \"r\" (val2),\n                );\n            } else doNotOptimizeAway(&val);\n        },\n        .Float => {\n            if ((t.Float.bits == 32 or t.Float.bits == 64) and builtin.zig_backend != .stage2_c) {\n                asm volatile (\"\"\n                    :\n                    : [val] \"rm\" (val),\n                );\n            } else doNotOptimizeAway(&val);\n        },\n        .Pointer => {\n            if (builtin.zig_backend == .stage2_c) {\n                doNotOptimizeAwayC(val);\n            } else {\n                asm volatile (\"\"\n                    :\n                    : [val] \"m\" (val),\n                    : \"memory\"\n                );\n            }\n        },\n        .Array => {\n            if (t.Array.len * @sizeOf(t.Array.child) <= 64) {\n                for (val) |v| doNotOptimizeAway(v);\n            } else doNotOptimizeAway(&val);\n        },\n        else => doNotOptimizeAway(&val),\n    }\n}\n\n/// .stage2_c doesn't support asm blocks yet, so use volatile stores instead\nvar deopt_target: if (builtin.zig_backend == .stage2_c) u8 else void = undefined;\nfn doNotOptimizeAwayC(ptr: anytype) void {\n    const dest = @as(*volatile u8, @ptrCast(&deopt_target));\n    for (asBytes(ptr)) |b| {\n        dest.* = b;\n    }\n    dest.* = 0;\n}\n\ntest doNotOptimizeAway {\n    comptime doNotOptimizeAway(\"test\");\n\n    doNotOptimizeAway(null);\n    doNotOptimizeAway(true);\n    doNotOptimizeAway(0);\n    doNotOptimizeAway(0.0);\n    doNotOptimizeAway(@as(u1, 0));\n    doNotOptimizeAway(@as(u3, 0));\n    doNotOptimizeAway(@as(u8, 0));\n    doNotOptimizeAway(@as(u16, 0));\n    doNotOptimizeAway(@as(u32, 0));\n    doNotOptimizeAway(@as(u64, 0));\n    doNotOptimizeAway(@as(u128, 0));\n    doNotOptimizeAway(@as(u13, 0));\n    doNotOptimizeAway(@as(u37, 0));\n    doNotOptimizeAway(@as(u96, 0));\n    doNotOptimizeAway(@as(u200, 0));\n    doNotOptimizeAway(@as(f32, 0.0));\n    doNotOptimizeAway(@as(f64, 0.0));\n    doNotOptimizeAway([_]u8{0} ** 4);\n    doNotOptimizeAway([_]u8{0} ** 100);\n    doNotOptimizeAway(@as(std.builtin.Endian, .little));\n}\n\ntest alignForward {\n    try testing.expect(alignForward(usize, 1, 1) == 1);\n    try testing.expect(alignForward(usize, 2, 1) == 2);\n    try testing.expect(alignForward(usize, 1, 2) == 2);\n    try testing.expect(alignForward(usize, 2, 2) == 2);\n    try testing.expect(alignForward(usize, 3, 2) == 4);\n    try testing.expect(alignForward(usize, 4, 2) == 4);\n    try testing.expect(alignForward(usize, 7, 8) == 8);\n    try testing.expect(alignForward(usize, 8, 8) == 8);\n    try testing.expect(alignForward(usize, 9, 8) == 16);\n    try testing.expect(alignForward(usize, 15, 8) == 16);\n    try testing.expect(alignForward(usize, 16, 8) == 16);\n    try testing.expect(alignForward(usize, 17, 8) == 24);\n}\n\n/// Round an address down to the previous (or current) aligned address.\n/// Unlike `alignBackward`, `alignment` can be any positive number, not just a power of 2.\npub fn alignBackwardAnyAlign(i: usize, alignment: usize) usize {\n    if (isValidAlign(alignment))\n        return alignBackward(usize, i, alignment);\n    assert(alignment != 0);\n    return i - @mod(i, alignment);\n}\n\n/// Round an address down to the previous (or current) aligned address.\n/// The alignment must be a power of 2 and greater than 0.\npub fn alignBackward(comptime T: type, addr: T, alignment: T) T {\n    assert(isValidAlignGeneric(T, alignment));\n    // 000010000 // example alignment\n    // 000001111 // subtract 1\n    // 111110000 // binary not\n    return addr & ~(alignment - 1);\n}\n\npub const alignBackwardGeneric = @compileError(\"renamed to alignBackward\");\n\n/// Returns whether `alignment` is a valid alignment, meaning it is\n/// a positive power of 2.\npub fn isValidAlign(alignment: usize) bool {\n    return isValidAlignGeneric(usize, alignment);\n}\n\n/// Returns whether `alignment` is a valid alignment, meaning it is\n/// a positive power of 2.\npub fn isValidAlignGeneric(comptime T: type, alignment: T) bool {\n    return alignment > 0 and std.math.isPowerOfTwo(alignment);\n}\n\npub fn isAlignedAnyAlign(i: usize, alignment: usize) bool {\n    if (isValidAlign(alignment))\n        return isAligned(i, alignment);\n    assert(alignment != 0);\n    return 0 == @mod(i, alignment);\n}\n\npub fn isAlignedLog2(addr: usize, log2_alignment: u8) bool {\n    return @ctz(addr) >= log2_alignment;\n}\n\n/// Given an address and an alignment, return true if the address is a multiple of the alignment\n/// The alignment must be a power of 2 and greater than 0.\npub fn isAligned(addr: usize, alignment: usize) bool {\n    return isAlignedGeneric(u64, addr, alignment);\n}\n\npub fn isAlignedGeneric(comptime T: type, addr: T, alignment: T) bool {\n    return alignBackward(T, addr, alignment) == addr;\n}\n\ntest isAligned {\n    try testing.expect(isAligned(0, 4));\n    try testing.expect(isAligned(1, 1));\n    try testing.expect(isAligned(2, 1));\n    try testing.expect(isAligned(2, 2));\n    try testing.expect(!isAligned(2, 4));\n    try testing.expect(isAligned(3, 1));\n    try testing.expect(!isAligned(3, 2));\n    try testing.expect(!isAligned(3, 4));\n    try testing.expect(isAligned(4, 4));\n    try testing.expect(isAligned(4, 2));\n    try testing.expect(isAligned(4, 1));\n    try testing.expect(!isAligned(4, 8));\n    try testing.expect(!isAligned(4, 16));\n}\n\ntest \"freeing empty string with null-terminated sentinel\" {\n    const empty_string = try testing.allocator.dupeZ(u8, \"\");\n    testing.allocator.free(empty_string);\n}\n\n/// Returns a slice with the given new alignment,\n/// all other pointer attributes copied from `AttributeSource`.\nfn AlignedSlice(comptime AttributeSource: type, comptime new_alignment: usize) type {\n    const info = @typeInfo(AttributeSource).Pointer;\n    return @Type(.{\n        .Pointer = .{\n            .size = .Slice,\n            .is_const = info.is_const,\n            .is_volatile = info.is_volatile,\n            .is_allowzero = info.is_allowzero,\n            .alignment = new_alignment,\n            .address_space = info.address_space,\n            .child = info.child,\n            .sentinel = null,\n        },\n    });\n}\n\n/// Returns the largest slice in the given bytes that conforms to the new alignment,\n/// or `null` if the given bytes contain no conforming address.\npub fn alignInBytes(bytes: []u8, comptime new_alignment: usize) ?[]align(new_alignment) u8 {\n    const begin_address = @intFromPtr(bytes.ptr);\n    const end_address = begin_address + bytes.len;\n\n    const begin_address_aligned = mem.alignForward(usize, begin_address, new_alignment);\n    const new_length = std.math.sub(usize, end_address, begin_address_aligned) catch |e| switch (e) {\n        error.Overflow => return null,\n    };\n    const alignment_offset = begin_address_aligned - begin_address;\n    return @alignCast(bytes[alignment_offset .. alignment_offset + new_length]);\n}\n\n/// Returns the largest sub-slice within the given slice that conforms to the new alignment,\n/// or `null` if the given slice contains no conforming address.\npub fn alignInSlice(slice: anytype, comptime new_alignment: usize) ?AlignedSlice(@TypeOf(slice), new_alignment) {\n    const bytes = sliceAsBytes(slice);\n    const aligned_bytes = alignInBytes(bytes, new_alignment) orelse return null;\n\n    const Element = @TypeOf(slice[0]);\n    const slice_length_bytes = aligned_bytes.len - (aligned_bytes.len % @sizeOf(Element));\n    const aligned_slice = bytesAsSlice(Element, aligned_bytes[0..slice_length_bytes]);\n    return @alignCast(aligned_slice);\n}\n\ntest \"read/write(Var)PackedInt\" {\n    switch (builtin.cpu.arch) {\n        // This test generates too much code to execute on WASI.\n        // LLVM backend fails with \"too many locals: locals exceed maximum\"\n        .wasm32, .wasm64 => return error.SkipZigTest,\n        else => {},\n    }\n\n    if (builtin.cpu.arch == .powerpc) {\n        // https://github.com/ziglang/zig/issues/16951\n        return error.SkipZigTest;\n    }\n\n    const foreign_endian: Endian = if (native_endian == .big) .little else .big;\n    const expect = std.testing.expect;\n    var prng = std.Random.DefaultPrng.init(1234);\n    const random = prng.random();\n\n    @setEvalBranchQuota(10_000);\n    inline for ([_]type{ u8, u16, u32, u128 }) |BackingType| {\n        for ([_]BackingType{\n            @as(BackingType, 0), // all zeros\n            -%@as(BackingType, 1), // all ones\n            random.int(BackingType), // random\n            random.int(BackingType), // random\n            random.int(BackingType), // random\n        }) |init_value| {\n            const uTs = [_]type{ u1, u3, u7, u8, u9, u10, u15, u16, u86 };\n            const iTs = [_]type{ i1, i3, i7, i8, i9, i10, i15, i16, i86 };\n            inline for (uTs ++ iTs) |PackedType| {\n                if (@bitSizeOf(PackedType) > @bitSizeOf(BackingType))\n                    continue;\n\n                const iPackedType = std.meta.Int(.signed, @bitSizeOf(PackedType));\n                const uPackedType = std.meta.Int(.unsigned, @bitSizeOf(PackedType));\n                const Log2T = std.math.Log2Int(BackingType);\n\n                const offset_at_end = @bitSizeOf(BackingType) - @bitSizeOf(PackedType);\n                for ([_]usize{ 0, 1, 7, 8, 9, 10, 15, 16, 86, offset_at_end }) |offset| {\n                    if (offset > offset_at_end or offset == @bitSizeOf(BackingType))\n                        continue;\n\n                    for ([_]PackedType{\n                        ~@as(PackedType, 0), // all ones: -1 iN / maxInt uN\n                        @as(PackedType, 0), // all zeros: 0 iN / 0 uN\n                        @as(PackedType, @bitCast(@as(iPackedType, math.maxInt(iPackedType)))), // maxInt iN\n                        @as(PackedType, @bitCast(@as(iPackedType, math.minInt(iPackedType)))), // maxInt iN\n                        random.int(PackedType), // random\n                        random.int(PackedType), // random\n                    }) |write_value| {\n                        { // Fixed-size Read/Write (Native-endian)\n\n                            // Initialize Value\n                            var value: BackingType = init_value;\n\n                            // Read\n                            const read_value1 = readPackedInt(PackedType, asBytes(&value), offset, native_endian);\n                            try expect(read_value1 == @as(PackedType, @bitCast(@as(uPackedType, @truncate(value >> @as(Log2T, @intCast(offset)))))));\n\n                            // Write\n                            writePackedInt(PackedType, asBytes(&value), offset, write_value, native_endian);\n                            try expect(write_value == @as(PackedType, @bitCast(@as(uPackedType, @truncate(value >> @as(Log2T, @intCast(offset)))))));\n\n                            // Read again\n                            const read_value2 = readPackedInt(PackedType, asBytes(&value), offset, native_endian);\n                            try expect(read_value2 == write_value);\n\n                            // Verify bits outside of the target integer are unmodified\n                            const diff_bits = init_value ^ value;\n                            if (offset != offset_at_end)\n                                try expect(diff_bits >> @as(Log2T, @intCast(offset + @bitSizeOf(PackedType))) == 0);\n                            if (offset != 0)\n                                try expect(diff_bits << @as(Log2T, @intCast(@bitSizeOf(BackingType) - offset)) == 0);\n                        }\n\n                        { // Fixed-size Read/Write (Foreign-endian)\n\n                            // Initialize Value\n                            var value: BackingType = @byteSwap(init_value);\n\n                            // Read\n                            const read_value1 = readPackedInt(PackedType, asBytes(&value), offset, foreign_endian);\n                            try expect(read_value1 == @as(PackedType, @bitCast(@as(uPackedType, @truncate(@byteSwap(value) >> @as(Log2T, @intCast(offset)))))));\n\n                            // Write\n                            writePackedInt(PackedType, asBytes(&value), offset, write_value, foreign_endian);\n                            try expect(write_value == @as(PackedType, @bitCast(@as(uPackedType, @truncate(@byteSwap(value) >> @as(Log2T, @intCast(offset)))))));\n\n                            // Read again\n                            const read_value2 = readPackedInt(PackedType, asBytes(&value), offset, foreign_endian);\n                            try expect(read_value2 == write_value);\n\n                            // Verify bits outside of the target integer are unmodified\n                            const diff_bits = init_value ^ @byteSwap(value);\n                            if (offset != offset_at_end)\n                                try expect(diff_bits >> @as(Log2T, @intCast(offset + @bitSizeOf(PackedType))) == 0);\n                            if (offset != 0)\n                                try expect(diff_bits << @as(Log2T, @intCast(@bitSizeOf(BackingType) - offset)) == 0);\n                        }\n\n                        const signedness = @typeInfo(PackedType).Int.signedness;\n                        const NextPowerOfTwoInt = std.meta.Int(signedness, try comptime std.math.ceilPowerOfTwo(u16, @bitSizeOf(PackedType)));\n                        const ui64 = std.meta.Int(signedness, 64);\n                        inline for ([_]type{ PackedType, NextPowerOfTwoInt, ui64 }) |U| {\n                            { // Variable-size Read/Write (Native-endian)\n\n                                if (@bitSizeOf(U) < @bitSizeOf(PackedType))\n                                    continue;\n\n                                // Initialize Value\n                                var value: BackingType = init_value;\n\n                                // Read\n                                const read_value1 = readVarPackedInt(U, asBytes(&value), offset, @bitSizeOf(PackedType), native_endian, signedness);\n                                try expect(read_value1 == @as(PackedType, @bitCast(@as(uPackedType, @truncate(value >> @as(Log2T, @intCast(offset)))))));\n\n                                // Write\n                                writeVarPackedInt(asBytes(&value), offset, @bitSizeOf(PackedType), @as(U, write_value), native_endian);\n                                try expect(write_value == @as(PackedType, @bitCast(@as(uPackedType, @truncate(value >> @as(Log2T, @intCast(offset)))))));\n\n                                // Read again\n                                const read_value2 = readVarPackedInt(U, asBytes(&value), offset, @bitSizeOf(PackedType), native_endian, signedness);\n                                try expect(read_value2 == write_value);\n\n                                // Verify bits outside of the target integer are unmodified\n                                const diff_bits = init_value ^ value;\n                                if (offset != offset_at_end)\n                                    try expect(diff_bits >> @as(Log2T, @intCast(offset + @bitSizeOf(PackedType))) == 0);\n                                if (offset != 0)\n                                    try expect(diff_bits << @as(Log2T, @intCast(@bitSizeOf(BackingType) - offset)) == 0);\n                            }\n\n                            { // Variable-size Read/Write (Foreign-endian)\n\n                                if (@bitSizeOf(U) < @bitSizeOf(PackedType))\n                                    continue;\n\n                                // Initialize Value\n                                var value: BackingType = @byteSwap(init_value);\n\n                                // Read\n                                const read_value1 = readVarPackedInt(U, asBytes(&value), offset, @bitSizeOf(PackedType), foreign_endian, signedness);\n                                try expect(read_value1 == @as(PackedType, @bitCast(@as(uPackedType, @truncate(@byteSwap(value) >> @as(Log2T, @intCast(offset)))))));\n\n                                // Write\n                                writeVarPackedInt(asBytes(&value), offset, @bitSizeOf(PackedType), @as(U, write_value), foreign_endian);\n                                try expect(write_value == @as(PackedType, @bitCast(@as(uPackedType, @truncate(@byteSwap(value) >> @as(Log2T, @intCast(offset)))))));\n\n                                // Read again\n                                const read_value2 = readVarPackedInt(U, asBytes(&value), offset, @bitSizeOf(PackedType), foreign_endian, signedness);\n                                try expect(read_value2 == write_value);\n\n                                // Verify bits outside of the target integer are unmodified\n                                const diff_bits = init_value ^ @byteSwap(value);\n                                if (offset != offset_at_end)\n                                    try expect(diff_bits >> @as(Log2T, @intCast(offset + @bitSizeOf(PackedType))) == 0);\n                                if (offset != 0)\n                                    try expect(diff_bits << @as(Log2T, @intCast(@bitSizeOf(BackingType) - offset)) == 0);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n",
    "//! This is intended to be merged into GeneralPurposeAllocator at some point.\n\nconst std = @import(\"../std.zig\");\nconst builtin = @import(\"builtin\");\nconst Allocator = std.mem.Allocator;\nconst mem = std.mem;\nconst assert = std.debug.assert;\nconst wasm = std.wasm;\nconst math = std.math;\n\ncomptime {\n    if (!builtin.target.isWasm()) {\n        @compileError(\"WasmPageAllocator is only available for wasm32 arch\");\n    }\n}\n\npub const vtable = Allocator.VTable{\n    .alloc = alloc,\n    .resize = resize,\n    .free = free,\n};\n\npub const Error = Allocator.Error;\n\nconst max_usize = math.maxInt(usize);\nconst ushift = math.Log2Int(usize);\nconst bigpage_size = 64 * 1024;\nconst pages_per_bigpage = bigpage_size / wasm.page_size;\nconst bigpage_count = max_usize / bigpage_size;\n\n/// Because of storing free list pointers, the minimum size class is 3.\nconst min_class = math.log2(math.ceilPowerOfTwoAssert(usize, 1 + @sizeOf(usize)));\nconst size_class_count = math.log2(bigpage_size) - min_class;\n/// 0 - 1 bigpage\n/// 1 - 2 bigpages\n/// 2 - 4 bigpages\n/// etc.\nconst big_size_class_count = math.log2(bigpage_count);\n\nvar next_addrs = [1]usize{0} ** size_class_count;\n/// For each size class, points to the freed pointer.\nvar frees = [1]usize{0} ** size_class_count;\n/// For each big size class, points to the freed pointer.\nvar big_frees = [1]usize{0} ** big_size_class_count;\n\nfn alloc(ctx: *anyopaque, len: usize, log2_align: u8, return_address: usize) ?[*]u8 {\n    _ = ctx;\n    _ = return_address;\n    // Make room for the freelist next pointer.\n    const alignment = @as(usize, 1) << @as(Allocator.Log2Align, @intCast(log2_align));\n    const actual_len = @max(len +| @sizeOf(usize), alignment);\n    const slot_size = math.ceilPowerOfTwo(usize, actual_len) catch return null;\n    const class = math.log2(slot_size) - min_class;\n    if (class < size_class_count) {\n        const addr = a: {\n            const top_free_ptr = frees[class];\n            if (top_free_ptr != 0) {\n                const node: *usize = @ptrFromInt(top_free_ptr + (slot_size - @sizeOf(usize)));\n                frees[class] = node.*;\n                break :a top_free_ptr;\n            }\n\n            const next_addr = next_addrs[class];\n            if (next_addr % wasm.page_size == 0) {\n                const addr = allocBigPages(1);\n                if (addr == 0) return null;\n                //std.debug.print(\"allocated fresh slot_size={d} class={d} addr=0x{x}\\n\", .{\n                //    slot_size, class, addr,\n                //});\n                next_addrs[class] = addr + slot_size;\n                break :a addr;\n            } else {\n                next_addrs[class] = next_addr + slot_size;\n                break :a next_addr;\n            }\n        };\n        return @ptrFromInt(addr);\n    }\n    const bigpages_needed = bigPagesNeeded(actual_len);\n    return @ptrFromInt(allocBigPages(bigpages_needed));\n}\n\nfn resize(\n    ctx: *anyopaque,\n    buf: []u8,\n    log2_buf_align: u8,\n    new_len: usize,\n    return_address: usize,\n) bool {\n    _ = ctx;\n    _ = return_address;\n    // We don't want to move anything from one size class to another, but we\n    // can recover bytes in between powers of two.\n    const buf_align = @as(usize, 1) << @as(Allocator.Log2Align, @intCast(log2_buf_align));\n    const old_actual_len = @max(buf.len + @sizeOf(usize), buf_align);\n    const new_actual_len = @max(new_len +| @sizeOf(usize), buf_align);\n    const old_small_slot_size = math.ceilPowerOfTwoAssert(usize, old_actual_len);\n    const old_small_class = math.log2(old_small_slot_size) - min_class;\n    if (old_small_class < size_class_count) {\n        const new_small_slot_size = math.ceilPowerOfTwo(usize, new_actual_len) catch return false;\n        return old_small_slot_size == new_small_slot_size;\n    } else {\n        const old_bigpages_needed = bigPagesNeeded(old_actual_len);\n        const old_big_slot_pages = math.ceilPowerOfTwoAssert(usize, old_bigpages_needed);\n        const new_bigpages_needed = bigPagesNeeded(new_actual_len);\n        const new_big_slot_pages = math.ceilPowerOfTwo(usize, new_bigpages_needed) catch return false;\n        return old_big_slot_pages == new_big_slot_pages;\n    }\n}\n\nfn free(\n    ctx: *anyopaque,\n    buf: []u8,\n    log2_buf_align: u8,\n    return_address: usize,\n) void {\n    _ = ctx;\n    _ = return_address;\n    const buf_align = @as(usize, 1) << @as(Allocator.Log2Align, @intCast(log2_buf_align));\n    const actual_len = @max(buf.len + @sizeOf(usize), buf_align);\n    const slot_size = math.ceilPowerOfTwoAssert(usize, actual_len);\n    const class = math.log2(slot_size) - min_class;\n    const addr = @intFromPtr(buf.ptr);\n    if (class < size_class_count) {\n        const node: *usize = @ptrFromInt(addr + (slot_size - @sizeOf(usize)));\n        node.* = frees[class];\n        frees[class] = addr;\n    } else {\n        const bigpages_needed = bigPagesNeeded(actual_len);\n        const pow2_pages = math.ceilPowerOfTwoAssert(usize, bigpages_needed);\n        const big_slot_size_bytes = pow2_pages * bigpage_size;\n        const node: *usize = @ptrFromInt(addr + (big_slot_size_bytes - @sizeOf(usize)));\n        const big_class = math.log2(pow2_pages);\n        node.* = big_frees[big_class];\n        big_frees[big_class] = addr;\n    }\n}\n\ninline fn bigPagesNeeded(byte_count: usize) usize {\n    return (byte_count + (bigpage_size + (@sizeOf(usize) - 1))) / bigpage_size;\n}\n\nfn allocBigPages(n: usize) usize {\n    const pow2_pages = math.ceilPowerOfTwoAssert(usize, n);\n    const slot_size_bytes = pow2_pages * bigpage_size;\n    const class = math.log2(pow2_pages);\n\n    const top_free_ptr = big_frees[class];\n    if (top_free_ptr != 0) {\n        const node: *usize = @ptrFromInt(top_free_ptr + (slot_size_bytes - @sizeOf(usize)));\n        big_frees[class] = node.*;\n        return top_free_ptr;\n    }\n\n    const page_index = @wasmMemoryGrow(0, pow2_pages * pages_per_bigpage);\n    if (page_index == -1) return 0;\n    return @as(usize, @intCast(page_index)) * wasm.page_size;\n}\n\nconst test_ally = Allocator{\n    .ptr = undefined,\n    .vtable = &vtable,\n};\n\ntest \"small allocations - free in same order\" {\n    var list: [513]*u64 = undefined;\n\n    var i: usize = 0;\n    while (i < 513) : (i += 1) {\n        const ptr = try test_ally.create(u64);\n        list[i] = ptr;\n    }\n\n    for (list) |ptr| {\n        test_ally.destroy(ptr);\n    }\n}\n\ntest \"small allocations - free in reverse order\" {\n    var list: [513]*u64 = undefined;\n\n    var i: usize = 0;\n    while (i < 513) : (i += 1) {\n        const ptr = try test_ally.create(u64);\n        list[i] = ptr;\n    }\n\n    i = list.len;\n    while (i > 0) {\n        i -= 1;\n        const ptr = list[i];\n        test_ally.destroy(ptr);\n    }\n}\n\ntest \"large allocations\" {\n    const ptr1 = try test_ally.alloc(u64, 42768);\n    const ptr2 = try test_ally.alloc(u64, 52768);\n    test_ally.free(ptr1);\n    const ptr3 = try test_ally.alloc(u64, 62768);\n    test_ally.free(ptr3);\n    test_ally.free(ptr2);\n}\n\ntest \"very large allocation\" {\n    try std.testing.expectError(error.OutOfMemory, test_ally.alloc(u8, math.maxInt(usize)));\n}\n\ntest \"realloc\" {\n    var slice = try test_ally.alignedAlloc(u8, @alignOf(u32), 1);\n    defer test_ally.free(slice);\n    slice[0] = 0x12;\n\n    // This reallocation should keep its pointer address.\n    const old_slice = slice;\n    slice = try test_ally.realloc(slice, 2);\n    try std.testing.expect(old_slice.ptr == slice.ptr);\n    try std.testing.expect(slice[0] == 0x12);\n    slice[1] = 0x34;\n\n    // This requires upgrading to a larger size class\n    slice = try test_ally.realloc(slice, 17);\n    try std.testing.expect(slice[0] == 0x12);\n    try std.testing.expect(slice[1] == 0x34);\n}\n\ntest \"shrink\" {\n    var slice = try test_ally.alloc(u8, 20);\n    defer test_ally.free(slice);\n\n    @memset(slice, 0x11);\n\n    try std.testing.expect(test_ally.resize(slice, 17));\n    slice = slice[0..17];\n\n    for (slice) |b| {\n        try std.testing.expect(b == 0x11);\n    }\n\n    try std.testing.expect(test_ally.resize(slice, 16));\n    slice = slice[0..16];\n\n    for (slice) |b| {\n        try std.testing.expect(b == 0x11);\n    }\n}\n\ntest \"large object - grow\" {\n    var slice1 = try test_ally.alloc(u8, bigpage_size * 2 - 20);\n    defer test_ally.free(slice1);\n\n    const old = slice1;\n    slice1 = try test_ally.realloc(slice1, bigpage_size * 2 - 10);\n    try std.testing.expect(slice1.ptr == old.ptr);\n\n    slice1 = try test_ally.realloc(slice1, bigpage_size * 2);\n    slice1 = try test_ally.realloc(slice1, bigpage_size * 2 + 1);\n}\n\ntest \"realloc small object to large object\" {\n    var slice = try test_ally.alloc(u8, 70);\n    defer test_ally.free(slice);\n    slice[0] = 0x12;\n    slice[60] = 0x34;\n\n    // This requires upgrading to a large object\n    const large_object_size = bigpage_size * 2 + 50;\n    slice = try test_ally.realloc(slice, large_object_size);\n    try std.testing.expect(slice[0] == 0x12);\n    try std.testing.expect(slice[60] == 0x34);\n}\n\ntest \"shrink large object to large object\" {\n    var slice = try test_ally.alloc(u8, bigpage_size * 2 + 50);\n    defer test_ally.free(slice);\n    slice[0] = 0x12;\n    slice[60] = 0x34;\n\n    try std.testing.expect(test_ally.resize(slice, bigpage_size * 2 + 1));\n    slice = slice[0 .. bigpage_size * 2 + 1];\n    try std.testing.expect(slice[0] == 0x12);\n    try std.testing.expect(slice[60] == 0x34);\n\n    try std.testing.expect(test_ally.resize(slice, bigpage_size * 2 + 1));\n    try std.testing.expect(slice[0] == 0x12);\n    try std.testing.expect(slice[60] == 0x34);\n\n    slice = try test_ally.realloc(slice, bigpage_size * 2);\n    try std.testing.expect(slice[0] == 0x12);\n    try std.testing.expect(slice[60] == 0x34);\n}\n\ntest \"realloc large object to small object\" {\n    var slice = try test_ally.alloc(u8, bigpage_size * 2 + 50);\n    defer test_ally.free(slice);\n    slice[0] = 0x12;\n    slice[16] = 0x34;\n\n    slice = try test_ally.realloc(slice, 19);\n    try std.testing.expect(slice[0] == 0x12);\n    try std.testing.expect(slice[16] == 0x34);\n}\n\ntest \"objects of size 1024 and 2048\" {\n    const slice = try test_ally.alloc(u8, 1025);\n    const slice2 = try test_ally.alloc(u8, 3000);\n\n    test_ally.free(slice);\n    test_ally.free(slice2);\n}\n\ntest \"standard allocator tests\" {\n    try std.heap.testAllocator(test_ally);\n    try std.heap.testAllocatorAligned(test_ally);\n}\n",
    "const builtin = @import(\"builtin\");\nconst std = @import(\"std.zig\");\nconst float = @import(\"math/float.zig\");\nconst assert = std.debug.assert;\nconst mem = std.mem;\nconst testing = std.testing;\n\n/// Euler's number (e)\npub const e = 2.71828182845904523536028747135266249775724709369995;\n\n/// Archimedes' constant ()\npub const pi = 3.14159265358979323846264338327950288419716939937510;\n\n/// Phi or Golden ratio constant () = (1 + sqrt(5))/2\npub const phi = 1.6180339887498948482045868343656381177203091798057628621;\n\n/// Circle constant ()\npub const tau = 2 * pi;\n\n/// log2(e)\npub const log2e = 1.442695040888963407359924681001892137;\n\n/// log10(e)\npub const log10e = 0.434294481903251827651128918916605082;\n\n/// ln(2)\npub const ln2 = 0.693147180559945309417232121458176568;\n\n/// ln(10)\npub const ln10 = 2.302585092994045684017991454684364208;\n\n/// 2/sqrt()\npub const two_sqrtpi = 1.128379167095512573896158903121545172;\n\n/// sqrt(2)\npub const sqrt2 = 1.414213562373095048801688724209698079;\n\n/// 1/sqrt(2)\npub const sqrt1_2 = 0.707106781186547524400844362104849039;\n\n/// pi/180.0\npub const rad_per_deg = 0.0174532925199432957692369076848861271344287188854172545609719144;\n\n/// 180.0/pi\npub const deg_per_rad = 57.295779513082320876798154814105170332405472466564321549160243861;\n\npub const floatExponentBits = float.floatExponentBits;\npub const floatMantissaBits = float.floatMantissaBits;\npub const floatFractionalBits = float.floatFractionalBits;\npub const floatExponentMin = float.floatExponentMin;\npub const floatExponentMax = float.floatExponentMax;\npub const floatTrueMin = float.floatTrueMin;\npub const floatMin = float.floatMin;\npub const floatMax = float.floatMax;\npub const floatEps = float.floatEps;\npub const floatEpsAt = float.floatEpsAt;\npub const inf = float.inf;\npub const nan = float.nan;\npub const snan = float.snan;\n\n/// Performs an approximate comparison of two floating point values `x` and `y`.\n/// Returns true if the absolute difference between them is less or equal than\n/// the specified tolerance.\n///\n/// The `tolerance` parameter is the absolute tolerance used when determining if\n/// the two numbers are close enough; a good value for this parameter is a small\n/// multiple of `floatEps(T)`.\n///\n/// Note that this function is recommended for comparing small numbers\n/// around zero; using `approxEqRel` is suggested otherwise.\n///\n/// NaN values are never considered equal to any value.\npub fn approxEqAbs(comptime T: type, x: T, y: T, tolerance: T) bool {\n    assert(@typeInfo(T) == .Float or @typeInfo(T) == .ComptimeFloat);\n    assert(tolerance >= 0);\n\n    // Fast path for equal values (and signed zeros and infinites).\n    if (x == y)\n        return true;\n\n    if (isNan(x) or isNan(y))\n        return false;\n\n    return @abs(x - y) <= tolerance;\n}\n\n/// Performs an approximate comparison of two floating point values `x` and `y`.\n/// Returns true if the absolute difference between them is less or equal than\n/// `max(|x|, |y|) * tolerance`, where `tolerance` is a positive number greater\n/// than zero.\n///\n/// The `tolerance` parameter is the relative tolerance used when determining if\n/// the two numbers are close enough; a good value for this parameter is usually\n/// `sqrt(floatEps(T))`, meaning that the two numbers are considered equal if at\n/// least half of the digits are equal.\n///\n/// Note that for comparisons of small numbers around zero this function won't\n/// give meaningful results, use `approxEqAbs` instead.\n///\n/// NaN values are never considered equal to any value.\npub fn approxEqRel(comptime T: type, x: T, y: T, tolerance: T) bool {\n    assert(@typeInfo(T) == .Float or @typeInfo(T) == .ComptimeFloat);\n    assert(tolerance > 0);\n\n    // Fast path for equal values (and signed zeros and infinites).\n    if (x == y)\n        return true;\n\n    if (isNan(x) or isNan(y))\n        return false;\n\n    return @abs(x - y) <= @max(@abs(x), @abs(y)) * tolerance;\n}\n\ntest approxEqAbs {\n    inline for ([_]type{ f16, f32, f64, f128 }) |T| {\n        const eps_value = comptime floatEps(T);\n        const min_value = comptime floatMin(T);\n\n        try testing.expect(approxEqAbs(T, 0.0, 0.0, eps_value));\n        try testing.expect(approxEqAbs(T, -0.0, -0.0, eps_value));\n        try testing.expect(approxEqAbs(T, 0.0, -0.0, eps_value));\n        try testing.expect(!approxEqAbs(T, 1.0 + 2 * eps_value, 1.0, eps_value));\n        try testing.expect(approxEqAbs(T, 1.0 + 1 * eps_value, 1.0, eps_value));\n        try testing.expect(approxEqAbs(T, min_value, 0.0, eps_value * 2));\n        try testing.expect(approxEqAbs(T, -min_value, 0.0, eps_value * 2));\n    }\n\n    comptime {\n        // `comptime_float` is guaranteed to have the same precision and operations of\n        // the largest other floating point type, which is f128 but it doesn't have a\n        // defined layout so we can't rely on `@bitCast` to construct the smallest\n        // possible epsilon value like we do in the tests above. In the same vein, we\n        // also can't represent a max/min, `NaN` or `Inf` values.\n        const eps_value = 1e-4;\n\n        try testing.expect(approxEqAbs(comptime_float, 0.0, 0.0, eps_value));\n        try testing.expect(approxEqAbs(comptime_float, -0.0, -0.0, eps_value));\n        try testing.expect(approxEqAbs(comptime_float, 0.0, -0.0, eps_value));\n        try testing.expect(!approxEqAbs(comptime_float, 1.0 + 2 * eps_value, 1.0, eps_value));\n        try testing.expect(approxEqAbs(comptime_float, 1.0 + 1 * eps_value, 1.0, eps_value));\n    }\n}\n\ntest approxEqRel {\n    inline for ([_]type{ f16, f32, f64, f128 }) |T| {\n        const eps_value = comptime floatEps(T);\n        const sqrt_eps_value = comptime sqrt(eps_value);\n        const nan_value = comptime nan(T);\n        const inf_value = comptime inf(T);\n        const min_value = comptime floatMin(T);\n\n        try testing.expect(approxEqRel(T, 1.0, 1.0, sqrt_eps_value));\n        try testing.expect(!approxEqRel(T, 1.0, 0.0, sqrt_eps_value));\n        try testing.expect(!approxEqRel(T, 1.0, nan_value, sqrt_eps_value));\n        try testing.expect(!approxEqRel(T, nan_value, nan_value, sqrt_eps_value));\n        try testing.expect(approxEqRel(T, inf_value, inf_value, sqrt_eps_value));\n        try testing.expect(approxEqRel(T, min_value, min_value, sqrt_eps_value));\n        try testing.expect(approxEqRel(T, -min_value, -min_value, sqrt_eps_value));\n    }\n\n    comptime {\n        // `comptime_float` is guaranteed to have the same precision and operations of\n        // the largest other floating point type, which is f128 but it doesn't have a\n        // defined layout so we can't rely on `@bitCast` to construct the smallest\n        // possible epsilon value like we do in the tests above. In the same vein, we\n        // also can't represent a max/min, `NaN` or `Inf` values.\n        const eps_value = 1e-4;\n        const sqrt_eps_value = sqrt(eps_value);\n\n        try testing.expect(approxEqRel(comptime_float, 1.0, 1.0, sqrt_eps_value));\n        try testing.expect(!approxEqRel(comptime_float, 1.0, 0.0, sqrt_eps_value));\n    }\n}\n\npub fn raiseInvalid() void {\n    // Raise INVALID fpu exception\n}\n\npub fn raiseUnderflow() void {\n    // Raise UNDERFLOW fpu exception\n}\n\npub fn raiseOverflow() void {\n    // Raise OVERFLOW fpu exception\n}\n\npub fn raiseInexact() void {\n    // Raise INEXACT fpu exception\n}\n\npub fn raiseDivByZero() void {\n    // Raise INEXACT fpu exception\n}\n\npub const isNan = @import(\"math/isnan.zig\").isNan;\npub const isSignalNan = @import(\"math/isnan.zig\").isSignalNan;\npub const frexp = @import(\"math/frexp.zig\").frexp;\npub const Frexp = @import(\"math/frexp.zig\").Frexp;\npub const modf = @import(\"math/modf.zig\").modf;\npub const Modf = @import(\"math/modf.zig\").Modf;\npub const copysign = @import(\"math/copysign.zig\").copysign;\npub const isFinite = @import(\"math/isfinite.zig\").isFinite;\npub const isInf = @import(\"math/isinf.zig\").isInf;\npub const isPositiveInf = @import(\"math/isinf.zig\").isPositiveInf;\npub const isNegativeInf = @import(\"math/isinf.zig\").isNegativeInf;\npub const isPositiveZero = @import(\"math/iszero.zig\").isPositiveZero;\npub const isNegativeZero = @import(\"math/iszero.zig\").isNegativeZero;\npub const isNormal = @import(\"math/isnormal.zig\").isNormal;\npub const nextAfter = @import(\"math/nextafter.zig\").nextAfter;\npub const signbit = @import(\"math/signbit.zig\").signbit;\npub const scalbn = @import(\"math/scalbn.zig\").scalbn;\npub const ldexp = @import(\"math/ldexp.zig\").ldexp;\npub const pow = @import(\"math/pow.zig\").pow;\npub const powi = @import(\"math/powi.zig\").powi;\npub const sqrt = @import(\"math/sqrt.zig\").sqrt;\npub const cbrt = @import(\"math/cbrt.zig\").cbrt;\npub const acos = @import(\"math/acos.zig\").acos;\npub const asin = @import(\"math/asin.zig\").asin;\npub const atan = @import(\"math/atan.zig\").atan;\npub const atan2 = @import(\"math/atan2.zig\").atan2;\npub const hypot = @import(\"math/hypot.zig\").hypot;\npub const expm1 = @import(\"math/expm1.zig\").expm1;\npub const ilogb = @import(\"math/ilogb.zig\").ilogb;\npub const log = @import(\"math/log.zig\").log;\npub const log2 = @import(\"math/log2.zig\").log2;\npub const log10 = @import(\"math/log10.zig\").log10;\npub const log10_int = @import(\"math/log10.zig\").log10_int;\npub const log_int = @import(\"math/log_int.zig\").log_int;\npub const log1p = @import(\"math/log1p.zig\").log1p;\npub const asinh = @import(\"math/asinh.zig\").asinh;\npub const acosh = @import(\"math/acosh.zig\").acosh;\npub const atanh = @import(\"math/atanh.zig\").atanh;\npub const sinh = @import(\"math/sinh.zig\").sinh;\npub const cosh = @import(\"math/cosh.zig\").cosh;\npub const tanh = @import(\"math/tanh.zig\").tanh;\npub const gcd = @import(\"math/gcd.zig\").gcd;\npub const gamma = @import(\"math/gamma.zig\").gamma;\npub const lgamma = @import(\"math/gamma.zig\").lgamma;\n\n/// Sine trigonometric function on a floating point number.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @sin\npub inline fn sin(value: anytype) @TypeOf(value) {\n    return @sin(value);\n}\n\n/// Cosine trigonometric function on a floating point number.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @cos\npub inline fn cos(value: anytype) @TypeOf(value) {\n    return @cos(value);\n}\n\n/// Tangent trigonometric function on a floating point number.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @tan\npub inline fn tan(value: anytype) @TypeOf(value) {\n    return @tan(value);\n}\n\n/// Converts an angle in radians to degrees. T must be a float or comptime number or a vector of floats.\npub fn radiansToDegrees(ang: anytype) if (@TypeOf(ang) == comptime_int) comptime_float else @TypeOf(ang) {\n    const T = @TypeOf(ang);\n    switch (@typeInfo(T)) {\n        .Float, .ComptimeFloat, .ComptimeInt => return ang * deg_per_rad,\n        .Vector => |V| if (@typeInfo(V.child) == .Float) return ang * @as(T, @splat(deg_per_rad)),\n        else => {},\n    }\n    @compileError(\"Input must be float or a comptime number, or a vector of floats.\");\n}\n\ntest radiansToDegrees {\n    const zero: f32 = 0;\n    const half_pi: f32 = pi / 2.0;\n    const neg_quart_pi: f32 = -pi / 4.0;\n    const one_pi: f32 = pi;\n    const two_pi: f32 = 2.0 * pi;\n    try std.testing.expectApproxEqAbs(@as(f32, 0), radiansToDegrees(zero), 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, 90), radiansToDegrees(half_pi), 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, -45), radiansToDegrees(neg_quart_pi), 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, 180), radiansToDegrees(one_pi), 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, 360), radiansToDegrees(two_pi), 1e-6);\n\n    const result = radiansToDegrees(@Vector(4, f32){\n        half_pi,\n        neg_quart_pi,\n        one_pi,\n        two_pi,\n    });\n    try std.testing.expectApproxEqAbs(@as(f32, 90), result[0], 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, -45), result[1], 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, 180), result[2], 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, 360), result[3], 1e-6);\n}\n\n/// Converts an angle in degrees to radians. T must be a float or comptime number or a vector of floats.\npub fn degreesToRadians(ang: anytype) if (@TypeOf(ang) == comptime_int) comptime_float else @TypeOf(ang) {\n    const T = @TypeOf(ang);\n    switch (@typeInfo(T)) {\n        .Float, .ComptimeFloat, .ComptimeInt => return ang * rad_per_deg,\n        .Vector => |V| if (@typeInfo(V.child) == .Float) return ang * @as(T, @splat(rad_per_deg)),\n        else => {},\n    }\n    @compileError(\"Input must be float or a comptime number, or a vector of floats.\");\n}\n\ntest degreesToRadians {\n    const ninety: f32 = 90;\n    const neg_two_seventy: f32 = -270;\n    const three_sixty: f32 = 360;\n    try std.testing.expectApproxEqAbs(@as(f32, pi / 2.0), degreesToRadians(ninety), 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, -3 * pi / 2.0), degreesToRadians(neg_two_seventy), 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, 2 * pi), degreesToRadians(three_sixty), 1e-6);\n\n    const result = degreesToRadians(@Vector(3, f32){\n        ninety,\n        neg_two_seventy,\n        three_sixty,\n    });\n    try std.testing.expectApproxEqAbs(@as(f32, pi / 2.0), result[0], 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, -3 * pi / 2.0), result[1], 1e-6);\n    try std.testing.expectApproxEqAbs(@as(f32, 2 * pi), result[2], 1e-6);\n}\n\n/// Base-e exponential function on a floating point number.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @exp\npub inline fn exp(value: anytype) @TypeOf(value) {\n    return @exp(value);\n}\n\n/// Base-2 exponential function on a floating point number.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @exp2\npub inline fn exp2(value: anytype) @TypeOf(value) {\n    return @exp2(value);\n}\n\npub const complex = @import(\"math/complex.zig\");\npub const Complex = complex.Complex;\n\npub const big = @import(\"math/big.zig\");\n\ntest {\n    _ = floatExponentBits;\n    _ = floatMantissaBits;\n    _ = floatFractionalBits;\n    _ = floatExponentMin;\n    _ = floatExponentMax;\n    _ = floatTrueMin;\n    _ = floatMin;\n    _ = floatMax;\n    _ = floatEps;\n    _ = inf;\n    _ = nan;\n    _ = snan;\n    _ = isNan;\n    _ = isSignalNan;\n    _ = frexp;\n    _ = Frexp;\n    _ = modf;\n    _ = Modf;\n    _ = copysign;\n    _ = isFinite;\n    _ = isInf;\n    _ = isPositiveInf;\n    _ = isNegativeInf;\n    _ = isNormal;\n    _ = nextAfter;\n    _ = signbit;\n    _ = scalbn;\n    _ = ldexp;\n    _ = pow;\n    _ = powi;\n    _ = sqrt;\n    _ = cbrt;\n    _ = acos;\n    _ = asin;\n    _ = atan;\n    _ = atan2;\n    _ = hypot;\n    _ = expm1;\n    _ = ilogb;\n    _ = log;\n    _ = log2;\n    _ = log10;\n    _ = log10_int;\n    _ = log_int;\n    _ = log1p;\n    _ = asinh;\n    _ = acosh;\n    _ = atanh;\n    _ = sinh;\n    _ = cosh;\n    _ = tanh;\n    _ = gcd;\n    _ = gamma;\n    _ = lgamma;\n\n    _ = complex;\n    _ = Complex;\n\n    _ = big;\n}\n\n/// Given two types, returns the smallest one which is capable of holding the\n/// full range of the minimum value.\npub fn Min(comptime A: type, comptime B: type) type {\n    switch (@typeInfo(A)) {\n        .Int => |a_info| switch (@typeInfo(B)) {\n            .Int => |b_info| if (a_info.signedness == .unsigned and b_info.signedness == .unsigned) {\n                if (a_info.bits < b_info.bits) {\n                    return A;\n                } else {\n                    return B;\n                }\n            },\n            else => {},\n        },\n        else => {},\n    }\n    return @TypeOf(@as(A, 0) + @as(B, 0));\n}\n\n/// Odd sawtooth function\n/// ```\n///         |\n///      /  | /    /\n///     /   |/    /\n///  --/----/----/--\n///   /    /|   /\n///  /    / |  /\n///         |\n/// ```\n/// Limit x to the half-open interval [-r, r).\npub fn wrap(x: anytype, r: anytype) @TypeOf(x) {\n    const info_x = @typeInfo(@TypeOf(x));\n    const info_r = @typeInfo(@TypeOf(r));\n    if (info_x == .Int and info_x.Int.signedness != .signed) {\n        @compileError(\"x must be floating point, comptime integer, or signed integer.\");\n    }\n    switch (info_r) {\n        .Int => {\n            // in the rare usecase of r not being comptime_int or float,\n            // take the penalty of having an intermediary type conversion,\n            // otherwise the alternative is to unwind iteratively to avoid overflow\n            const R = comptime do: {\n                var info = info_r;\n                info.Int.bits += 1;\n                info.Int.signedness = .signed;\n                break :do @Type(info);\n            };\n            const radius: if (info_r.Int.signedness == .signed) @TypeOf(r) else R = r;\n            return @intCast(@mod(x - radius, 2 * @as(R, r)) - r); // provably impossible to overflow\n        },\n        else => {\n            return @mod(x - r, 2 * r) - r;\n        },\n    }\n}\ntest wrap {\n    // Within range\n    try testing.expect(wrap(@as(i32, -75), @as(i32, 180)) == -75);\n    try testing.expect(wrap(@as(i32, -75), @as(i32, -180)) == -75);\n    // Below\n    try testing.expect(wrap(@as(i32, -225), @as(i32, 180)) == 135);\n    try testing.expect(wrap(@as(i32, -225), @as(i32, -180)) == 135);\n    // Above\n    try testing.expect(wrap(@as(i32, 361), @as(i32, 180)) == 1);\n    try testing.expect(wrap(@as(i32, 361), @as(i32, -180)) == 1);\n\n    // One period, right limit, positive r\n    try testing.expect(wrap(@as(i32, 180), @as(i32, 180)) == -180);\n    // One period, left limit, positive r\n    try testing.expect(wrap(@as(i32, -180), @as(i32, 180)) == -180);\n    // One period, right limit, negative r\n    try testing.expect(wrap(@as(i32, 180), @as(i32, -180)) == 180);\n    // One period, left limit, negative r\n    try testing.expect(wrap(@as(i32, -180), @as(i32, -180)) == 180);\n\n    // Two periods, right limit, positive r\n    try testing.expect(wrap(@as(i32, 540), @as(i32, 180)) == -180);\n    // Two periods, left limit, positive r\n    try testing.expect(wrap(@as(i32, -540), @as(i32, 180)) == -180);\n    // Two periods, right limit, negative r\n    try testing.expect(wrap(@as(i32, 540), @as(i32, -180)) == 180);\n    // Two periods, left limit, negative r\n    try testing.expect(wrap(@as(i32, -540), @as(i32, -180)) == 180);\n\n    // Floating point\n    try testing.expect(wrap(@as(f32, 1.125), @as(f32, 1.0)) == -0.875);\n    try testing.expect(wrap(@as(f32, -127.5), @as(f32, 180)) == -127.5);\n\n    // Mix of comptime and non-comptime\n    var i: i32 = 1;\n    _ = &i;\n    try testing.expect(wrap(i, 10) == 1);\n\n    const limit: i32 = 180;\n    // Within range\n    try testing.expect(wrap(@as(i32, -75), limit) == -75);\n    // Below\n    try testing.expect(wrap(@as(i32, -225), limit) == 135);\n    // Above\n    try testing.expect(wrap(@as(i32, 361), limit) == 1);\n}\n\n/// Odd ramp function\n/// ```\n///         |  _____\n///         | /\n///         |/\n///  -------/-------\n///        /|\n///  _____/ |\n///         |\n/// ```\n/// Limit val to the inclusive range [lower, upper].\npub fn clamp(val: anytype, lower: anytype, upper: anytype) @TypeOf(val, lower, upper) {\n    const T = @TypeOf(val, lower, upper);\n    switch (@typeInfo(T)) {\n        .Int, .Float, .ComptimeInt, .ComptimeFloat => assert(lower <= upper),\n        .Vector => |vinfo| switch (@typeInfo(vinfo.child)) {\n            .Int, .Float => assert(@reduce(.And, lower <= upper)),\n            else => @compileError(\"Expected vector of ints or floats, found \" ++ @typeName(T)),\n        },\n        else => @compileError(\"Expected an int, float or vector of one, found \" ++ @typeName(T)),\n    }\n    return @max(lower, @min(val, upper));\n}\ntest clamp {\n    // Within range\n    try testing.expect(std.math.clamp(@as(i32, -1), @as(i32, -4), @as(i32, 7)) == -1);\n    // Below\n    try testing.expect(std.math.clamp(@as(i32, -5), @as(i32, -4), @as(i32, 7)) == -4);\n    // Above\n    try testing.expect(std.math.clamp(@as(i32, 8), @as(i32, -4), @as(i32, 7)) == 7);\n\n    // Floating point\n    try testing.expect(std.math.clamp(@as(f32, 1.1), @as(f32, 0.0), @as(f32, 1.0)) == 1.0);\n    try testing.expect(std.math.clamp(@as(f32, -127.5), @as(f32, -200), @as(f32, -100)) == -127.5);\n\n    // Vector\n    try testing.expect(@reduce(.And, std.math.clamp(@as(@Vector(3, f32), .{ 1.4, 15.23, 28.3 }), @as(@Vector(3, f32), .{ 9.8, 13.2, 15.6 }), @as(@Vector(3, f32), .{ 15.2, 22.8, 26.3 })) == @as(@Vector(3, f32), .{ 9.8, 15.23, 26.3 })));\n\n    // Mix of comptime and non-comptime\n    var i: i32 = 1;\n    _ = &i;\n    try testing.expect(std.math.clamp(i, 0, 1) == 1);\n}\n\n/// Returns the product of a and b. Returns an error on overflow.\npub fn mul(comptime T: type, a: T, b: T) (error{Overflow}!T) {\n    if (T == comptime_int) return a * b;\n    const ov = @mulWithOverflow(a, b);\n    if (ov[1] != 0) return error.Overflow;\n    return ov[0];\n}\n\n/// Returns the sum of a and b. Returns an error on overflow.\npub fn add(comptime T: type, a: T, b: T) (error{Overflow}!T) {\n    if (T == comptime_int) return a + b;\n    const ov = @addWithOverflow(a, b);\n    if (ov[1] != 0) return error.Overflow;\n    return ov[0];\n}\n\n/// Returns a - b, or an error on overflow.\npub fn sub(comptime T: type, a: T, b: T) (error{Overflow}!T) {\n    if (T == comptime_int) return a - b;\n    const ov = @subWithOverflow(a, b);\n    if (ov[1] != 0) return error.Overflow;\n    return ov[0];\n}\n\npub fn negate(x: anytype) !@TypeOf(x) {\n    return sub(@TypeOf(x), 0, x);\n}\n\n/// Shifts a left by shift_amt. Returns an error on overflow. shift_amt\n/// is unsigned.\npub fn shlExact(comptime T: type, a: T, shift_amt: Log2Int(T)) !T {\n    if (T == comptime_int) return a << shift_amt;\n    const ov = @shlWithOverflow(a, shift_amt);\n    if (ov[1] != 0) return error.Overflow;\n    return ov[0];\n}\n\n/// Shifts left. Overflowed bits are truncated.\n/// A negative shift amount results in a right shift.\npub fn shl(comptime T: type, a: T, shift_amt: anytype) T {\n    const abs_shift_amt = @abs(shift_amt);\n\n    const casted_shift_amt = blk: {\n        if (@typeInfo(T) == .Vector) {\n            const C = @typeInfo(T).Vector.child;\n            const len = @typeInfo(T).Vector.len;\n            if (abs_shift_amt >= @typeInfo(C).Int.bits) return @splat(0);\n            break :blk @as(@Vector(len, Log2Int(C)), @splat(@as(Log2Int(C), @intCast(abs_shift_amt))));\n        } else {\n            if (abs_shift_amt >= @typeInfo(T).Int.bits) return 0;\n            break :blk @as(Log2Int(T), @intCast(abs_shift_amt));\n        }\n    };\n\n    if (@TypeOf(shift_amt) == comptime_int or @typeInfo(@TypeOf(shift_amt)).Int.signedness == .signed) {\n        if (shift_amt < 0) {\n            return a >> casted_shift_amt;\n        }\n    }\n\n    return a << casted_shift_amt;\n}\n\ntest shl {\n    if (builtin.zig_backend == .stage2_llvm and builtin.cpu.arch == .aarch64) {\n        // https://github.com/ziglang/zig/issues/12012\n        return error.SkipZigTest;\n    }\n\n    try testing.expect(shl(u8, 0b11111111, @as(usize, 3)) == 0b11111000);\n    try testing.expect(shl(u8, 0b11111111, @as(usize, 8)) == 0);\n    try testing.expect(shl(u8, 0b11111111, @as(usize, 9)) == 0);\n    try testing.expect(shl(u8, 0b11111111, @as(isize, -2)) == 0b00111111);\n    try testing.expect(shl(u8, 0b11111111, 3) == 0b11111000);\n    try testing.expect(shl(u8, 0b11111111, 8) == 0);\n    try testing.expect(shl(u8, 0b11111111, 9) == 0);\n    try testing.expect(shl(u8, 0b11111111, -2) == 0b00111111);\n    try testing.expect(shl(@Vector(1, u32), @Vector(1, u32){42}, @as(usize, 1))[0] == @as(u32, 42) << 1);\n    try testing.expect(shl(@Vector(1, u32), @Vector(1, u32){42}, @as(isize, -1))[0] == @as(u32, 42) >> 1);\n    try testing.expect(shl(@Vector(1, u32), @Vector(1, u32){42}, 33)[0] == 0);\n}\n\n/// Shifts right. Overflowed bits are truncated.\n/// A negative shift amount results in a left shift.\npub fn shr(comptime T: type, a: T, shift_amt: anytype) T {\n    const abs_shift_amt = @abs(shift_amt);\n\n    const casted_shift_amt = blk: {\n        if (@typeInfo(T) == .Vector) {\n            const C = @typeInfo(T).Vector.child;\n            const len = @typeInfo(T).Vector.len;\n            if (abs_shift_amt >= @typeInfo(C).Int.bits) return @splat(0);\n            break :blk @as(@Vector(len, Log2Int(C)), @splat(@as(Log2Int(C), @intCast(abs_shift_amt))));\n        } else {\n            if (abs_shift_amt >= @typeInfo(T).Int.bits) return 0;\n            break :blk @as(Log2Int(T), @intCast(abs_shift_amt));\n        }\n    };\n\n    if (@TypeOf(shift_amt) == comptime_int or @typeInfo(@TypeOf(shift_amt)).Int.signedness == .signed) {\n        if (shift_amt < 0) {\n            return a << casted_shift_amt;\n        }\n    }\n\n    return a >> casted_shift_amt;\n}\n\ntest shr {\n    if (builtin.zig_backend == .stage2_llvm and builtin.cpu.arch == .aarch64) {\n        // https://github.com/ziglang/zig/issues/12012\n        return error.SkipZigTest;\n    }\n\n    try testing.expect(shr(u8, 0b11111111, @as(usize, 3)) == 0b00011111);\n    try testing.expect(shr(u8, 0b11111111, @as(usize, 8)) == 0);\n    try testing.expect(shr(u8, 0b11111111, @as(usize, 9)) == 0);\n    try testing.expect(shr(u8, 0b11111111, @as(isize, -2)) == 0b11111100);\n    try testing.expect(shr(u8, 0b11111111, 3) == 0b00011111);\n    try testing.expect(shr(u8, 0b11111111, 8) == 0);\n    try testing.expect(shr(u8, 0b11111111, 9) == 0);\n    try testing.expect(shr(u8, 0b11111111, -2) == 0b11111100);\n    try testing.expect(shr(@Vector(1, u32), @Vector(1, u32){42}, @as(usize, 1))[0] == @as(u32, 42) >> 1);\n    try testing.expect(shr(@Vector(1, u32), @Vector(1, u32){42}, @as(isize, -1))[0] == @as(u32, 42) << 1);\n    try testing.expect(shr(@Vector(1, u32), @Vector(1, u32){42}, 33)[0] == 0);\n}\n\n/// Rotates right. Only unsigned values can be rotated.  Negative shift\n/// values result in shift modulo the bit count.\npub fn rotr(comptime T: type, x: T, r: anytype) T {\n    if (@typeInfo(T) == .Vector) {\n        const C = @typeInfo(T).Vector.child;\n        if (C == u0) return 0;\n\n        if (@typeInfo(C).Int.signedness == .signed) {\n            @compileError(\"cannot rotate signed integers\");\n        }\n        const ar: Log2Int(C) = @intCast(@mod(r, @typeInfo(C).Int.bits));\n        return (x >> @splat(ar)) | (x << @splat(1 + ~ar));\n    } else if (@typeInfo(T).Int.signedness == .signed) {\n        @compileError(\"cannot rotate signed integer\");\n    } else {\n        if (T == u0) return 0;\n\n        if (comptime isPowerOfTwo(@typeInfo(T).Int.bits)) {\n            const ar: Log2Int(T) = @intCast(@mod(r, @typeInfo(T).Int.bits));\n            return x >> ar | x << (1 +% ~ar);\n        } else {\n            const ar = @mod(r, @typeInfo(T).Int.bits);\n            return shr(T, x, ar) | shl(T, x, @typeInfo(T).Int.bits - ar);\n        }\n    }\n}\n\ntest rotr {\n    if (builtin.zig_backend == .stage2_llvm and builtin.cpu.arch == .aarch64) {\n        // https://github.com/ziglang/zig/issues/12012\n        return error.SkipZigTest;\n    }\n\n    try testing.expect(rotr(u0, 0b0, @as(usize, 3)) == 0b0);\n    try testing.expect(rotr(u5, 0b00001, @as(usize, 0)) == 0b00001);\n    try testing.expect(rotr(u6, 0b000001, @as(usize, 7)) == 0b100000);\n    try testing.expect(rotr(u8, 0b00000001, @as(usize, 0)) == 0b00000001);\n    try testing.expect(rotr(u8, 0b00000001, @as(usize, 9)) == 0b10000000);\n    try testing.expect(rotr(u8, 0b00000001, @as(usize, 8)) == 0b00000001);\n    try testing.expect(rotr(u8, 0b00000001, @as(usize, 4)) == 0b00010000);\n    try testing.expect(rotr(u8, 0b00000001, @as(isize, -1)) == 0b00000010);\n    try testing.expect(rotr(u12, 0o7777, 1) == 0o7777);\n    try testing.expect(rotr(@Vector(1, u32), @Vector(1, u32){1}, @as(usize, 1))[0] == @as(u32, 1) << 31);\n    try testing.expect(rotr(@Vector(1, u32), @Vector(1, u32){1}, @as(isize, -1))[0] == @as(u32, 1) << 1);\n}\n\n/// Rotates left. Only unsigned values can be rotated.  Negative shift\n/// values result in shift modulo the bit count.\npub fn rotl(comptime T: type, x: T, r: anytype) T {\n    if (@typeInfo(T) == .Vector) {\n        const C = @typeInfo(T).Vector.child;\n        if (C == u0) return 0;\n\n        if (@typeInfo(C).Int.signedness == .signed) {\n            @compileError(\"cannot rotate signed integers\");\n        }\n        const ar: Log2Int(C) = @intCast(@mod(r, @typeInfo(C).Int.bits));\n        return (x << @splat(ar)) | (x >> @splat(1 +% ~ar));\n    } else if (@typeInfo(T).Int.signedness == .signed) {\n        @compileError(\"cannot rotate signed integer\");\n    } else {\n        if (T == u0) return 0;\n\n        if (comptime isPowerOfTwo(@typeInfo(T).Int.bits)) {\n            const ar: Log2Int(T) = @intCast(@mod(r, @typeInfo(T).Int.bits));\n            return x << ar | x >> 1 +% ~ar;\n        } else {\n            const ar = @mod(r, @typeInfo(T).Int.bits);\n            return shl(T, x, ar) | shr(T, x, @typeInfo(T).Int.bits - ar);\n        }\n    }\n}\n\ntest rotl {\n    if (builtin.zig_backend == .stage2_llvm and builtin.cpu.arch == .aarch64) {\n        // https://github.com/ziglang/zig/issues/12012\n        return error.SkipZigTest;\n    }\n\n    try testing.expect(rotl(u0, 0b0, @as(usize, 3)) == 0b0);\n    try testing.expect(rotl(u5, 0b00001, @as(usize, 0)) == 0b00001);\n    try testing.expect(rotl(u6, 0b000001, @as(usize, 7)) == 0b000010);\n    try testing.expect(rotl(u8, 0b00000001, @as(usize, 0)) == 0b00000001);\n    try testing.expect(rotl(u8, 0b00000001, @as(usize, 9)) == 0b00000010);\n    try testing.expect(rotl(u8, 0b00000001, @as(usize, 8)) == 0b00000001);\n    try testing.expect(rotl(u8, 0b00000001, @as(usize, 4)) == 0b00010000);\n    try testing.expect(rotl(u8, 0b00000001, @as(isize, -1)) == 0b10000000);\n    try testing.expect(rotl(u12, 0o7777, 1) == 0o7777);\n    try testing.expect(rotl(@Vector(1, u32), @Vector(1, u32){1 << 31}, @as(usize, 1))[0] == 1);\n    try testing.expect(rotl(@Vector(1, u32), @Vector(1, u32){1 << 31}, @as(isize, -1))[0] == @as(u32, 1) << 30);\n}\n\n/// Returns an unsigned int type that can hold the number of bits in T\n/// - 1. Suitable for 0-based bit indices of T.\npub fn Log2Int(comptime T: type) type {\n    // comptime ceil log2\n    if (T == comptime_int) return comptime_int;\n    comptime var count = 0;\n    comptime var s = @typeInfo(T).Int.bits - 1;\n    inline while (s != 0) : (s >>= 1) {\n        count += 1;\n    }\n\n    return std.meta.Int(.unsigned, count);\n}\n\n/// Returns an unsigned int type that can hold the number of bits in T.\npub fn Log2IntCeil(comptime T: type) type {\n    // comptime ceil log2\n    if (T == comptime_int) return comptime_int;\n    comptime var count = 0;\n    comptime var s = @typeInfo(T).Int.bits;\n    inline while (s != 0) : (s >>= 1) {\n        count += 1;\n    }\n\n    return std.meta.Int(.unsigned, count);\n}\n\n/// Returns the smallest integer type that can hold both from and to.\npub fn IntFittingRange(comptime from: comptime_int, comptime to: comptime_int) type {\n    assert(from <= to);\n    if (from == 0 and to == 0) {\n        return u0;\n    }\n    const signedness: std.builtin.Signedness = if (from < 0) .signed else .unsigned;\n    const largest_positive_integer = @max(if (from < 0) (-from) - 1 else from, to); // two's complement\n    const base = log2(largest_positive_integer);\n    const upper = (1 << base) - 1;\n    var magnitude_bits = if (upper >= largest_positive_integer) base else base + 1;\n    if (signedness == .signed) {\n        magnitude_bits += 1;\n    }\n    return std.meta.Int(signedness, magnitude_bits);\n}\n\ntest IntFittingRange {\n    try testing.expect(IntFittingRange(0, 0) == u0);\n    try testing.expect(IntFittingRange(0, 1) == u1);\n    try testing.expect(IntFittingRange(0, 2) == u2);\n    try testing.expect(IntFittingRange(0, 3) == u2);\n    try testing.expect(IntFittingRange(0, 4) == u3);\n    try testing.expect(IntFittingRange(0, 7) == u3);\n    try testing.expect(IntFittingRange(0, 8) == u4);\n    try testing.expect(IntFittingRange(0, 9) == u4);\n    try testing.expect(IntFittingRange(0, 15) == u4);\n    try testing.expect(IntFittingRange(0, 16) == u5);\n    try testing.expect(IntFittingRange(0, 17) == u5);\n    try testing.expect(IntFittingRange(0, 4095) == u12);\n    try testing.expect(IntFittingRange(2000, 4095) == u12);\n    try testing.expect(IntFittingRange(0, 4096) == u13);\n    try testing.expect(IntFittingRange(2000, 4096) == u13);\n    try testing.expect(IntFittingRange(0, 4097) == u13);\n    try testing.expect(IntFittingRange(2000, 4097) == u13);\n    try testing.expect(IntFittingRange(0, 123456789123456798123456789) == u87);\n    try testing.expect(IntFittingRange(0, 123456789123456798123456789123456789123456798123456789) == u177);\n\n    try testing.expect(IntFittingRange(-1, -1) == i1);\n    try testing.expect(IntFittingRange(-1, 0) == i1);\n    try testing.expect(IntFittingRange(-1, 1) == i2);\n    try testing.expect(IntFittingRange(-2, -2) == i2);\n    try testing.expect(IntFittingRange(-2, -1) == i2);\n    try testing.expect(IntFittingRange(-2, 0) == i2);\n    try testing.expect(IntFittingRange(-2, 1) == i2);\n    try testing.expect(IntFittingRange(-2, 2) == i3);\n    try testing.expect(IntFittingRange(-1, 2) == i3);\n    try testing.expect(IntFittingRange(-1, 3) == i3);\n    try testing.expect(IntFittingRange(-1, 4) == i4);\n    try testing.expect(IntFittingRange(-1, 7) == i4);\n    try testing.expect(IntFittingRange(-1, 8) == i5);\n    try testing.expect(IntFittingRange(-1, 9) == i5);\n    try testing.expect(IntFittingRange(-1, 15) == i5);\n    try testing.expect(IntFittingRange(-1, 16) == i6);\n    try testing.expect(IntFittingRange(-1, 17) == i6);\n    try testing.expect(IntFittingRange(-1, 4095) == i13);\n    try testing.expect(IntFittingRange(-4096, 4095) == i13);\n    try testing.expect(IntFittingRange(-1, 4096) == i14);\n    try testing.expect(IntFittingRange(-4097, 4095) == i14);\n    try testing.expect(IntFittingRange(-1, 4097) == i14);\n    try testing.expect(IntFittingRange(-1, 123456789123456798123456789) == i88);\n    try testing.expect(IntFittingRange(-1, 123456789123456798123456789123456789123456798123456789) == i178);\n}\n\ntest \"overflow functions\" {\n    try testOverflow();\n    try comptime testOverflow();\n}\n\nfn testOverflow() !void {\n    try testing.expect((mul(i32, 3, 4) catch unreachable) == 12);\n    try testing.expect((add(i32, 3, 4) catch unreachable) == 7);\n    try testing.expect((sub(i32, 3, 4) catch unreachable) == -1);\n    try testing.expect((shlExact(i32, 0b11, 4) catch unreachable) == 0b110000);\n}\n\n/// Divide numerator by denominator, rounding toward zero. Returns an\n/// error on overflow or when denominator is zero.\npub fn divTrunc(comptime T: type, numerator: T, denominator: T) !T {\n    @setRuntimeSafety(false);\n    if (denominator == 0) return error.DivisionByZero;\n    if (@typeInfo(T) == .Int and @typeInfo(T).Int.signedness == .signed and numerator == minInt(T) and denominator == -1) return error.Overflow;\n    return @divTrunc(numerator, denominator);\n}\n\ntest divTrunc {\n    try testDivTrunc();\n    try comptime testDivTrunc();\n}\nfn testDivTrunc() !void {\n    try testing.expect((divTrunc(i32, 5, 3) catch unreachable) == 1);\n    try testing.expect((divTrunc(i32, -5, 3) catch unreachable) == -1);\n    try testing.expectError(error.DivisionByZero, divTrunc(i8, -5, 0));\n    try testing.expectError(error.Overflow, divTrunc(i8, -128, -1));\n\n    try testing.expect((divTrunc(f32, 5.0, 3.0) catch unreachable) == 1.0);\n    try testing.expect((divTrunc(f32, -5.0, 3.0) catch unreachable) == -1.0);\n}\n\n/// Divide numerator by denominator, rounding toward negative\n/// infinity. Returns an error on overflow or when denominator is\n/// zero.\npub fn divFloor(comptime T: type, numerator: T, denominator: T) !T {\n    @setRuntimeSafety(false);\n    if (denominator == 0) return error.DivisionByZero;\n    if (@typeInfo(T) == .Int and @typeInfo(T).Int.signedness == .signed and numerator == minInt(T) and denominator == -1) return error.Overflow;\n    return @divFloor(numerator, denominator);\n}\n\ntest divFloor {\n    try testDivFloor();\n    try comptime testDivFloor();\n}\nfn testDivFloor() !void {\n    try testing.expect((divFloor(i32, 5, 3) catch unreachable) == 1);\n    try testing.expect((divFloor(i32, -5, 3) catch unreachable) == -2);\n    try testing.expectError(error.DivisionByZero, divFloor(i8, -5, 0));\n    try testing.expectError(error.Overflow, divFloor(i8, -128, -1));\n\n    try testing.expect((divFloor(f32, 5.0, 3.0) catch unreachable) == 1.0);\n    try testing.expect((divFloor(f32, -5.0, 3.0) catch unreachable) == -2.0);\n}\n\n/// Divide numerator by denominator, rounding toward positive\n/// infinity. Returns an error on overflow or when denominator is\n/// zero.\npub fn divCeil(comptime T: type, numerator: T, denominator: T) !T {\n    @setRuntimeSafety(false);\n    if (denominator == 0) return error.DivisionByZero;\n    const info = @typeInfo(T);\n    switch (info) {\n        .ComptimeFloat, .Float => return @ceil(numerator / denominator),\n        .ComptimeInt, .Int => {\n            if (numerator < 0 and denominator < 0) {\n                if (info == .Int and numerator == minInt(T) and denominator == -1)\n                    return error.Overflow;\n                return @divFloor(numerator + 1, denominator) + 1;\n            }\n            if (numerator > 0 and denominator > 0)\n                return @divFloor(numerator - 1, denominator) + 1;\n            return @divTrunc(numerator, denominator);\n        },\n        else => @compileError(\"divCeil unsupported on \" ++ @typeName(T)),\n    }\n}\n\ntest divCeil {\n    try testDivCeil();\n    try comptime testDivCeil();\n}\nfn testDivCeil() !void {\n    try testing.expectEqual(@as(i32, 2), divCeil(i32, 5, 3) catch unreachable);\n    try testing.expectEqual(@as(i32, -1), divCeil(i32, -5, 3) catch unreachable);\n    try testing.expectEqual(@as(i32, -1), divCeil(i32, 5, -3) catch unreachable);\n    try testing.expectEqual(@as(i32, 2), divCeil(i32, -5, -3) catch unreachable);\n    try testing.expectEqual(@as(i32, 0), divCeil(i32, 0, 5) catch unreachable);\n    try testing.expectEqual(@as(u32, 0), divCeil(u32, 0, 5) catch unreachable);\n    try testing.expectError(error.DivisionByZero, divCeil(i8, -5, 0));\n    try testing.expectError(error.Overflow, divCeil(i8, -128, -1));\n\n    try testing.expectEqual(@as(f32, 0.0), divCeil(f32, 0.0, 5.0) catch unreachable);\n    try testing.expectEqual(@as(f32, 2.0), divCeil(f32, 5.0, 3.0) catch unreachable);\n    try testing.expectEqual(@as(f32, -1.0), divCeil(f32, -5.0, 3.0) catch unreachable);\n    try testing.expectEqual(@as(f32, -1.0), divCeil(f32, 5.0, -3.0) catch unreachable);\n    try testing.expectEqual(@as(f32, 2.0), divCeil(f32, -5.0, -3.0) catch unreachable);\n\n    try testing.expectEqual(6, divCeil(comptime_int, 23, 4) catch unreachable);\n    try testing.expectEqual(-5, divCeil(comptime_int, -23, 4) catch unreachable);\n    try testing.expectEqual(-5, divCeil(comptime_int, 23, -4) catch unreachable);\n    try testing.expectEqual(6, divCeil(comptime_int, -23, -4) catch unreachable);\n    try testing.expectError(error.DivisionByZero, divCeil(comptime_int, 23, 0));\n\n    try testing.expectEqual(6.0, divCeil(comptime_float, 23.0, 4.0) catch unreachable);\n    try testing.expectEqual(-5.0, divCeil(comptime_float, -23.0, 4.0) catch unreachable);\n    try testing.expectEqual(-5.0, divCeil(comptime_float, 23.0, -4.0) catch unreachable);\n    try testing.expectEqual(6.0, divCeil(comptime_float, -23.0, -4.0) catch unreachable);\n    try testing.expectError(error.DivisionByZero, divCeil(comptime_float, 23.0, 0.0));\n}\n\n/// Divide numerator by denominator. Return an error if quotient is\n/// not an integer, denominator is zero, or on overflow.\npub fn divExact(comptime T: type, numerator: T, denominator: T) !T {\n    @setRuntimeSafety(false);\n    if (denominator == 0) return error.DivisionByZero;\n    if (@typeInfo(T) == .Int and @typeInfo(T).Int.signedness == .signed and numerator == minInt(T) and denominator == -1) return error.Overflow;\n    const result = @divTrunc(numerator, denominator);\n    if (result * denominator != numerator) return error.UnexpectedRemainder;\n    return result;\n}\n\ntest divExact {\n    try testDivExact();\n    try comptime testDivExact();\n}\nfn testDivExact() !void {\n    try testing.expect((divExact(i32, 10, 5) catch unreachable) == 2);\n    try testing.expect((divExact(i32, -10, 5) catch unreachable) == -2);\n    try testing.expectError(error.DivisionByZero, divExact(i8, -5, 0));\n    try testing.expectError(error.Overflow, divExact(i8, -128, -1));\n    try testing.expectError(error.UnexpectedRemainder, divExact(i32, 5, 2));\n\n    try testing.expect((divExact(f32, 10.0, 5.0) catch unreachable) == 2.0);\n    try testing.expect((divExact(f32, -10.0, 5.0) catch unreachable) == -2.0);\n    try testing.expectError(error.UnexpectedRemainder, divExact(f32, 5.0, 2.0));\n}\n\n/// Returns numerator modulo denominator, or an error if denominator is\n/// zero or negative. Negative numerators never result in negative\n/// return values.\npub fn mod(comptime T: type, numerator: T, denominator: T) !T {\n    @setRuntimeSafety(false);\n    if (denominator == 0) return error.DivisionByZero;\n    if (denominator < 0) return error.NegativeDenominator;\n    return @mod(numerator, denominator);\n}\n\ntest mod {\n    try testMod();\n    try comptime testMod();\n}\nfn testMod() !void {\n    try testing.expect((mod(i32, -5, 3) catch unreachable) == 1);\n    try testing.expect((mod(i32, 5, 3) catch unreachable) == 2);\n    try testing.expectError(error.NegativeDenominator, mod(i32, 10, -1));\n    try testing.expectError(error.DivisionByZero, mod(i32, 10, 0));\n\n    try testing.expect((mod(f32, -5, 3) catch unreachable) == 1);\n    try testing.expect((mod(f32, 5, 3) catch unreachable) == 2);\n    try testing.expectError(error.NegativeDenominator, mod(f32, 10, -1));\n    try testing.expectError(error.DivisionByZero, mod(f32, 10, 0));\n}\n\n/// Returns the remainder when numerator is divided by denominator, or\n/// an error if denominator is zero or negative. Negative numerators\n/// can give negative results.\npub fn rem(comptime T: type, numerator: T, denominator: T) !T {\n    @setRuntimeSafety(false);\n    if (denominator == 0) return error.DivisionByZero;\n    if (denominator < 0) return error.NegativeDenominator;\n    return @rem(numerator, denominator);\n}\n\ntest rem {\n    try testRem();\n    try comptime testRem();\n}\nfn testRem() !void {\n    try testing.expect((rem(i32, -5, 3) catch unreachable) == -2);\n    try testing.expect((rem(i32, 5, 3) catch unreachable) == 2);\n    try testing.expectError(error.NegativeDenominator, rem(i32, 10, -1));\n    try testing.expectError(error.DivisionByZero, rem(i32, 10, 0));\n\n    try testing.expect((rem(f32, -5, 3) catch unreachable) == -2);\n    try testing.expect((rem(f32, 5, 3) catch unreachable) == 2);\n    try testing.expectError(error.NegativeDenominator, rem(f32, 10, -1));\n    try testing.expectError(error.DivisionByZero, rem(f32, 10, 0));\n}\n\n/// Returns the negation of the integer parameter.\n/// Result is a signed integer.\npub fn negateCast(x: anytype) !std.meta.Int(.signed, @bitSizeOf(@TypeOf(x))) {\n    if (@typeInfo(@TypeOf(x)).Int.signedness == .signed) return negate(x);\n\n    const int = std.meta.Int(.signed, @bitSizeOf(@TypeOf(x)));\n    if (x > -minInt(int)) return error.Overflow;\n\n    if (x == -minInt(int)) return minInt(int);\n\n    return -@as(int, @intCast(x));\n}\n\ntest negateCast {\n    try testing.expect((negateCast(@as(u32, 999)) catch unreachable) == -999);\n    try testing.expect(@TypeOf(negateCast(@as(u32, 999)) catch unreachable) == i32);\n\n    try testing.expect((negateCast(@as(u32, -minInt(i32))) catch unreachable) == minInt(i32));\n    try testing.expect(@TypeOf(negateCast(@as(u32, -minInt(i32))) catch unreachable) == i32);\n\n    try testing.expectError(error.Overflow, negateCast(@as(u32, maxInt(i32) + 10)));\n}\n\n/// Cast an integer to a different integer type. If the value doesn't fit,\n/// return null.\npub fn cast(comptime T: type, x: anytype) ?T {\n    comptime assert(@typeInfo(T) == .Int); // must pass an integer\n    const is_comptime = @TypeOf(x) == comptime_int;\n    comptime assert(is_comptime or @typeInfo(@TypeOf(x)) == .Int); // must pass an integer\n    if ((is_comptime or maxInt(@TypeOf(x)) > maxInt(T)) and x > maxInt(T)) {\n        return null;\n    } else if ((is_comptime or minInt(@TypeOf(x)) < minInt(T)) and x < minInt(T)) {\n        return null;\n    } else {\n        return @as(T, @intCast(x));\n    }\n}\n\ntest cast {\n    try testing.expect(cast(u8, 300) == null);\n    try testing.expect(cast(u8, @as(u32, 300)) == null);\n    try testing.expect(cast(i8, -200) == null);\n    try testing.expect(cast(i8, @as(i32, -200)) == null);\n    try testing.expect(cast(u8, -1) == null);\n    try testing.expect(cast(u8, @as(i8, -1)) == null);\n    try testing.expect(cast(u64, -1) == null);\n    try testing.expect(cast(u64, @as(i8, -1)) == null);\n\n    try testing.expect(cast(u8, 255).? == @as(u8, 255));\n    try testing.expect(cast(u8, @as(u32, 255)).? == @as(u8, 255));\n    try testing.expect(@TypeOf(cast(u8, 255).?) == u8);\n    try testing.expect(@TypeOf(cast(u8, @as(u32, 255)).?) == u8);\n}\n\npub const AlignCastError = error{UnalignedMemory};\n\nfn AlignCastResult(comptime alignment: u29, comptime Ptr: type) type {\n    var ptr_info = @typeInfo(Ptr);\n    ptr_info.Pointer.alignment = alignment;\n    return @Type(ptr_info);\n}\n\n/// Align cast a pointer but return an error if it's the wrong alignment\npub fn alignCast(comptime alignment: u29, ptr: anytype) AlignCastError!AlignCastResult(alignment, @TypeOf(ptr)) {\n    const addr = @intFromPtr(ptr);\n    if (addr % alignment != 0) {\n        return error.UnalignedMemory;\n    }\n    return @alignCast(ptr);\n}\n\n/// Asserts `int > 0`.\npub fn isPowerOfTwo(int: anytype) bool {\n    assert(int > 0);\n    return (int & (int - 1)) == 0;\n}\n\ntest isPowerOfTwo {\n    try testing.expect(isPowerOfTwo(@as(u8, 1)));\n    try testing.expect(isPowerOfTwo(2));\n    try testing.expect(!isPowerOfTwo(@as(i16, 3)));\n    try testing.expect(isPowerOfTwo(4));\n    try testing.expect(!isPowerOfTwo(@as(u32, 31)));\n    try testing.expect(isPowerOfTwo(32));\n    try testing.expect(!isPowerOfTwo(@as(i64, 63)));\n    try testing.expect(isPowerOfTwo(128));\n    try testing.expect(isPowerOfTwo(@as(u128, 256)));\n}\n\n/// Aligns the given integer type bit width to a width divisible by 8.\npub fn ByteAlignedInt(comptime T: type) type {\n    const info = @typeInfo(T).Int;\n    const bits = (info.bits + 7) / 8 * 8;\n    const extended_type = std.meta.Int(info.signedness, bits);\n    return extended_type;\n}\n\ntest ByteAlignedInt {\n    try testing.expect(ByteAlignedInt(u0) == u0);\n    try testing.expect(ByteAlignedInt(i0) == i0);\n    try testing.expect(ByteAlignedInt(u3) == u8);\n    try testing.expect(ByteAlignedInt(u8) == u8);\n    try testing.expect(ByteAlignedInt(i111) == i112);\n    try testing.expect(ByteAlignedInt(u129) == u136);\n}\n\n/// Rounds the given floating point number to an integer, away from zero.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @round\npub inline fn round(value: anytype) @TypeOf(value) {\n    return @round(value);\n}\n\n/// Rounds the given floating point number to an integer, towards zero.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @trunc\npub inline fn trunc(value: anytype) @TypeOf(value) {\n    return @trunc(value);\n}\n\n/// Returns the largest integral value not greater than the given floating point number.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @floor\npub inline fn floor(value: anytype) @TypeOf(value) {\n    return @floor(value);\n}\n\n/// Returns the nearest power of two less than or equal to value, or\n/// zero if value is less than or equal to zero.\npub fn floorPowerOfTwo(comptime T: type, value: T) T {\n    const uT = std.meta.Int(.unsigned, @typeInfo(T).Int.bits);\n    if (value <= 0) return 0;\n    return @as(T, 1) << log2_int(uT, @as(uT, @intCast(value)));\n}\n\ntest floorPowerOfTwo {\n    try testFloorPowerOfTwo();\n    try comptime testFloorPowerOfTwo();\n}\n\nfn testFloorPowerOfTwo() !void {\n    try testing.expect(floorPowerOfTwo(u32, 63) == 32);\n    try testing.expect(floorPowerOfTwo(u32, 64) == 64);\n    try testing.expect(floorPowerOfTwo(u32, 65) == 64);\n    try testing.expect(floorPowerOfTwo(u32, 0) == 0);\n    try testing.expect(floorPowerOfTwo(u4, 7) == 4);\n    try testing.expect(floorPowerOfTwo(u4, 8) == 8);\n    try testing.expect(floorPowerOfTwo(u4, 9) == 8);\n    try testing.expect(floorPowerOfTwo(u4, 0) == 0);\n    try testing.expect(floorPowerOfTwo(i4, 7) == 4);\n    try testing.expect(floorPowerOfTwo(i4, -8) == 0);\n    try testing.expect(floorPowerOfTwo(i4, -1) == 0);\n    try testing.expect(floorPowerOfTwo(i4, 0) == 0);\n}\n\n/// Returns the smallest integral value not less than the given floating point number.\n/// Uses a dedicated hardware instruction when available.\n/// This is the same as calling the builtin @ceil\npub inline fn ceil(value: anytype) @TypeOf(value) {\n    return @ceil(value);\n}\n\n/// Returns the next power of two (if the value is not already a power of two).\n/// Only unsigned integers can be used. Zero is not an allowed input.\n/// Result is a type with 1 more bit than the input type.\npub fn ceilPowerOfTwoPromote(comptime T: type, value: T) std.meta.Int(@typeInfo(T).Int.signedness, @typeInfo(T).Int.bits + 1) {\n    comptime assert(@typeInfo(T) == .Int);\n    comptime assert(@typeInfo(T).Int.signedness == .unsigned);\n    assert(value != 0);\n    const PromotedType = std.meta.Int(@typeInfo(T).Int.signedness, @typeInfo(T).Int.bits + 1);\n    const ShiftType = std.math.Log2Int(PromotedType);\n    return @as(PromotedType, 1) << @as(ShiftType, @intCast(@typeInfo(T).Int.bits - @clz(value - 1)));\n}\n\n/// Returns the next power of two (if the value is not already a power of two).\n/// Only unsigned integers can be used. Zero is not an allowed input.\n/// If the value doesn't fit, returns an error.\npub fn ceilPowerOfTwo(comptime T: type, value: T) (error{Overflow}!T) {\n    comptime assert(@typeInfo(T) == .Int);\n    const info = @typeInfo(T).Int;\n    comptime assert(info.signedness == .unsigned);\n    const PromotedType = std.meta.Int(info.signedness, info.bits + 1);\n    const overflowBit = @as(PromotedType, 1) << info.bits;\n    const x = ceilPowerOfTwoPromote(T, value);\n    if (overflowBit & x != 0) {\n        return error.Overflow;\n    }\n    return @as(T, @intCast(x));\n}\n\n/// Returns the next power of two (if the value is not already a power\n/// of two). Only unsigned integers can be used. Zero is not an\n/// allowed input. Asserts that the value fits.\npub fn ceilPowerOfTwoAssert(comptime T: type, value: T) T {\n    return ceilPowerOfTwo(T, value) catch unreachable;\n}\n\ntest ceilPowerOfTwoPromote {\n    try testCeilPowerOfTwoPromote();\n    try comptime testCeilPowerOfTwoPromote();\n}\n\nfn testCeilPowerOfTwoPromote() !void {\n    try testing.expectEqual(@as(u33, 1), ceilPowerOfTwoPromote(u32, 1));\n    try testing.expectEqual(@as(u33, 2), ceilPowerOfTwoPromote(u32, 2));\n    try testing.expectEqual(@as(u33, 64), ceilPowerOfTwoPromote(u32, 63));\n    try testing.expectEqual(@as(u33, 64), ceilPowerOfTwoPromote(u32, 64));\n    try testing.expectEqual(@as(u33, 128), ceilPowerOfTwoPromote(u32, 65));\n    try testing.expectEqual(@as(u6, 8), ceilPowerOfTwoPromote(u5, 7));\n    try testing.expectEqual(@as(u6, 8), ceilPowerOfTwoPromote(u5, 8));\n    try testing.expectEqual(@as(u6, 16), ceilPowerOfTwoPromote(u5, 9));\n    try testing.expectEqual(@as(u5, 16), ceilPowerOfTwoPromote(u4, 9));\n}\n\ntest ceilPowerOfTwo {\n    try testCeilPowerOfTwo();\n    try comptime testCeilPowerOfTwo();\n}\n\nfn testCeilPowerOfTwo() !void {\n    try testing.expectEqual(@as(u32, 1), try ceilPowerOfTwo(u32, 1));\n    try testing.expectEqual(@as(u32, 2), try ceilPowerOfTwo(u32, 2));\n    try testing.expectEqual(@as(u32, 64), try ceilPowerOfTwo(u32, 63));\n    try testing.expectEqual(@as(u32, 64), try ceilPowerOfTwo(u32, 64));\n    try testing.expectEqual(@as(u32, 128), try ceilPowerOfTwo(u32, 65));\n    try testing.expectEqual(@as(u5, 8), try ceilPowerOfTwo(u5, 7));\n    try testing.expectEqual(@as(u5, 8), try ceilPowerOfTwo(u5, 8));\n    try testing.expectEqual(@as(u5, 16), try ceilPowerOfTwo(u5, 9));\n    try testing.expectError(error.Overflow, ceilPowerOfTwo(u4, 9));\n}\n\n/// Return the log base 2 of integer value x, rounding down to the\n/// nearest integer.\npub fn log2_int(comptime T: type, x: T) Log2Int(T) {\n    if (@typeInfo(T) != .Int or @typeInfo(T).Int.signedness != .unsigned)\n        @compileError(\"log2_int requires an unsigned integer, found \" ++ @typeName(T));\n    assert(x != 0);\n    return @as(Log2Int(T), @intCast(@typeInfo(T).Int.bits - 1 - @clz(x)));\n}\n\n/// Return the log base 2 of integer value x, rounding up to the\n/// nearest integer.\npub fn log2_int_ceil(comptime T: type, x: T) Log2IntCeil(T) {\n    if (@typeInfo(T) != .Int or @typeInfo(T).Int.signedness != .unsigned)\n        @compileError(\"log2_int_ceil requires an unsigned integer, found \" ++ @typeName(T));\n    assert(x != 0);\n    if (x == 1) return 0;\n    const log2_val: Log2IntCeil(T) = log2_int(T, x - 1);\n    return log2_val + 1;\n}\n\ntest log2_int_ceil {\n    try testing.expect(log2_int_ceil(u32, 1) == 0);\n    try testing.expect(log2_int_ceil(u32, 2) == 1);\n    try testing.expect(log2_int_ceil(u32, 3) == 2);\n    try testing.expect(log2_int_ceil(u32, 4) == 2);\n    try testing.expect(log2_int_ceil(u32, 5) == 3);\n    try testing.expect(log2_int_ceil(u32, 6) == 3);\n    try testing.expect(log2_int_ceil(u32, 7) == 3);\n    try testing.expect(log2_int_ceil(u32, 8) == 3);\n    try testing.expect(log2_int_ceil(u32, 9) == 4);\n    try testing.expect(log2_int_ceil(u32, 10) == 4);\n}\n\n/// Cast a value to a different type. If the value doesn't fit in, or\n/// can't be perfectly represented by, the new type, it will be\n/// converted to the closest possible representation.\npub fn lossyCast(comptime T: type, value: anytype) T {\n    switch (@typeInfo(T)) {\n        .Float => {\n            switch (@typeInfo(@TypeOf(value))) {\n                .Int => return @as(T, @floatFromInt(value)),\n                .Float => return @as(T, @floatCast(value)),\n                .ComptimeInt => return @as(T, value),\n                .ComptimeFloat => return @as(T, value),\n                else => @compileError(\"bad type\"),\n            }\n        },\n        .Int => {\n            switch (@typeInfo(@TypeOf(value))) {\n                .Int, .ComptimeInt => {\n                    if (value >= maxInt(T)) {\n                        return @as(T, maxInt(T));\n                    } else if (value <= minInt(T)) {\n                        return @as(T, minInt(T));\n                    } else {\n                        return @as(T, @intCast(value));\n                    }\n                },\n                .Float, .ComptimeFloat => {\n                    if (isNan(value)) {\n                        return 0;\n                    } else if (value >= maxInt(T)) {\n                        return @as(T, maxInt(T));\n                    } else if (value <= minInt(T)) {\n                        return @as(T, minInt(T));\n                    } else {\n                        return @as(T, @intFromFloat(value));\n                    }\n                },\n                else => @compileError(\"bad type\"),\n            }\n        },\n        else => @compileError(\"bad result type\"),\n    }\n}\n\ntest lossyCast {\n    try testing.expect(lossyCast(i16, 70000.0) == @as(i16, 32767));\n    try testing.expect(lossyCast(u32, @as(i16, -255)) == @as(u32, 0));\n    try testing.expect(lossyCast(i9, @as(u32, 200)) == @as(i9, 200));\n    try testing.expect(lossyCast(u32, @as(f32, maxInt(u32))) == maxInt(u32));\n    try testing.expect(lossyCast(u32, nan(f32)) == 0);\n}\n\n/// Performs linear interpolation between *a* and *b* based on *t*.\n/// *t* ranges from 0.0 to 1.0, but may exceed these bounds.\n/// Supports floats and vectors of floats.\n///\n/// This does not guarantee returning *b* if *t* is 1 due to floating-point errors.\n/// This is monotonic.\npub fn lerp(a: anytype, b: anytype, t: anytype) @TypeOf(a, b, t) {\n    const Type = @TypeOf(a, b, t);\n    return @mulAdd(Type, b - a, t, a);\n}\n\ntest lerp {\n    if (builtin.zig_backend == .stage2_c) return error.SkipZigTest; // https://github.com/ziglang/zig/issues/17884\n    if (builtin.zig_backend == .stage2_x86_64 and\n        !comptime std.Target.x86.featureSetHas(builtin.cpu.features, .fma)) return error.SkipZigTest;\n\n    try testing.expectEqual(@as(f64, 75), lerp(50, 100, 0.5));\n    try testing.expectEqual(@as(f32, 43.75), lerp(50, 25, 0.25));\n    try testing.expectEqual(@as(f64, -31.25), lerp(-50, 25, 0.25));\n\n    try testing.expectEqual(@as(f64, 30), lerp(10, 20, 2.0));\n    try testing.expectEqual(@as(f64, 5), lerp(10, 20, -0.5));\n\n    try testing.expectApproxEqRel(@as(f32, -7.16067345e+03), lerp(-10000.12345, -5000.12345, 0.56789), 1e-19);\n    try testing.expectApproxEqRel(@as(f64, 7.010987590521e+62), lerp(0.123456789e-64, 0.123456789e64, 0.56789), 1e-33);\n\n    try testing.expectEqual(@as(f32, 0.0), lerp(@as(f32, 1.0e8), 1.0, 1.0));\n    try testing.expectEqual(@as(f64, 0.0), lerp(@as(f64, 1.0e16), 1.0, 1.0));\n    try testing.expectEqual(@as(f32, 1.0), lerp(@as(f32, 1.0e7), 1.0, 1.0));\n    try testing.expectEqual(@as(f64, 1.0), lerp(@as(f64, 1.0e15), 1.0, 1.0));\n\n    {\n        const a: @Vector(3, f32) = @splat(0);\n        const b: @Vector(3, f32) = @splat(50);\n        const t: @Vector(3, f32) = @splat(0.5);\n        try testing.expectEqual(\n            @Vector(3, f32){ 25, 25, 25 },\n            lerp(a, b, t),\n        );\n    }\n    {\n        const a: @Vector(3, f64) = @splat(50);\n        const b: @Vector(3, f64) = @splat(100);\n        const t: @Vector(3, f64) = @splat(0.5);\n        try testing.expectEqual(\n            @Vector(3, f64){ 75, 75, 75 },\n            lerp(a, b, t),\n        );\n    }\n    {\n        const a: @Vector(2, f32) = @splat(40);\n        const b: @Vector(2, f32) = @splat(80);\n        const t: @Vector(2, f32) = @Vector(2, f32){ 0.25, 0.75 };\n        try testing.expectEqual(\n            @Vector(2, f32){ 50, 70 },\n            lerp(a, b, t),\n        );\n    }\n}\n\n/// Returns the maximum value of integer type T.\npub fn maxInt(comptime T: type) comptime_int {\n    const info = @typeInfo(T);\n    const bit_count = info.Int.bits;\n    if (bit_count == 0) return 0;\n    return (1 << (bit_count - @intFromBool(info.Int.signedness == .signed))) - 1;\n}\n\n/// Returns the minimum value of integer type T.\npub fn minInt(comptime T: type) comptime_int {\n    const info = @typeInfo(T);\n    const bit_count = info.Int.bits;\n    if (info.Int.signedness == .unsigned) return 0;\n    if (bit_count == 0) return 0;\n    return -(1 << (bit_count - 1));\n}\n\ntest maxInt {\n    try testing.expect(maxInt(u0) == 0);\n    try testing.expect(maxInt(u1) == 1);\n    try testing.expect(maxInt(u8) == 255);\n    try testing.expect(maxInt(u16) == 65535);\n    try testing.expect(maxInt(u32) == 4294967295);\n    try testing.expect(maxInt(u64) == 18446744073709551615);\n    try testing.expect(maxInt(u128) == 340282366920938463463374607431768211455);\n\n    try testing.expect(maxInt(i0) == 0);\n    try testing.expect(maxInt(i1) == 0);\n    try testing.expect(maxInt(i8) == 127);\n    try testing.expect(maxInt(i16) == 32767);\n    try testing.expect(maxInt(i32) == 2147483647);\n    try testing.expect(maxInt(i63) == 4611686018427387903);\n    try testing.expect(maxInt(i64) == 9223372036854775807);\n    try testing.expect(maxInt(i128) == 170141183460469231731687303715884105727);\n}\n\ntest minInt {\n    try testing.expect(minInt(u0) == 0);\n    try testing.expect(minInt(u1) == 0);\n    try testing.expect(minInt(u8) == 0);\n    try testing.expect(minInt(u16) == 0);\n    try testing.expect(minInt(u32) == 0);\n    try testing.expect(minInt(u63) == 0);\n    try testing.expect(minInt(u64) == 0);\n    try testing.expect(minInt(u128) == 0);\n\n    try testing.expect(minInt(i0) == 0);\n    try testing.expect(minInt(i1) == -1);\n    try testing.expect(minInt(i8) == -128);\n    try testing.expect(minInt(i16) == -32768);\n    try testing.expect(minInt(i32) == -2147483648);\n    try testing.expect(minInt(i63) == -4611686018427387904);\n    try testing.expect(minInt(i64) == -9223372036854775808);\n    try testing.expect(minInt(i128) == -170141183460469231731687303715884105728);\n}\n\ntest \"max value type\" {\n    const x: u32 = maxInt(i32);\n    try testing.expect(x == 2147483647);\n}\n\n/// Multiply a and b. Return type is wide enough to guarantee no\n/// overflow.\npub fn mulWide(comptime T: type, a: T, b: T) std.meta.Int(\n    @typeInfo(T).Int.signedness,\n    @typeInfo(T).Int.bits * 2,\n) {\n    const ResultInt = std.meta.Int(\n        @typeInfo(T).Int.signedness,\n        @typeInfo(T).Int.bits * 2,\n    );\n    return @as(ResultInt, a) * @as(ResultInt, b);\n}\n\ntest mulWide {\n    try testing.expect(mulWide(u8, 5, 5) == 25);\n    try testing.expect(mulWide(i8, 5, -5) == -25);\n    try testing.expect(mulWide(u8, 100, 100) == 10000);\n}\n\n/// See also `CompareOperator`.\npub const Order = enum {\n    /// Greater than (`>`)\n    gt,\n\n    /// Less than (`<`)\n    lt,\n\n    /// Equal (`==`)\n    eq,\n\n    pub fn invert(self: Order) Order {\n        return switch (self) {\n            .lt => .gt,\n            .eq => .eq,\n            .gt => .lt,\n        };\n    }\n\n    test invert {\n        try testing.expect(Order.invert(order(0, 0)) == .eq);\n        try testing.expect(Order.invert(order(1, 0)) == .lt);\n        try testing.expect(Order.invert(order(-1, 0)) == .gt);\n    }\n\n    pub fn differ(self: Order) ?Order {\n        return if (self != .eq) self else null;\n    }\n\n    test differ {\n        const neg: i32 = -1;\n        const zero: i32 = 0;\n        const pos: i32 = 1;\n        try testing.expect(order(zero, neg).differ() orelse\n            order(pos, zero) == .gt);\n        try testing.expect(order(zero, zero).differ() orelse\n            order(zero, zero) == .eq);\n        try testing.expect(order(pos, pos).differ() orelse\n            order(neg, zero) == .lt);\n        try testing.expect(order(zero, zero).differ() orelse\n            order(pos, neg).differ() orelse\n            order(neg, zero) == .gt);\n        try testing.expect(order(pos, pos).differ() orelse\n            order(pos, pos).differ() orelse\n            order(neg, neg) == .eq);\n        try testing.expect(order(zero, pos).differ() orelse\n            order(neg, pos).differ() orelse\n            order(pos, neg) == .lt);\n    }\n\n    pub fn compare(self: Order, op: CompareOperator) bool {\n        return switch (self) {\n            .lt => switch (op) {\n                .lt => true,\n                .lte => true,\n                .eq => false,\n                .gte => false,\n                .gt => false,\n                .neq => true,\n            },\n            .eq => switch (op) {\n                .lt => false,\n                .lte => true,\n                .eq => true,\n                .gte => true,\n                .gt => false,\n                .neq => false,\n            },\n            .gt => switch (op) {\n                .lt => false,\n                .lte => false,\n                .eq => false,\n                .gte => true,\n                .gt => true,\n                .neq => true,\n            },\n        };\n    }\n\n    // https://github.com/ziglang/zig/issues/19295\n    test \"compare\" {\n        try testing.expect(order(-1, 0).compare(.lt));\n        try testing.expect(order(-1, 0).compare(.lte));\n        try testing.expect(order(0, 0).compare(.lte));\n        try testing.expect(order(0, 0).compare(.eq));\n        try testing.expect(order(0, 0).compare(.gte));\n        try testing.expect(order(1, 0).compare(.gte));\n        try testing.expect(order(1, 0).compare(.gt));\n        try testing.expect(order(1, 0).compare(.neq));\n    }\n};\n\n/// Given two numbers, this function returns the order they are with respect to each other.\npub fn order(a: anytype, b: anytype) Order {\n    if (a == b) {\n        return .eq;\n    } else if (a < b) {\n        return .lt;\n    } else if (a > b) {\n        return .gt;\n    } else {\n        unreachable;\n    }\n}\n\n/// See also `Order`.\npub const CompareOperator = enum {\n    /// Less than (`<`)\n    lt,\n    /// Less than or equal (`<=`)\n    lte,\n    /// Equal (`==`)\n    eq,\n    /// Greater than or equal (`>=`)\n    gte,\n    /// Greater than (`>`)\n    gt,\n    /// Not equal (`!=`)\n    neq,\n\n    /// Reverse the direction of the comparison.\n    /// Use when swapping the left and right hand operands.\n    pub fn reverse(op: CompareOperator) CompareOperator {\n        return switch (op) {\n            .lt => .gt,\n            .lte => .gte,\n            .gt => .lt,\n            .gte => .lte,\n            .eq => .eq,\n            .neq => .neq,\n        };\n    }\n\n    test reverse {\n        inline for (@typeInfo(CompareOperator).Enum.fields) |op_field| {\n            const op = @as(CompareOperator, @enumFromInt(op_field.value));\n            try testing.expect(compare(2, op, 3) == compare(3, op.reverse(), 2));\n            try testing.expect(compare(3, op, 3) == compare(3, op.reverse(), 3));\n            try testing.expect(compare(4, op, 3) == compare(3, op.reverse(), 4));\n        }\n    }\n};\n\n/// This function does the same thing as comparison operators, however the\n/// operator is a runtime-known enum value. Works on any operands that\n/// support comparison operators.\npub fn compare(a: anytype, op: CompareOperator, b: anytype) bool {\n    return switch (op) {\n        .lt => a < b,\n        .lte => a <= b,\n        .eq => a == b,\n        .neq => a != b,\n        .gt => a > b,\n        .gte => a >= b,\n    };\n}\n\ntest compare {\n    try testing.expect(compare(@as(i8, -1), .lt, @as(u8, 255)));\n    try testing.expect(compare(@as(i8, 2), .gt, @as(u8, 1)));\n    try testing.expect(!compare(@as(i8, -1), .gte, @as(u8, 255)));\n    try testing.expect(compare(@as(u8, 255), .gt, @as(i8, -1)));\n    try testing.expect(!compare(@as(u8, 255), .lte, @as(i8, -1)));\n    try testing.expect(compare(@as(i8, -1), .lt, @as(u9, 255)));\n    try testing.expect(!compare(@as(i8, -1), .gte, @as(u9, 255)));\n    try testing.expect(compare(@as(u9, 255), .gt, @as(i8, -1)));\n    try testing.expect(!compare(@as(u9, 255), .lte, @as(i8, -1)));\n    try testing.expect(compare(@as(i9, -1), .lt, @as(u8, 255)));\n    try testing.expect(!compare(@as(i9, -1), .gte, @as(u8, 255)));\n    try testing.expect(compare(@as(u8, 255), .gt, @as(i9, -1)));\n    try testing.expect(!compare(@as(u8, 255), .lte, @as(i9, -1)));\n    try testing.expect(compare(@as(u8, 1), .lt, @as(u8, 2)));\n    try testing.expect(@as(u8, @bitCast(@as(i8, -1))) == @as(u8, 255));\n    try testing.expect(!compare(@as(u8, 255), .eq, @as(i8, -1)));\n    try testing.expect(compare(@as(u8, 1), .eq, @as(u8, 1)));\n}\n\ntest order {\n    try testing.expect(order(0, 0) == .eq);\n    try testing.expect(order(1, 0) == .gt);\n    try testing.expect(order(-1, 0) == .lt);\n}\n\n/// Returns a mask of all ones if value is true,\n/// and a mask of all zeroes if value is false.\n/// Compiles to one instruction for register sized integers.\npub inline fn boolMask(comptime MaskInt: type, value: bool) MaskInt {\n    if (@typeInfo(MaskInt) != .Int)\n        @compileError(\"boolMask requires an integer mask type.\");\n\n    if (MaskInt == u0 or MaskInt == i0)\n        @compileError(\"boolMask cannot convert to u0 or i0, they are too small.\");\n\n    // The u1 and i1 cases tend to overflow,\n    // so we special case them here.\n    if (MaskInt == u1) return @intFromBool(value);\n    if (MaskInt == i1) {\n        // The @as here is a workaround for #7950\n        return @as(i1, @bitCast(@as(u1, @intFromBool(value))));\n    }\n\n    return -%@as(MaskInt, @intCast(@intFromBool(value)));\n}\n\ntest boolMask {\n    const runTest = struct {\n        fn runTest() !void {\n            try testing.expectEqual(@as(u1, 0), boolMask(u1, false));\n            try testing.expectEqual(@as(u1, 1), boolMask(u1, true));\n\n            try testing.expectEqual(@as(i1, 0), boolMask(i1, false));\n            try testing.expectEqual(@as(i1, -1), boolMask(i1, true));\n\n            try testing.expectEqual(@as(u13, 0), boolMask(u13, false));\n            try testing.expectEqual(@as(u13, 0x1FFF), boolMask(u13, true));\n\n            try testing.expectEqual(@as(i13, 0), boolMask(i13, false));\n            try testing.expectEqual(@as(i13, -1), boolMask(i13, true));\n\n            try testing.expectEqual(@as(u32, 0), boolMask(u32, false));\n            try testing.expectEqual(@as(u32, 0xFFFF_FFFF), boolMask(u32, true));\n\n            try testing.expectEqual(@as(i32, 0), boolMask(i32, false));\n            try testing.expectEqual(@as(i32, -1), boolMask(i32, true));\n        }\n    }.runTest;\n    try runTest();\n    try comptime runTest();\n}\n\n/// Return the mod of `num` with the smallest integer type\npub fn comptimeMod(num: anytype, comptime denom: comptime_int) IntFittingRange(0, denom - 1) {\n    return @as(IntFittingRange(0, denom - 1), @intCast(@mod(num, denom)));\n}\n\npub const F80 = struct {\n    fraction: u64,\n    exp: u16,\n};\n\npub fn make_f80(repr: F80) f80 {\n    const int = (@as(u80, repr.exp) << 64) | repr.fraction;\n    return @as(f80, @bitCast(int));\n}\n\npub fn break_f80(x: f80) F80 {\n    const int = @as(u80, @bitCast(x));\n    return .{\n        .fraction = @as(u64, @truncate(int)),\n        .exp = @as(u16, @truncate(int >> 64)),\n    };\n}\n\n/// Returns -1, 0, or 1.\n/// Supports integer and float types and vectors of integer and float types.\n/// Unsigned integer types will always return 0 or 1.\n/// Branchless.\npub inline fn sign(i: anytype) @TypeOf(i) {\n    const T = @TypeOf(i);\n    return switch (@typeInfo(T)) {\n        .Int, .ComptimeInt => @as(T, @intFromBool(i > 0)) - @as(T, @intFromBool(i < 0)),\n        .Float, .ComptimeFloat => @as(T, @floatFromInt(@intFromBool(i > 0))) - @as(T, @floatFromInt(@intFromBool(i < 0))),\n        .Vector => |vinfo| blk: {\n            switch (@typeInfo(vinfo.child)) {\n                .Int, .Float => {\n                    const zero: T = @splat(0);\n                    const one: T = @splat(1);\n                    break :blk @select(vinfo.child, i > zero, one, zero) - @select(vinfo.child, i < zero, one, zero);\n                },\n                else => @compileError(\"Expected vector of ints or floats, found \" ++ @typeName(T)),\n            }\n        },\n        else => @compileError(\"Expected an int, float or vector of one, found \" ++ @typeName(T)),\n    };\n}\n\nfn testSign() !void {\n    // each of the following blocks checks the inputs\n    // 2, -2, 0, { 2, -2, 0 } provide expected output\n    // 1, -1, 0, { 1, -1, 0 } for the given T\n    // (negative values omitted for unsigned types)\n    {\n        const T = i8;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, -1), sign(@as(T, -2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(3, T){ 1, -1, 0 }, sign(@Vector(3, T){ 2, -2, 0 }));\n    }\n    {\n        const T = i32;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, -1), sign(@as(T, -2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(3, T){ 1, -1, 0 }, sign(@Vector(3, T){ 2, -2, 0 }));\n    }\n    {\n        const T = i64;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, -1), sign(@as(T, -2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(3, T){ 1, -1, 0 }, sign(@Vector(3, T){ 2, -2, 0 }));\n    }\n    {\n        const T = u8;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(2, T){ 1, 0 }, sign(@Vector(2, T){ 2, 0 }));\n    }\n    {\n        const T = u32;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(2, T){ 1, 0 }, sign(@Vector(2, T){ 2, 0 }));\n    }\n    {\n        const T = u64;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(2, T){ 1, 0 }, sign(@Vector(2, T){ 2, 0 }));\n    }\n    {\n        const T = f16;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, -1), sign(@as(T, -2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(3, T){ 1, -1, 0 }, sign(@Vector(3, T){ 2, -2, 0 }));\n    }\n    {\n        const T = f32;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, -1), sign(@as(T, -2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(3, T){ 1, -1, 0 }, sign(@Vector(3, T){ 2, -2, 0 }));\n    }\n    {\n        const T = f64;\n        try std.testing.expectEqual(@as(T, 1), sign(@as(T, 2)));\n        try std.testing.expectEqual(@as(T, -1), sign(@as(T, -2)));\n        try std.testing.expectEqual(@as(T, 0), sign(@as(T, 0)));\n        try std.testing.expectEqual(@Vector(3, T){ 1, -1, 0 }, sign(@Vector(3, T){ 2, -2, 0 }));\n    }\n\n    // comptime_int\n    try std.testing.expectEqual(-1, sign(-10));\n    try std.testing.expectEqual(1, sign(10));\n    try std.testing.expectEqual(0, sign(0));\n    // comptime_float\n    try std.testing.expectEqual(-1.0, sign(-10.0));\n    try std.testing.expectEqual(1.0, sign(10.0));\n    try std.testing.expectEqual(0.0, sign(0.0));\n}\n\ntest sign {\n    if (builtin.zig_backend == .stage2_llvm) {\n        // https://github.com/ziglang/zig/issues/12012\n        return error.SkipZigTest;\n    }\n    try testSign();\n    try comptime testSign();\n}\n",
    "const std = @import(\"../std.zig\");\nconst builtin = @import(\"builtin\");\nconst math = std.math;\nconst expect = std.testing.expect;\n\n/// Returns the base-2 logarithm of x.\n///\n/// Special Cases:\n///  - log2(+inf)  = +inf\n///  - log2(0)     = -inf\n///  - log2(x)     = nan if x < 0\n///  - log2(nan)   = nan\npub fn log2(x: anytype) @TypeOf(x) {\n    const T = @TypeOf(x);\n    switch (@typeInfo(T)) {\n        .ComptimeFloat => {\n            return @as(comptime_float, @log2(x));\n        },\n        .Float => return @log2(x),\n        .ComptimeInt => comptime {\n            var x_shifted = x;\n            // First, calculate floorPowerOfTwo(x)\n            var shift_amt = 1;\n            while (x_shifted >> (shift_amt << 1) != 0) shift_amt <<= 1;\n\n            // Answer is in the range [shift_amt, 2 * shift_amt - 1]\n            // We can find it in O(log(N)) using binary search.\n            var result = 0;\n            while (shift_amt != 0) : (shift_amt >>= 1) {\n                if (x_shifted >> shift_amt != 0) {\n                    x_shifted >>= shift_amt;\n                    result += shift_amt;\n                }\n            }\n            return result;\n        },\n        .Int => |IntType| switch (IntType.signedness) {\n            .signed => @compileError(\"log2 not implemented for signed integers\"),\n            .unsigned => return math.log2_int(T, x),\n        },\n        else => @compileError(\"log2 not implemented for \" ++ @typeName(T)),\n    }\n}\n\ntest log2 {\n    // https://github.com/ziglang/zig/issues/13703\n    if (builtin.cpu.arch == .aarch64 and builtin.os.tag == .windows) return error.SkipZigTest;\n\n    try expect(log2(@as(f32, 0.2)) == @log2(0.2));\n    try expect(log2(@as(f64, 0.2)) == @log2(0.2));\n    comptime {\n        try expect(log2(1) == 0);\n        try expect(log2(15) == 3);\n        try expect(log2(16) == 4);\n        try expect(log2(1 << 4073) == 4073);\n    }\n}\n",
    "//! String formatting and parsing.\n\nconst std = @import(\"std.zig\");\nconst builtin = @import(\"builtin\");\n\nconst io = std.io;\nconst math = std.math;\nconst assert = std.debug.assert;\nconst mem = std.mem;\nconst unicode = std.unicode;\nconst meta = std.meta;\nconst lossyCast = math.lossyCast;\nconst expectFmt = std.testing.expectFmt;\n\npub const default_max_depth = 3;\n\npub const Alignment = enum {\n    left,\n    center,\n    right,\n};\n\npub const FormatOptions = struct {\n    precision: ?usize = null,\n    width: ?usize = null,\n    alignment: Alignment = .right,\n    fill: u21 = ' ',\n};\n\n/// Renders fmt string with args, calling `writer` with slices of bytes.\n/// If `writer` returns an error, the error is returned from `format` and\n/// `writer` is not called again.\n///\n/// The format string must be comptime-known and may contain placeholders following\n/// this format:\n/// `{[argument][specifier]:[fill][alignment][width].[precision]}`\n///\n/// Above, each word including its surrounding [ and ] is a parameter which you have to replace with something:\n///\n/// - *argument* is either the numeric index or the field name of the argument that should be inserted\n///   - when using a field name, you are required to enclose the field name (an identifier) in square\n///     brackets, e.g. {[score]...} as opposed to the numeric index form which can be written e.g. {2...}\n/// - *specifier* is a type-dependent formatting option that determines how a type should formatted (see below)\n/// - *fill* is a single unicode codepoint which is used to pad the formatted text\n/// - *alignment* is one of the three bytes '<', '^', or '>' to make the text left-, center-, or right-aligned, respectively\n/// - *width* is the total width of the field in unicode codepoints\n/// - *precision* specifies how many decimals a formatted number should have\n///\n/// Note that most of the parameters are optional and may be omitted. Also you can leave out separators like `:` and `.` when\n/// all parameters after the separator are omitted.\n/// Only exception is the *fill* parameter. If *fill* is required, one has to specify *alignment* as well, as otherwise\n/// the digits after `:` is interpreted as *width*, not *fill*.\n///\n/// The *specifier* has several options for types:\n/// - `x` and `X`: output numeric value in hexadecimal notation\n/// - `s`:\n///   - for pointer-to-many and C pointers of u8, print as a C-string using zero-termination\n///   - for slices of u8, print the entire slice as a string without zero-termination\n/// - `e`: output floating point value in scientific notation\n/// - `d`: output numeric value in decimal notation\n/// - `b`: output integer value in binary notation\n/// - `o`: output integer value in octal notation\n/// - `c`: output integer as an ASCII character. Integer type must have 8 bits at max.\n/// - `u`: output integer as an UTF-8 sequence. Integer type must have 21 bits at max.\n/// - `?`: output optional value as either the unwrapped value, or `null`; may be followed by a format specifier for the underlying value.\n/// - `!`: output error union value as either the unwrapped value, or the formatted error value; may be followed by a format specifier for the underlying value.\n/// - `*`: output the address of the value instead of the value itself.\n/// - `any`: output a value of any type using its default format.\n///\n/// If a formatted user type contains a function of the type\n/// ```\n/// pub fn format(value: ?, comptime fmt: []const u8, options: std.fmt.FormatOptions, writer: anytype) !void\n/// ```\n/// with `?` being the type formatted, this function will be called instead of the default implementation.\n/// This allows user types to be formatted in a logical manner instead of dumping all fields of the type.\n///\n/// A user type may be a `struct`, `vector`, `union` or `enum` type.\n///\n/// To print literal curly braces, escape them by writing them twice, e.g. `{{` or `}}`.\npub fn format(\n    writer: anytype,\n    comptime fmt: []const u8,\n    args: anytype,\n) !void {\n    const ArgsType = @TypeOf(args);\n    const args_type_info = @typeInfo(ArgsType);\n    if (args_type_info != .Struct) {\n        @compileError(\"expected tuple or struct argument, found \" ++ @typeName(ArgsType));\n    }\n\n    const fields_info = args_type_info.Struct.fields;\n    if (fields_info.len > max_format_args) {\n        @compileError(\"32 arguments max are supported per format call\");\n    }\n\n    @setEvalBranchQuota(2000000);\n    comptime var arg_state: ArgState = .{ .args_len = fields_info.len };\n    comptime var i = 0;\n    inline while (i < fmt.len) {\n        const start_index = i;\n\n        inline while (i < fmt.len) : (i += 1) {\n            switch (fmt[i]) {\n                '{', '}' => break,\n                else => {},\n            }\n        }\n\n        comptime var end_index = i;\n        comptime var unescape_brace = false;\n\n        // Handle {{ and }}, those are un-escaped as single braces\n        if (i + 1 < fmt.len and fmt[i + 1] == fmt[i]) {\n            unescape_brace = true;\n            // Make the first brace part of the literal...\n            end_index += 1;\n            // ...and skip both\n            i += 2;\n        }\n\n        // Write out the literal\n        if (start_index != end_index) {\n            try writer.writeAll(fmt[start_index..end_index]);\n        }\n\n        // We've already skipped the other brace, restart the loop\n        if (unescape_brace) continue;\n\n        if (i >= fmt.len) break;\n\n        if (fmt[i] == '}') {\n            @compileError(\"missing opening {\");\n        }\n\n        // Get past the {\n        comptime assert(fmt[i] == '{');\n        i += 1;\n\n        const fmt_begin = i;\n        // Find the closing brace\n        inline while (i < fmt.len and fmt[i] != '}') : (i += 1) {}\n        const fmt_end = i;\n\n        if (i >= fmt.len) {\n            @compileError(\"missing closing }\");\n        }\n\n        // Get past the }\n        comptime assert(fmt[i] == '}');\n        i += 1;\n\n        const placeholder = comptime Placeholder.parse(fmt[fmt_begin..fmt_end].*);\n        const arg_pos = comptime switch (placeholder.arg) {\n            .none => null,\n            .number => |pos| pos,\n            .named => |arg_name| meta.fieldIndex(ArgsType, arg_name) orelse\n                @compileError(\"no argument with name '\" ++ arg_name ++ \"'\"),\n        };\n\n        const width = switch (placeholder.width) {\n            .none => null,\n            .number => |v| v,\n            .named => |arg_name| blk: {\n                const arg_i = comptime meta.fieldIndex(ArgsType, arg_name) orelse\n                    @compileError(\"no argument with name '\" ++ arg_name ++ \"'\");\n                _ = comptime arg_state.nextArg(arg_i) orelse @compileError(\"too few arguments\");\n                break :blk @field(args, arg_name);\n            },\n        };\n\n        const precision = switch (placeholder.precision) {\n            .none => null,\n            .number => |v| v,\n            .named => |arg_name| blk: {\n                const arg_i = comptime meta.fieldIndex(ArgsType, arg_name) orelse\n                    @compileError(\"no argument with name '\" ++ arg_name ++ \"'\");\n                _ = comptime arg_state.nextArg(arg_i) orelse @compileError(\"too few arguments\");\n                break :blk @field(args, arg_name);\n            },\n        };\n\n        const arg_to_print = comptime arg_state.nextArg(arg_pos) orelse\n            @compileError(\"too few arguments\");\n\n        try formatType(\n            @field(args, fields_info[arg_to_print].name),\n            placeholder.specifier_arg,\n            FormatOptions{\n                .fill = placeholder.fill,\n                .alignment = placeholder.alignment,\n                .width = width,\n                .precision = precision,\n            },\n            writer,\n            std.options.fmt_max_depth,\n        );\n    }\n\n    if (comptime arg_state.hasUnusedArgs()) {\n        const missing_count = arg_state.args_len - @popCount(arg_state.used_args);\n        switch (missing_count) {\n            0 => unreachable,\n            1 => @compileError(\"unused argument in '\" ++ fmt ++ \"'\"),\n            else => @compileError(comptimePrint(\"{d}\", .{missing_count}) ++ \" unused arguments in '\" ++ fmt ++ \"'\"),\n        }\n    }\n}\n\nfn cacheString(str: anytype) []const u8 {\n    return &str;\n}\n\npub const Placeholder = struct {\n    specifier_arg: []const u8,\n    fill: u21,\n    alignment: Alignment,\n    arg: Specifier,\n    width: Specifier,\n    precision: Specifier,\n\n    pub fn parse(comptime str: anytype) Placeholder {\n        const view = std.unicode.Utf8View.initComptime(&str);\n        comptime var parser = Parser{\n            .buf = &str,\n            .iter = view.iterator(),\n        };\n\n        // Parse the positional argument number\n        const arg = comptime parser.specifier() catch |err|\n            @compileError(@errorName(err));\n\n        // Parse the format specifier\n        const specifier_arg = comptime parser.until(':');\n\n        // Skip the colon, if present\n        if (comptime parser.char()) |ch| {\n            if (ch != ':') {\n                @compileError(\"expected : or }, found '\" ++ unicode.utf8EncodeComptime(ch) ++ \"'\");\n            }\n        }\n\n        // Parse the fill character\n        // The fill parameter requires the alignment parameter to be specified\n        // too\n        const fill = comptime if (parser.peek(1)) |ch|\n            switch (ch) {\n                '<', '^', '>' => parser.char().?,\n                else => ' ',\n            }\n        else\n            ' ';\n\n        // Parse the alignment parameter\n        const alignment: Alignment = comptime if (parser.peek(0)) |ch| init: {\n            switch (ch) {\n                '<', '^', '>' => _ = parser.char(),\n                else => {},\n            }\n            break :init switch (ch) {\n                '<' => .left,\n                '^' => .center,\n                else => .right,\n            };\n        } else .right;\n\n        // Parse the width parameter\n        const width = comptime parser.specifier() catch |err|\n            @compileError(@errorName(err));\n\n        // Skip the dot, if present\n        if (comptime parser.char()) |ch| {\n            if (ch != '.') {\n                @compileError(\"expected . or }, found '\" ++ unicode.utf8EncodeComptime(ch) ++ \"'\");\n            }\n        }\n\n        // Parse the precision parameter\n        const precision = comptime parser.specifier() catch |err|\n            @compileError(@errorName(err));\n\n        if (comptime parser.char()) |ch| {\n            @compileError(\"extraneous trailing character '\" ++ unicode.utf8EncodeComptime(ch) ++ \"'\");\n        }\n\n        return Placeholder{\n            .specifier_arg = cacheString(specifier_arg[0..specifier_arg.len].*),\n            .fill = fill,\n            .alignment = alignment,\n            .arg = arg,\n            .width = width,\n            .precision = precision,\n        };\n    }\n};\n\npub const Specifier = union(enum) {\n    none,\n    number: usize,\n    named: []const u8,\n};\n\npub const Parser = struct {\n    buf: []const u8,\n    pos: usize = 0,\n    iter: std.unicode.Utf8Iterator = undefined,\n\n    // Returns a decimal number or null if the current character is not a\n    // digit\n    pub fn number(self: *@This()) ?usize {\n        var r: ?usize = null;\n\n        while (self.peek(0)) |code_point| {\n            switch (code_point) {\n                '0'...'9' => {\n                    if (r == null) r = 0;\n                    r.? *= 10;\n                    r.? += code_point - '0';\n                },\n                else => break,\n            }\n            _ = self.iter.nextCodepoint();\n        }\n\n        return r;\n    }\n\n    // Returns a substring of the input starting from the current position\n    // and ending where `ch` is found or until the end if not found\n    pub fn until(self: *@This(), ch: u21) []const u8 {\n        var result: []const u8 = &[_]u8{};\n        while (self.peek(0)) |code_point| {\n            if (code_point == ch)\n                break;\n            result = result ++ (self.iter.nextCodepointSlice() orelse &[_]u8{});\n        }\n        return result;\n    }\n\n    // Returns one character, if available\n    pub fn char(self: *@This()) ?u21 {\n        if (self.iter.nextCodepoint()) |code_point| {\n            return code_point;\n        }\n        return null;\n    }\n\n    pub fn maybe(self: *@This(), val: u21) bool {\n        if (self.peek(0) == val) {\n            _ = self.iter.nextCodepoint();\n            return true;\n        }\n        return false;\n    }\n\n    // Returns a decimal number or null if the current character is not a\n    // digit\n    pub fn specifier(self: *@This()) !Specifier {\n        if (self.maybe('[')) {\n            const arg_name = self.until(']');\n\n            if (!self.maybe(']'))\n                return @field(anyerror, \"Expected closing ]\");\n\n            return Specifier{ .named = arg_name };\n        }\n        if (self.number()) |i|\n            return Specifier{ .number = i };\n\n        return Specifier{ .none = {} };\n    }\n\n    // Returns the n-th next character or null if that's past the end\n    pub fn peek(self: *@This(), n: usize) ?u21 {\n        const original_i = self.iter.i;\n        defer self.iter.i = original_i;\n\n        var i = 0;\n        var code_point: ?u21 = null;\n        while (i <= n) : (i += 1) {\n            code_point = self.iter.nextCodepoint();\n            if (code_point == null) return null;\n        }\n        return code_point;\n    }\n};\n\npub const ArgSetType = u32;\nconst max_format_args = @typeInfo(ArgSetType).Int.bits;\n\npub const ArgState = struct {\n    next_arg: usize = 0,\n    used_args: ArgSetType = 0,\n    args_len: usize,\n\n    pub fn hasUnusedArgs(self: *@This()) bool {\n        return @popCount(self.used_args) != self.args_len;\n    }\n\n    pub fn nextArg(self: *@This(), arg_index: ?usize) ?usize {\n        const next_index = arg_index orelse init: {\n            const arg = self.next_arg;\n            self.next_arg += 1;\n            break :init arg;\n        };\n\n        if (next_index >= self.args_len) {\n            return null;\n        }\n\n        // Mark this argument as used\n        self.used_args |= @as(ArgSetType, 1) << @as(u5, @intCast(next_index));\n        return next_index;\n    }\n};\n\npub fn formatAddress(value: anytype, options: FormatOptions, writer: anytype) @TypeOf(writer).Error!void {\n    _ = options;\n    const T = @TypeOf(value);\n\n    switch (@typeInfo(T)) {\n        .Pointer => |info| {\n            try writer.writeAll(@typeName(info.child) ++ \"@\");\n            if (info.size == .Slice)\n                try formatInt(@intFromPtr(value.ptr), 16, .lower, FormatOptions{}, writer)\n            else\n                try formatInt(@intFromPtr(value), 16, .lower, FormatOptions{}, writer);\n            return;\n        },\n        .Optional => |info| {\n            if (@typeInfo(info.child) == .Pointer) {\n                try writer.writeAll(@typeName(info.child) ++ \"@\");\n                try formatInt(@intFromPtr(value), 16, .lower, FormatOptions{}, writer);\n                return;\n            }\n        },\n        else => {},\n    }\n\n    @compileError(\"cannot format non-pointer type \" ++ @typeName(T) ++ \" with * specifier\");\n}\n\n// This ANY const is a workaround for: https://github.com/ziglang/zig/issues/7948\nconst ANY = \"any\";\n\npub fn defaultSpec(comptime T: type) [:0]const u8 {\n    switch (@typeInfo(T)) {\n        .Array => |_| return ANY,\n        .Pointer => |ptr_info| switch (ptr_info.size) {\n            .One => switch (@typeInfo(ptr_info.child)) {\n                .Array => |_| return ANY,\n                else => {},\n            },\n            .Many, .C => return \"*\",\n            .Slice => return ANY,\n        },\n        .Optional => |info| return \"?\" ++ defaultSpec(info.child),\n        .ErrorUnion => |info| return \"!\" ++ defaultSpec(info.payload),\n        else => {},\n    }\n    return \"\";\n}\n\nfn stripOptionalOrErrorUnionSpec(comptime fmt: []const u8) []const u8 {\n    return if (std.mem.eql(u8, fmt[1..], ANY))\n        ANY\n    else\n        fmt[1..];\n}\n\npub fn invalidFmtError(comptime fmt: []const u8, value: anytype) void {\n    @compileError(\"invalid format string '\" ++ fmt ++ \"' for type '\" ++ @typeName(@TypeOf(value)) ++ \"'\");\n}\n\npub fn formatType(\n    value: anytype,\n    comptime fmt: []const u8,\n    options: FormatOptions,\n    writer: anytype,\n    max_depth: usize,\n) @TypeOf(writer).Error!void {\n    const T = @TypeOf(value);\n    const actual_fmt = comptime if (std.mem.eql(u8, fmt, ANY))\n        defaultSpec(T)\n    else if (fmt.len != 0 and (fmt[0] == '?' or fmt[0] == '!')) switch (@typeInfo(T)) {\n        .Optional, .ErrorUnion => fmt,\n        else => stripOptionalOrErrorUnionSpec(fmt),\n    } else fmt;\n\n    if (comptime std.mem.eql(u8, actual_fmt, \"*\")) {\n        return formatAddress(value, options, writer);\n    }\n\n    if (std.meta.hasMethod(T, \"format\")) {\n        return try value.format(actual_fmt, options, writer);\n    }\n\n    switch (@typeInfo(T)) {\n        .ComptimeInt, .Int, .ComptimeFloat, .Float => {\n            return formatValue(value, actual_fmt, options, writer);\n        },\n        .Void => {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            return formatBuf(\"void\", options, writer);\n        },\n        .Bool => {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            return formatBuf(if (value) \"true\" else \"false\", options, writer);\n        },\n        .Optional => {\n            if (actual_fmt.len == 0 or actual_fmt[0] != '?')\n                @compileError(\"cannot format optional without a specifier (i.e. {?} or {any})\");\n            const remaining_fmt = comptime stripOptionalOrErrorUnionSpec(actual_fmt);\n            if (value) |payload| {\n                return formatType(payload, remaining_fmt, options, writer, max_depth);\n            } else {\n                return formatBuf(\"null\", options, writer);\n            }\n        },\n        .ErrorUnion => {\n            if (actual_fmt.len == 0 or actual_fmt[0] != '!')\n                @compileError(\"cannot format error union without a specifier (i.e. {!} or {any})\");\n            const remaining_fmt = comptime stripOptionalOrErrorUnionSpec(actual_fmt);\n            if (value) |payload| {\n                return formatType(payload, remaining_fmt, options, writer, max_depth);\n            } else |err| {\n                return formatType(err, \"\", options, writer, max_depth);\n            }\n        },\n        .ErrorSet => {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            try writer.writeAll(\"error.\");\n            return writer.writeAll(@errorName(value));\n        },\n        .Enum => |enumInfo| {\n            try writer.writeAll(@typeName(T));\n            if (enumInfo.is_exhaustive) {\n                if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n                try writer.writeAll(\".\");\n                try writer.writeAll(@tagName(value));\n                return;\n            }\n\n            // Use @tagName only if value is one of known fields\n            @setEvalBranchQuota(3 * enumInfo.fields.len);\n            inline for (enumInfo.fields) |enumField| {\n                if (@intFromEnum(value) == enumField.value) {\n                    try writer.writeAll(\".\");\n                    try writer.writeAll(@tagName(value));\n                    return;\n                }\n            }\n\n            try writer.writeAll(\"(\");\n            try formatType(@intFromEnum(value), actual_fmt, options, writer, max_depth);\n            try writer.writeAll(\")\");\n        },\n        .Union => |info| {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            try writer.writeAll(@typeName(T));\n            if (max_depth == 0) {\n                return writer.writeAll(\"{ ... }\");\n            }\n            if (info.tag_type) |UnionTagType| {\n                try writer.writeAll(\"{ .\");\n                try writer.writeAll(@tagName(@as(UnionTagType, value)));\n                try writer.writeAll(\" = \");\n                inline for (info.fields) |u_field| {\n                    if (value == @field(UnionTagType, u_field.name)) {\n                        try formatType(@field(value, u_field.name), ANY, options, writer, max_depth - 1);\n                    }\n                }\n                try writer.writeAll(\" }\");\n            } else {\n                try format(writer, \"@{x}\", .{@intFromPtr(&value)});\n            }\n        },\n        .Struct => |info| {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            if (info.is_tuple) {\n                // Skip the type and field names when formatting tuples.\n                if (max_depth == 0) {\n                    return writer.writeAll(\"{ ... }\");\n                }\n                try writer.writeAll(\"{\");\n                inline for (info.fields, 0..) |f, i| {\n                    if (i == 0) {\n                        try writer.writeAll(\" \");\n                    } else {\n                        try writer.writeAll(\", \");\n                    }\n                    try formatType(@field(value, f.name), ANY, options, writer, max_depth - 1);\n                }\n                return writer.writeAll(\" }\");\n            }\n            try writer.writeAll(@typeName(T));\n            if (max_depth == 0) {\n                return writer.writeAll(\"{ ... }\");\n            }\n            try writer.writeAll(\"{\");\n            inline for (info.fields, 0..) |f, i| {\n                if (i == 0) {\n                    try writer.writeAll(\" .\");\n                } else {\n                    try writer.writeAll(\", .\");\n                }\n                try writer.writeAll(f.name);\n                try writer.writeAll(\" = \");\n                try formatType(@field(value, f.name), ANY, options, writer, max_depth - 1);\n            }\n            try writer.writeAll(\" }\");\n        },\n        .Pointer => |ptr_info| switch (ptr_info.size) {\n            .One => switch (@typeInfo(ptr_info.child)) {\n                .Array, .Enum, .Union, .Struct => {\n                    return formatType(value.*, actual_fmt, options, writer, max_depth);\n                },\n                else => return format(writer, \"{s}@{x}\", .{ @typeName(ptr_info.child), @intFromPtr(value) }),\n            },\n            .Many, .C => {\n                if (actual_fmt.len == 0)\n                    @compileError(\"cannot format pointer without a specifier (i.e. {s} or {*})\");\n                if (ptr_info.sentinel) |_| {\n                    return formatType(mem.span(value), actual_fmt, options, writer, max_depth);\n                }\n                if (actual_fmt[0] == 's' and ptr_info.child == u8) {\n                    return formatBuf(mem.span(value), options, writer);\n                }\n                invalidFmtError(fmt, value);\n            },\n            .Slice => {\n                if (actual_fmt.len == 0)\n                    @compileError(\"cannot format slice without a specifier (i.e. {s} or {any})\");\n                if (max_depth == 0) {\n                    return writer.writeAll(\"{ ... }\");\n                }\n                if (actual_fmt[0] == 's' and ptr_info.child == u8) {\n                    return formatBuf(value, options, writer);\n                }\n                try writer.writeAll(\"{ \");\n                for (value, 0..) |elem, i| {\n                    try formatType(elem, actual_fmt, options, writer, max_depth - 1);\n                    if (i != value.len - 1) {\n                        try writer.writeAll(\", \");\n                    }\n                }\n                try writer.writeAll(\" }\");\n            },\n        },\n        .Array => |info| {\n            if (actual_fmt.len == 0)\n                @compileError(\"cannot format array without a specifier (i.e. {s} or {any})\");\n            if (max_depth == 0) {\n                return writer.writeAll(\"{ ... }\");\n            }\n            if (actual_fmt[0] == 's' and info.child == u8) {\n                return formatBuf(&value, options, writer);\n            }\n            try writer.writeAll(\"{ \");\n            for (value, 0..) |elem, i| {\n                try formatType(elem, actual_fmt, options, writer, max_depth - 1);\n                if (i < value.len - 1) {\n                    try writer.writeAll(\", \");\n                }\n            }\n            try writer.writeAll(\" }\");\n        },\n        .Vector => |info| {\n            try writer.writeAll(\"{ \");\n            var i: usize = 0;\n            while (i < info.len) : (i += 1) {\n                try formatValue(value[i], actual_fmt, options, writer);\n                if (i < info.len - 1) {\n                    try writer.writeAll(\", \");\n                }\n            }\n            try writer.writeAll(\" }\");\n        },\n        .Fn => @compileError(\"unable to format function body type, use '*const \" ++ @typeName(T) ++ \"' for a function pointer type\"),\n        .Type => {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            return formatBuf(@typeName(value), options, writer);\n        },\n        .EnumLiteral => {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            const buffer = [_]u8{'.'} ++ @tagName(value);\n            return formatBuf(buffer, options, writer);\n        },\n        .Null => {\n            if (actual_fmt.len != 0) invalidFmtError(fmt, value);\n            return formatBuf(\"null\", options, writer);\n        },\n        else => @compileError(\"unable to format type '\" ++ @typeName(T) ++ \"'\"),\n    }\n}\n\nfn formatValue(\n    value: anytype,\n    comptime fmt: []const u8,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    const T = @TypeOf(value);\n    switch (@typeInfo(T)) {\n        .Float, .ComptimeFloat => return formatFloatValue(value, fmt, options, writer),\n        .Int, .ComptimeInt => return formatIntValue(value, fmt, options, writer),\n        .Bool => return formatBuf(if (value) \"true\" else \"false\", options, writer),\n        else => comptime unreachable,\n    }\n}\n\npub fn formatIntValue(\n    value: anytype,\n    comptime fmt: []const u8,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    comptime var base = 10;\n    comptime var case: Case = .lower;\n\n    const int_value = if (@TypeOf(value) == comptime_int) blk: {\n        const Int = math.IntFittingRange(value, value);\n        break :blk @as(Int, value);\n    } else value;\n\n    if (fmt.len == 0 or comptime std.mem.eql(u8, fmt, \"d\")) {\n        base = 10;\n        case = .lower;\n    } else if (comptime std.mem.eql(u8, fmt, \"c\")) {\n        if (@typeInfo(@TypeOf(int_value)).Int.bits <= 8) {\n            return formatAsciiChar(@as(u8, int_value), options, writer);\n        } else {\n            @compileError(\"cannot print integer that is larger than 8 bits as an ASCII character\");\n        }\n    } else if (comptime std.mem.eql(u8, fmt, \"u\")) {\n        if (@typeInfo(@TypeOf(int_value)).Int.bits <= 21) {\n            return formatUnicodeCodepoint(@as(u21, int_value), options, writer);\n        } else {\n            @compileError(\"cannot print integer that is larger than 21 bits as an UTF-8 sequence\");\n        }\n    } else if (comptime std.mem.eql(u8, fmt, \"b\")) {\n        base = 2;\n        case = .lower;\n    } else if (comptime std.mem.eql(u8, fmt, \"x\")) {\n        base = 16;\n        case = .lower;\n    } else if (comptime std.mem.eql(u8, fmt, \"X\")) {\n        base = 16;\n        case = .upper;\n    } else if (comptime std.mem.eql(u8, fmt, \"o\")) {\n        base = 8;\n        case = .lower;\n    } else {\n        invalidFmtError(fmt, value);\n    }\n\n    return formatInt(int_value, base, case, options, writer);\n}\n\npub const format_float = @import(\"fmt/format_float.zig\");\npub const formatFloat = format_float.formatFloat;\npub const FormatFloatError = format_float.FormatError;\n\nfn formatFloatValue(\n    value: anytype,\n    comptime fmt: []const u8,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    var buf: [format_float.bufferSize(.decimal, f64)]u8 = undefined;\n\n    if (fmt.len == 0 or comptime std.mem.eql(u8, fmt, \"e\")) {\n        const s = formatFloat(&buf, value, .{ .mode = .scientific, .precision = options.precision }) catch |err| switch (err) {\n            error.BufferTooSmall => \"(float)\",\n        };\n        return formatBuf(s, options, writer);\n    } else if (comptime std.mem.eql(u8, fmt, \"d\")) {\n        const s = formatFloat(&buf, value, .{ .mode = .decimal, .precision = options.precision }) catch |err| switch (err) {\n            error.BufferTooSmall => \"(float)\",\n        };\n        return formatBuf(s, options, writer);\n    } else if (comptime std.mem.eql(u8, fmt, \"x\")) {\n        var buf_stream = std.io.fixedBufferStream(&buf);\n        formatFloatHexadecimal(value, options, buf_stream.writer()) catch |err| switch (err) {\n            error.NoSpaceLeft => unreachable,\n        };\n        return formatBuf(buf_stream.getWritten(), options, writer);\n    } else {\n        invalidFmtError(fmt, value);\n    }\n}\n\ntest {\n    _ = &format_float;\n}\n\npub const Case = enum { lower, upper };\n\nfn formatSliceHexImpl(comptime case: Case) type {\n    const charset = \"0123456789\" ++ if (case == .upper) \"ABCDEF\" else \"abcdef\";\n\n    return struct {\n        pub fn formatSliceHexImpl(\n            bytes: []const u8,\n            comptime fmt: []const u8,\n            options: std.fmt.FormatOptions,\n            writer: anytype,\n        ) !void {\n            _ = fmt;\n            _ = options;\n            var buf: [2]u8 = undefined;\n\n            for (bytes) |c| {\n                buf[0] = charset[c >> 4];\n                buf[1] = charset[c & 15];\n                try writer.writeAll(&buf);\n            }\n        }\n    };\n}\n\nconst formatSliceHexLower = formatSliceHexImpl(.lower).formatSliceHexImpl;\nconst formatSliceHexUpper = formatSliceHexImpl(.upper).formatSliceHexImpl;\n\n/// Return a Formatter for a []const u8 where every byte is formatted as a pair\n/// of lowercase hexadecimal digits.\npub fn fmtSliceHexLower(bytes: []const u8) std.fmt.Formatter(formatSliceHexLower) {\n    return .{ .data = bytes };\n}\n\n/// Return a Formatter for a []const u8 where every byte is formatted as pair\n/// of uppercase hexadecimal digits.\npub fn fmtSliceHexUpper(bytes: []const u8) std.fmt.Formatter(formatSliceHexUpper) {\n    return .{ .data = bytes };\n}\n\nfn formatSliceEscapeImpl(comptime case: Case) type {\n    const charset = \"0123456789\" ++ if (case == .upper) \"ABCDEF\" else \"abcdef\";\n\n    return struct {\n        pub fn formatSliceEscapeImpl(\n            bytes: []const u8,\n            comptime fmt: []const u8,\n            options: std.fmt.FormatOptions,\n            writer: anytype,\n        ) !void {\n            _ = fmt;\n            _ = options;\n            var buf: [4]u8 = undefined;\n\n            buf[0] = '\\\\';\n            buf[1] = 'x';\n\n            for (bytes) |c| {\n                if (std.ascii.isPrint(c)) {\n                    try writer.writeByte(c);\n                } else {\n                    buf[2] = charset[c >> 4];\n                    buf[3] = charset[c & 15];\n                    try writer.writeAll(&buf);\n                }\n            }\n        }\n    };\n}\n\nconst formatSliceEscapeLower = formatSliceEscapeImpl(.lower).formatSliceEscapeImpl;\nconst formatSliceEscapeUpper = formatSliceEscapeImpl(.upper).formatSliceEscapeImpl;\n\n/// Return a Formatter for a []const u8 where every non-printable ASCII\n/// character is escaped as \\xNN, where NN is the character in lowercase\n/// hexadecimal notation.\npub fn fmtSliceEscapeLower(bytes: []const u8) std.fmt.Formatter(formatSliceEscapeLower) {\n    return .{ .data = bytes };\n}\n\n/// Return a Formatter for a []const u8 where every non-printable ASCII\n/// character is escaped as \\xNN, where NN is the character in uppercase\n/// hexadecimal notation.\npub fn fmtSliceEscapeUpper(bytes: []const u8) std.fmt.Formatter(formatSliceEscapeUpper) {\n    return .{ .data = bytes };\n}\n\nfn formatSizeImpl(comptime base: comptime_int) type {\n    return struct {\n        fn formatSizeImpl(\n            value: u64,\n            comptime fmt: []const u8,\n            options: FormatOptions,\n            writer: anytype,\n        ) !void {\n            _ = fmt;\n            if (value == 0) {\n                return formatBuf(\"0B\", options, writer);\n            }\n            // The worst case in terms of space needed is 32 bytes + 3 for the suffix.\n            var buf: [format_float.min_buffer_size + 3]u8 = undefined;\n\n            const mags_si = \" kMGTPEZY\";\n            const mags_iec = \" KMGTPEZY\";\n\n            const log2 = math.log2(value);\n            const magnitude = switch (base) {\n                1000 => @min(log2 / comptime math.log2(1000), mags_si.len - 1),\n                1024 => @min(log2 / 10, mags_iec.len - 1),\n                else => unreachable,\n            };\n            const new_value = lossyCast(f64, value) / math.pow(f64, lossyCast(f64, base), lossyCast(f64, magnitude));\n            const suffix = switch (base) {\n                1000 => mags_si[magnitude],\n                1024 => mags_iec[magnitude],\n                else => unreachable,\n            };\n\n            const s = switch (magnitude) {\n                0 => buf[0..formatIntBuf(&buf, value, 10, .lower, .{})],\n                else => formatFloat(&buf, new_value, .{ .mode = .decimal, .precision = options.precision }) catch |err| switch (err) {\n                    error.BufferTooSmall => unreachable,\n                },\n            };\n\n            var i: usize = s.len;\n            if (suffix == ' ') {\n                buf[i] = 'B';\n                i += 1;\n            } else switch (base) {\n                1000 => {\n                    buf[i..][0..2].* = [_]u8{ suffix, 'B' };\n                    i += 2;\n                },\n                1024 => {\n                    buf[i..][0..3].* = [_]u8{ suffix, 'i', 'B' };\n                    i += 3;\n                },\n                else => unreachable,\n            }\n\n            return formatBuf(buf[0..i], options, writer);\n        }\n    };\n}\n\nconst formatSizeDec = formatSizeImpl(1000).formatSizeImpl;\nconst formatSizeBin = formatSizeImpl(1024).formatSizeImpl;\n\n/// Return a Formatter for a u64 value representing a file size.\n/// This formatter represents the number as multiple of 1000 and uses the SI\n/// measurement units (kB, MB, GB, ...).\npub fn fmtIntSizeDec(value: u64) std.fmt.Formatter(formatSizeDec) {\n    return .{ .data = value };\n}\n\n/// Return a Formatter for a u64 value representing a file size.\n/// This formatter represents the number as multiple of 1024 and uses the IEC\n/// measurement units (KiB, MiB, GiB, ...).\npub fn fmtIntSizeBin(value: u64) std.fmt.Formatter(formatSizeBin) {\n    return .{ .data = value };\n}\n\nfn checkTextFmt(comptime fmt: []const u8) void {\n    if (fmt.len != 1)\n        @compileError(\"unsupported format string '\" ++ fmt ++ \"' when formatting text\");\n    switch (fmt[0]) {\n        // Example of deprecation:\n        // '[deprecated_specifier]' => @compileError(\"specifier '[deprecated_specifier]' has been deprecated, wrap your argument in `std.some_function` instead\"),\n        'x' => @compileError(\"specifier 'x' has been deprecated, wrap your argument in std.fmt.fmtSliceHexLower instead\"),\n        'X' => @compileError(\"specifier 'X' has been deprecated, wrap your argument in std.fmt.fmtSliceHexUpper instead\"),\n        else => {},\n    }\n}\n\npub fn formatText(\n    bytes: []const u8,\n    comptime fmt: []const u8,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    comptime checkTextFmt(fmt);\n    return formatBuf(bytes, options, writer);\n}\n\npub fn formatAsciiChar(\n    c: u8,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    return formatBuf(@as(*const [1]u8, &c), options, writer);\n}\n\npub fn formatUnicodeCodepoint(\n    c: u21,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    var buf: [4]u8 = undefined;\n    const len = unicode.utf8Encode(c, &buf) catch |err| switch (err) {\n        error.Utf8CannotEncodeSurrogateHalf, error.CodepointTooLarge => {\n            return formatBuf(&unicode.utf8EncodeComptime(unicode.replacement_character), options, writer);\n        },\n    };\n    return formatBuf(buf[0..len], options, writer);\n}\n\npub fn formatBuf(\n    buf: []const u8,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    if (options.width) |min_width| {\n        // In case of error assume the buffer content is ASCII-encoded\n        const width = unicode.utf8CountCodepoints(buf) catch buf.len;\n        const padding = if (width < min_width) min_width - width else 0;\n\n        if (padding == 0)\n            return writer.writeAll(buf);\n\n        var fill_buffer: [4]u8 = undefined;\n        const fill_utf8 = if (unicode.utf8Encode(options.fill, &fill_buffer)) |len|\n            fill_buffer[0..len]\n        else |err| switch (err) {\n            error.Utf8CannotEncodeSurrogateHalf,\n            error.CodepointTooLarge,\n            => &unicode.utf8EncodeComptime(unicode.replacement_character),\n        };\n        switch (options.alignment) {\n            .left => {\n                try writer.writeAll(buf);\n                try writer.writeBytesNTimes(fill_utf8, padding);\n            },\n            .center => {\n                const left_padding = padding / 2;\n                const right_padding = (padding + 1) / 2;\n                try writer.writeBytesNTimes(fill_utf8, left_padding);\n                try writer.writeAll(buf);\n                try writer.writeBytesNTimes(fill_utf8, right_padding);\n            },\n            .right => {\n                try writer.writeBytesNTimes(fill_utf8, padding);\n                try writer.writeAll(buf);\n            },\n        }\n    } else {\n        // Fast path, avoid counting the number of codepoints\n        try writer.writeAll(buf);\n    }\n}\n\npub fn formatFloatHexadecimal(\n    value: anytype,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    if (math.signbit(value)) {\n        try writer.writeByte('-');\n    }\n    if (math.isNan(value)) {\n        return writer.writeAll(\"nan\");\n    }\n    if (math.isInf(value)) {\n        return writer.writeAll(\"inf\");\n    }\n\n    const T = @TypeOf(value);\n    const TU = std.meta.Int(.unsigned, @bitSizeOf(T));\n\n    const mantissa_bits = math.floatMantissaBits(T);\n    const fractional_bits = math.floatFractionalBits(T);\n    const exponent_bits = math.floatExponentBits(T);\n    const mantissa_mask = (1 << mantissa_bits) - 1;\n    const exponent_mask = (1 << exponent_bits) - 1;\n    const exponent_bias = (1 << (exponent_bits - 1)) - 1;\n\n    const as_bits = @as(TU, @bitCast(value));\n    var mantissa = as_bits & mantissa_mask;\n    var exponent: i32 = @as(u16, @truncate((as_bits >> mantissa_bits) & exponent_mask));\n\n    const is_denormal = exponent == 0 and mantissa != 0;\n    const is_zero = exponent == 0 and mantissa == 0;\n\n    if (is_zero) {\n        // Handle this case here to simplify the logic below.\n        try writer.writeAll(\"0x0\");\n        if (options.precision) |precision| {\n            if (precision > 0) {\n                try writer.writeAll(\".\");\n                try writer.writeByteNTimes('0', precision);\n            }\n        } else {\n            try writer.writeAll(\".0\");\n        }\n        try writer.writeAll(\"p0\");\n        return;\n    }\n\n    if (is_denormal) {\n        // Adjust the exponent for printing.\n        exponent += 1;\n    } else {\n        if (fractional_bits == mantissa_bits)\n            mantissa |= 1 << fractional_bits; // Add the implicit integer bit.\n    }\n\n    const mantissa_digits = (fractional_bits + 3) / 4;\n    // Fill in zeroes to round the fraction width to a multiple of 4.\n    mantissa <<= mantissa_digits * 4 - fractional_bits;\n\n    if (options.precision) |precision| {\n        // Round if needed.\n        if (precision < mantissa_digits) {\n            // We always have at least 4 extra bits.\n            var extra_bits = (mantissa_digits - precision) * 4;\n            // The result LSB is the Guard bit, we need two more (Round and\n            // Sticky) to round the value.\n            while (extra_bits > 2) {\n                mantissa = (mantissa >> 1) | (mantissa & 1);\n                extra_bits -= 1;\n            }\n            // Round to nearest, tie to even.\n            mantissa |= @intFromBool(mantissa & 0b100 != 0);\n            mantissa += 1;\n            // Drop the excess bits.\n            mantissa >>= 2;\n            // Restore the alignment.\n            mantissa <<= @as(math.Log2Int(TU), @intCast((mantissa_digits - precision) * 4));\n\n            const overflow = mantissa & (1 << 1 + mantissa_digits * 4) != 0;\n            // Prefer a normalized result in case of overflow.\n            if (overflow) {\n                mantissa >>= 1;\n                exponent += 1;\n            }\n        }\n    }\n\n    // +1 for the decimal part.\n    var buf: [1 + mantissa_digits]u8 = undefined;\n    _ = formatIntBuf(&buf, mantissa, 16, .lower, .{ .fill = '0', .width = 1 + mantissa_digits });\n\n    try writer.writeAll(\"0x\");\n    try writer.writeByte(buf[0]);\n    const trimmed = mem.trimRight(u8, buf[1..], \"0\");\n    if (options.precision) |precision| {\n        if (precision > 0) try writer.writeAll(\".\");\n    } else if (trimmed.len > 0) {\n        try writer.writeAll(\".\");\n    }\n    try writer.writeAll(trimmed);\n    // Add trailing zeros if explicitly requested.\n    if (options.precision) |precision| if (precision > 0) {\n        if (precision > trimmed.len)\n            try writer.writeByteNTimes('0', precision - trimmed.len);\n    };\n    try writer.writeAll(\"p\");\n    try formatInt(exponent - exponent_bias, 10, .lower, .{}, writer);\n}\n\npub fn formatInt(\n    value: anytype,\n    base: u8,\n    case: Case,\n    options: FormatOptions,\n    writer: anytype,\n) !void {\n    assert(base >= 2);\n\n    const int_value = if (@TypeOf(value) == comptime_int) blk: {\n        const Int = math.IntFittingRange(value, value);\n        break :blk @as(Int, value);\n    } else value;\n\n    const value_info = @typeInfo(@TypeOf(int_value)).Int;\n\n    // The type must have the same size as `base` or be wider in order for the\n    // division to work\n    const min_int_bits = comptime @max(value_info.bits, 8);\n    const MinInt = std.meta.Int(.unsigned, min_int_bits);\n\n    const abs_value = @abs(int_value);\n    // The worst case in terms of space needed is base 2, plus 1 for the sign\n    var buf: [1 + @max(@as(comptime_int, value_info.bits), 1)]u8 = undefined;\n\n    var a: MinInt = abs_value;\n    var index: usize = buf.len;\n\n    if (base == 10) {\n        while (a >= 100) : (a = @divTrunc(a, 100)) {\n            index -= 2;\n            buf[index..][0..2].* = digits2(@as(usize, @intCast(a % 100)));\n        }\n\n        if (a < 10) {\n            index -= 1;\n            buf[index] = '0' + @as(u8, @intCast(a));\n        } else {\n            index -= 2;\n            buf[index..][0..2].* = digits2(@as(usize, @intCast(a)));\n        }\n    } else {\n        while (true) {\n            const digit = a % base;\n            index -= 1;\n            buf[index] = digitToChar(@as(u8, @intCast(digit)), case);\n            a /= base;\n            if (a == 0) break;\n        }\n    }\n\n    if (value_info.signedness == .signed) {\n        if (value < 0) {\n            // Negative integer\n            index -= 1;\n            buf[index] = '-';\n        } else if (options.width == null or options.width.? == 0) {\n            // Positive integer, omit the plus sign\n        } else {\n            // Positive integer\n            index -= 1;\n            buf[index] = '+';\n        }\n    }\n\n    return formatBuf(buf[index..], options, writer);\n}\n\npub fn formatIntBuf(out_buf: []u8, value: anytype, base: u8, case: Case, options: FormatOptions) usize {\n    var fbs = std.io.fixedBufferStream(out_buf);\n    formatInt(value, base, case, options, fbs.writer()) catch unreachable;\n    return fbs.pos;\n}\n\n// Converts values in the range [0, 100) to a string.\npub fn digits2(value: usize) [2]u8 {\n    return (\"0001020304050607080910111213141516171819\" ++\n        \"2021222324252627282930313233343536373839\" ++\n        \"4041424344454647484950515253545556575859\" ++\n        \"6061626364656667686970717273747576777879\" ++\n        \"8081828384858687888990919293949596979899\")[value * 2 ..][0..2].*;\n}\n\nconst FormatDurationData = struct {\n    ns: u64,\n    negative: bool = false,\n};\n\nfn formatDuration(data: FormatDurationData, comptime fmt: []const u8, options: std.fmt.FormatOptions, writer: anytype) !void {\n    _ = fmt;\n\n    // worst case: \"-XXXyXXwXXdXXhXXmXX.XXXs\".len = 24\n    var buf: [24]u8 = undefined;\n    var fbs = std.io.fixedBufferStream(&buf);\n    var buf_writer = fbs.writer();\n    if (data.negative) {\n        buf_writer.writeByte('-') catch unreachable;\n    }\n\n    var ns_remaining = data.ns;\n    inline for (.{\n        .{ .ns = 365 * std.time.ns_per_day, .sep = 'y' },\n        .{ .ns = std.time.ns_per_week, .sep = 'w' },\n        .{ .ns = std.time.ns_per_day, .sep = 'd' },\n        .{ .ns = std.time.ns_per_hour, .sep = 'h' },\n        .{ .ns = std.time.ns_per_min, .sep = 'm' },\n    }) |unit| {\n        if (ns_remaining >= unit.ns) {\n            const units = ns_remaining / unit.ns;\n            formatInt(units, 10, .lower, .{}, buf_writer) catch unreachable;\n            buf_writer.writeByte(unit.sep) catch unreachable;\n            ns_remaining -= units * unit.ns;\n            if (ns_remaining == 0)\n                return formatBuf(fbs.getWritten(), options, writer);\n        }\n    }\n\n    inline for (.{\n        .{ .ns = std.time.ns_per_s, .sep = \"s\" },\n        .{ .ns = std.time.ns_per_ms, .sep = \"ms\" },\n        .{ .ns = std.time.ns_per_us, .sep = \"us\" },\n    }) |unit| {\n        const kunits = ns_remaining * 1000 / unit.ns;\n        if (kunits >= 1000) {\n            formatInt(kunits / 1000, 10, .lower, .{}, buf_writer) catch unreachable;\n            const frac = kunits % 1000;\n            if (frac > 0) {\n                // Write up to 3 decimal places\n                var decimal_buf = [_]u8{ '.', 0, 0, 0 };\n                _ = formatIntBuf(decimal_buf[1..], frac, 10, .lower, .{ .fill = '0', .width = 3 });\n                var end: usize = 4;\n                while (end > 1) : (end -= 1) {\n                    if (decimal_buf[end - 1] != '0') break;\n                }\n                buf_writer.writeAll(decimal_buf[0..end]) catch unreachable;\n            }\n            buf_writer.writeAll(unit.sep) catch unreachable;\n            return formatBuf(fbs.getWritten(), options, writer);\n        }\n    }\n\n    formatInt(ns_remaining, 10, .lower, .{}, buf_writer) catch unreachable;\n    buf_writer.writeAll(\"ns\") catch unreachable;\n    return formatBuf(fbs.getWritten(), options, writer);\n}\n\n/// Return a Formatter for number of nanoseconds according to its magnitude:\n/// [#y][#w][#d][#h][#m]#[.###][n|u|m]s\npub fn fmtDuration(ns: u64) Formatter(formatDuration) {\n    const data = FormatDurationData{ .ns = ns };\n    return .{ .data = data };\n}\n\ntest fmtDuration {\n    var buf: [24]u8 = undefined;\n    inline for (.{\n        .{ .s = \"0ns\", .d = 0 },\n        .{ .s = \"1ns\", .d = 1 },\n        .{ .s = \"999ns\", .d = std.time.ns_per_us - 1 },\n        .{ .s = \"1us\", .d = std.time.ns_per_us },\n        .{ .s = \"1.45us\", .d = 1450 },\n        .{ .s = \"1.5us\", .d = 3 * std.time.ns_per_us / 2 },\n        .{ .s = \"14.5us\", .d = 14500 },\n        .{ .s = \"145us\", .d = 145000 },\n        .{ .s = \"999.999us\", .d = std.time.ns_per_ms - 1 },\n        .{ .s = \"1ms\", .d = std.time.ns_per_ms + 1 },\n        .{ .s = \"1.5ms\", .d = 3 * std.time.ns_per_ms / 2 },\n        .{ .s = \"1.11ms\", .d = 1110000 },\n        .{ .s = \"1.111ms\", .d = 1111000 },\n        .{ .s = \"1.111ms\", .d = 1111100 },\n        .{ .s = \"999.999ms\", .d = std.time.ns_per_s - 1 },\n        .{ .s = \"1s\", .d = std.time.ns_per_s },\n        .{ .s = \"59.999s\", .d = std.time.ns_per_min - 1 },\n        .{ .s = \"1m\", .d = std.time.ns_per_min },\n        .{ .s = \"1h\", .d = std.time.ns_per_hour },\n        .{ .s = \"1d\", .d = std.time.ns_per_day },\n        .{ .s = \"1w\", .d = std.time.ns_per_week },\n        .{ .s = \"1y\", .d = 365 * std.time.ns_per_day },\n        .{ .s = \"1y52w23h59m59.999s\", .d = 730 * std.time.ns_per_day - 1 }, // 365d = 52w1d\n        .{ .s = \"1y1h1.001s\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_s + std.time.ns_per_ms },\n        .{ .s = \"1y1h1s\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_s + 999 * std.time.ns_per_us },\n        .{ .s = \"1y1h999.999us\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms - 1 },\n        .{ .s = \"1y1h1ms\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms },\n        .{ .s = \"1y1h1ms\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms + 1 },\n        .{ .s = \"1y1m999ns\", .d = 365 * std.time.ns_per_day + std.time.ns_per_min + 999 },\n        .{ .s = \"584y49w23h34m33.709s\", .d = math.maxInt(u64) },\n    }) |tc| {\n        const slice = try bufPrint(&buf, \"{}\", .{fmtDuration(tc.d)});\n        try std.testing.expectEqualStrings(tc.s, slice);\n    }\n\n    inline for (.{\n        .{ .s = \"=======0ns\", .f = \"{s:=>10}\", .d = 0 },\n        .{ .s = \"1ns=======\", .f = \"{s:=<10}\", .d = 1 },\n        .{ .s = \"  999ns   \", .f = \"{s:^10}\", .d = std.time.ns_per_us - 1 },\n    }) |tc| {\n        const slice = try bufPrint(&buf, tc.f, .{fmtDuration(tc.d)});\n        try std.testing.expectEqualStrings(tc.s, slice);\n    }\n}\n\nfn formatDurationSigned(ns: i64, comptime fmt: []const u8, options: std.fmt.FormatOptions, writer: anytype) !void {\n    if (ns < 0) {\n        const data = FormatDurationData{ .ns = @as(u64, @intCast(-ns)), .negative = true };\n        try formatDuration(data, fmt, options, writer);\n    } else {\n        const data = FormatDurationData{ .ns = @as(u64, @intCast(ns)) };\n        try formatDuration(data, fmt, options, writer);\n    }\n}\n\n/// Return a Formatter for number of nanoseconds according to its signed magnitude:\n/// [#y][#w][#d][#h][#m]#[.###][n|u|m]s\npub fn fmtDurationSigned(ns: i64) Formatter(formatDurationSigned) {\n    return .{ .data = ns };\n}\n\ntest fmtDurationSigned {\n    var buf: [24]u8 = undefined;\n    inline for (.{\n        .{ .s = \"0ns\", .d = 0 },\n        .{ .s = \"1ns\", .d = 1 },\n        .{ .s = \"-1ns\", .d = -(1) },\n        .{ .s = \"999ns\", .d = std.time.ns_per_us - 1 },\n        .{ .s = \"-999ns\", .d = -(std.time.ns_per_us - 1) },\n        .{ .s = \"1us\", .d = std.time.ns_per_us },\n        .{ .s = \"-1us\", .d = -(std.time.ns_per_us) },\n        .{ .s = \"1.45us\", .d = 1450 },\n        .{ .s = \"-1.45us\", .d = -(1450) },\n        .{ .s = \"1.5us\", .d = 3 * std.time.ns_per_us / 2 },\n        .{ .s = \"-1.5us\", .d = -(3 * std.time.ns_per_us / 2) },\n        .{ .s = \"14.5us\", .d = 14500 },\n        .{ .s = \"-14.5us\", .d = -(14500) },\n        .{ .s = \"145us\", .d = 145000 },\n        .{ .s = \"-145us\", .d = -(145000) },\n        .{ .s = \"999.999us\", .d = std.time.ns_per_ms - 1 },\n        .{ .s = \"-999.999us\", .d = -(std.time.ns_per_ms - 1) },\n        .{ .s = \"1ms\", .d = std.time.ns_per_ms + 1 },\n        .{ .s = \"-1ms\", .d = -(std.time.ns_per_ms + 1) },\n        .{ .s = \"1.5ms\", .d = 3 * std.time.ns_per_ms / 2 },\n        .{ .s = \"-1.5ms\", .d = -(3 * std.time.ns_per_ms / 2) },\n        .{ .s = \"1.11ms\", .d = 1110000 },\n        .{ .s = \"-1.11ms\", .d = -(1110000) },\n        .{ .s = \"1.111ms\", .d = 1111000 },\n        .{ .s = \"-1.111ms\", .d = -(1111000) },\n        .{ .s = \"1.111ms\", .d = 1111100 },\n        .{ .s = \"-1.111ms\", .d = -(1111100) },\n        .{ .s = \"999.999ms\", .d = std.time.ns_per_s - 1 },\n        .{ .s = \"-999.999ms\", .d = -(std.time.ns_per_s - 1) },\n        .{ .s = \"1s\", .d = std.time.ns_per_s },\n        .{ .s = \"-1s\", .d = -(std.time.ns_per_s) },\n        .{ .s = \"59.999s\", .d = std.time.ns_per_min - 1 },\n        .{ .s = \"-59.999s\", .d = -(std.time.ns_per_min - 1) },\n        .{ .s = \"1m\", .d = std.time.ns_per_min },\n        .{ .s = \"-1m\", .d = -(std.time.ns_per_min) },\n        .{ .s = \"1h\", .d = std.time.ns_per_hour },\n        .{ .s = \"-1h\", .d = -(std.time.ns_per_hour) },\n        .{ .s = \"1d\", .d = std.time.ns_per_day },\n        .{ .s = \"-1d\", .d = -(std.time.ns_per_day) },\n        .{ .s = \"1w\", .d = std.time.ns_per_week },\n        .{ .s = \"-1w\", .d = -(std.time.ns_per_week) },\n        .{ .s = \"1y\", .d = 365 * std.time.ns_per_day },\n        .{ .s = \"-1y\", .d = -(365 * std.time.ns_per_day) },\n        .{ .s = \"1y52w23h59m59.999s\", .d = 730 * std.time.ns_per_day - 1 }, // 365d = 52w1d\n        .{ .s = \"-1y52w23h59m59.999s\", .d = -(730 * std.time.ns_per_day - 1) }, // 365d = 52w1d\n        .{ .s = \"1y1h1.001s\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_s + std.time.ns_per_ms },\n        .{ .s = \"-1y1h1.001s\", .d = -(365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_s + std.time.ns_per_ms) },\n        .{ .s = \"1y1h1s\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_s + 999 * std.time.ns_per_us },\n        .{ .s = \"-1y1h1s\", .d = -(365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_s + 999 * std.time.ns_per_us) },\n        .{ .s = \"1y1h999.999us\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms - 1 },\n        .{ .s = \"-1y1h999.999us\", .d = -(365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms - 1) },\n        .{ .s = \"1y1h1ms\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms },\n        .{ .s = \"-1y1h1ms\", .d = -(365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms) },\n        .{ .s = \"1y1h1ms\", .d = 365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms + 1 },\n        .{ .s = \"-1y1h1ms\", .d = -(365 * std.time.ns_per_day + std.time.ns_per_hour + std.time.ns_per_ms + 1) },\n        .{ .s = \"1y1m999ns\", .d = 365 * std.time.ns_per_day + std.time.ns_per_min + 999 },\n        .{ .s = \"-1y1m999ns\", .d = -(365 * std.time.ns_per_day + std.time.ns_per_min + 999) },\n        .{ .s = \"292y24w3d23h47m16.854s\", .d = math.maxInt(i64) },\n        .{ .s = \"-292y24w3d23h47m16.854s\", .d = math.minInt(i64) + 1 },\n    }) |tc| {\n        const slice = try bufPrint(&buf, \"{}\", .{fmtDurationSigned(tc.d)});\n        try std.testing.expectEqualStrings(tc.s, slice);\n    }\n\n    inline for (.{\n        .{ .s = \"=======0ns\", .f = \"{s:=>10}\", .d = 0 },\n        .{ .s = \"1ns=======\", .f = \"{s:=<10}\", .d = 1 },\n        .{ .s = \"-1ns======\", .f = \"{s:=<10}\", .d = -(1) },\n        .{ .s = \"  -999ns  \", .f = \"{s:^10}\", .d = -(std.time.ns_per_us - 1) },\n    }) |tc| {\n        const slice = try bufPrint(&buf, tc.f, .{fmtDurationSigned(tc.d)});\n        try std.testing.expectEqualStrings(tc.s, slice);\n    }\n}\n\npub const ParseIntError = error{\n    /// The result cannot fit in the type specified\n    Overflow,\n\n    /// The input was empty or contained an invalid character\n    InvalidCharacter,\n};\n\n/// Creates a Formatter type from a format function. Wrapping data in Formatter(func) causes\n/// the data to be formatted using the given function `func`.  `func` must be of the following\n/// form:\n///\n///     fn formatExample(\n///         data: T,\n///         comptime fmt: []const u8,\n///         options: std.fmt.FormatOptions,\n///         writer: anytype,\n///     ) !void;\n///\npub fn Formatter(comptime format_fn: anytype) type {\n    const Data = @typeInfo(@TypeOf(format_fn)).Fn.params[0].type.?;\n    return struct {\n        data: Data,\n        pub fn format(\n            self: @This(),\n            comptime fmt: []const u8,\n            options: std.fmt.FormatOptions,\n            writer: anytype,\n        ) @TypeOf(writer).Error!void {\n            try format_fn(self.data, fmt, options, writer);\n        }\n    };\n}\n\n/// Parses the string `buf` as signed or unsigned representation in the\n/// specified base of an integral value of type `T`.\n///\n/// When `base` is zero the string prefix is examined to detect the true base:\n///  * A prefix of \"0b\" implies base=2,\n///  * A prefix of \"0o\" implies base=8,\n///  * A prefix of \"0x\" implies base=16,\n///  * Otherwise base=10 is assumed.\n///\n/// Ignores '_' character in `buf`.\n/// See also `parseUnsigned`.\npub fn parseInt(comptime T: type, buf: []const u8, base: u8) ParseIntError!T {\n    return parseIntWithGenericCharacter(T, u8, buf, base);\n}\n\n/// Like `parseInt`, but with a generic `Character` type.\npub fn parseIntWithGenericCharacter(\n    comptime Result: type,\n    comptime Character: type,\n    buf: []const Character,\n    base: u8,\n) ParseIntError!Result {\n    if (buf.len == 0) return error.InvalidCharacter;\n    if (buf[0] == '+') return parseIntWithSign(Result, Character, buf[1..], base, .pos);\n    if (buf[0] == '-') return parseIntWithSign(Result, Character, buf[1..], base, .neg);\n    return parseIntWithSign(Result, Character, buf, base, .pos);\n}\n\ntest parseInt {\n    try std.testing.expectEqual(-10, try parseInt(i32, \"-10\", 10));\n    try std.testing.expectEqual(10, try parseInt(i32, \"+10\", 10));\n    try std.testing.expectEqual(10, try parseInt(u32, \"+10\", 10));\n    try std.testing.expectError(error.Overflow, parseInt(u32, \"-10\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \" 10\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"10 \", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"_10_\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"0x_10_\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"0x10_\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"0x_10\", 10));\n    try std.testing.expectEqual(255, try parseInt(u8, \"255\", 10));\n    try std.testing.expectError(error.Overflow, parseInt(u8, \"256\", 10));\n\n    // +0 and -0 should work for unsigned\n    try std.testing.expectEqual(0, try parseInt(u8, \"-0\", 10));\n    try std.testing.expectEqual(0, try parseInt(u8, \"+0\", 10));\n\n    // ensure minInt is parsed correctly\n    try std.testing.expectEqual(math.minInt(i1), try parseInt(i1, \"-1\", 10));\n    try std.testing.expectEqual(math.minInt(i8), try parseInt(i8, \"-128\", 10));\n    try std.testing.expectEqual(math.minInt(i43), try parseInt(i43, \"-4398046511104\", 10));\n\n    // empty string or bare +- is invalid\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(i32, \"\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"+\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(i32, \"+\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"-\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(i32, \"-\", 10));\n\n    // autodectect the base\n    try std.testing.expectEqual(111, try parseInt(i32, \"111\", 0));\n    try std.testing.expectEqual(111, try parseInt(i32, \"1_1_1\", 0));\n    try std.testing.expectEqual(111, try parseInt(i32, \"1_1_1\", 0));\n    try std.testing.expectEqual(7, try parseInt(i32, \"+0b111\", 0));\n    try std.testing.expectEqual(7, try parseInt(i32, \"+0B111\", 0));\n    try std.testing.expectEqual(7, try parseInt(i32, \"+0b1_11\", 0));\n    try std.testing.expectEqual(73, try parseInt(i32, \"+0o111\", 0));\n    try std.testing.expectEqual(73, try parseInt(i32, \"+0O111\", 0));\n    try std.testing.expectEqual(73, try parseInt(i32, \"+0o11_1\", 0));\n    try std.testing.expectEqual(273, try parseInt(i32, \"+0x111\", 0));\n    try std.testing.expectEqual(-7, try parseInt(i32, \"-0b111\", 0));\n    try std.testing.expectEqual(-7, try parseInt(i32, \"-0b11_1\", 0));\n    try std.testing.expectEqual(-73, try parseInt(i32, \"-0o111\", 0));\n    try std.testing.expectEqual(-273, try parseInt(i32, \"-0x111\", 0));\n    try std.testing.expectEqual(-273, try parseInt(i32, \"-0X111\", 0));\n    try std.testing.expectEqual(-273, try parseInt(i32, \"-0x1_11\", 0));\n\n    // bare binary/octal/decimal prefix is invalid\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"0b\", 0));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"0o\", 0));\n    try std.testing.expectError(error.InvalidCharacter, parseInt(u32, \"0x\", 0));\n\n    // edge cases which previously errored due to base overflowing T\n    try std.testing.expectEqual(@as(i2, -2), try std.fmt.parseInt(i2, \"-10\", 2));\n    try std.testing.expectEqual(@as(i4, -8), try std.fmt.parseInt(i4, \"-10\", 8));\n    try std.testing.expectEqual(@as(i5, -16), try std.fmt.parseInt(i5, \"-10\", 16));\n}\n\nfn parseIntWithSign(\n    comptime Result: type,\n    comptime Character: type,\n    buf: []const Character,\n    base: u8,\n    comptime sign: enum { pos, neg },\n) ParseIntError!Result {\n    if (buf.len == 0) return error.InvalidCharacter;\n\n    var buf_base = base;\n    var buf_start = buf;\n    if (base == 0) {\n        // Treat is as a decimal number by default.\n        buf_base = 10;\n        // Detect the base by looking at buf prefix.\n        if (buf.len > 2 and buf[0] == '0') {\n            if (math.cast(u8, buf[1])) |c| switch (std.ascii.toLower(c)) {\n                'b' => {\n                    buf_base = 2;\n                    buf_start = buf[2..];\n                },\n                'o' => {\n                    buf_base = 8;\n                    buf_start = buf[2..];\n                },\n                'x' => {\n                    buf_base = 16;\n                    buf_start = buf[2..];\n                },\n                else => {},\n            };\n        }\n    }\n\n    const add = switch (sign) {\n        .pos => math.add,\n        .neg => math.sub,\n    };\n\n    // accumulate into Accumulate which is always 8 bits or larger.  this prevents\n    // `buf_base` from overflowing Result.\n    const info = @typeInfo(Result);\n    const Accumulate = std.meta.Int(info.Int.signedness, @max(8, info.Int.bits));\n    var accumulate: Accumulate = 0;\n\n    if (buf_start[0] == '_' or buf_start[buf_start.len - 1] == '_') return error.InvalidCharacter;\n\n    for (buf_start) |c| {\n        if (c == '_') continue;\n        const digit = try charToDigit(math.cast(u8, c) orelse return error.InvalidCharacter, buf_base);\n        if (accumulate != 0) {\n            accumulate = try math.mul(Accumulate, accumulate, math.cast(Accumulate, buf_base) orelse return error.Overflow);\n        } else if (sign == .neg) {\n            // The first digit of a negative number.\n            // Consider parsing \"-4\" as an i3.\n            // This should work, but positive 4 overflows i3, so we can't cast the digit to T and subtract.\n            accumulate = math.cast(Accumulate, -@as(i8, @intCast(digit))) orelse return error.Overflow;\n            continue;\n        }\n        accumulate = try add(Accumulate, accumulate, math.cast(Accumulate, digit) orelse return error.Overflow);\n    }\n\n    return if (Result == Accumulate)\n        accumulate\n    else\n        math.cast(Result, accumulate) orelse return error.Overflow;\n}\n\n/// Parses the string `buf` as unsigned representation in the specified base\n/// of an integral value of type `T`.\n///\n/// When `base` is zero the string prefix is examined to detect the true base:\n///  * A prefix of \"0b\" implies base=2,\n///  * A prefix of \"0o\" implies base=8,\n///  * A prefix of \"0x\" implies base=16,\n///  * Otherwise base=10 is assumed.\n///\n/// Ignores '_' character in `buf`.\n/// See also `parseInt`.\npub fn parseUnsigned(comptime T: type, buf: []const u8, base: u8) ParseIntError!T {\n    return parseIntWithSign(T, u8, buf, base, .pos);\n}\n\ntest parseUnsigned {\n    try std.testing.expectEqual(50124, try parseUnsigned(u16, \"050124\", 10));\n    try std.testing.expectEqual(65535, try parseUnsigned(u16, \"65535\", 10));\n    try std.testing.expectEqual(65535, try parseUnsigned(u16, \"65_535\", 10));\n    try std.testing.expectError(error.Overflow, parseUnsigned(u16, \"65536\", 10));\n\n    try std.testing.expectEqual(0xffffffffffffffff, try parseUnsigned(u64, \"0ffffffffffffffff\", 16));\n    try std.testing.expectEqual(0xffffffffffffffff, try parseUnsigned(u64, \"0f_fff_fff_fff_fff_fff\", 16));\n    try std.testing.expectError(error.Overflow, parseUnsigned(u64, \"10000000000000000\", 16));\n\n    try std.testing.expectEqual(0xDEADBEEF, try parseUnsigned(u32, \"DeadBeef\", 16));\n\n    try std.testing.expectEqual(1, try parseUnsigned(u7, \"1\", 10));\n    try std.testing.expectEqual(8, try parseUnsigned(u7, \"1000\", 2));\n\n    try std.testing.expectError(error.InvalidCharacter, parseUnsigned(u32, \"f\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseUnsigned(u8, \"109\", 8));\n\n    try std.testing.expectEqual(1442151747, try parseUnsigned(u32, \"NUMBER\", 36));\n\n    // these numbers should fit even though the base itself doesn't fit in the destination type\n    try std.testing.expectEqual(0, try parseUnsigned(u1, \"0\", 10));\n    try std.testing.expectEqual(1, try parseUnsigned(u1, \"1\", 10));\n    try std.testing.expectError(error.Overflow, parseUnsigned(u1, \"2\", 10));\n    try std.testing.expectEqual(1, try parseUnsigned(u1, \"001\", 16));\n    try std.testing.expectEqual(3, try parseUnsigned(u2, \"3\", 16));\n    try std.testing.expectError(error.Overflow, parseUnsigned(u2, \"4\", 16));\n\n    // parseUnsigned does not expect a sign\n    try std.testing.expectError(error.InvalidCharacter, parseUnsigned(u8, \"+0\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseUnsigned(u8, \"-0\", 10));\n\n    // test empty string error\n    try std.testing.expectError(error.InvalidCharacter, parseUnsigned(u8, \"\", 10));\n}\n\n/// Parses a number like '2G', '2Gi', or '2GiB'.\npub fn parseIntSizeSuffix(buf: []const u8, digit_base: u8) ParseIntError!usize {\n    var without_B = buf;\n    if (mem.endsWith(u8, buf, \"B\")) without_B.len -= 1;\n    var without_i = without_B;\n    var magnitude_base: usize = 1000;\n    if (mem.endsWith(u8, without_B, \"i\")) {\n        without_i.len -= 1;\n        magnitude_base = 1024;\n    }\n    if (without_i.len == 0) return error.InvalidCharacter;\n    const orders_of_magnitude: usize = switch (without_i[without_i.len - 1]) {\n        'k', 'K' => 1,\n        'M' => 2,\n        'G' => 3,\n        'T' => 4,\n        'P' => 5,\n        'E' => 6,\n        'Z' => 7,\n        'Y' => 8,\n        'R' => 9,\n        'Q' => 10,\n        else => 0,\n    };\n    var without_suffix = without_i;\n    if (orders_of_magnitude > 0) {\n        without_suffix.len -= 1;\n    } else if (without_i.len != without_B.len) {\n        return error.InvalidCharacter;\n    }\n    const multiplier = math.powi(usize, magnitude_base, orders_of_magnitude) catch |err| switch (err) {\n        error.Underflow => unreachable,\n        error.Overflow => return error.Overflow,\n    };\n    const number = try std.fmt.parseInt(usize, without_suffix, digit_base);\n    return math.mul(usize, number, multiplier);\n}\n\ntest parseIntSizeSuffix {\n    try std.testing.expectEqual(2, try parseIntSizeSuffix(\"2\", 10));\n    try std.testing.expectEqual(2, try parseIntSizeSuffix(\"2B\", 10));\n    try std.testing.expectEqual(2000, try parseIntSizeSuffix(\"2kB\", 10));\n    try std.testing.expectEqual(2000, try parseIntSizeSuffix(\"2k\", 10));\n    try std.testing.expectEqual(2048, try parseIntSizeSuffix(\"2KiB\", 10));\n    try std.testing.expectEqual(2048, try parseIntSizeSuffix(\"2Ki\", 10));\n    try std.testing.expectEqual(10240, try parseIntSizeSuffix(\"aKiB\", 16));\n    try std.testing.expectError(error.InvalidCharacter, parseIntSizeSuffix(\"\", 10));\n    try std.testing.expectError(error.InvalidCharacter, parseIntSizeSuffix(\"2iB\", 10));\n}\n\npub const parseFloat = @import(\"fmt/parse_float.zig\").parseFloat;\npub const ParseFloatError = @import(\"fmt/parse_float.zig\").ParseFloatError;\n\ntest {\n    _ = &parseFloat;\n}\n\npub fn charToDigit(c: u8, base: u8) (error{InvalidCharacter}!u8) {\n    const value = switch (c) {\n        '0'...'9' => c - '0',\n        'A'...'Z' => c - 'A' + 10,\n        'a'...'z' => c - 'a' + 10,\n        else => return error.InvalidCharacter,\n    };\n\n    if (value >= base) return error.InvalidCharacter;\n\n    return value;\n}\n\npub fn digitToChar(digit: u8, case: Case) u8 {\n    return switch (digit) {\n        0...9 => digit + '0',\n        10...35 => digit + ((if (case == .upper) @as(u8, 'A') else @as(u8, 'a')) - 10),\n        else => unreachable,\n    };\n}\n\npub const BufPrintError = error{\n    /// As much as possible was written to the buffer, but it was too small to fit all the printed bytes.\n    NoSpaceLeft,\n};\n\n/// Print a Formatter string into `buf`. Actually just a thin wrapper around `format` and `fixedBufferStream`.\n/// Returns a slice of the bytes printed to.\npub fn bufPrint(buf: []u8, comptime fmt: []const u8, args: anytype) BufPrintError![]u8 {\n    var fbs = std.io.fixedBufferStream(buf);\n    format(fbs.writer().any(), fmt, args) catch |err| switch (err) {\n        error.NoSpaceLeft => return error.NoSpaceLeft,\n        else => unreachable,\n    };\n    return fbs.getWritten();\n}\n\npub fn bufPrintZ(buf: []u8, comptime fmt: []const u8, args: anytype) BufPrintError![:0]u8 {\n    const result = try bufPrint(buf, fmt ++ \"\\x00\", args);\n    return result[0 .. result.len - 1 :0];\n}\n\n/// Count the characters needed for format. Useful for preallocating memory\npub fn count(comptime fmt: []const u8, args: anytype) u64 {\n    var counting_writer = std.io.countingWriter(std.io.null_writer);\n    format(counting_writer.writer().any(), fmt, args) catch unreachable;\n    return counting_writer.bytes_written;\n}\n\npub const AllocPrintError = error{OutOfMemory};\n\npub fn allocPrint(allocator: mem.Allocator, comptime fmt: []const u8, args: anytype) AllocPrintError![]u8 {\n    const size = math.cast(usize, count(fmt, args)) orelse return error.OutOfMemory;\n    const buf = try allocator.alloc(u8, size);\n    return bufPrint(buf, fmt, args) catch |err| switch (err) {\n        error.NoSpaceLeft => unreachable, // we just counted the size above\n    };\n}\n\npub fn allocPrintZ(allocator: mem.Allocator, comptime fmt: []const u8, args: anytype) AllocPrintError![:0]u8 {\n    const result = try allocPrint(allocator, fmt ++ \"\\x00\", args);\n    return result[0 .. result.len - 1 :0];\n}\n\ntest bufPrintIntToSlice {\n    var buffer: [100]u8 = undefined;\n    const buf = buffer[0..];\n\n    try std.testing.expectEqualSlices(u8, \"-1\", bufPrintIntToSlice(buf, @as(i1, -1), 10, .lower, FormatOptions{}));\n\n    try std.testing.expectEqualSlices(u8, \"-101111000110000101001110\", bufPrintIntToSlice(buf, @as(i32, -12345678), 2, .lower, FormatOptions{}));\n    try std.testing.expectEqualSlices(u8, \"-12345678\", bufPrintIntToSlice(buf, @as(i32, -12345678), 10, .lower, FormatOptions{}));\n    try std.testing.expectEqualSlices(u8, \"-bc614e\", bufPrintIntToSlice(buf, @as(i32, -12345678), 16, .lower, FormatOptions{}));\n    try std.testing.expectEqualSlices(u8, \"-BC614E\", bufPrintIntToSlice(buf, @as(i32, -12345678), 16, .upper, FormatOptions{}));\n\n    try std.testing.expectEqualSlices(u8, \"12345678\", bufPrintIntToSlice(buf, @as(u32, 12345678), 10, .upper, FormatOptions{}));\n\n    try std.testing.expectEqualSlices(u8, \"   666\", bufPrintIntToSlice(buf, @as(u32, 666), 10, .lower, FormatOptions{ .width = 6 }));\n    try std.testing.expectEqualSlices(u8, \"  1234\", bufPrintIntToSlice(buf, @as(u32, 0x1234), 16, .lower, FormatOptions{ .width = 6 }));\n    try std.testing.expectEqualSlices(u8, \"1234\", bufPrintIntToSlice(buf, @as(u32, 0x1234), 16, .lower, FormatOptions{ .width = 1 }));\n\n    try std.testing.expectEqualSlices(u8, \"+42\", bufPrintIntToSlice(buf, @as(i32, 42), 10, .lower, FormatOptions{ .width = 3 }));\n    try std.testing.expectEqualSlices(u8, \"-42\", bufPrintIntToSlice(buf, @as(i32, -42), 10, .lower, FormatOptions{ .width = 3 }));\n}\n\npub fn bufPrintIntToSlice(buf: []u8, value: anytype, base: u8, case: Case, options: FormatOptions) []u8 {\n    return buf[0..formatIntBuf(buf, value, base, case, options)];\n}\n\npub inline fn comptimePrint(comptime fmt: []const u8, args: anytype) *const [count(fmt, args):0]u8 {\n    comptime {\n        var buf: [count(fmt, args):0]u8 = undefined;\n        _ = bufPrint(&buf, fmt, args) catch unreachable;\n        buf[buf.len] = 0;\n        const final = buf;\n        return &final;\n    }\n}\n\ntest comptimePrint {\n    @setEvalBranchQuota(2000);\n    try std.testing.expectEqual(*const [3:0]u8, @TypeOf(comptimePrint(\"{}\", .{100})));\n    try std.testing.expectEqualSlices(u8, \"100\", comptimePrint(\"{}\", .{100}));\n    try std.testing.expectEqualStrings(\"30\", comptimePrint(\"{d}\", .{30.0}));\n    try std.testing.expectEqualStrings(\"30.0\", comptimePrint(\"{d:3.1}\", .{30.0}));\n    try std.testing.expectEqualStrings(\"0.05\", comptimePrint(\"{d}\", .{0.05}));\n    try std.testing.expectEqualStrings(\"5e-2\", comptimePrint(\"{e}\", .{0.05}));\n}\n\ntest \"parse u64 digit too big\" {\n    _ = parseUnsigned(u64, \"123a\", 10) catch |err| {\n        if (err == error.InvalidCharacter) return;\n        unreachable;\n    };\n    unreachable;\n}\n\ntest \"parse unsigned comptime\" {\n    comptime {\n        try std.testing.expectEqual(2, try parseUnsigned(usize, \"2\", 10));\n    }\n}\n\ntest \"escaped braces\" {\n    try expectFmt(\"escaped: {{foo}}\\n\", \"escaped: {{{{foo}}}}\\n\", .{});\n    try expectFmt(\"escaped: {foo}\\n\", \"escaped: {{foo}}\\n\", .{});\n}\n\ntest \"optional\" {\n    {\n        const value: ?i32 = 1234;\n        try expectFmt(\"optional: 1234\\n\", \"optional: {?}\\n\", .{value});\n        try expectFmt(\"optional: 1234\\n\", \"optional: {?d}\\n\", .{value});\n        try expectFmt(\"optional: 4d2\\n\", \"optional: {?x}\\n\", .{value});\n    }\n    {\n        const value: ?[]const u8 = \"string\";\n        try expectFmt(\"optional: string\\n\", \"optional: {?s}\\n\", .{value});\n    }\n    {\n        const value: ?i32 = null;\n        try expectFmt(\"optional: null\\n\", \"optional: {?}\\n\", .{value});\n    }\n    {\n        const value = @as(?*i32, @ptrFromInt(0xf000d000));\n        try expectFmt(\"optional: *i32@f000d000\\n\", \"optional: {*}\\n\", .{value});\n    }\n}\n\ntest \"error\" {\n    {\n        const value: anyerror!i32 = 1234;\n        try expectFmt(\"error union: 1234\\n\", \"error union: {!}\\n\", .{value});\n        try expectFmt(\"error union: 1234\\n\", \"error union: {!d}\\n\", .{value});\n        try expectFmt(\"error union: 4d2\\n\", \"error union: {!x}\\n\", .{value});\n    }\n    {\n        const value: anyerror![]const u8 = \"string\";\n        try expectFmt(\"error union: string\\n\", \"error union: {!s}\\n\", .{value});\n    }\n    {\n        const value: anyerror!i32 = error.InvalidChar;\n        try expectFmt(\"error union: error.InvalidChar\\n\", \"error union: {!}\\n\", .{value});\n    }\n}\n\ntest \"int.small\" {\n    {\n        const value: u3 = 0b101;\n        try expectFmt(\"u3: 5\\n\", \"u3: {}\\n\", .{value});\n    }\n}\n\ntest \"int.specifier\" {\n    {\n        const value: u8 = 'a';\n        try expectFmt(\"u8: a\\n\", \"u8: {c}\\n\", .{value});\n    }\n    {\n        const value: u8 = 0b1100;\n        try expectFmt(\"u8: 0b1100\\n\", \"u8: 0b{b}\\n\", .{value});\n    }\n    {\n        const value: u16 = 0o1234;\n        try expectFmt(\"u16: 0o1234\\n\", \"u16: 0o{o}\\n\", .{value});\n    }\n    {\n        const value: u8 = 'a';\n        try expectFmt(\"UTF-8: a\\n\", \"UTF-8: {u}\\n\", .{value});\n    }\n    {\n        const value: u21 = 0x1F310;\n        try expectFmt(\"UTF-8: \\n\", \"UTF-8: {u}\\n\", .{value});\n    }\n    {\n        const value: u21 = 0xD800;\n        try expectFmt(\"UTF-8: \\n\", \"UTF-8: {u}\\n\", .{value});\n    }\n    {\n        const value: u21 = 0x110001;\n        try expectFmt(\"UTF-8: \\n\", \"UTF-8: {u}\\n\", .{value});\n    }\n}\n\ntest \"int.padded\" {\n    try expectFmt(\"u8: '   1'\", \"u8: '{:4}'\", .{@as(u8, 1)});\n    try expectFmt(\"u8: '1000'\", \"u8: '{:0<4}'\", .{@as(u8, 1)});\n    try expectFmt(\"u8: '0001'\", \"u8: '{:0>4}'\", .{@as(u8, 1)});\n    try expectFmt(\"u8: '0100'\", \"u8: '{:0^4}'\", .{@as(u8, 1)});\n    try expectFmt(\"i8: '-1  '\", \"i8: '{:<4}'\", .{@as(i8, -1)});\n    try expectFmt(\"i8: '  -1'\", \"i8: '{:>4}'\", .{@as(i8, -1)});\n    try expectFmt(\"i8: ' -1 '\", \"i8: '{:^4}'\", .{@as(i8, -1)});\n    try expectFmt(\"i16: '-1234'\", \"i16: '{:4}'\", .{@as(i16, -1234)});\n    try expectFmt(\"i16: '+1234'\", \"i16: '{:4}'\", .{@as(i16, 1234)});\n    try expectFmt(\"i16: '-12345'\", \"i16: '{:4}'\", .{@as(i16, -12345)});\n    try expectFmt(\"i16: '+12345'\", \"i16: '{:4}'\", .{@as(i16, 12345)});\n    try expectFmt(\"u16: '12345'\", \"u16: '{:4}'\", .{@as(u16, 12345)});\n\n    try expectFmt(\"UTF-8: '   '\", \"UTF-8: '{u:<4}'\", .{''});\n    try expectFmt(\"UTF-8: '   '\", \"UTF-8: '{u:>4}'\", .{''});\n    try expectFmt(\"UTF-8: '   '\", \"UTF-8: '{u:^4}'\", .{''});\n}\n\ntest \"buffer\" {\n    {\n        var buf1: [32]u8 = undefined;\n        var fbs = std.io.fixedBufferStream(&buf1);\n        try formatType(1234, \"\", FormatOptions{}, fbs.writer(), std.options.fmt_max_depth);\n        try std.testing.expectEqualStrings(\"1234\", fbs.getWritten());\n\n        fbs.reset();\n        try formatType('a', \"c\", FormatOptions{}, fbs.writer(), std.options.fmt_max_depth);\n        try std.testing.expectEqualStrings(\"a\", fbs.getWritten());\n\n        fbs.reset();\n        try formatType(0b1100, \"b\", FormatOptions{}, fbs.writer(), std.options.fmt_max_depth);\n        try std.testing.expectEqualStrings(\"1100\", fbs.getWritten());\n    }\n}\n\n// Test formatting of arrays by value, by single-item pointer, and as a slice\nfn expectArrayFmt(expected: []const u8, comptime template: []const u8, comptime array_value: anytype) !void {\n    try expectFmt(expected, template, .{array_value});\n    try expectFmt(expected, template, .{&array_value});\n    var runtime_zero: usize = 0;\n    _ = &runtime_zero;\n    try expectFmt(expected, template, .{array_value[runtime_zero..]});\n}\n\ntest \"array\" {\n    {\n        const value: [3]u8 = \"abc\".*;\n        try expectArrayFmt(\"array: abc\\n\", \"array: {s}\\n\", value);\n        try expectArrayFmt(\"array: { 97, 98, 99 }\\n\", \"array: {d}\\n\", value);\n        try expectArrayFmt(\"array: { 61, 62, 63 }\\n\", \"array: {x}\\n\", value);\n        try expectArrayFmt(\"array: { 97, 98, 99 }\\n\", \"array: {any}\\n\", value);\n\n        var buf: [100]u8 = undefined;\n        try expectFmt(\n            try bufPrint(buf[0..], \"array: [3]u8@{x}\\n\", .{@intFromPtr(&value)}),\n            \"array: {*}\\n\",\n            .{&value},\n        );\n    }\n\n    {\n        const value = [2][3]u8{ \"abc\".*, \"def\".* };\n\n        try expectArrayFmt(\"array: { abc, def }\\n\", \"array: {s}\\n\", value);\n        try expectArrayFmt(\"array: { { 97, 98, 99 }, { 100, 101, 102 } }\\n\", \"array: {d}\\n\", value);\n        try expectArrayFmt(\"array: { { 61, 62, 63 }, { 64, 65, 66 } }\\n\", \"array: {x}\\n\", value);\n    }\n}\n\ntest \"slice\" {\n    {\n        const value: []const u8 = \"abc\";\n        try expectFmt(\"slice: abc\\n\", \"slice: {s}\\n\", .{value});\n        try expectFmt(\"slice: { 97, 98, 99 }\\n\", \"slice: {d}\\n\", .{value});\n        try expectFmt(\"slice: { 61, 62, 63 }\\n\", \"slice: {x}\\n\", .{value});\n        try expectFmt(\"slice: { 97, 98, 99 }\\n\", \"slice: {any}\\n\", .{value});\n    }\n    {\n        var runtime_zero: usize = 0;\n        _ = &runtime_zero;\n        const value = @as([*]align(1) const []const u8, @ptrFromInt(0xdeadbeef))[runtime_zero..runtime_zero];\n        try expectFmt(\"slice: []const u8@deadbeef\\n\", \"slice: {*}\\n\", .{value});\n    }\n    {\n        const null_term_slice: [:0]const u8 = \"\\x00hello\\x00\";\n        try expectFmt(\"buf: \\x00hello\\x00\\n\", \"buf: {s}\\n\", .{null_term_slice});\n    }\n\n    try expectFmt(\"buf:  Test\\n\", \"buf: {s:5}\\n\", .{\"Test\"});\n    try expectFmt(\"buf: Test\\n Other text\", \"buf: {s}\\n Other text\", .{\"Test\"});\n\n    {\n        var int_slice = [_]u32{ 1, 4096, 391891, 1111111111 };\n        var runtime_zero: usize = 0;\n        _ = &runtime_zero;\n        try expectFmt(\"int: { 1, 4096, 391891, 1111111111 }\", \"int: {any}\", .{int_slice[runtime_zero..]});\n        try expectFmt(\"int: { 1, 4096, 391891, 1111111111 }\", \"int: {d}\", .{int_slice[runtime_zero..]});\n        try expectFmt(\"int: { 1, 1000, 5fad3, 423a35c7 }\", \"int: {x}\", .{int_slice[runtime_zero..]});\n        try expectFmt(\"int: { 00001, 01000, 5fad3, 423a35c7 }\", \"int: {x:0>5}\", .{int_slice[runtime_zero..]});\n    }\n    {\n        const S1 = struct {\n            x: u8,\n        };\n        const struct_slice: []const S1 = &[_]S1{ S1{ .x = 8 }, S1{ .x = 42 } };\n        try expectFmt(\"slice: { fmt.test.slice.S1{ .x = 8 }, fmt.test.slice.S1{ .x = 42 } }\", \"slice: {any}\", .{struct_slice});\n    }\n    {\n        const S2 = struct {\n            x: u8,\n\n            pub fn format(s: @This(), comptime _: []const u8, _: std.fmt.FormatOptions, writer: anytype) !void {\n                try writer.print(\"S2({})\", .{s.x});\n            }\n        };\n        const struct_slice: []const S2 = &[_]S2{ S2{ .x = 8 }, S2{ .x = 42 } };\n        try expectFmt(\"slice: { S2(8), S2(42) }\", \"slice: {any}\", .{struct_slice});\n    }\n}\n\ntest \"escape non-printable\" {\n    try expectFmt(\"abc 123\", \"{s}\", .{fmtSliceEscapeLower(\"abc 123\")});\n    try expectFmt(\"ab\\\\xffc\", \"{s}\", .{fmtSliceEscapeLower(\"ab\\xffc\")});\n    try expectFmt(\"abc 123\", \"{s}\", .{fmtSliceEscapeUpper(\"abc 123\")});\n    try expectFmt(\"ab\\\\xFFc\", \"{s}\", .{fmtSliceEscapeUpper(\"ab\\xffc\")});\n}\n\ntest \"pointer\" {\n    {\n        const value = @as(*align(1) i32, @ptrFromInt(0xdeadbeef));\n        try expectFmt(\"pointer: i32@deadbeef\\n\", \"pointer: {}\\n\", .{value});\n        try expectFmt(\"pointer: i32@deadbeef\\n\", \"pointer: {*}\\n\", .{value});\n    }\n    const FnPtr = *align(1) const fn () void;\n    {\n        const value = @as(FnPtr, @ptrFromInt(0xdeadbeef));\n        try expectFmt(\"pointer: fn () void@deadbeef\\n\", \"pointer: {}\\n\", .{value});\n    }\n    {\n        const value = @as(FnPtr, @ptrFromInt(0xdeadbeef));\n        try expectFmt(\"pointer: fn () void@deadbeef\\n\", \"pointer: {}\\n\", .{value});\n    }\n}\n\ntest \"cstr\" {\n    try expectFmt(\n        \"cstr: Test C\\n\",\n        \"cstr: {s}\\n\",\n        .{@as([*c]const u8, @ptrCast(\"Test C\"))},\n    );\n    try expectFmt(\n        \"cstr:     Test C\\n\",\n        \"cstr: {s:10}\\n\",\n        .{@as([*c]const u8, @ptrCast(\"Test C\"))},\n    );\n}\n\ntest \"filesize\" {\n    try expectFmt(\"file size: 42B\\n\", \"file size: {}\\n\", .{fmtIntSizeDec(42)});\n    try expectFmt(\"file size: 42B\\n\", \"file size: {}\\n\", .{fmtIntSizeBin(42)});\n    try expectFmt(\"file size: 63MB\\n\", \"file size: {}\\n\", .{fmtIntSizeDec(63 * 1000 * 1000)});\n    try expectFmt(\"file size: 63MiB\\n\", \"file size: {}\\n\", .{fmtIntSizeBin(63 * 1024 * 1024)});\n    try expectFmt(\"file size: 42B\\n\", \"file size: {:.2}\\n\", .{fmtIntSizeDec(42)});\n    try expectFmt(\"file size:       42B\\n\", \"file size: {:>9.2}\\n\", .{fmtIntSizeDec(42)});\n    try expectFmt(\"file size: 66.06MB\\n\", \"file size: {:.2}\\n\", .{fmtIntSizeDec(63 * 1024 * 1024)});\n    try expectFmt(\"file size: 60.08MiB\\n\", \"file size: {:.2}\\n\", .{fmtIntSizeBin(63 * 1000 * 1000)});\n    try expectFmt(\"file size: =66.06MB=\\n\", \"file size: {:=^9.2}\\n\", .{fmtIntSizeDec(63 * 1024 * 1024)});\n    try expectFmt(\"file size:   66.06MB\\n\", \"file size: {: >9.2}\\n\", .{fmtIntSizeDec(63 * 1024 * 1024)});\n    try expectFmt(\"file size: 66.06MB  \\n\", \"file size: {: <9.2}\\n\", .{fmtIntSizeDec(63 * 1024 * 1024)});\n    try expectFmt(\"file size: 0.01844674407370955ZB\\n\", \"file size: {}\\n\", .{fmtIntSizeDec(math.maxInt(u64))});\n}\n\ntest \"struct\" {\n    {\n        const Struct = struct {\n            field: u8,\n        };\n        const value = Struct{ .field = 42 };\n        try expectFmt(\"struct: fmt.test.struct.Struct{ .field = 42 }\\n\", \"struct: {}\\n\", .{value});\n        try expectFmt(\"struct: fmt.test.struct.Struct{ .field = 42 }\\n\", \"struct: {}\\n\", .{&value});\n    }\n    {\n        const Struct = struct {\n            a: u0,\n            b: u1,\n        };\n        const value = Struct{ .a = 0, .b = 1 };\n        try expectFmt(\"struct: fmt.test.struct.Struct{ .a = 0, .b = 1 }\\n\", \"struct: {}\\n\", .{value});\n    }\n\n    const S = struct {\n        a: u32,\n        b: anyerror,\n    };\n\n    const inst = S{\n        .a = 456,\n        .b = error.Unused,\n    };\n\n    try expectFmt(\"fmt.test.struct.S{ .a = 456, .b = error.Unused }\", \"{}\", .{inst});\n    // Tuples\n    try expectFmt(\"{ }\", \"{}\", .{.{}});\n    try expectFmt(\"{ -1 }\", \"{}\", .{.{-1}});\n    try expectFmt(\"{ -1, 42, 2.5e4 }\", \"{}\", .{.{ -1, 42, 0.25e5 }});\n}\n\ntest \"enum\" {\n    const Enum = enum {\n        One,\n        Two,\n    };\n    const value = Enum.Two;\n    try expectFmt(\"enum: fmt.test.enum.Enum.Two\\n\", \"enum: {}\\n\", .{value});\n    try expectFmt(\"enum: fmt.test.enum.Enum.Two\\n\", \"enum: {}\\n\", .{&value});\n    try expectFmt(\"enum: fmt.test.enum.Enum.One\\n\", \"enum: {}\\n\", .{Enum.One});\n    try expectFmt(\"enum: fmt.test.enum.Enum.Two\\n\", \"enum: {}\\n\", .{Enum.Two});\n\n    // test very large enum to verify ct branch quota is large enough\n    // TODO: https://github.com/ziglang/zig/issues/15609\n    if (!((builtin.cpu.arch == .wasm32) and builtin.mode == .Debug)) {\n        try expectFmt(\"enum: os.windows.win32error.Win32Error.INVALID_FUNCTION\\n\", \"enum: {}\\n\", .{std.os.windows.Win32Error.INVALID_FUNCTION});\n    }\n\n    const E = enum {\n        One,\n        Two,\n        Three,\n    };\n\n    const inst = E.Two;\n\n    try expectFmt(\"fmt.test.enum.E.Two\", \"{}\", .{inst});\n}\n\ntest \"non-exhaustive enum\" {\n    const Enum = enum(u16) {\n        One = 0x000f,\n        Two = 0xbeef,\n        _,\n    };\n    try expectFmt(\"enum: fmt.test.non-exhaustive enum.Enum.One\\n\", \"enum: {}\\n\", .{Enum.One});\n    try expectFmt(\"enum: fmt.test.non-exhaustive enum.Enum.Two\\n\", \"enum: {}\\n\", .{Enum.Two});\n    try expectFmt(\"enum: fmt.test.non-exhaustive enum.Enum(4660)\\n\", \"enum: {}\\n\", .{@as(Enum, @enumFromInt(0x1234))});\n    try expectFmt(\"enum: fmt.test.non-exhaustive enum.Enum.One\\n\", \"enum: {x}\\n\", .{Enum.One});\n    try expectFmt(\"enum: fmt.test.non-exhaustive enum.Enum.Two\\n\", \"enum: {x}\\n\", .{Enum.Two});\n    try expectFmt(\"enum: fmt.test.non-exhaustive enum.Enum.Two\\n\", \"enum: {X}\\n\", .{Enum.Two});\n    try expectFmt(\"enum: fmt.test.non-exhaustive enum.Enum(1234)\\n\", \"enum: {x}\\n\", .{@as(Enum, @enumFromInt(0x1234))});\n}\n\ntest \"float.scientific\" {\n    try expectFmt(\"f32: 1.34e0\", \"f32: {e}\", .{@as(f32, 1.34)});\n    try expectFmt(\"f32: 1.234e1\", \"f32: {e}\", .{@as(f32, 12.34)});\n    try expectFmt(\"f64: -1.234e11\", \"f64: {e}\", .{@as(f64, -12.34e10)});\n    try expectFmt(\"f64: 9.99996e-40\", \"f64: {e}\", .{@as(f64, 9.999960e-40)});\n}\n\ntest \"float.scientific.precision\" {\n    try expectFmt(\"f64: 1.40971e-42\", \"f64: {e:.5}\", .{@as(f64, 1.409706e-42)});\n    try expectFmt(\"f64: 1.00000e-9\", \"f64: {e:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 814313563))))});\n    try expectFmt(\"f64: 7.81250e-3\", \"f64: {e:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 1006632960))))});\n    // libc rounds 1.000005e5 to 1.00000e5 but zig does 1.00001e5.\n    // In fact, libc doesn't round a lot of 5 cases up when one past the precision point.\n    try expectFmt(\"f64: 1.00001e5\", \"f64: {e:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 1203982400))))});\n}\n\ntest \"float.special\" {\n    try expectFmt(\"f64: nan\", \"f64: {}\", .{math.nan(f64)});\n    // negative nan is not defined by IEE 754,\n    // and ARM thus normalizes it to positive nan\n    if (builtin.target.cpu.arch != .arm) {\n        try expectFmt(\"f64: -nan\", \"f64: {}\", .{-math.nan(f64)});\n    }\n    try expectFmt(\"f64: inf\", \"f64: {}\", .{math.inf(f64)});\n    try expectFmt(\"f64: -inf\", \"f64: {}\", .{-math.inf(f64)});\n}\n\ntest \"float.hexadecimal.special\" {\n    try expectFmt(\"f64: nan\", \"f64: {x}\", .{math.nan(f64)});\n    // negative nan is not defined by IEE 754,\n    // and ARM thus normalizes it to positive nan\n    if (builtin.target.cpu.arch != .arm) {\n        try expectFmt(\"f64: -nan\", \"f64: {x}\", .{-math.nan(f64)});\n    }\n    try expectFmt(\"f64: inf\", \"f64: {x}\", .{math.inf(f64)});\n    try expectFmt(\"f64: -inf\", \"f64: {x}\", .{-math.inf(f64)});\n\n    try expectFmt(\"f64: 0x0.0p0\", \"f64: {x}\", .{@as(f64, 0)});\n    try expectFmt(\"f64: -0x0.0p0\", \"f64: {x}\", .{-@as(f64, 0)});\n}\n\ntest \"float.hexadecimal\" {\n    try expectFmt(\"f16: 0x1.554p-2\", \"f16: {x}\", .{@as(f16, 1.0 / 3.0)});\n    try expectFmt(\"f32: 0x1.555556p-2\", \"f32: {x}\", .{@as(f32, 1.0 / 3.0)});\n    try expectFmt(\"f64: 0x1.5555555555555p-2\", \"f64: {x}\", .{@as(f64, 1.0 / 3.0)});\n    try expectFmt(\"f80: 0x1.5555555555555556p-2\", \"f80: {x}\", .{@as(f80, 1.0 / 3.0)});\n    try expectFmt(\"f128: 0x1.5555555555555555555555555555p-2\", \"f128: {x}\", .{@as(f128, 1.0 / 3.0)});\n\n    try expectFmt(\"f16: 0x1p-14\", \"f16: {x}\", .{math.floatMin(f16)});\n    try expectFmt(\"f32: 0x1p-126\", \"f32: {x}\", .{math.floatMin(f32)});\n    try expectFmt(\"f64: 0x1p-1022\", \"f64: {x}\", .{math.floatMin(f64)});\n    try expectFmt(\"f80: 0x1p-16382\", \"f80: {x}\", .{math.floatMin(f80)});\n    try expectFmt(\"f128: 0x1p-16382\", \"f128: {x}\", .{math.floatMin(f128)});\n\n    try expectFmt(\"f16: 0x0.004p-14\", \"f16: {x}\", .{math.floatTrueMin(f16)});\n    try expectFmt(\"f32: 0x0.000002p-126\", \"f32: {x}\", .{math.floatTrueMin(f32)});\n    try expectFmt(\"f64: 0x0.0000000000001p-1022\", \"f64: {x}\", .{math.floatTrueMin(f64)});\n    try expectFmt(\"f80: 0x0.0000000000000002p-16382\", \"f80: {x}\", .{math.floatTrueMin(f80)});\n    try expectFmt(\"f128: 0x0.0000000000000000000000000001p-16382\", \"f128: {x}\", .{math.floatTrueMin(f128)});\n\n    try expectFmt(\"f16: 0x1.ffcp15\", \"f16: {x}\", .{math.floatMax(f16)});\n    try expectFmt(\"f32: 0x1.fffffep127\", \"f32: {x}\", .{math.floatMax(f32)});\n    try expectFmt(\"f64: 0x1.fffffffffffffp1023\", \"f64: {x}\", .{math.floatMax(f64)});\n    try expectFmt(\"f80: 0x1.fffffffffffffffep16383\", \"f80: {x}\", .{math.floatMax(f80)});\n    try expectFmt(\"f128: 0x1.ffffffffffffffffffffffffffffp16383\", \"f128: {x}\", .{math.floatMax(f128)});\n}\n\ntest \"float.hexadecimal.precision\" {\n    try expectFmt(\"f16: 0x1.5p-2\", \"f16: {x:.1}\", .{@as(f16, 1.0 / 3.0)});\n    try expectFmt(\"f32: 0x1.555p-2\", \"f32: {x:.3}\", .{@as(f32, 1.0 / 3.0)});\n    try expectFmt(\"f64: 0x1.55555p-2\", \"f64: {x:.5}\", .{@as(f64, 1.0 / 3.0)});\n    try expectFmt(\"f80: 0x1.5555555p-2\", \"f80: {x:.7}\", .{@as(f80, 1.0 / 3.0)});\n    try expectFmt(\"f128: 0x1.555555555p-2\", \"f128: {x:.9}\", .{@as(f128, 1.0 / 3.0)});\n\n    try expectFmt(\"f16: 0x1.00000p0\", \"f16: {x:.5}\", .{@as(f16, 1.0)});\n    try expectFmt(\"f32: 0x1.00000p0\", \"f32: {x:.5}\", .{@as(f32, 1.0)});\n    try expectFmt(\"f64: 0x1.00000p0\", \"f64: {x:.5}\", .{@as(f64, 1.0)});\n    try expectFmt(\"f80: 0x1.00000p0\", \"f80: {x:.5}\", .{@as(f80, 1.0)});\n    try expectFmt(\"f128: 0x1.00000p0\", \"f128: {x:.5}\", .{@as(f128, 1.0)});\n}\n\ntest \"float.decimal\" {\n    try expectFmt(\"f64: 152314000000000000000000000000\", \"f64: {d}\", .{@as(f64, 1.52314e29)});\n    try expectFmt(\"f32: 0\", \"f32: {d}\", .{@as(f32, 0.0)});\n    try expectFmt(\"f32: 0\", \"f32: {d:.0}\", .{@as(f32, 0.0)});\n    try expectFmt(\"f32: 1.1\", \"f32: {d:.1}\", .{@as(f32, 1.1234)});\n    try expectFmt(\"f32: 1234.57\", \"f32: {d:.2}\", .{@as(f32, 1234.567)});\n    // -11.1234 is converted to f64 -11.12339... internally (errol3() function takes f64).\n    // -11.12339... is rounded back up to -11.1234\n    try expectFmt(\"f32: -11.1234\", \"f32: {d:.4}\", .{@as(f32, -11.1234)});\n    try expectFmt(\"f32: 91.12345\", \"f32: {d:.5}\", .{@as(f32, 91.12345)});\n    try expectFmt(\"f64: 91.1234567890\", \"f64: {d:.10}\", .{@as(f64, 91.12345678901235)});\n    try expectFmt(\"f64: 0.00000\", \"f64: {d:.5}\", .{@as(f64, 0.0)});\n    try expectFmt(\"f64: 6\", \"f64: {d:.0}\", .{@as(f64, 5.700)});\n    try expectFmt(\"f64: 10.0\", \"f64: {d:.1}\", .{@as(f64, 9.999)});\n    try expectFmt(\"f64: 1.000\", \"f64: {d:.3}\", .{@as(f64, 1.0)});\n    try expectFmt(\"f64: 0.00030000\", \"f64: {d:.8}\", .{@as(f64, 0.0003)});\n    try expectFmt(\"f64: 0.00000\", \"f64: {d:.5}\", .{@as(f64, 1.40130e-45)});\n    try expectFmt(\"f64: 0.00000\", \"f64: {d:.5}\", .{@as(f64, 9.999960e-40)});\n    try expectFmt(\"f64: 10000000000000.00\", \"f64: {d:.2}\", .{@as(f64, 9999999999999.999)});\n    try expectFmt(\"f64: 10000000000000000000000000000000000000\", \"f64: {d}\", .{@as(f64, 1e37)});\n    try expectFmt(\"f64: 100000000000000000000000000000000000000\", \"f64: {d}\", .{@as(f64, 1e38)});\n}\n\ntest \"float.libc.sanity\" {\n    try expectFmt(\"f64: 0.00001\", \"f64: {d:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 916964781))))});\n    try expectFmt(\"f64: 0.00001\", \"f64: {d:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 925353389))))});\n    try expectFmt(\"f64: 0.10000\", \"f64: {d:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 1036831278))))});\n    try expectFmt(\"f64: 1.00000\", \"f64: {d:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 1065353133))))});\n    try expectFmt(\"f64: 10.00000\", \"f64: {d:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 1092616192))))});\n\n    // libc differences\n    //\n    // This is 0.015625 exactly according to gdb. We thus round down,\n    // however glibc rounds up for some reason. This occurs for all\n    // floats of the form x.yyyy25 on a precision point.\n    try expectFmt(\"f64: 0.01563\", \"f64: {d:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 1015021568))))});\n    // errol3 rounds to ... 630 but libc rounds to ...632. Grisu3\n    // also rounds to 630 so I'm inclined to believe libc is not\n    // optimal here.\n    try expectFmt(\"f64: 18014400656965630.00000\", \"f64: {d:.5}\", .{@as(f64, @as(f32, @bitCast(@as(u32, 1518338049))))});\n}\n\ntest \"custom\" {\n    const Vec2 = struct {\n        const SelfType = @This();\n        x: f32,\n        y: f32,\n\n        pub fn format(\n            self: SelfType,\n            comptime fmt: []const u8,\n            options: FormatOptions,\n            writer: anytype,\n        ) !void {\n            _ = options;\n            if (fmt.len == 0 or comptime std.mem.eql(u8, fmt, \"p\")) {\n                return std.fmt.format(writer, \"({d:.3},{d:.3})\", .{ self.x, self.y });\n            } else if (comptime std.mem.eql(u8, fmt, \"d\")) {\n                return std.fmt.format(writer, \"{d:.3}x{d:.3}\", .{ self.x, self.y });\n            } else {\n                @compileError(\"unknown format character: '\" ++ fmt ++ \"'\");\n            }\n        }\n    };\n\n    var value = Vec2{\n        .x = 10.2,\n        .y = 2.22,\n    };\n    try expectFmt(\"point: (10.200,2.220)\\n\", \"point: {}\\n\", .{&value});\n    try expectFmt(\"dim: 10.200x2.220\\n\", \"dim: {d}\\n\", .{&value});\n\n    // same thing but not passing a pointer\n    try expectFmt(\"point: (10.200,2.220)\\n\", \"point: {}\\n\", .{value});\n    try expectFmt(\"dim: 10.200x2.220\\n\", \"dim: {d}\\n\", .{value});\n}\n\ntest \"union\" {\n    const TU = union(enum) {\n        float: f32,\n        int: u32,\n    };\n\n    const UU = union {\n        float: f32,\n        int: u32,\n    };\n\n    const EU = extern union {\n        float: f32,\n        int: u32,\n    };\n\n    const tu_inst = TU{ .int = 123 };\n    const uu_inst = UU{ .int = 456 };\n    const eu_inst = EU{ .float = 321.123 };\n\n    try expectFmt(\"fmt.test.union.TU{ .int = 123 }\", \"{}\", .{tu_inst});\n\n    var buf: [100]u8 = undefined;\n    const uu_result = try bufPrint(buf[0..], \"{}\", .{uu_inst});\n    try std.testing.expectEqualStrings(\"fmt.test.union.UU@\", uu_result[0..18]);\n\n    const eu_result = try bufPrint(buf[0..], \"{}\", .{eu_inst});\n    try std.testing.expectEqualStrings(\"fmt.test.union.EU@\", eu_result[0..18]);\n}\n\ntest \"struct.self-referential\" {\n    const S = struct {\n        const SelfType = @This();\n        a: ?*SelfType,\n    };\n\n    var inst = S{\n        .a = null,\n    };\n    inst.a = &inst;\n\n    try expectFmt(\"fmt.test.struct.self-referential.S{ .a = fmt.test.struct.self-referential.S{ .a = fmt.test.struct.self-referential.S{ .a = fmt.test.struct.self-referential.S{ ... } } } }\", \"{}\", .{inst});\n}\n\ntest \"struct.zero-size\" {\n    const A = struct {\n        fn foo() void {}\n    };\n    const B = struct {\n        a: A,\n        c: i32,\n    };\n\n    const a = A{};\n    const b = B{ .a = a, .c = 0 };\n\n    try expectFmt(\"fmt.test.struct.zero-size.B{ .a = fmt.test.struct.zero-size.A{ }, .c = 0 }\", \"{}\", .{b});\n}\n\ntest \"bytes.hex\" {\n    const some_bytes = \"\\xCA\\xFE\\xBA\\xBE\";\n    try expectFmt(\"lowercase: cafebabe\\n\", \"lowercase: {x}\\n\", .{fmtSliceHexLower(some_bytes)});\n    try expectFmt(\"uppercase: CAFEBABE\\n\", \"uppercase: {X}\\n\", .{fmtSliceHexUpper(some_bytes)});\n    //Test Slices\n    try expectFmt(\"uppercase: CAFE\\n\", \"uppercase: {X}\\n\", .{fmtSliceHexUpper(some_bytes[0..2])});\n    try expectFmt(\"lowercase: babe\\n\", \"lowercase: {x}\\n\", .{fmtSliceHexLower(some_bytes[2..])});\n    const bytes_with_zeros = \"\\x00\\x0E\\xBA\\xBE\";\n    try expectFmt(\"lowercase: 000ebabe\\n\", \"lowercase: {x}\\n\", .{fmtSliceHexLower(bytes_with_zeros)});\n}\n\n/// Encodes a sequence of bytes as hexadecimal digits.\n/// Returns an array containing the encoded bytes.\npub fn bytesToHex(input: anytype, case: Case) [input.len * 2]u8 {\n    if (input.len == 0) return [_]u8{};\n    comptime assert(@TypeOf(input[0]) == u8); // elements to encode must be unsigned bytes\n\n    const charset = \"0123456789\" ++ if (case == .upper) \"ABCDEF\" else \"abcdef\";\n    var result: [input.len * 2]u8 = undefined;\n    for (input, 0..) |b, i| {\n        result[i * 2 + 0] = charset[b >> 4];\n        result[i * 2 + 1] = charset[b & 15];\n    }\n    return result;\n}\n\n/// Decodes the sequence of bytes represented by the specified string of\n/// hexadecimal characters.\n/// Returns a slice of the output buffer containing the decoded bytes.\npub fn hexToBytes(out: []u8, input: []const u8) ![]u8 {\n    // Expect 0 or n pairs of hexadecimal digits.\n    if (input.len & 1 != 0)\n        return error.InvalidLength;\n    if (out.len * 2 < input.len)\n        return error.NoSpaceLeft;\n\n    var in_i: usize = 0;\n    while (in_i < input.len) : (in_i += 2) {\n        const hi = try charToDigit(input[in_i], 16);\n        const lo = try charToDigit(input[in_i + 1], 16);\n        out[in_i / 2] = (hi << 4) | lo;\n    }\n\n    return out[0 .. in_i / 2];\n}\n\ntest bytesToHex {\n    const input = \"input slice\";\n    const encoded = bytesToHex(input, .lower);\n    var decoded: [input.len]u8 = undefined;\n    try std.testing.expectEqualSlices(u8, input, try hexToBytes(&decoded, &encoded));\n}\n\ntest hexToBytes {\n    var buf: [32]u8 = undefined;\n    try expectFmt(\"90\" ** 32, \"{s}\", .{fmtSliceHexUpper(try hexToBytes(&buf, \"90\" ** 32))});\n    try expectFmt(\"ABCD\", \"{s}\", .{fmtSliceHexUpper(try hexToBytes(&buf, \"ABCD\"))});\n    try expectFmt(\"\", \"{s}\", .{fmtSliceHexUpper(try hexToBytes(&buf, \"\"))});\n    try std.testing.expectError(error.InvalidCharacter, hexToBytes(&buf, \"012Z\"));\n    try std.testing.expectError(error.InvalidLength, hexToBytes(&buf, \"AAA\"));\n    try std.testing.expectError(error.NoSpaceLeft, hexToBytes(buf[0..1], \"ABAB\"));\n}\n\ntest \"formatIntValue with comptime_int\" {\n    const value: comptime_int = 123456789123456789;\n\n    var buf: [20]u8 = undefined;\n    var fbs = std.io.fixedBufferStream(&buf);\n    try formatIntValue(value, \"\", FormatOptions{}, fbs.writer());\n    try std.testing.expectEqualStrings(\"123456789123456789\", fbs.getWritten());\n}\n\ntest \"formatFloatValue with comptime_float\" {\n    const value: comptime_float = 1.0;\n\n    var buf: [20]u8 = undefined;\n    var fbs = std.io.fixedBufferStream(&buf);\n    try formatFloatValue(value, \"\", FormatOptions{}, fbs.writer());\n    try std.testing.expectEqualStrings(fbs.getWritten(), \"1e0\");\n\n    try expectFmt(\"1e0\", \"{}\", .{value});\n    try expectFmt(\"1e0\", \"{}\", .{1.0});\n}\n\ntest \"formatType max_depth\" {\n    const Vec2 = struct {\n        const SelfType = @This();\n        x: f32,\n        y: f32,\n\n        pub fn format(\n            self: SelfType,\n            comptime fmt: []const u8,\n            options: FormatOptions,\n            writer: anytype,\n        ) !void {\n            _ = options;\n            if (fmt.len == 0) {\n                return std.fmt.format(writer, \"({d:.3},{d:.3})\", .{ self.x, self.y });\n            } else {\n                @compileError(\"unknown format string: '\" ++ fmt ++ \"'\");\n            }\n        }\n    };\n    const E = enum {\n        One,\n        Two,\n        Three,\n    };\n    const TU = union(enum) {\n        const SelfType = @This();\n        float: f32,\n        int: u32,\n        ptr: ?*SelfType,\n    };\n    const S = struct {\n        const SelfType = @This();\n        a: ?*SelfType,\n        tu: TU,\n        e: E,\n        vec: Vec2,\n    };\n\n    var inst = S{\n        .a = null,\n        .tu = TU{ .ptr = null },\n        .e = E.Two,\n        .vec = Vec2{ .x = 10.2, .y = 2.22 },\n    };\n    inst.a = &inst;\n    inst.tu.ptr = &inst.tu;\n\n    var buf: [1000]u8 = undefined;\n    var fbs = std.io.fixedBufferStream(&buf);\n    try formatType(inst, \"\", FormatOptions{}, fbs.writer(), 0);\n    try std.testing.expectEqualStrings(\"fmt.test.formatType max_depth.S{ ... }\", fbs.getWritten());\n\n    fbs.reset();\n    try formatType(inst, \"\", FormatOptions{}, fbs.writer(), 1);\n    try std.testing.expectEqualStrings(\"fmt.test.formatType max_depth.S{ .a = fmt.test.formatType max_depth.S{ ... }, .tu = fmt.test.formatType max_depth.TU{ ... }, .e = fmt.test.formatType max_depth.E.Two, .vec = (10.200,2.220) }\", fbs.getWritten());\n\n    fbs.reset();\n    try formatType(inst, \"\", FormatOptions{}, fbs.writer(), 2);\n    try std.testing.expectEqualStrings(\"fmt.test.formatType max_depth.S{ .a = fmt.test.formatType max_depth.S{ .a = fmt.test.formatType max_depth.S{ ... }, .tu = fmt.test.formatType max_depth.TU{ ... }, .e = fmt.test.formatType max_depth.E.Two, .vec = (10.200,2.220) }, .tu = fmt.test.formatType max_depth.TU{ .ptr = fmt.test.formatType max_depth.TU{ ... } }, .e = fmt.test.formatType max_depth.E.Two, .vec = (10.200,2.220) }\", fbs.getWritten());\n\n    fbs.reset();\n    try formatType(inst, \"\", FormatOptions{}, fbs.writer(), 3);\n    try std.testing.expectEqualStrings(\"fmt.test.formatType max_depth.S{ .a = fmt.test.formatType max_depth.S{ .a = fmt.test.formatType max_depth.S{ .a = fmt.test.formatType max_depth.S{ ... }, .tu = fmt.test.formatType max_depth.TU{ ... }, .e = fmt.test.formatType max_depth.E.Two, .vec = (10.200,2.220) }, .tu = fmt.test.formatType max_depth.TU{ .ptr = fmt.test.formatType max_depth.TU{ ... } }, .e = fmt.test.formatType max_depth.E.Two, .vec = (10.200,2.220) }, .tu = fmt.test.formatType max_depth.TU{ .ptr = fmt.test.formatType max_depth.TU{ .ptr = fmt.test.formatType max_depth.TU{ ... } } }, .e = fmt.test.formatType max_depth.E.Two, .vec = (10.200,2.220) }\", fbs.getWritten());\n}\n\ntest \"positional\" {\n    try expectFmt(\"2 1 0\", \"{2} {1} {0}\", .{ @as(usize, 0), @as(usize, 1), @as(usize, 2) });\n    try expectFmt(\"2 1 0\", \"{2} {1} {}\", .{ @as(usize, 0), @as(usize, 1), @as(usize, 2) });\n    try expectFmt(\"0 0\", \"{0} {0}\", .{@as(usize, 0)});\n    try expectFmt(\"0 1\", \"{} {1}\", .{ @as(usize, 0), @as(usize, 1) });\n    try expectFmt(\"1 0 0 1\", \"{1} {} {0} {}\", .{ @as(usize, 0), @as(usize, 1) });\n}\n\ntest \"positional with specifier\" {\n    try expectFmt(\"10.0\", \"{0d:.1}\", .{@as(f64, 9.999)});\n}\n\ntest \"positional/alignment/width/precision\" {\n    try expectFmt(\"10.0\", \"{0d: >3.1}\", .{@as(f64, 9.999)});\n}\n\ntest \"vector\" {\n    if (builtin.target.cpu.arch == .riscv64) {\n        // https://github.com/ziglang/zig/issues/4486\n        return error.SkipZigTest;\n    }\n\n    const vbool: @Vector(4, bool) = [_]bool{ true, false, true, false };\n    const vi64: @Vector(4, i64) = [_]i64{ -2, -1, 0, 1 };\n    const vu64: @Vector(4, u64) = [_]u64{ 1000, 2000, 3000, 4000 };\n\n    try expectFmt(\"{ true, false, true, false }\", \"{}\", .{vbool});\n    try expectFmt(\"{ -2, -1, 0, 1 }\", \"{}\", .{vi64});\n    try expectFmt(\"{    -2,    -1,    +0,    +1 }\", \"{d:5}\", .{vi64});\n    try expectFmt(\"{ 1000, 2000, 3000, 4000 }\", \"{}\", .{vu64});\n    try expectFmt(\"{ 3e8, 7d0, bb8, fa0 }\", \"{x}\", .{vu64});\n}\n\ntest \"enum-literal\" {\n    try expectFmt(\".hello_world\", \"{}\", .{.hello_world});\n}\n\ntest \"padding\" {\n    try expectFmt(\"Simple\", \"{s}\", .{\"Simple\"});\n    try expectFmt(\"      true\", \"{:10}\", .{true});\n    try expectFmt(\"      true\", \"{:>10}\", .{true});\n    try expectFmt(\"======true\", \"{:=>10}\", .{true});\n    try expectFmt(\"true======\", \"{:=<10}\", .{true});\n    try expectFmt(\"   true   \", \"{:^10}\", .{true});\n    try expectFmt(\"===true===\", \"{:=^10}\", .{true});\n    try expectFmt(\"           Minimum width\", \"{s:18} width\", .{\"Minimum\"});\n    try expectFmt(\"==================Filled\", \"{s:=>24}\", .{\"Filled\"});\n    try expectFmt(\"        Centered        \", \"{s:^24}\", .{\"Centered\"});\n    try expectFmt(\"-\", \"{s:-^1}\", .{\"\"});\n    try expectFmt(\"==crpe===\", \"{s:=^10}\", .{\"crpe\"});\n    try expectFmt(\"=====crpe\", \"{s:=>10}\", .{\"crpe\"});\n    try expectFmt(\"crpe=====\", \"{s:=<10}\", .{\"crpe\"});\n    try expectFmt(\"====a\", \"{c:=>5}\", .{'a'});\n    try expectFmt(\"==a==\", \"{c:=^5}\", .{'a'});\n    try expectFmt(\"a====\", \"{c:=<5}\", .{'a'});\n}\n\ntest \"padding fill char utf\" {\n    try expectFmt(\"crpe\", \"{s:^10}\", .{\"crpe\"});\n    try expectFmt(\"crpe\", \"{s:>10}\", .{\"crpe\"});\n    try expectFmt(\"crpe\", \"{s:<10}\", .{\"crpe\"});\n    try expectFmt(\"a\", \"{c:>5}\", .{'a'});\n    try expectFmt(\"a\", \"{c:^5}\", .{'a'});\n    try expectFmt(\"a\", \"{c:<5}\", .{'a'});\n}\n\ntest \"decimal float padding\" {\n    const number: f32 = 3.1415;\n    try expectFmt(\"left-pad:   **3.142\\n\", \"left-pad:   {d:*>7.3}\\n\", .{number});\n    try expectFmt(\"center-pad: *3.142*\\n\", \"center-pad: {d:*^7.3}\\n\", .{number});\n    try expectFmt(\"right-pad:  3.142**\\n\", \"right-pad:  {d:*<7.3}\\n\", .{number});\n}\n\ntest \"sci float padding\" {\n    const number: f32 = 3.1415;\n    try expectFmt(\"left-pad:   ****3.142e0\\n\", \"left-pad:   {e:*>11.3}\\n\", .{number});\n    try expectFmt(\"center-pad: **3.142e0**\\n\", \"center-pad: {e:*^11.3}\\n\", .{number});\n    try expectFmt(\"right-pad:  3.142e0****\\n\", \"right-pad:  {e:*<11.3}\\n\", .{number});\n}\n\ntest \"null\" {\n    const inst = null;\n    try expectFmt(\"null\", \"{}\", .{inst});\n}\n\ntest \"type\" {\n    try expectFmt(\"u8\", \"{}\", .{u8});\n    try expectFmt(\"?f32\", \"{}\", .{?f32});\n    try expectFmt(\"[]const u8\", \"{}\", .{[]const u8});\n}\n\ntest \"named arguments\" {\n    try expectFmt(\"hello world!\", \"{s} world{c}\", .{ \"hello\", '!' });\n    try expectFmt(\"hello world!\", \"{[greeting]s} world{[punctuation]c}\", .{ .punctuation = '!', .greeting = \"hello\" });\n    try expectFmt(\"hello world!\", \"{[1]s} world{[0]c}\", .{ '!', \"hello\" });\n}\n\ntest \"runtime width specifier\" {\n    const width: usize = 9;\n    try expectFmt(\"~~hello~~\", \"{s:~^[1]}\", .{ \"hello\", width });\n    try expectFmt(\"~~hello~~\", \"{s:~^[width]}\", .{ .string = \"hello\", .width = width });\n    try expectFmt(\"    hello\", \"{s:[1]}\", .{ \"hello\", width });\n    try expectFmt(\"42     hello\", \"{d} {s:[2]}\", .{ 42, \"hello\", width });\n}\n\ntest \"runtime precision specifier\" {\n    const number: f32 = 3.1415;\n    const precision: usize = 2;\n    try expectFmt(\"3.14e0\", \"{:1.[1]}\", .{ number, precision });\n    try expectFmt(\"3.14e0\", \"{:1.[precision]}\", .{ .number = number, .precision = precision });\n}\n\ntest \"recursive format function\" {\n    const R = union(enum) {\n        const R = @This();\n        Leaf: i32,\n        Branch: struct { left: *const R, right: *const R },\n\n        pub fn format(self: R, comptime _: []const u8, _: std.fmt.FormatOptions, writer: anytype) !void {\n            return switch (self) {\n                .Leaf => |n| std.fmt.format(writer, \"Leaf({})\", .{n}),\n                .Branch => |b| std.fmt.format(writer, \"Branch({}, {})\", .{ b.left, b.right }),\n            };\n        }\n    };\n\n    var r = R{ .Leaf = 1 };\n    try expectFmt(\"Leaf(1)\\n\", \"{}\\n\", .{&r});\n}\n",
    "const std = @import(\"std.zig\");\nconst builtin = @import(\"builtin\");\nconst root = @import(\"root\");\nconst c = std.c;\nconst is_windows = builtin.os.tag == .windows;\nconst windows = std.os.windows;\nconst posix = std.posix;\n\nconst math = std.math;\nconst assert = std.debug.assert;\nconst fs = std.fs;\nconst mem = std.mem;\nconst meta = std.meta;\nconst File = std.fs.File;\nconst Allocator = std.mem.Allocator;\n\nfn getStdOutHandle() posix.fd_t {\n    if (is_windows) {\n        if (builtin.zig_backend == .stage2_aarch64) {\n            // TODO: this is just a temporary workaround until we advance aarch64 backend further along.\n            return windows.GetStdHandle(windows.STD_OUTPUT_HANDLE) catch windows.INVALID_HANDLE_VALUE;\n        }\n        return windows.peb().ProcessParameters.hStdOutput;\n    }\n\n    if (@hasDecl(root, \"os\") and @hasDecl(root.os, \"io\") and @hasDecl(root.os.io, \"getStdOutHandle\")) {\n        return root.os.io.getStdOutHandle();\n    }\n\n    return posix.STDOUT_FILENO;\n}\n\npub fn getStdOut() File {\n    return .{ .handle = getStdOutHandle() };\n}\n\nfn getStdErrHandle() posix.fd_t {\n    if (is_windows) {\n        if (builtin.zig_backend == .stage2_aarch64) {\n            // TODO: this is just a temporary workaround until we advance aarch64 backend further along.\n            return windows.GetStdHandle(windows.STD_ERROR_HANDLE) catch windows.INVALID_HANDLE_VALUE;\n        }\n        return windows.peb().ProcessParameters.hStdError;\n    }\n\n    if (@hasDecl(root, \"os\") and @hasDecl(root.os, \"io\") and @hasDecl(root.os.io, \"getStdErrHandle\")) {\n        return root.os.io.getStdErrHandle();\n    }\n\n    return posix.STDERR_FILENO;\n}\n\npub fn getStdErr() File {\n    return .{ .handle = getStdErrHandle() };\n}\n\nfn getStdInHandle() posix.fd_t {\n    if (is_windows) {\n        if (builtin.zig_backend == .stage2_aarch64) {\n            // TODO: this is just a temporary workaround until we advance aarch64 backend further along.\n            return windows.GetStdHandle(windows.STD_INPUT_HANDLE) catch windows.INVALID_HANDLE_VALUE;\n        }\n        return windows.peb().ProcessParameters.hStdInput;\n    }\n\n    if (@hasDecl(root, \"os\") and @hasDecl(root.os, \"io\") and @hasDecl(root.os.io, \"getStdInHandle\")) {\n        return root.os.io.getStdInHandle();\n    }\n\n    return posix.STDIN_FILENO;\n}\n\npub fn getStdIn() File {\n    return .{ .handle = getStdInHandle() };\n}\n\npub fn GenericReader(\n    comptime Context: type,\n    comptime ReadError: type,\n    /// Returns the number of bytes read. It may be less than buffer.len.\n    /// If the number of bytes read is 0, it means end of stream.\n    /// End of stream is not an error condition.\n    comptime readFn: fn (context: Context, buffer: []u8) ReadError!usize,\n) type {\n    return struct {\n        context: Context,\n\n        pub const Error = ReadError;\n        pub const NoEofError = ReadError || error{\n            EndOfStream,\n        };\n\n        pub inline fn read(self: Self, buffer: []u8) Error!usize {\n            return readFn(self.context, buffer);\n        }\n\n        pub inline fn readAll(self: Self, buffer: []u8) Error!usize {\n            return @errorCast(self.any().readAll(buffer));\n        }\n\n        pub inline fn readAtLeast(self: Self, buffer: []u8, len: usize) Error!usize {\n            return @errorCast(self.any().readAtLeast(buffer, len));\n        }\n\n        pub inline fn readNoEof(self: Self, buf: []u8) NoEofError!void {\n            return @errorCast(self.any().readNoEof(buf));\n        }\n\n        pub inline fn readAllArrayList(\n            self: Self,\n            array_list: *std.ArrayList(u8),\n            max_append_size: usize,\n        ) (error{StreamTooLong} || Allocator.Error || Error)!void {\n            return @errorCast(self.any().readAllArrayList(array_list, max_append_size));\n        }\n\n        pub inline fn readAllArrayListAligned(\n            self: Self,\n            comptime alignment: ?u29,\n            array_list: *std.ArrayListAligned(u8, alignment),\n            max_append_size: usize,\n        ) (error{StreamTooLong} || Allocator.Error || Error)!void {\n            return @errorCast(self.any().readAllArrayListAligned(\n                alignment,\n                array_list,\n                max_append_size,\n            ));\n        }\n\n        pub inline fn readAllAlloc(\n            self: Self,\n            allocator: Allocator,\n            max_size: usize,\n        ) (Error || Allocator.Error || error{StreamTooLong})![]u8 {\n            return @errorCast(self.any().readAllAlloc(allocator, max_size));\n        }\n\n        pub inline fn readUntilDelimiterArrayList(\n            self: Self,\n            array_list: *std.ArrayList(u8),\n            delimiter: u8,\n            max_size: usize,\n        ) (NoEofError || Allocator.Error || error{StreamTooLong})!void {\n            return @errorCast(self.any().readUntilDelimiterArrayList(\n                array_list,\n                delimiter,\n                max_size,\n            ));\n        }\n\n        pub inline fn readUntilDelimiterAlloc(\n            self: Self,\n            allocator: Allocator,\n            delimiter: u8,\n            max_size: usize,\n        ) (NoEofError || Allocator.Error || error{StreamTooLong})![]u8 {\n            return @errorCast(self.any().readUntilDelimiterAlloc(\n                allocator,\n                delimiter,\n                max_size,\n            ));\n        }\n\n        pub inline fn readUntilDelimiter(\n            self: Self,\n            buf: []u8,\n            delimiter: u8,\n        ) (NoEofError || error{StreamTooLong})![]u8 {\n            return @errorCast(self.any().readUntilDelimiter(buf, delimiter));\n        }\n\n        pub inline fn readUntilDelimiterOrEofAlloc(\n            self: Self,\n            allocator: Allocator,\n            delimiter: u8,\n            max_size: usize,\n        ) (Error || Allocator.Error || error{StreamTooLong})!?[]u8 {\n            return @errorCast(self.any().readUntilDelimiterOrEofAlloc(\n                allocator,\n                delimiter,\n                max_size,\n            ));\n        }\n\n        pub inline fn readUntilDelimiterOrEof(\n            self: Self,\n            buf: []u8,\n            delimiter: u8,\n        ) (Error || error{StreamTooLong})!?[]u8 {\n            return @errorCast(self.any().readUntilDelimiterOrEof(buf, delimiter));\n        }\n\n        pub inline fn streamUntilDelimiter(\n            self: Self,\n            writer: anytype,\n            delimiter: u8,\n            optional_max_size: ?usize,\n        ) (NoEofError || error{StreamTooLong} || @TypeOf(writer).Error)!void {\n            return @errorCast(self.any().streamUntilDelimiter(\n                writer,\n                delimiter,\n                optional_max_size,\n            ));\n        }\n\n        pub inline fn skipUntilDelimiterOrEof(self: Self, delimiter: u8) Error!void {\n            return @errorCast(self.any().skipUntilDelimiterOrEof(delimiter));\n        }\n\n        pub inline fn readByte(self: Self) NoEofError!u8 {\n            return @errorCast(self.any().readByte());\n        }\n\n        pub inline fn readByteSigned(self: Self) NoEofError!i8 {\n            return @errorCast(self.any().readByteSigned());\n        }\n\n        pub inline fn readBytesNoEof(\n            self: Self,\n            comptime num_bytes: usize,\n        ) NoEofError![num_bytes]u8 {\n            return @errorCast(self.any().readBytesNoEof(num_bytes));\n        }\n\n        pub inline fn readIntoBoundedBytes(\n            self: Self,\n            comptime num_bytes: usize,\n            bounded: *std.BoundedArray(u8, num_bytes),\n        ) Error!void {\n            return @errorCast(self.any().readIntoBoundedBytes(num_bytes, bounded));\n        }\n\n        pub inline fn readBoundedBytes(\n            self: Self,\n            comptime num_bytes: usize,\n        ) Error!std.BoundedArray(u8, num_bytes) {\n            return @errorCast(self.any().readBoundedBytes(num_bytes));\n        }\n\n        pub inline fn readInt(self: Self, comptime T: type, endian: std.builtin.Endian) NoEofError!T {\n            return @errorCast(self.any().readInt(T, endian));\n        }\n\n        pub inline fn readVarInt(\n            self: Self,\n            comptime ReturnType: type,\n            endian: std.builtin.Endian,\n            size: usize,\n        ) NoEofError!ReturnType {\n            return @errorCast(self.any().readVarInt(ReturnType, endian, size));\n        }\n\n        pub const SkipBytesOptions = AnyReader.SkipBytesOptions;\n\n        pub inline fn skipBytes(\n            self: Self,\n            num_bytes: u64,\n            comptime options: SkipBytesOptions,\n        ) NoEofError!void {\n            return @errorCast(self.any().skipBytes(num_bytes, options));\n        }\n\n        pub inline fn isBytes(self: Self, slice: []const u8) NoEofError!bool {\n            return @errorCast(self.any().isBytes(slice));\n        }\n\n        pub inline fn readStruct(self: Self, comptime T: type) NoEofError!T {\n            return @errorCast(self.any().readStruct(T));\n        }\n\n        pub inline fn readStructEndian(self: Self, comptime T: type, endian: std.builtin.Endian) NoEofError!T {\n            return @errorCast(self.any().readStructEndian(T, endian));\n        }\n\n        pub const ReadEnumError = NoEofError || error{\n            /// An integer was read, but it did not match any of the tags in the supplied enum.\n            InvalidValue,\n        };\n\n        pub inline fn readEnum(\n            self: Self,\n            comptime Enum: type,\n            endian: std.builtin.Endian,\n        ) ReadEnumError!Enum {\n            return @errorCast(self.any().readEnum(Enum, endian));\n        }\n\n        pub inline fn any(self: *const Self) AnyReader {\n            return .{\n                .context = @ptrCast(&self.context),\n                .readFn = typeErasedReadFn,\n            };\n        }\n\n        const Self = @This();\n\n        fn typeErasedReadFn(context: *const anyopaque, buffer: []u8) anyerror!usize {\n            const ptr: *const Context = @alignCast(@ptrCast(context));\n            return readFn(ptr.*, buffer);\n        }\n    };\n}\n\npub fn GenericWriter(\n    comptime Context: type,\n    comptime WriteError: type,\n    comptime writeFn: fn (context: Context, bytes: []const u8) WriteError!usize,\n) type {\n    return struct {\n        context: Context,\n\n        const Self = @This();\n        pub const Error = WriteError;\n\n        pub inline fn write(self: Self, bytes: []const u8) Error!usize {\n            return writeFn(self.context, bytes);\n        }\n\n        pub inline fn writeAll(self: Self, bytes: []const u8) Error!void {\n            return @errorCast(self.any().writeAll(bytes));\n        }\n\n        pub inline fn print(self: Self, comptime format: []const u8, args: anytype) Error!void {\n            return @errorCast(self.any().print(format, args));\n        }\n\n        pub inline fn writeByte(self: Self, byte: u8) Error!void {\n            return @errorCast(self.any().writeByte(byte));\n        }\n\n        pub inline fn writeByteNTimes(self: Self, byte: u8, n: usize) Error!void {\n            return @errorCast(self.any().writeByteNTimes(byte, n));\n        }\n\n        pub inline fn writeBytesNTimes(self: Self, bytes: []const u8, n: usize) Error!void {\n            return @errorCast(self.any().writeBytesNTimes(bytes, n));\n        }\n\n        pub inline fn writeInt(self: Self, comptime T: type, value: T, endian: std.builtin.Endian) Error!void {\n            return @errorCast(self.any().writeInt(T, value, endian));\n        }\n\n        pub inline fn writeStruct(self: Self, value: anytype) Error!void {\n            return @errorCast(self.any().writeStruct(value));\n        }\n\n        pub inline fn writeStructEndian(self: Self, value: anytype, endian: std.builtin.Endian) Error!void {\n            return @errorCast(self.any().writeStructEndian(value, endian));\n        }\n\n        pub inline fn any(self: *const Self) AnyWriter {\n            return .{\n                .context = @ptrCast(&self.context),\n                .writeFn = typeErasedWriteFn,\n            };\n        }\n\n        fn typeErasedWriteFn(context: *const anyopaque, bytes: []const u8) anyerror!usize {\n            const ptr: *const Context = @alignCast(@ptrCast(context));\n            return writeFn(ptr.*, bytes);\n        }\n    };\n}\n\n/// Deprecated; consider switching to `AnyReader` or use `GenericReader`\n/// to use previous API.\npub const Reader = GenericReader;\n/// Deprecated; consider switching to `AnyWriter` or use `GenericWriter`\n/// to use previous API.\npub const Writer = GenericWriter;\n\npub const AnyReader = @import(\"io/Reader.zig\");\npub const AnyWriter = @import(\"io/Writer.zig\");\n\npub const SeekableStream = @import(\"io/seekable_stream.zig\").SeekableStream;\n\npub const BufferedWriter = @import(\"io/buffered_writer.zig\").BufferedWriter;\npub const bufferedWriter = @import(\"io/buffered_writer.zig\").bufferedWriter;\n\npub const BufferedReader = @import(\"io/buffered_reader.zig\").BufferedReader;\npub const bufferedReader = @import(\"io/buffered_reader.zig\").bufferedReader;\npub const bufferedReaderSize = @import(\"io/buffered_reader.zig\").bufferedReaderSize;\n\npub const FixedBufferStream = @import(\"io/fixed_buffer_stream.zig\").FixedBufferStream;\npub const fixedBufferStream = @import(\"io/fixed_buffer_stream.zig\").fixedBufferStream;\n\npub const CWriter = @import(\"io/c_writer.zig\").CWriter;\npub const cWriter = @import(\"io/c_writer.zig\").cWriter;\n\npub const LimitedReader = @import(\"io/limited_reader.zig\").LimitedReader;\npub const limitedReader = @import(\"io/limited_reader.zig\").limitedReader;\n\npub const CountingWriter = @import(\"io/counting_writer.zig\").CountingWriter;\npub const countingWriter = @import(\"io/counting_writer.zig\").countingWriter;\npub const CountingReader = @import(\"io/counting_reader.zig\").CountingReader;\npub const countingReader = @import(\"io/counting_reader.zig\").countingReader;\n\npub const MultiWriter = @import(\"io/multi_writer.zig\").MultiWriter;\npub const multiWriter = @import(\"io/multi_writer.zig\").multiWriter;\n\npub const BitReader = @import(\"io/bit_reader.zig\").BitReader;\npub const bitReader = @import(\"io/bit_reader.zig\").bitReader;\n\npub const BitWriter = @import(\"io/bit_writer.zig\").BitWriter;\npub const bitWriter = @import(\"io/bit_writer.zig\").bitWriter;\n\npub const ChangeDetectionStream = @import(\"io/change_detection_stream.zig\").ChangeDetectionStream;\npub const changeDetectionStream = @import(\"io/change_detection_stream.zig\").changeDetectionStream;\n\npub const FindByteWriter = @import(\"io/find_byte_writer.zig\").FindByteWriter;\npub const findByteWriter = @import(\"io/find_byte_writer.zig\").findByteWriter;\n\npub const BufferedAtomicFile = @import(\"io/buffered_atomic_file.zig\").BufferedAtomicFile;\n\npub const StreamSource = @import(\"io/stream_source.zig\").StreamSource;\n\npub const tty = @import(\"io/tty.zig\");\n\n/// A Writer that doesn't write to anything.\npub const null_writer: NullWriter = .{ .context = {} };\n\nconst NullWriter = Writer(void, error{}, dummyWrite);\nfn dummyWrite(context: void, data: []const u8) error{}!usize {\n    _ = context;\n    return data.len;\n}\n\ntest null_writer {\n    null_writer.writeAll(\"yay\" ** 10) catch |err| switch (err) {};\n}\n\npub fn poll(\n    allocator: Allocator,\n    comptime StreamEnum: type,\n    files: PollFiles(StreamEnum),\n) Poller(StreamEnum) {\n    const enum_fields = @typeInfo(StreamEnum).Enum.fields;\n    var result: Poller(StreamEnum) = undefined;\n\n    if (is_windows) result.windows = .{\n        .first_read_done = false,\n        .overlapped = [1]windows.OVERLAPPED{\n            mem.zeroes(windows.OVERLAPPED),\n        } ** enum_fields.len,\n        .active = .{\n            .count = 0,\n            .handles_buf = undefined,\n            .stream_map = undefined,\n        },\n    };\n\n    inline for (0..enum_fields.len) |i| {\n        result.fifos[i] = .{\n            .allocator = allocator,\n            .buf = &.{},\n            .head = 0,\n            .count = 0,\n        };\n        if (is_windows) {\n            result.windows.active.handles_buf[i] = @field(files, enum_fields[i].name).handle;\n        } else {\n            result.poll_fds[i] = .{\n                .fd = @field(files, enum_fields[i].name).handle,\n                .events = posix.POLL.IN,\n                .revents = undefined,\n            };\n        }\n    }\n    return result;\n}\n\npub const PollFifo = std.fifo.LinearFifo(u8, .Dynamic);\n\npub fn Poller(comptime StreamEnum: type) type {\n    return struct {\n        const enum_fields = @typeInfo(StreamEnum).Enum.fields;\n        const PollFd = if (is_windows) void else posix.pollfd;\n\n        fifos: [enum_fields.len]PollFifo,\n        poll_fds: [enum_fields.len]PollFd,\n        windows: if (is_windows) struct {\n            first_read_done: bool,\n            overlapped: [enum_fields.len]windows.OVERLAPPED,\n            active: struct {\n                count: math.IntFittingRange(0, enum_fields.len),\n                handles_buf: [enum_fields.len]windows.HANDLE,\n                stream_map: [enum_fields.len]StreamEnum,\n\n                pub fn removeAt(self: *@This(), index: u32) void {\n                    std.debug.assert(index < self.count);\n                    for (index + 1..self.count) |i| {\n                        self.handles_buf[i - 1] = self.handles_buf[i];\n                        self.stream_map[i - 1] = self.stream_map[i];\n                    }\n                    self.count -= 1;\n                }\n            },\n        } else void,\n\n        const Self = @This();\n\n        pub fn deinit(self: *Self) void {\n            if (is_windows) {\n                // cancel any pending IO to prevent clobbering OVERLAPPED value\n                for (self.windows.active.handles_buf[0..self.windows.active.count]) |h| {\n                    _ = windows.kernel32.CancelIo(h);\n                }\n            }\n            inline for (&self.fifos) |*q| q.deinit();\n            self.* = undefined;\n        }\n\n        pub fn poll(self: *Self) !bool {\n            if (is_windows) {\n                return pollWindows(self, null);\n            } else {\n                return pollPosix(self, null);\n            }\n        }\n\n        pub fn pollTimeout(self: *Self, nanoseconds: u64) !bool {\n            if (is_windows) {\n                return pollWindows(self, nanoseconds);\n            } else {\n                return pollPosix(self, nanoseconds);\n            }\n        }\n\n        pub inline fn fifo(self: *Self, comptime which: StreamEnum) *PollFifo {\n            return &self.fifos[@intFromEnum(which)];\n        }\n\n        fn pollWindows(self: *Self, nanoseconds: ?u64) !bool {\n            const bump_amt = 512;\n\n            if (!self.windows.first_read_done) {\n                // Windows Async IO requires an initial call to ReadFile before waiting on the handle\n                for (0..enum_fields.len) |i| {\n                    const handle = self.windows.active.handles_buf[i];\n                    switch (try windowsAsyncRead(\n                        handle,\n                        &self.windows.overlapped[i],\n                        &self.fifos[i],\n                        bump_amt,\n                    )) {\n                        .pending => {\n                            self.windows.active.handles_buf[self.windows.active.count] = handle;\n                            self.windows.active.stream_map[self.windows.active.count] = @as(StreamEnum, @enumFromInt(i));\n                            self.windows.active.count += 1;\n                        },\n                        .closed => {}, // don't add to the wait_objects list\n                    }\n                }\n                self.windows.first_read_done = true;\n            }\n\n            while (true) {\n                if (self.windows.active.count == 0) return false;\n\n                const status = windows.kernel32.WaitForMultipleObjects(\n                    self.windows.active.count,\n                    &self.windows.active.handles_buf,\n                    0,\n                    if (nanoseconds) |ns|\n                        @min(std.math.cast(u32, ns / std.time.ns_per_ms) orelse (windows.INFINITE - 1), windows.INFINITE - 1)\n                    else\n                        windows.INFINITE,\n                );\n                if (status == windows.WAIT_FAILED)\n                    return windows.unexpectedError(windows.kernel32.GetLastError());\n                if (status == windows.WAIT_TIMEOUT)\n                    return true;\n\n                if (status < windows.WAIT_OBJECT_0 or status > windows.WAIT_OBJECT_0 + enum_fields.len - 1)\n                    unreachable;\n\n                const active_idx = status - windows.WAIT_OBJECT_0;\n\n                const handle = self.windows.active.handles_buf[active_idx];\n                const stream_idx = @intFromEnum(self.windows.active.stream_map[active_idx]);\n                var read_bytes: u32 = undefined;\n                if (0 == windows.kernel32.GetOverlappedResult(\n                    handle,\n                    &self.windows.overlapped[stream_idx],\n                    &read_bytes,\n                    0,\n                )) switch (windows.kernel32.GetLastError()) {\n                    .BROKEN_PIPE => {\n                        self.windows.active.removeAt(active_idx);\n                        continue;\n                    },\n                    else => |err| return windows.unexpectedError(err),\n                };\n\n                self.fifos[stream_idx].update(read_bytes);\n\n                switch (try windowsAsyncRead(\n                    handle,\n                    &self.windows.overlapped[stream_idx],\n                    &self.fifos[stream_idx],\n                    bump_amt,\n                )) {\n                    .pending => {},\n                    .closed => self.windows.active.removeAt(active_idx),\n                }\n                return true;\n            }\n        }\n\n        fn pollPosix(self: *Self, nanoseconds: ?u64) !bool {\n            // We ask for ensureUnusedCapacity with this much extra space. This\n            // has more of an effect on small reads because once the reads\n            // start to get larger the amount of space an ArrayList will\n            // allocate grows exponentially.\n            const bump_amt = 512;\n\n            const err_mask = posix.POLL.ERR | posix.POLL.NVAL | posix.POLL.HUP;\n\n            const events_len = try posix.poll(&self.poll_fds, if (nanoseconds) |ns|\n                std.math.cast(i32, ns / std.time.ns_per_ms) orelse std.math.maxInt(i32)\n            else\n                -1);\n            if (events_len == 0) {\n                for (self.poll_fds) |poll_fd| {\n                    if (poll_fd.fd != -1) return true;\n                } else return false;\n            }\n\n            var keep_polling = false;\n            inline for (&self.poll_fds, &self.fifos) |*poll_fd, *q| {\n                // Try reading whatever is available before checking the error\n                // conditions.\n                // It's still possible to read after a POLL.HUP is received,\n                // always check if there's some data waiting to be read first.\n                if (poll_fd.revents & posix.POLL.IN != 0) {\n                    const buf = try q.writableWithSize(bump_amt);\n                    const amt = try posix.read(poll_fd.fd, buf);\n                    q.update(amt);\n                    if (amt == 0) {\n                        // Remove the fd when the EOF condition is met.\n                        poll_fd.fd = -1;\n                    } else {\n                        keep_polling = true;\n                    }\n                } else if (poll_fd.revents & err_mask != 0) {\n                    // Exclude the fds that signaled an error.\n                    poll_fd.fd = -1;\n                } else if (poll_fd.fd != -1) {\n                    keep_polling = true;\n                }\n            }\n            return keep_polling;\n        }\n    };\n}\n\nfn windowsAsyncRead(\n    handle: windows.HANDLE,\n    overlapped: *windows.OVERLAPPED,\n    fifo: *PollFifo,\n    bump_amt: usize,\n) !enum { pending, closed } {\n    while (true) {\n        const buf = try fifo.writableWithSize(bump_amt);\n        var read_bytes: u32 = undefined;\n        const read_result = windows.kernel32.ReadFile(handle, buf.ptr, math.cast(u32, buf.len) orelse math.maxInt(u32), &read_bytes, overlapped);\n        if (read_result == 0) return switch (windows.kernel32.GetLastError()) {\n            .IO_PENDING => .pending,\n            .BROKEN_PIPE => .closed,\n            else => |err| windows.unexpectedError(err),\n        };\n        fifo.update(read_bytes);\n    }\n}\n\n/// Given an enum, returns a struct with fields of that enum, each field\n/// representing an I/O stream for polling.\npub fn PollFiles(comptime StreamEnum: type) type {\n    const enum_fields = @typeInfo(StreamEnum).Enum.fields;\n    var struct_fields: [enum_fields.len]std.builtin.Type.StructField = undefined;\n    for (&struct_fields, enum_fields) |*struct_field, enum_field| {\n        struct_field.* = .{\n            .name = enum_field.name ++ \"\",\n            .type = fs.File,\n            .default_value = null,\n            .is_comptime = false,\n            .alignment = @alignOf(fs.File),\n        };\n    }\n    return @Type(.{ .Struct = .{\n        .layout = .auto,\n        .fields = &struct_fields,\n        .decls = &.{},\n        .is_tuple = false,\n    } });\n}\n\ntest {\n    _ = AnyReader;\n    _ = AnyWriter;\n    _ = @import(\"io/bit_reader.zig\");\n    _ = @import(\"io/bit_writer.zig\");\n    _ = @import(\"io/buffered_atomic_file.zig\");\n    _ = @import(\"io/buffered_reader.zig\");\n    _ = @import(\"io/buffered_writer.zig\");\n    _ = @import(\"io/c_writer.zig\");\n    _ = @import(\"io/counting_writer.zig\");\n    _ = @import(\"io/counting_reader.zig\");\n    _ = @import(\"io/fixed_buffer_stream.zig\");\n    _ = @import(\"io/seekable_stream.zig\");\n    _ = @import(\"io/stream_source.zig\");\n    _ = @import(\"io/test.zig\");\n}\n",
    "const std = @import(\"../std.zig\");\nconst io = std.io;\nconst testing = std.testing;\nconst mem = std.mem;\nconst assert = std.debug.assert;\n\n/// This turns a byte buffer into an `io.Writer`, `io.Reader`, or `io.SeekableStream`.\n/// If the supplied byte buffer is const, then `io.Writer` is not available.\npub fn FixedBufferStream(comptime Buffer: type) type {\n    return struct {\n        /// `Buffer` is either a `[]u8` or `[]const u8`.\n        buffer: Buffer,\n        pos: usize,\n\n        pub const ReadError = error{};\n        pub const WriteError = error{NoSpaceLeft};\n        pub const SeekError = error{};\n        pub const GetSeekPosError = error{};\n\n        pub const Reader = io.Reader(*Self, ReadError, read);\n        pub const Writer = io.Writer(*Self, WriteError, write);\n\n        pub const SeekableStream = io.SeekableStream(\n            *Self,\n            SeekError,\n            GetSeekPosError,\n            seekTo,\n            seekBy,\n            getPos,\n            getEndPos,\n        );\n\n        const Self = @This();\n\n        pub fn reader(self: *Self) Reader {\n            return .{ .context = self };\n        }\n\n        pub fn writer(self: *Self) Writer {\n            return .{ .context = self };\n        }\n\n        pub fn seekableStream(self: *Self) SeekableStream {\n            return .{ .context = self };\n        }\n\n        pub fn read(self: *Self, dest: []u8) ReadError!usize {\n            const size = @min(dest.len, self.buffer.len - self.pos);\n            const end = self.pos + size;\n\n            @memcpy(dest[0..size], self.buffer[self.pos..end]);\n            self.pos = end;\n\n            return size;\n        }\n\n        /// If the returned number of bytes written is less than requested, the\n        /// buffer is full. Returns `error.NoSpaceLeft` when no bytes would be written.\n        /// Note: `error.NoSpaceLeft` matches the corresponding error from\n        /// `std.fs.File.WriteError`.\n        pub fn write(self: *Self, bytes: []const u8) WriteError!usize {\n            if (bytes.len == 0) return 0;\n            if (self.pos >= self.buffer.len) return error.NoSpaceLeft;\n\n            const n = @min(self.buffer.len - self.pos, bytes.len);\n            @memcpy(self.buffer[self.pos..][0..n], bytes[0..n]);\n            self.pos += n;\n\n            if (n == 0) return error.NoSpaceLeft;\n\n            return n;\n        }\n\n        pub fn seekTo(self: *Self, pos: u64) SeekError!void {\n            self.pos = @min(std.math.lossyCast(usize, pos), self.buffer.len);\n        }\n\n        pub fn seekBy(self: *Self, amt: i64) SeekError!void {\n            if (amt < 0) {\n                const abs_amt = @abs(amt);\n                const abs_amt_usize = std.math.cast(usize, abs_amt) orelse std.math.maxInt(usize);\n                if (abs_amt_usize > self.pos) {\n                    self.pos = 0;\n                } else {\n                    self.pos -= abs_amt_usize;\n                }\n            } else {\n                const amt_usize = std.math.cast(usize, amt) orelse std.math.maxInt(usize);\n                const new_pos = std.math.add(usize, self.pos, amt_usize) catch std.math.maxInt(usize);\n                self.pos = @min(self.buffer.len, new_pos);\n            }\n        }\n\n        pub fn getEndPos(self: *Self) GetSeekPosError!u64 {\n            return self.buffer.len;\n        }\n\n        pub fn getPos(self: *Self) GetSeekPosError!u64 {\n            return self.pos;\n        }\n\n        pub fn getWritten(self: Self) Buffer {\n            return self.buffer[0..self.pos];\n        }\n\n        pub fn reset(self: *Self) void {\n            self.pos = 0;\n        }\n    };\n}\n\npub fn fixedBufferStream(buffer: anytype) FixedBufferStream(Slice(@TypeOf(buffer))) {\n    return .{ .buffer = buffer, .pos = 0 };\n}\n\nfn Slice(comptime T: type) type {\n    switch (@typeInfo(T)) {\n        .Pointer => |ptr_info| {\n            var new_ptr_info = ptr_info;\n            switch (ptr_info.size) {\n                .Slice => {},\n                .One => switch (@typeInfo(ptr_info.child)) {\n                    .Array => |info| new_ptr_info.child = info.child,\n                    else => @compileError(\"invalid type given to fixedBufferStream\"),\n                },\n                else => @compileError(\"invalid type given to fixedBufferStream\"),\n            }\n            new_ptr_info.size = .Slice;\n            return @Type(.{ .Pointer = new_ptr_info });\n        },\n        else => @compileError(\"invalid type given to fixedBufferStream\"),\n    }\n}\n\ntest \"output\" {\n    var buf: [255]u8 = undefined;\n    var fbs = fixedBufferStream(&buf);\n    const stream = fbs.writer();\n\n    try stream.print(\"{s}{s}!\", .{ \"Hello\", \"World\" });\n    try testing.expectEqualSlices(u8, \"HelloWorld!\", fbs.getWritten());\n}\n\ntest \"output at comptime\" {\n    comptime {\n        var buf: [255]u8 = undefined;\n        var fbs = fixedBufferStream(&buf);\n        const stream = fbs.writer();\n\n        try stream.print(\"{s}{s}!\", .{ \"Hello\", \"World\" });\n        try testing.expectEqualSlices(u8, \"HelloWorld!\", fbs.getWritten());\n    }\n}\n\ntest \"output 2\" {\n    var buffer: [10]u8 = undefined;\n    var fbs = fixedBufferStream(&buffer);\n\n    try fbs.writer().writeAll(\"Hello\");\n    try testing.expect(mem.eql(u8, fbs.getWritten(), \"Hello\"));\n\n    try fbs.writer().writeAll(\"world\");\n    try testing.expect(mem.eql(u8, fbs.getWritten(), \"Helloworld\"));\n\n    try testing.expectError(error.NoSpaceLeft, fbs.writer().writeAll(\"!\"));\n    try testing.expect(mem.eql(u8, fbs.getWritten(), \"Helloworld\"));\n\n    fbs.reset();\n    try testing.expect(fbs.getWritten().len == 0);\n\n    try testing.expectError(error.NoSpaceLeft, fbs.writer().writeAll(\"Hello world!\"));\n    try testing.expect(mem.eql(u8, fbs.getWritten(), \"Hello worl\"));\n\n    try fbs.seekTo((try fbs.getEndPos()) + 1);\n    try testing.expectError(error.NoSpaceLeft, fbs.writer().writeAll(\"H\"));\n}\n\ntest \"input\" {\n    const bytes = [_]u8{ 1, 2, 3, 4, 5, 6, 7 };\n    var fbs = fixedBufferStream(&bytes);\n\n    var dest: [4]u8 = undefined;\n\n    var read = try fbs.reader().read(&dest);\n    try testing.expect(read == 4);\n    try testing.expect(mem.eql(u8, dest[0..4], bytes[0..4]));\n\n    read = try fbs.reader().read(&dest);\n    try testing.expect(read == 3);\n    try testing.expect(mem.eql(u8, dest[0..3], bytes[4..7]));\n\n    read = try fbs.reader().read(&dest);\n    try testing.expect(read == 0);\n\n    try fbs.seekTo((try fbs.getEndPos()) + 1);\n    read = try fbs.reader().read(&dest);\n    try testing.expect(read == 0);\n}\n",
    "const std = @import(\"std.zig\");\nconst debug = std.debug;\nconst mem = std.mem;\nconst math = std.math;\nconst testing = std.testing;\nconst root = @import(\"root\");\n\npub const TrailerFlags = @import(\"meta/trailer_flags.zig\").TrailerFlags;\n\nconst Type = std.builtin.Type;\n\ntest {\n    _ = TrailerFlags;\n}\n\n/// Returns the variant of an enum type, `T`, which is named `str`, or `null` if no such variant exists.\npub fn stringToEnum(comptime T: type, str: []const u8) ?T {\n    // Using StaticStringMap here is more performant, but it will start to take too\n    // long to compile if the enum is large enough, due to the current limits of comptime\n    // performance when doing things like constructing lookup maps at comptime.\n    // TODO The '100' here is arbitrary and should be increased when possible:\n    // - https://github.com/ziglang/zig/issues/4055\n    // - https://github.com/ziglang/zig/issues/3863\n    if (@typeInfo(T).Enum.fields.len <= 100) {\n        const kvs = comptime build_kvs: {\n            const EnumKV = struct { []const u8, T };\n            var kvs_array: [@typeInfo(T).Enum.fields.len]EnumKV = undefined;\n            for (@typeInfo(T).Enum.fields, 0..) |enumField, i| {\n                kvs_array[i] = .{ enumField.name, @field(T, enumField.name) };\n            }\n            break :build_kvs kvs_array[0..];\n        };\n        const map = std.StaticStringMap(T).initComptime(kvs);\n        return map.get(str);\n    } else {\n        inline for (@typeInfo(T).Enum.fields) |enumField| {\n            if (mem.eql(u8, str, enumField.name)) {\n                return @field(T, enumField.name);\n            }\n        }\n        return null;\n    }\n}\n\ntest stringToEnum {\n    const E1 = enum {\n        A,\n        B,\n    };\n    try testing.expect(E1.A == stringToEnum(E1, \"A\").?);\n    try testing.expect(E1.B == stringToEnum(E1, \"B\").?);\n    try testing.expect(null == stringToEnum(E1, \"C\"));\n}\n\n/// Returns the alignment of type T.\n/// Note that if T is a pointer type the result is different than the one\n/// returned by @alignOf(T).\n/// If T is a pointer type the alignment of the type it points to is returned.\npub fn alignment(comptime T: type) comptime_int {\n    return switch (@typeInfo(T)) {\n        .Optional => |info| switch (@typeInfo(info.child)) {\n            .Pointer, .Fn => alignment(info.child),\n            else => @alignOf(T),\n        },\n        .Pointer => |info| info.alignment,\n        else => @alignOf(T),\n    };\n}\n\ntest alignment {\n    try testing.expect(alignment(u8) == 1);\n    try testing.expect(alignment(*align(1) u8) == 1);\n    try testing.expect(alignment(*align(2) u8) == 2);\n    try testing.expect(alignment([]align(1) u8) == 1);\n    try testing.expect(alignment([]align(2) u8) == 2);\n    try testing.expect(alignment(fn () void) > 0);\n    try testing.expect(alignment(*const fn () void) > 0);\n    try testing.expect(alignment(*align(128) const fn () void) == 128);\n}\n\n/// Given a parameterized type (array, vector, pointer, optional), returns the \"child type\".\npub fn Child(comptime T: type) type {\n    return switch (@typeInfo(T)) {\n        .Array => |info| info.child,\n        .Vector => |info| info.child,\n        .Pointer => |info| info.child,\n        .Optional => |info| info.child,\n        else => @compileError(\"Expected pointer, optional, array or vector type, found '\" ++ @typeName(T) ++ \"'\"),\n    };\n}\n\ntest Child {\n    try testing.expect(Child([1]u8) == u8);\n    try testing.expect(Child(*u8) == u8);\n    try testing.expect(Child([]u8) == u8);\n    try testing.expect(Child(?u8) == u8);\n    try testing.expect(Child(@Vector(2, u8)) == u8);\n}\n\n/// Given a \"memory span\" type (array, slice, vector, or pointer to such), returns the \"element type\".\npub fn Elem(comptime T: type) type {\n    switch (@typeInfo(T)) {\n        .Array => |info| return info.child,\n        .Vector => |info| return info.child,\n        .Pointer => |info| switch (info.size) {\n            .One => switch (@typeInfo(info.child)) {\n                .Array => |array_info| return array_info.child,\n                .Vector => |vector_info| return vector_info.child,\n                else => {},\n            },\n            .Many, .C, .Slice => return info.child,\n        },\n        .Optional => |info| return Elem(info.child),\n        else => {},\n    }\n    @compileError(\"Expected pointer, slice, array or vector type, found '\" ++ @typeName(T) ++ \"'\");\n}\n\ntest Elem {\n    try testing.expect(Elem([1]u8) == u8);\n    try testing.expect(Elem([*]u8) == u8);\n    try testing.expect(Elem([]u8) == u8);\n    try testing.expect(Elem(*[10]u8) == u8);\n    try testing.expect(Elem(@Vector(2, u8)) == u8);\n    try testing.expect(Elem(*@Vector(2, u8)) == u8);\n    try testing.expect(Elem(?[*]u8) == u8);\n}\n\n/// Given a type which can have a sentinel e.g. `[:0]u8`, returns the sentinel value,\n/// or `null` if there is not one.\n/// Types which cannot possibly have a sentinel will be a compile error.\n/// Result is always comptime-known.\npub inline fn sentinel(comptime T: type) ?Elem(T) {\n    switch (@typeInfo(T)) {\n        .Array => |info| {\n            const sentinel_ptr = info.sentinel orelse return null;\n            return @as(*const info.child, @ptrCast(sentinel_ptr)).*;\n        },\n        .Pointer => |info| {\n            switch (info.size) {\n                .Many, .Slice => {\n                    const sentinel_ptr = info.sentinel orelse return null;\n                    return @as(*align(1) const info.child, @ptrCast(sentinel_ptr)).*;\n                },\n                .One => switch (@typeInfo(info.child)) {\n                    .Array => |array_info| {\n                        const sentinel_ptr = array_info.sentinel orelse return null;\n                        return @as(*align(1) const array_info.child, @ptrCast(sentinel_ptr)).*;\n                    },\n                    else => {},\n                },\n                else => {},\n            }\n        },\n        else => {},\n    }\n    @compileError(\"type '\" ++ @typeName(T) ++ \"' cannot possibly have a sentinel\");\n}\n\ntest sentinel {\n    try testSentinel();\n    try comptime testSentinel();\n}\n\nfn testSentinel() !void {\n    try testing.expectEqual(@as(u8, 0), sentinel([:0]u8).?);\n    try testing.expectEqual(@as(u8, 0), sentinel([*:0]u8).?);\n    try testing.expectEqual(@as(u8, 0), sentinel([5:0]u8).?);\n    try testing.expectEqual(@as(u8, 0), sentinel(*const [5:0]u8).?);\n\n    try testing.expect(sentinel([]u8) == null);\n    try testing.expect(sentinel([*]u8) == null);\n    try testing.expect(sentinel([5]u8) == null);\n    try testing.expect(sentinel(*const [5]u8) == null);\n}\n\n/// Given a \"memory span\" type, returns the same type except with the given sentinel value.\npub fn Sentinel(comptime T: type, comptime sentinel_val: Elem(T)) type {\n    switch (@typeInfo(T)) {\n        .Pointer => |info| switch (info.size) {\n            .One => switch (@typeInfo(info.child)) {\n                .Array => |array_info| return @Type(.{\n                    .Pointer = .{\n                        .size = info.size,\n                        .is_const = info.is_const,\n                        .is_volatile = info.is_volatile,\n                        .alignment = info.alignment,\n                        .address_space = info.address_space,\n                        .child = @Type(.{\n                            .Array = .{\n                                .len = array_info.len,\n                                .child = array_info.child,\n                                .sentinel = @as(?*const anyopaque, @ptrCast(&sentinel_val)),\n                            },\n                        }),\n                        .is_allowzero = info.is_allowzero,\n                        .sentinel = info.sentinel,\n                    },\n                }),\n                else => {},\n            },\n            .Many, .Slice => return @Type(.{\n                .Pointer = .{\n                    .size = info.size,\n                    .is_const = info.is_const,\n                    .is_volatile = info.is_volatile,\n                    .alignment = info.alignment,\n                    .address_space = info.address_space,\n                    .child = info.child,\n                    .is_allowzero = info.is_allowzero,\n                    .sentinel = @as(?*const anyopaque, @ptrCast(&sentinel_val)),\n                },\n            }),\n            else => {},\n        },\n        .Optional => |info| switch (@typeInfo(info.child)) {\n            .Pointer => |ptr_info| switch (ptr_info.size) {\n                .Many => return @Type(.{\n                    .Optional = .{\n                        .child = @Type(.{\n                            .Pointer = .{\n                                .size = ptr_info.size,\n                                .is_const = ptr_info.is_const,\n                                .is_volatile = ptr_info.is_volatile,\n                                .alignment = ptr_info.alignment,\n                                .address_space = ptr_info.address_space,\n                                .child = ptr_info.child,\n                                .is_allowzero = ptr_info.is_allowzero,\n                                .sentinel = @as(?*const anyopaque, @ptrCast(&sentinel_val)),\n                            },\n                        }),\n                    },\n                }),\n                else => {},\n            },\n            else => {},\n        },\n        else => {},\n    }\n    @compileError(\"Unable to derive a sentinel pointer type from \" ++ @typeName(T));\n}\n\npub const assumeSentinel = @compileError(\"This function has been removed, consider using std.mem.sliceTo() or if needed a @ptrCast()\");\n\npub fn containerLayout(comptime T: type) Type.ContainerLayout {\n    return switch (@typeInfo(T)) {\n        .Struct => |info| info.layout,\n        .Union => |info| info.layout,\n        else => @compileError(\"expected struct or union type, found '\" ++ @typeName(T) ++ \"'\"),\n    };\n}\n\ntest containerLayout {\n    const S1 = struct {};\n    const S2 = packed struct {};\n    const S3 = extern struct {};\n    const U1 = union {\n        a: u8,\n    };\n    const U2 = packed union {\n        a: u8,\n    };\n    const U3 = extern union {\n        a: u8,\n    };\n\n    try testing.expect(containerLayout(S1) == .auto);\n    try testing.expect(containerLayout(S2) == .@\"packed\");\n    try testing.expect(containerLayout(S3) == .@\"extern\");\n    try testing.expect(containerLayout(U1) == .auto);\n    try testing.expect(containerLayout(U2) == .@\"packed\");\n    try testing.expect(containerLayout(U3) == .@\"extern\");\n}\n\n/// Instead of this function, prefer to use e.g. `@typeInfo(foo).Struct.decls`\n/// directly when you know what kind of type it is.\npub fn declarations(comptime T: type) []const Type.Declaration {\n    return switch (@typeInfo(T)) {\n        .Struct => |info| info.decls,\n        .Enum => |info| info.decls,\n        .Union => |info| info.decls,\n        .Opaque => |info| info.decls,\n        else => @compileError(\"Expected struct, enum, union, or opaque type, found '\" ++ @typeName(T) ++ \"'\"),\n    };\n}\n\ntest declarations {\n    const E1 = enum {\n        A,\n\n        pub fn a() void {}\n    };\n    const S1 = struct {\n        pub fn a() void {}\n    };\n    const U1 = union {\n        a: u8,\n\n        pub fn a() void {}\n    };\n    const O1 = opaque {\n        pub fn a() void {}\n    };\n\n    const decls = comptime [_][]const Type.Declaration{\n        declarations(E1),\n        declarations(S1),\n        declarations(U1),\n        declarations(O1),\n    };\n\n    inline for (decls) |decl| {\n        try testing.expect(decl.len == 1);\n        try testing.expect(comptime mem.eql(u8, decl[0].name, \"a\"));\n    }\n}\n\npub fn declarationInfo(comptime T: type, comptime decl_name: []const u8) Type.Declaration {\n    inline for (comptime declarations(T)) |decl| {\n        if (comptime mem.eql(u8, decl.name, decl_name))\n            return decl;\n    }\n\n    @compileError(\"'\" ++ @typeName(T) ++ \"' has no declaration '\" ++ decl_name ++ \"'\");\n}\n\ntest declarationInfo {\n    const E1 = enum {\n        A,\n\n        pub fn a() void {}\n    };\n    const S1 = struct {\n        pub fn a() void {}\n    };\n    const U1 = union {\n        a: u8,\n\n        pub fn a() void {}\n    };\n\n    const infos = comptime [_]Type.Declaration{\n        declarationInfo(E1, \"a\"),\n        declarationInfo(S1, \"a\"),\n        declarationInfo(U1, \"a\"),\n    };\n\n    inline for (infos) |info| {\n        try testing.expect(comptime mem.eql(u8, info.name, \"a\"));\n    }\n}\npub fn fields(comptime T: type) switch (@typeInfo(T)) {\n    .Struct => []const Type.StructField,\n    .Union => []const Type.UnionField,\n    .ErrorSet => []const Type.Error,\n    .Enum => []const Type.EnumField,\n    else => @compileError(\"Expected struct, union, error set or enum type, found '\" ++ @typeName(T) ++ \"'\"),\n} {\n    return switch (@typeInfo(T)) {\n        .Struct => |info| info.fields,\n        .Union => |info| info.fields,\n        .Enum => |info| info.fields,\n        .ErrorSet => |errors| errors.?, // must be non global error set\n        else => @compileError(\"Expected struct, union, error set or enum type, found '\" ++ @typeName(T) ++ \"'\"),\n    };\n}\n\ntest fields {\n    const E1 = enum {\n        A,\n    };\n    const E2 = error{A};\n    const S1 = struct {\n        a: u8,\n    };\n    const U1 = union {\n        a: u8,\n    };\n\n    const e1f = comptime fields(E1);\n    const e2f = comptime fields(E2);\n    const sf = comptime fields(S1);\n    const uf = comptime fields(U1);\n\n    try testing.expect(e1f.len == 1);\n    try testing.expect(e2f.len == 1);\n    try testing.expect(sf.len == 1);\n    try testing.expect(uf.len == 1);\n    try testing.expect(mem.eql(u8, e1f[0].name, \"A\"));\n    try testing.expect(mem.eql(u8, e2f[0].name, \"A\"));\n    try testing.expect(mem.eql(u8, sf[0].name, \"a\"));\n    try testing.expect(mem.eql(u8, uf[0].name, \"a\"));\n    try testing.expect(comptime sf[0].type == u8);\n    try testing.expect(comptime uf[0].type == u8);\n}\n\npub fn fieldInfo(comptime T: type, comptime field: FieldEnum(T)) switch (@typeInfo(T)) {\n    .Struct => Type.StructField,\n    .Union => Type.UnionField,\n    .ErrorSet => Type.Error,\n    .Enum => Type.EnumField,\n    else => @compileError(\"Expected struct, union, error set or enum type, found '\" ++ @typeName(T) ++ \"'\"),\n} {\n    return fields(T)[@intFromEnum(field)];\n}\n\ntest fieldInfo {\n    const E1 = enum {\n        A,\n    };\n    const E2 = error{A};\n    const S1 = struct {\n        a: u8,\n    };\n    const U1 = union {\n        a: u8,\n    };\n\n    const e1f = fieldInfo(E1, .A);\n    const e2f = fieldInfo(E2, .A);\n    const sf = fieldInfo(S1, .a);\n    const uf = fieldInfo(U1, .a);\n\n    try testing.expect(mem.eql(u8, e1f.name, \"A\"));\n    try testing.expect(mem.eql(u8, e2f.name, \"A\"));\n    try testing.expect(mem.eql(u8, sf.name, \"a\"));\n    try testing.expect(mem.eql(u8, uf.name, \"a\"));\n    try testing.expect(comptime sf.type == u8);\n    try testing.expect(comptime uf.type == u8);\n}\n\npub fn FieldType(comptime T: type, comptime field: FieldEnum(T)) type {\n    if (@typeInfo(T) != .Struct and @typeInfo(T) != .Union) {\n        @compileError(\"Expected struct or union, found '\" ++ @typeName(T) ++ \"'\");\n    }\n\n    return fieldInfo(T, field).type;\n}\n\ntest FieldType {\n    const S = struct {\n        a: u8,\n        b: u16,\n    };\n\n    const U = union {\n        c: u32,\n        d: *const u8,\n    };\n\n    try testing.expect(FieldType(S, .a) == u8);\n    try testing.expect(FieldType(S, .b) == u16);\n\n    try testing.expect(FieldType(U, .c) == u32);\n    try testing.expect(FieldType(U, .d) == *const u8);\n}\n\npub fn fieldNames(comptime T: type) *const [fields(T).len][:0]const u8 {\n    return comptime blk: {\n        const fieldInfos = fields(T);\n        var names: [fieldInfos.len][:0]const u8 = undefined;\n        // This concat can be removed with the next zig1 update.\n        for (&names, fieldInfos) |*name, field| name.* = field.name ++ \"\";\n        const final = names;\n        break :blk &final;\n    };\n}\n\ntest fieldNames {\n    const E1 = enum { A, B };\n    const E2 = error{A};\n    const S1 = struct {\n        a: u8,\n    };\n    const U1 = union {\n        a: u8,\n        b: void,\n    };\n\n    const e1names = fieldNames(E1);\n    const e2names = fieldNames(E2);\n    const s1names = fieldNames(S1);\n    const u1names = fieldNames(U1);\n\n    try testing.expect(e1names.len == 2);\n    try testing.expectEqualSlices(u8, e1names[0], \"A\");\n    try testing.expectEqualSlices(u8, e1names[1], \"B\");\n    try testing.expect(e2names.len == 1);\n    try testing.expectEqualSlices(u8, e2names[0], \"A\");\n    try testing.expect(s1names.len == 1);\n    try testing.expectEqualSlices(u8, s1names[0], \"a\");\n    try testing.expect(u1names.len == 2);\n    try testing.expectEqualSlices(u8, u1names[0], \"a\");\n    try testing.expectEqualSlices(u8, u1names[1], \"b\");\n}\n\n/// Given an enum or error set type, returns a pointer to an array containing all tags for that\n/// enum or error set.\npub fn tags(comptime T: type) *const [fields(T).len]T {\n    return comptime blk: {\n        const fieldInfos = fields(T);\n        var res: [fieldInfos.len]T = undefined;\n        for (fieldInfos, 0..) |field, i| {\n            res[i] = @field(T, field.name);\n        }\n        const final = res;\n        break :blk &final;\n    };\n}\n\ntest tags {\n    const E1 = enum { A, B };\n    const E2 = error{A};\n\n    const e1_tags = tags(E1);\n    const e2_tags = tags(E2);\n\n    try testing.expect(e1_tags.len == 2);\n    try testing.expectEqual(E1.A, e1_tags[0]);\n    try testing.expectEqual(E1.B, e1_tags[1]);\n    try testing.expect(e2_tags.len == 1);\n    try testing.expectEqual(E2.A, e2_tags[0]);\n}\n\n/// Returns an enum with a variant named after each field of `T`.\npub fn FieldEnum(comptime T: type) type {\n    const field_infos = fields(T);\n\n    if (field_infos.len == 0) {\n        return @Type(.{\n            .Enum = .{\n                .tag_type = u0,\n                .fields = &.{},\n                .decls = &.{},\n                .is_exhaustive = true,\n            },\n        });\n    }\n\n    if (@typeInfo(T) == .Union) {\n        if (@typeInfo(T).Union.tag_type) |tag_type| {\n            for (std.enums.values(tag_type), 0..) |v, i| {\n                if (@intFromEnum(v) != i) break; // enum values not consecutive\n                if (!std.mem.eql(u8, @tagName(v), field_infos[i].name)) break; // fields out of order\n            } else {\n                return tag_type;\n            }\n        }\n    }\n\n    var enumFields: [field_infos.len]std.builtin.Type.EnumField = undefined;\n    var decls = [_]std.builtin.Type.Declaration{};\n    inline for (field_infos, 0..) |field, i| {\n        enumFields[i] = .{\n            .name = field.name ++ \"\",\n            .value = i,\n        };\n    }\n    return @Type(.{\n        .Enum = .{\n            .tag_type = std.math.IntFittingRange(0, field_infos.len - 1),\n            .fields = &enumFields,\n            .decls = &decls,\n            .is_exhaustive = true,\n        },\n    });\n}\n\nfn expectEqualEnum(expected: anytype, actual: @TypeOf(expected)) !void {\n    // TODO: https://github.com/ziglang/zig/issues/7419\n    // testing.expectEqual(@typeInfo(expected).Enum, @typeInfo(actual).Enum);\n    try testing.expectEqual(\n        @typeInfo(expected).Enum.tag_type,\n        @typeInfo(actual).Enum.tag_type,\n    );\n    // For comparing decls and fields, we cannot use the meta eql function here\n    // because the language does not guarantee that the slice pointers for field names\n    // and decl names will be the same.\n    comptime {\n        const expected_fields = @typeInfo(expected).Enum.fields;\n        const actual_fields = @typeInfo(actual).Enum.fields;\n        if (expected_fields.len != actual_fields.len) return error.FailedTest;\n        for (expected_fields, 0..) |expected_field, i| {\n            const actual_field = actual_fields[i];\n            try testing.expectEqual(expected_field.value, actual_field.value);\n            try testing.expectEqualStrings(expected_field.name, actual_field.name);\n        }\n    }\n    comptime {\n        const expected_decls = @typeInfo(expected).Enum.decls;\n        const actual_decls = @typeInfo(actual).Enum.decls;\n        if (expected_decls.len != actual_decls.len) return error.FailedTest;\n        for (expected_decls, 0..) |expected_decl, i| {\n            const actual_decl = actual_decls[i];\n            try testing.expectEqualStrings(expected_decl.name, actual_decl.name);\n        }\n    }\n    try testing.expectEqual(\n        @typeInfo(expected).Enum.is_exhaustive,\n        @typeInfo(actual).Enum.is_exhaustive,\n    );\n}\n\ntest FieldEnum {\n    try expectEqualEnum(enum {}, FieldEnum(struct {}));\n    try expectEqualEnum(enum { a }, FieldEnum(struct { a: u8 }));\n    try expectEqualEnum(enum { a, b, c }, FieldEnum(struct { a: u8, b: void, c: f32 }));\n    try expectEqualEnum(enum { a, b, c }, FieldEnum(union { a: u8, b: void, c: f32 }));\n\n    const Tagged = union(enum) { a: u8, b: void, c: f32 };\n    try testing.expectEqual(Tag(Tagged), FieldEnum(Tagged));\n\n    const Tag2 = enum { a, b, c };\n    const Tagged2 = union(Tag2) { a: u8, b: void, c: f32 };\n    try testing.expect(Tag(Tagged2) == FieldEnum(Tagged2));\n\n    const Tag3 = enum(u8) { a, b, c = 7 };\n    const Tagged3 = union(Tag3) { a: u8, b: void, c: f32 };\n    try testing.expect(Tag(Tagged3) != FieldEnum(Tagged3));\n}\n\npub fn DeclEnum(comptime T: type) type {\n    const fieldInfos = std.meta.declarations(T);\n    var enumDecls: [fieldInfos.len]std.builtin.Type.EnumField = undefined;\n    var decls = [_]std.builtin.Type.Declaration{};\n    inline for (fieldInfos, 0..) |field, i| {\n        enumDecls[i] = .{ .name = field.name ++ \"\", .value = i };\n    }\n    return @Type(.{\n        .Enum = .{\n            .tag_type = std.math.IntFittingRange(0, fieldInfos.len - 1),\n            .fields = &enumDecls,\n            .decls = &decls,\n            .is_exhaustive = true,\n        },\n    });\n}\n\ntest DeclEnum {\n    const A = struct {\n        pub const a: u8 = 0;\n    };\n    const B = union {\n        foo: void,\n\n        pub const a: u8 = 0;\n        pub const b: void = {};\n        pub const c: f32 = 0;\n    };\n    const C = enum {\n        bar,\n\n        pub const a: u8 = 0;\n        pub const b: void = {};\n        pub const c: f32 = 0;\n    };\n    try expectEqualEnum(enum { a }, DeclEnum(A));\n    try expectEqualEnum(enum { a, b, c }, DeclEnum(B));\n    try expectEqualEnum(enum { a, b, c }, DeclEnum(C));\n}\n\npub fn Tag(comptime T: type) type {\n    return switch (@typeInfo(T)) {\n        .Enum => |info| info.tag_type,\n        .Union => |info| info.tag_type orelse @compileError(@typeName(T) ++ \" has no tag type\"),\n        else => @compileError(\"expected enum or union type, found '\" ++ @typeName(T) ++ \"'\"),\n    };\n}\n\ntest Tag {\n    const E = enum(u8) {\n        C = 33,\n        D,\n    };\n    const U = union(E) {\n        C: u8,\n        D: u16,\n    };\n\n    try testing.expect(Tag(E) == u8);\n    try testing.expect(Tag(U) == E);\n}\n\n///Returns the active tag of a tagged union\npub fn activeTag(u: anytype) Tag(@TypeOf(u)) {\n    const T = @TypeOf(u);\n    return @as(Tag(T), u);\n}\n\ntest activeTag {\n    const UE = enum {\n        Int,\n        Float,\n    };\n\n    const U = union(UE) {\n        Int: u32,\n        Float: f32,\n    };\n\n    var u = U{ .Int = 32 };\n    try testing.expect(activeTag(u) == UE.Int);\n\n    u = U{ .Float = 112.9876 };\n    try testing.expect(activeTag(u) == UE.Float);\n}\n\nconst TagPayloadType = TagPayload;\n\npub fn TagPayloadByName(comptime U: type, comptime tag_name: []const u8) type {\n    const info = @typeInfo(U).Union;\n\n    inline for (info.fields) |field_info| {\n        if (comptime mem.eql(u8, field_info.name, tag_name))\n            return field_info.type;\n    }\n\n    @compileError(\"no field '\" ++ tag_name ++ \"' in union '\" ++ @typeName(U) ++ \"'\");\n}\n\n/// Given a tagged union type, and an enum, return the type of the union field\n/// corresponding to the enum tag.\npub fn TagPayload(comptime U: type, comptime tag: Tag(U)) type {\n    return TagPayloadByName(U, @tagName(tag));\n}\n\ntest TagPayload {\n    const Event = union(enum) {\n        Moved: struct {\n            from: i32,\n            to: i32,\n        },\n    };\n    const MovedEvent = TagPayload(Event, Event.Moved);\n    const e: Event = .{ .Moved = undefined };\n    try testing.expect(MovedEvent == @TypeOf(e.Moved));\n}\n\n/// Compares two of any type for equality. Containers are compared on a field-by-field basis,\n/// where possible. Pointers are not followed.\npub fn eql(a: anytype, b: @TypeOf(a)) bool {\n    const T = @TypeOf(a);\n\n    switch (@typeInfo(T)) {\n        .Struct => |info| {\n            inline for (info.fields) |field_info| {\n                if (!eql(@field(a, field_info.name), @field(b, field_info.name))) return false;\n            }\n            return true;\n        },\n        .ErrorUnion => {\n            if (a) |a_p| {\n                if (b) |b_p| return eql(a_p, b_p) else |_| return false;\n            } else |a_e| {\n                if (b) |_| return false else |b_e| return a_e == b_e;\n            }\n        },\n        .Union => |info| {\n            if (info.tag_type) |UnionTag| {\n                const tag_a = activeTag(a);\n                const tag_b = activeTag(b);\n                if (tag_a != tag_b) return false;\n\n                inline for (info.fields) |field_info| {\n                    if (@field(UnionTag, field_info.name) == tag_a) {\n                        return eql(@field(a, field_info.name), @field(b, field_info.name));\n                    }\n                }\n                return false;\n            }\n\n            @compileError(\"cannot compare untagged union type \" ++ @typeName(T));\n        },\n        .Array => {\n            if (a.len != b.len) return false;\n            for (a, 0..) |e, i|\n                if (!eql(e, b[i])) return false;\n            return true;\n        },\n        .Vector => |info| {\n            var i: usize = 0;\n            while (i < info.len) : (i += 1) {\n                if (!eql(a[i], b[i])) return false;\n            }\n            return true;\n        },\n        .Pointer => |info| {\n            return switch (info.size) {\n                .One, .Many, .C => a == b,\n                .Slice => a.ptr == b.ptr and a.len == b.len,\n            };\n        },\n        .Optional => {\n            if (a == null and b == null) return true;\n            if (a == null or b == null) return false;\n            return eql(a.?, b.?);\n        },\n        else => return a == b,\n    }\n}\n\ntest eql {\n    const S = struct {\n        a: u32,\n        b: f64,\n        c: [5]u8,\n    };\n\n    const U = union(enum) {\n        s: S,\n        f: ?f32,\n    };\n\n    const s_1 = S{\n        .a = 134,\n        .b = 123.3,\n        .c = \"12345\".*,\n    };\n\n    var s_3 = S{\n        .a = 134,\n        .b = 123.3,\n        .c = \"12345\".*,\n    };\n\n    const u_1 = U{ .f = 24 };\n    const u_2 = U{ .s = s_1 };\n    const u_3 = U{ .f = 24 };\n\n    try testing.expect(eql(s_1, s_3));\n    try testing.expect(eql(&s_1, &s_1));\n    try testing.expect(!eql(&s_1, &s_3));\n    try testing.expect(eql(u_1, u_3));\n    try testing.expect(!eql(u_1, u_2));\n\n    const a1 = \"abcdef\".*;\n    const a2 = \"abcdef\".*;\n    const a3 = \"ghijkl\".*;\n\n    try testing.expect(eql(a1, a2));\n    try testing.expect(!eql(a1, a3));\n\n    const EU = struct {\n        fn tst(err: bool) !u8 {\n            if (err) return error.Error;\n            return @as(u8, 5);\n        }\n    };\n\n    try testing.expect(eql(EU.tst(true), EU.tst(true)));\n    try testing.expect(eql(EU.tst(false), EU.tst(false)));\n    try testing.expect(!eql(EU.tst(false), EU.tst(true)));\n\n    const V = @Vector(4, u32);\n    const v1: V = @splat(1);\n    const v2: V = @splat(1);\n    const v3: V = @splat(2);\n\n    try testing.expect(eql(v1, v2));\n    try testing.expect(!eql(v1, v3));\n}\n\ntest intToEnum {\n    const E1 = enum {\n        A,\n    };\n    const E2 = enum {\n        A,\n        B,\n    };\n    const E3 = enum(i8) { A, _ };\n\n    var zero: u8 = 0;\n    var one: u16 = 1;\n    _ = &zero;\n    _ = &one;\n    try testing.expect(intToEnum(E1, zero) catch unreachable == E1.A);\n    try testing.expect(intToEnum(E2, one) catch unreachable == E2.B);\n    try testing.expect(intToEnum(E3, zero) catch unreachable == E3.A);\n    try testing.expect(intToEnum(E3, 127) catch unreachable == @as(E3, @enumFromInt(127)));\n    try testing.expect(intToEnum(E3, -128) catch unreachable == @as(E3, @enumFromInt(-128)));\n    try testing.expectError(error.InvalidEnumTag, intToEnum(E1, one));\n    try testing.expectError(error.InvalidEnumTag, intToEnum(E3, 128));\n    try testing.expectError(error.InvalidEnumTag, intToEnum(E3, -129));\n}\n\npub const IntToEnumError = error{InvalidEnumTag};\n\npub fn intToEnum(comptime EnumTag: type, tag_int: anytype) IntToEnumError!EnumTag {\n    const enum_info = @typeInfo(EnumTag).Enum;\n\n    if (!enum_info.is_exhaustive) {\n        if (std.math.cast(enum_info.tag_type, tag_int)) |tag| {\n            return @as(EnumTag, @enumFromInt(tag));\n        }\n        return error.InvalidEnumTag;\n    }\n\n    // We don't direcly iterate over the fields of EnumTag, as that\n    // would require an inline loop. Instead, we create an array of\n    // values that is comptime-know, but can be iterated at runtime\n    // without requiring an inline loop. This generates better\n    // machine code.\n    const values = comptime blk: {\n        var result: [enum_info.fields.len]enum_info.tag_type = undefined;\n        for (&result, enum_info.fields) |*dst, src| {\n            dst.* = src.value;\n        }\n        break :blk result;\n    };\n    for (values) |v| {\n        if (v == tag_int) return @enumFromInt(tag_int);\n    }\n    return error.InvalidEnumTag;\n}\n\n/// Given a type and a name, return the field index according to source order.\n/// Returns `null` if the field is not found.\npub fn fieldIndex(comptime T: type, comptime name: []const u8) ?comptime_int {\n    inline for (fields(T), 0..) |field, i| {\n        if (mem.eql(u8, field.name, name))\n            return i;\n    }\n    return null;\n}\n\npub const refAllDecls = @compileError(\"refAllDecls has been moved from std.meta to std.testing\");\n\n/// Returns a slice of pointers to public declarations of a namespace.\npub fn declList(comptime Namespace: type, comptime Decl: type) []const *const Decl {\n    const S = struct {\n        fn declNameLessThan(context: void, lhs: *const Decl, rhs: *const Decl) bool {\n            _ = context;\n            return mem.lessThan(u8, lhs.name, rhs.name);\n        }\n    };\n    comptime {\n        const decls = declarations(Namespace);\n        var array: [decls.len]*const Decl = undefined;\n        for (decls, 0..) |decl, i| {\n            array[i] = &@field(Namespace, decl.name);\n        }\n        mem.sort(*const Decl, &array, {}, S.declNameLessThan);\n        return &array;\n    }\n}\n\npub const IntType = @compileError(\"replaced by std.meta.Int\");\n\npub fn Int(comptime signedness: std.builtin.Signedness, comptime bit_count: u16) type {\n    return @Type(.{\n        .Int = .{\n            .signedness = signedness,\n            .bits = bit_count,\n        },\n    });\n}\n\npub fn Float(comptime bit_count: u8) type {\n    return @Type(.{\n        .Float = .{ .bits = bit_count },\n    });\n}\n\ntest Float {\n    try testing.expectEqual(f16, Float(16));\n    try testing.expectEqual(f32, Float(32));\n    try testing.expectEqual(f64, Float(64));\n    try testing.expectEqual(f128, Float(128));\n}\n\n/// For a given function type, returns a tuple type which fields will\n/// correspond to the argument types.\n///\n/// Examples:\n/// - `ArgsTuple(fn () void)`  `tuple { }`\n/// - `ArgsTuple(fn (a: u32) u32)`  `tuple { u32 }`\n/// - `ArgsTuple(fn (a: u32, b: f16) noreturn)`  `tuple { u32, f16 }`\npub fn ArgsTuple(comptime Function: type) type {\n    const info = @typeInfo(Function);\n    if (info != .Fn)\n        @compileError(\"ArgsTuple expects a function type\");\n\n    const function_info = info.Fn;\n    if (function_info.is_var_args)\n        @compileError(\"Cannot create ArgsTuple for variadic function\");\n\n    var argument_field_list: [function_info.params.len]type = undefined;\n    inline for (function_info.params, 0..) |arg, i| {\n        const T = arg.type orelse @compileError(\"cannot create ArgsTuple for function with an 'anytype' parameter\");\n        argument_field_list[i] = T;\n    }\n\n    return CreateUniqueTuple(argument_field_list.len, argument_field_list);\n}\n\n/// For a given anonymous list of types, returns a new tuple type\n/// with those types as fields.\n///\n/// Examples:\n/// - `Tuple(&[_]type {})`  `tuple { }`\n/// - `Tuple(&[_]type {f32})`  `tuple { f32 }`\n/// - `Tuple(&[_]type {f32,u32})`  `tuple { f32, u32 }`\npub fn Tuple(comptime types: []const type) type {\n    return CreateUniqueTuple(types.len, types[0..types.len].*);\n}\n\nfn CreateUniqueTuple(comptime N: comptime_int, comptime types: [N]type) type {\n    var tuple_fields: [types.len]std.builtin.Type.StructField = undefined;\n    inline for (types, 0..) |T, i| {\n        @setEvalBranchQuota(10_000);\n        var num_buf: [128]u8 = undefined;\n        tuple_fields[i] = .{\n            .name = std.fmt.bufPrintZ(&num_buf, \"{d}\", .{i}) catch unreachable,\n            .type = T,\n            .default_value = null,\n            .is_comptime = false,\n            .alignment = if (@sizeOf(T) > 0) @alignOf(T) else 0,\n        };\n    }\n\n    return @Type(.{\n        .Struct = .{\n            .is_tuple = true,\n            .layout = .auto,\n            .decls = &.{},\n            .fields = &tuple_fields,\n        },\n    });\n}\n\nconst TupleTester = struct {\n    fn assertTypeEqual(comptime Expected: type, comptime Actual: type) void {\n        if (Expected != Actual)\n            @compileError(\"Expected type \" ++ @typeName(Expected) ++ \", but got type \" ++ @typeName(Actual));\n    }\n\n    fn assertTuple(comptime expected: anytype, comptime Actual: type) void {\n        const info = @typeInfo(Actual);\n        if (info != .Struct)\n            @compileError(\"Expected struct type\");\n        if (!info.Struct.is_tuple)\n            @compileError(\"Struct type must be a tuple type\");\n\n        const fields_list = std.meta.fields(Actual);\n        if (expected.len != fields_list.len)\n            @compileError(\"Argument count mismatch\");\n\n        inline for (fields_list, 0..) |fld, i| {\n            if (expected[i] != fld.type) {\n                @compileError(\"Field \" ++ fld.name ++ \" expected to be type \" ++ @typeName(expected[i]) ++ \", but was type \" ++ @typeName(fld.type));\n            }\n        }\n    }\n};\n\ntest ArgsTuple {\n    TupleTester.assertTuple(.{}, ArgsTuple(fn () void));\n    TupleTester.assertTuple(.{u32}, ArgsTuple(fn (a: u32) []const u8));\n    TupleTester.assertTuple(.{ u32, f16 }, ArgsTuple(fn (a: u32, b: f16) noreturn));\n    TupleTester.assertTuple(.{ u32, f16, []const u8, void }, ArgsTuple(fn (a: u32, b: f16, c: []const u8, void) noreturn));\n    TupleTester.assertTuple(.{u32}, ArgsTuple(fn (comptime a: u32) []const u8));\n}\n\ntest Tuple {\n    TupleTester.assertTuple(.{}, Tuple(&[_]type{}));\n    TupleTester.assertTuple(.{u32}, Tuple(&[_]type{u32}));\n    TupleTester.assertTuple(.{ u32, f16 }, Tuple(&[_]type{ u32, f16 }));\n    TupleTester.assertTuple(.{ u32, f16, []const u8, void }, Tuple(&[_]type{ u32, f16, []const u8, void }));\n}\n\ntest \"Tuple deduplication\" {\n    const T1 = std.meta.Tuple(&.{ u32, f32, i8 });\n    const T2 = std.meta.Tuple(&.{ u32, f32, i8 });\n    const T3 = std.meta.Tuple(&.{ u32, f32, i7 });\n\n    if (T1 != T2) {\n        @compileError(\"std.meta.Tuple doesn't deduplicate tuple types.\");\n    }\n    if (T1 == T3) {\n        @compileError(\"std.meta.Tuple fails to generate different types.\");\n    }\n}\n\ntest \"ArgsTuple forwarding\" {\n    const T1 = std.meta.Tuple(&.{ u32, f32, i8 });\n    const T2 = std.meta.ArgsTuple(fn (u32, f32, i8) void);\n    const T3 = std.meta.ArgsTuple(fn (u32, f32, i8) callconv(.C) noreturn);\n\n    if (T1 != T2) {\n        @compileError(\"std.meta.ArgsTuple produces different types than std.meta.Tuple\");\n    }\n    if (T1 != T3) {\n        @compileError(\"std.meta.ArgsTuple produces different types for the same argument lists.\");\n    }\n}\n\n/// Returns whether `error_union` contains an error.\npub fn isError(error_union: anytype) bool {\n    return if (error_union) |_| false else |_| true;\n}\n\ntest isError {\n    try std.testing.expect(isError(math.divTrunc(u8, 5, 0)));\n    try std.testing.expect(!isError(math.divTrunc(u8, 5, 5)));\n}\n\n/// Returns true if a type has a namespace and the namespace contains `name`;\n/// `false` otherwise. Result is always comptime-known.\npub inline fn hasFn(comptime T: type, comptime name: []const u8) bool {\n    switch (@typeInfo(T)) {\n        .Struct, .Union, .Enum, .Opaque => {},\n        else => return false,\n    }\n    if (!@hasDecl(T, name))\n        return false;\n\n    return @typeInfo(@TypeOf(@field(T, name))) == .Fn;\n}\n\ntest hasFn {\n    const S1 = struct {\n        pub fn foo() void {}\n    };\n\n    try std.testing.expect(hasFn(S1, \"foo\"));\n    try std.testing.expect(!hasFn(S1, \"bar\"));\n    try std.testing.expect(!hasFn(*S1, \"foo\"));\n\n    const S2 = struct {\n        foo: fn () void,\n    };\n\n    try std.testing.expect(!hasFn(S2, \"foo\"));\n}\n\n/// Returns true if a type has a `name` method; `false` otherwise.\n/// Result is always comptime-known.\npub inline fn hasMethod(comptime T: type, comptime name: []const u8) bool {\n    return switch (@typeInfo(T)) {\n        .Pointer => |P| switch (P.size) {\n            .One => hasFn(P.child, name),\n            .Many, .Slice, .C => false,\n        },\n        else => hasFn(T, name),\n    };\n}\n\ntest hasMethod {\n    try std.testing.expect(!hasMethod(u32, \"foo\"));\n    try std.testing.expect(!hasMethod([]u32, \"len\"));\n    try std.testing.expect(!hasMethod(struct { u32, u64 }, \"len\"));\n\n    const S1 = struct {\n        pub fn foo() void {}\n    };\n\n    try std.testing.expect(hasMethod(S1, \"foo\"));\n    try std.testing.expect(hasMethod(*S1, \"foo\"));\n\n    try std.testing.expect(!hasMethod(S1, \"bar\"));\n    try std.testing.expect(!hasMethod(*[1]S1, \"foo\"));\n    try std.testing.expect(!hasMethod(*[10]S1, \"foo\"));\n    try std.testing.expect(!hasMethod([]S1, \"foo\"));\n\n    const S2 = struct {\n        foo: fn () void,\n    };\n\n    try std.testing.expect(!hasMethod(S2, \"foo\"));\n\n    const U = union {\n        pub fn foo() void {}\n    };\n\n    try std.testing.expect(hasMethod(U, \"foo\"));\n    try std.testing.expect(hasMethod(*U, \"foo\"));\n    try std.testing.expect(!hasMethod(U, \"bar\"));\n}\n\n/// True if every value of the type `T` has a unique bit pattern representing it.\n/// In other words, `T` has no unused bits and no padding.\n/// Result is always comptime-known.\npub inline fn hasUniqueRepresentation(comptime T: type) bool {\n    return switch (@typeInfo(T)) {\n        else => false, // TODO can we know if it's true for some of these types ?\n\n        .AnyFrame,\n        .Enum,\n        .ErrorSet,\n        .Fn,\n        => true,\n\n        .Bool => false,\n\n        .Int => |info| @sizeOf(T) * 8 == info.bits,\n\n        .Pointer => |info| info.size != .Slice,\n\n        .Array => |info| hasUniqueRepresentation(info.child),\n\n        .Struct => |info| {\n            if (info.layout == .@\"packed\") return @sizeOf(T) * 8 == @bitSizeOf(T);\n\n            var sum_size = @as(usize, 0);\n\n            inline for (info.fields) |field| {\n                if (!hasUniqueRepresentation(field.type)) return false;\n                sum_size += @sizeOf(field.type);\n            }\n\n            return @sizeOf(T) == sum_size;\n        },\n\n        .Vector => |info| hasUniqueRepresentation(info.child) and\n            @sizeOf(T) == @sizeOf(info.child) * info.len,\n    };\n}\n\ntest hasUniqueRepresentation {\n    const TestStruct1 = struct {\n        a: u32,\n        b: u32,\n    };\n\n    try testing.expect(hasUniqueRepresentation(TestStruct1));\n\n    const TestStruct2 = struct {\n        a: u32,\n        b: u16,\n    };\n\n    try testing.expect(!hasUniqueRepresentation(TestStruct2));\n\n    const TestStruct3 = struct {\n        a: u32,\n        b: u32,\n    };\n\n    try testing.expect(hasUniqueRepresentation(TestStruct3));\n\n    const TestStruct4 = struct { a: []const u8 };\n\n    try testing.expect(!hasUniqueRepresentation(TestStruct4));\n\n    const TestStruct5 = struct { a: TestStruct4 };\n\n    try testing.expect(!hasUniqueRepresentation(TestStruct5));\n\n    const TestStruct6 = packed struct(u8) {\n        @\"0\": bool,\n        @\"1\": bool,\n        @\"2\": bool,\n        @\"3\": bool,\n        @\"4\": bool,\n        @\"5\": bool,\n        @\"6\": bool,\n        @\"7\": bool,\n    };\n\n    try testing.expect(hasUniqueRepresentation(TestStruct6));\n\n    const TestUnion1 = packed union {\n        a: u32,\n        b: u16,\n    };\n\n    try testing.expect(!hasUniqueRepresentation(TestUnion1));\n\n    const TestUnion2 = extern union {\n        a: u32,\n        b: u16,\n    };\n\n    try testing.expect(!hasUniqueRepresentation(TestUnion2));\n\n    const TestUnion3 = union {\n        a: u32,\n        b: u16,\n    };\n\n    try testing.expect(!hasUniqueRepresentation(TestUnion3));\n\n    const TestUnion4 = union(enum) {\n        a: u32,\n        b: u16,\n    };\n\n    try testing.expect(!hasUniqueRepresentation(TestUnion4));\n\n    inline for ([_]type{ i0, u8, i16, u32, i64 }) |T| {\n        try testing.expect(hasUniqueRepresentation(T));\n    }\n    inline for ([_]type{ i1, u9, i17, u33, i24 }) |T| {\n        try testing.expect(!hasUniqueRepresentation(T));\n    }\n\n    try testing.expect(!hasUniqueRepresentation([]u8));\n    try testing.expect(!hasUniqueRepresentation([]const u8));\n\n    try testing.expect(hasUniqueRepresentation(@Vector(std.simd.suggestVectorLength(u8) orelse 1, u8)));\n    try testing.expect(@sizeOf(@Vector(3, u8)) == 3 or !hasUniqueRepresentation(@Vector(3, u8)));\n}\n",
    "const std = @import(\"../std.zig\");\nconst assert = std.debug.assert;\nconst mem = std.mem;\nconst native_endian = @import(\"builtin\").target.cpu.arch.endian();\n\ncontext: *const anyopaque,\nwriteFn: *const fn (context: *const anyopaque, bytes: []const u8) anyerror!usize,\n\nconst Self = @This();\npub const Error = anyerror;\n\npub fn write(self: Self, bytes: []const u8) anyerror!usize {\n    return self.writeFn(self.context, bytes);\n}\n\npub fn writeAll(self: Self, bytes: []const u8) anyerror!void {\n    var index: usize = 0;\n    while (index != bytes.len) {\n        index += try self.write(bytes[index..]);\n    }\n}\n\npub fn print(self: Self, comptime format: []const u8, args: anytype) anyerror!void {\n    return std.fmt.format(self, format, args);\n}\n\npub fn writeByte(self: Self, byte: u8) anyerror!void {\n    const array = [1]u8{byte};\n    return self.writeAll(&array);\n}\n\npub fn writeByteNTimes(self: Self, byte: u8, n: usize) anyerror!void {\n    var bytes: [256]u8 = undefined;\n    @memset(bytes[0..], byte);\n\n    var remaining: usize = n;\n    while (remaining > 0) {\n        const to_write = @min(remaining, bytes.len);\n        try self.writeAll(bytes[0..to_write]);\n        remaining -= to_write;\n    }\n}\n\npub fn writeBytesNTimes(self: Self, bytes: []const u8, n: usize) anyerror!void {\n    var i: usize = 0;\n    while (i < n) : (i += 1) {\n        try self.writeAll(bytes);\n    }\n}\n\npub inline fn writeInt(self: Self, comptime T: type, value: T, endian: std.builtin.Endian) anyerror!void {\n    var bytes: [@divExact(@typeInfo(T).Int.bits, 8)]u8 = undefined;\n    mem.writeInt(std.math.ByteAlignedInt(@TypeOf(value)), &bytes, value, endian);\n    return self.writeAll(&bytes);\n}\n\npub fn writeStruct(self: Self, value: anytype) anyerror!void {\n    // Only extern and packed structs have defined in-memory layout.\n    comptime assert(@typeInfo(@TypeOf(value)).Struct.layout != .auto);\n    return self.writeAll(mem.asBytes(&value));\n}\n\npub fn writeStructEndian(self: Self, value: anytype, endian: std.builtin.Endian) anyerror!void {\n    // TODO: make sure this value is not a reference type\n    if (native_endian == endian) {\n        return self.writeStruct(value);\n    } else {\n        var copy = value;\n        mem.byteSwapAllFields(@TypeOf(value), &copy);\n        return self.writeStruct(copy);\n    }\n}\n\npub fn writeFile(self: Self, file: std.fs.File) anyerror!void {\n    // TODO: figure out how to adjust std lib abstractions so that this ends up\n    // doing sendfile or maybe even copy_file_range under the right conditions.\n    var buf: [4000]u8 = undefined;\n    while (true) {\n        const n = try file.readAll(&buf);\n        try self.writeAll(buf[0..n]);\n        if (n < buf.len) return;\n    }\n}\n",
    "const std = @import(\"./std.zig\");\nconst builtin = @import(\"builtin\");\nconst assert = std.debug.assert;\nconst testing = std.testing;\nconst mem = std.mem;\nconst native_endian = builtin.cpu.arch.endian();\n\n/// Use this to replace an unknown, unrecognized, or unrepresentable character.\n///\n/// See also: https://en.wikipedia.org/wiki/Specials_(Unicode_block)#Replacement_character\npub const replacement_character: u21 = 0xFFFD;\n\n/// Returns how many bytes the UTF-8 representation would require\n/// for the given codepoint.\npub fn utf8CodepointSequenceLength(c: u21) !u3 {\n    if (c < 0x80) return @as(u3, 1);\n    if (c < 0x800) return @as(u3, 2);\n    if (c < 0x10000) return @as(u3, 3);\n    if (c < 0x110000) return @as(u3, 4);\n    return error.CodepointTooLarge;\n}\n\n/// Given the first byte of a UTF-8 codepoint,\n/// returns a number 1-4 indicating the total length of the codepoint in bytes.\n/// If this byte does not match the form of a UTF-8 start byte, returns Utf8InvalidStartByte.\npub fn utf8ByteSequenceLength(first_byte: u8) !u3 {\n    // The switch is optimized much better than a \"smart\" approach using @clz\n    return switch (first_byte) {\n        0b0000_0000...0b0111_1111 => 1,\n        0b1100_0000...0b1101_1111 => 2,\n        0b1110_0000...0b1110_1111 => 3,\n        0b1111_0000...0b1111_0111 => 4,\n        else => error.Utf8InvalidStartByte,\n    };\n}\n\n/// Encodes the given codepoint into a UTF-8 byte sequence.\n/// c: the codepoint.\n/// out: the out buffer to write to. Must have a len >= utf8CodepointSequenceLength(c).\n/// Errors: if c cannot be encoded in UTF-8.\n/// Returns: the number of bytes written to out.\npub fn utf8Encode(c: u21, out: []u8) error{ Utf8CannotEncodeSurrogateHalf, CodepointTooLarge }!u3 {\n    return utf8EncodeImpl(c, out, .cannot_encode_surrogate_half);\n}\n\nconst Surrogates = enum {\n    cannot_encode_surrogate_half,\n    can_encode_surrogate_half,\n};\n\nfn utf8EncodeImpl(c: u21, out: []u8, comptime surrogates: Surrogates) !u3 {\n    const length = try utf8CodepointSequenceLength(c);\n    assert(out.len >= length);\n    switch (length) {\n        // The pattern for each is the same\n        // - Increasing the initial shift by 6 each time\n        // - Each time after the first shorten the shifted\n        //   value to a max of 0b111111 (63)\n        1 => out[0] = @as(u8, @intCast(c)), // Can just do 0 + codepoint for initial range\n        2 => {\n            out[0] = @as(u8, @intCast(0b11000000 | (c >> 6)));\n            out[1] = @as(u8, @intCast(0b10000000 | (c & 0b111111)));\n        },\n        3 => {\n            if (surrogates == .cannot_encode_surrogate_half and isSurrogateCodepoint(c)) {\n                return error.Utf8CannotEncodeSurrogateHalf;\n            }\n            out[0] = @as(u8, @intCast(0b11100000 | (c >> 12)));\n            out[1] = @as(u8, @intCast(0b10000000 | ((c >> 6) & 0b111111)));\n            out[2] = @as(u8, @intCast(0b10000000 | (c & 0b111111)));\n        },\n        4 => {\n            out[0] = @as(u8, @intCast(0b11110000 | (c >> 18)));\n            out[1] = @as(u8, @intCast(0b10000000 | ((c >> 12) & 0b111111)));\n            out[2] = @as(u8, @intCast(0b10000000 | ((c >> 6) & 0b111111)));\n            out[3] = @as(u8, @intCast(0b10000000 | (c & 0b111111)));\n        },\n        else => unreachable,\n    }\n    return length;\n}\n\npub inline fn utf8EncodeComptime(comptime c: u21) [\n    utf8CodepointSequenceLength(c) catch |err|\n        @compileError(@errorName(err))\n]u8 {\n    comptime var result: [\n        utf8CodepointSequenceLength(c) catch\n            unreachable\n    ]u8 = undefined;\n    comptime assert((utf8Encode(c, &result) catch |err|\n        @compileError(@errorName(err))) == result.len);\n    return result;\n}\n\nconst Utf8DecodeError = Utf8Decode2Error || Utf8Decode3Error || Utf8Decode4Error;\n\n/// Decodes the UTF-8 codepoint encoded in the given slice of bytes.\n/// bytes.len must be equal to utf8ByteSequenceLength(bytes[0]) catch unreachable.\n/// If you already know the length at comptime, you can call one of\n/// utf8Decode2,utf8Decode3,utf8Decode4 directly instead of this function.\npub fn utf8Decode(bytes: []const u8) Utf8DecodeError!u21 {\n    return switch (bytes.len) {\n        1 => @as(u21, bytes[0]),\n        2 => utf8Decode2(bytes),\n        3 => utf8Decode3(bytes),\n        4 => utf8Decode4(bytes),\n        else => unreachable,\n    };\n}\n\nconst Utf8Decode2Error = error{\n    Utf8ExpectedContinuation,\n    Utf8OverlongEncoding,\n};\npub fn utf8Decode2(bytes: []const u8) Utf8Decode2Error!u21 {\n    assert(bytes.len == 2);\n    assert(bytes[0] & 0b11100000 == 0b11000000);\n    var value: u21 = bytes[0] & 0b00011111;\n\n    if (bytes[1] & 0b11000000 != 0b10000000) return error.Utf8ExpectedContinuation;\n    value <<= 6;\n    value |= bytes[1] & 0b00111111;\n\n    if (value < 0x80) return error.Utf8OverlongEncoding;\n\n    return value;\n}\n\nconst Utf8Decode3Error = Utf8Decode3AllowSurrogateHalfError || error{\n    Utf8EncodesSurrogateHalf,\n};\npub fn utf8Decode3(bytes: []const u8) Utf8Decode3Error!u21 {\n    const value = try utf8Decode3AllowSurrogateHalf(bytes);\n\n    if (0xd800 <= value and value <= 0xdfff) return error.Utf8EncodesSurrogateHalf;\n\n    return value;\n}\n\nconst Utf8Decode3AllowSurrogateHalfError = error{\n    Utf8ExpectedContinuation,\n    Utf8OverlongEncoding,\n};\npub fn utf8Decode3AllowSurrogateHalf(bytes: []const u8) Utf8Decode3AllowSurrogateHalfError!u21 {\n    assert(bytes.len == 3);\n    assert(bytes[0] & 0b11110000 == 0b11100000);\n    var value: u21 = bytes[0] & 0b00001111;\n\n    if (bytes[1] & 0b11000000 != 0b10000000) return error.Utf8ExpectedContinuation;\n    value <<= 6;\n    value |= bytes[1] & 0b00111111;\n\n    if (bytes[2] & 0b11000000 != 0b10000000) return error.Utf8ExpectedContinuation;\n    value <<= 6;\n    value |= bytes[2] & 0b00111111;\n\n    if (value < 0x800) return error.Utf8OverlongEncoding;\n\n    return value;\n}\n\nconst Utf8Decode4Error = error{\n    Utf8ExpectedContinuation,\n    Utf8OverlongEncoding,\n    Utf8CodepointTooLarge,\n};\npub fn utf8Decode4(bytes: []const u8) Utf8Decode4Error!u21 {\n    assert(bytes.len == 4);\n    assert(bytes[0] & 0b11111000 == 0b11110000);\n    var value: u21 = bytes[0] & 0b00000111;\n\n    if (bytes[1] & 0b11000000 != 0b10000000) return error.Utf8ExpectedContinuation;\n    value <<= 6;\n    value |= bytes[1] & 0b00111111;\n\n    if (bytes[2] & 0b11000000 != 0b10000000) return error.Utf8ExpectedContinuation;\n    value <<= 6;\n    value |= bytes[2] & 0b00111111;\n\n    if (bytes[3] & 0b11000000 != 0b10000000) return error.Utf8ExpectedContinuation;\n    value <<= 6;\n    value |= bytes[3] & 0b00111111;\n\n    if (value < 0x10000) return error.Utf8OverlongEncoding;\n    if (value > 0x10FFFF) return error.Utf8CodepointTooLarge;\n\n    return value;\n}\n\n/// Returns true if the given unicode codepoint can be encoded in UTF-8.\npub fn utf8ValidCodepoint(value: u21) bool {\n    return switch (value) {\n        0xD800...0xDFFF => false, // Surrogates range\n        0x110000...0x1FFFFF => false, // Above the maximum codepoint value\n        else => true,\n    };\n}\n\n/// Returns the length of a supplied UTF-8 string literal in terms of unicode\n/// codepoints.\npub fn utf8CountCodepoints(s: []const u8) !usize {\n    var len: usize = 0;\n\n    const N = @sizeOf(usize);\n    const MASK = 0x80 * (std.math.maxInt(usize) / 0xff);\n\n    var i: usize = 0;\n    while (i < s.len) {\n        // Fast path for ASCII sequences\n        while (i + N <= s.len) : (i += N) {\n            const v = mem.readInt(usize, s[i..][0..N], native_endian);\n            if (v & MASK != 0) break;\n            len += N;\n        }\n\n        if (i < s.len) {\n            const n = try utf8ByteSequenceLength(s[i]);\n            if (i + n > s.len) return error.TruncatedInput;\n\n            switch (n) {\n                1 => {}, // ASCII, no validation needed\n                else => _ = try utf8Decode(s[i..][0..n]),\n            }\n\n            i += n;\n            len += 1;\n        }\n    }\n\n    return len;\n}\n\n/// Returns true if the input consists entirely of UTF-8 codepoints\npub fn utf8ValidateSlice(input: []const u8) bool {\n    return utf8ValidateSliceImpl(input, .cannot_encode_surrogate_half);\n}\n\nfn utf8ValidateSliceImpl(input: []const u8, comptime surrogates: Surrogates) bool {\n    var remaining = input;\n\n    if (std.simd.suggestVectorLength(u8)) |chunk_len| {\n        const Chunk = @Vector(chunk_len, u8);\n\n        // Fast path. Check for and skip ASCII characters at the start of the input.\n        while (remaining.len >= chunk_len) {\n            const chunk: Chunk = remaining[0..chunk_len].*;\n            const mask: Chunk = @splat(0x80);\n            if (@reduce(.Or, chunk & mask == mask)) {\n                // found a non ASCII byte\n                break;\n            }\n            remaining = remaining[chunk_len..];\n        }\n    }\n\n    // default lowest and highest continuation byte\n    const lo_cb = 0b10000000;\n    const hi_cb = 0b10111111;\n\n    const min_non_ascii_codepoint = 0x80;\n\n    // The first nibble is used to identify the continuation byte range to\n    // accept. The second nibble is the size.\n    const xx = 0xF1; // invalid: size 1\n    const as = 0xF0; // ASCII: size 1\n    const s1 = 0x02; // accept 0, size 2\n    const s2 = switch (surrogates) {\n        .cannot_encode_surrogate_half => 0x13, // accept 1, size 3\n        .can_encode_surrogate_half => 0x03, // accept 0, size 3\n    };\n    const s3 = 0x03; // accept 0, size 3\n    const s4 = switch (surrogates) {\n        .cannot_encode_surrogate_half => 0x23, // accept 2, size 3\n        .can_encode_surrogate_half => 0x03, // accept 0, size 3\n    };\n    const s5 = 0x34; // accept 3, size 4\n    const s6 = 0x04; // accept 0, size 4\n    const s7 = 0x44; // accept 4, size 4\n\n    // Information about the first byte in a UTF-8 sequence.\n    const first = comptime ([_]u8{as} ** 128) ++ ([_]u8{xx} ** 64) ++ [_]u8{\n        xx, xx, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1,\n        s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1, s1,\n        s2, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s4, s3, s3,\n        s5, s6, s6, s6, s7, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx,\n    };\n\n    const n = remaining.len;\n    var i: usize = 0;\n    while (i < n) {\n        const first_byte = remaining[i];\n        if (first_byte < min_non_ascii_codepoint) {\n            i += 1;\n            continue;\n        }\n\n        const info = first[first_byte];\n        if (info == xx) {\n            return false; // Illegal starter byte.\n        }\n\n        const size = info & 7;\n        if (i + size > n) {\n            return false; // Short or invalid.\n        }\n\n        // Figure out the acceptable low and high continuation bytes, starting\n        // with our defaults.\n        var accept_lo: u8 = lo_cb;\n        var accept_hi: u8 = hi_cb;\n\n        switch (info >> 4) {\n            0 => {},\n            1 => accept_lo = 0xA0,\n            2 => accept_hi = 0x9F,\n            3 => accept_lo = 0x90,\n            4 => accept_hi = 0x8F,\n            else => unreachable,\n        }\n\n        const c1 = remaining[i + 1];\n        if (c1 < accept_lo or accept_hi < c1) {\n            return false;\n        }\n\n        switch (size) {\n            2 => i += 2,\n            3 => {\n                const c2 = remaining[i + 2];\n                if (c2 < lo_cb or hi_cb < c2) {\n                    return false;\n                }\n                i += 3;\n            },\n            4 => {\n                const c2 = remaining[i + 2];\n                if (c2 < lo_cb or hi_cb < c2) {\n                    return false;\n                }\n                const c3 = remaining[i + 3];\n                if (c3 < lo_cb or hi_cb < c3) {\n                    return false;\n                }\n                i += 4;\n            },\n            else => unreachable,\n        }\n    }\n\n    return true;\n}\n\n/// Utf8View iterates the code points of a utf-8 encoded string.\n///\n/// ```\n/// var utf8 = (try std.unicode.Utf8View.init(\"hi there\")).iterator();\n/// while (utf8.nextCodepointSlice()) |codepoint| {\n///   std.debug.print(\"got codepoint {s}\\n\", .{codepoint});\n/// }\n/// ```\npub const Utf8View = struct {\n    bytes: []const u8,\n\n    pub fn init(s: []const u8) !Utf8View {\n        if (!utf8ValidateSlice(s)) {\n            return error.InvalidUtf8;\n        }\n\n        return initUnchecked(s);\n    }\n\n    pub fn initUnchecked(s: []const u8) Utf8View {\n        return Utf8View{ .bytes = s };\n    }\n\n    pub inline fn initComptime(comptime s: []const u8) Utf8View {\n        return comptime if (init(s)) |r| r else |err| switch (err) {\n            error.InvalidUtf8 => {\n                @compileError(\"invalid utf8\");\n            },\n        };\n    }\n\n    pub fn iterator(s: Utf8View) Utf8Iterator {\n        return Utf8Iterator{\n            .bytes = s.bytes,\n            .i = 0,\n        };\n    }\n};\n\npub const Utf8Iterator = struct {\n    bytes: []const u8,\n    i: usize,\n\n    pub fn nextCodepointSlice(it: *Utf8Iterator) ?[]const u8 {\n        if (it.i >= it.bytes.len) {\n            return null;\n        }\n\n        const cp_len = utf8ByteSequenceLength(it.bytes[it.i]) catch unreachable;\n        it.i += cp_len;\n        return it.bytes[it.i - cp_len .. it.i];\n    }\n\n    pub fn nextCodepoint(it: *Utf8Iterator) ?u21 {\n        const slice = it.nextCodepointSlice() orelse return null;\n        return utf8Decode(slice) catch unreachable;\n    }\n\n    /// Look ahead at the next n codepoints without advancing the iterator.\n    /// If fewer than n codepoints are available, then return the remainder of the string.\n    pub fn peek(it: *Utf8Iterator, n: usize) []const u8 {\n        const original_i = it.i;\n        defer it.i = original_i;\n\n        var end_ix = original_i;\n        var found: usize = 0;\n        while (found < n) : (found += 1) {\n            const next_codepoint = it.nextCodepointSlice() orelse return it.bytes[original_i..];\n            end_ix += next_codepoint.len;\n        }\n\n        return it.bytes[original_i..end_ix];\n    }\n};\n\npub fn utf16IsHighSurrogate(c: u16) bool {\n    return c & ~@as(u16, 0x03ff) == 0xd800;\n}\n\npub fn utf16IsLowSurrogate(c: u16) bool {\n    return c & ~@as(u16, 0x03ff) == 0xdc00;\n}\n\n/// Returns how many code units the UTF-16 representation would require\n/// for the given codepoint.\npub fn utf16CodepointSequenceLength(c: u21) !u2 {\n    if (c <= 0xFFFF) return 1;\n    if (c <= 0x10FFFF) return 2;\n    return error.CodepointTooLarge;\n}\n\ntest utf16CodepointSequenceLength {\n    try testing.expectEqual(@as(u2, 1), try utf16CodepointSequenceLength('a'));\n    try testing.expectEqual(@as(u2, 1), try utf16CodepointSequenceLength(0xFFFF));\n    try testing.expectEqual(@as(u2, 2), try utf16CodepointSequenceLength(0x10000));\n    try testing.expectEqual(@as(u2, 2), try utf16CodepointSequenceLength(0x10FFFF));\n    try testing.expectError(error.CodepointTooLarge, utf16CodepointSequenceLength(0x110000));\n}\n\n/// Given the first code unit of a UTF-16 codepoint, returns a number 1-2\n/// indicating the total length of the codepoint in UTF-16 code units.\n/// If this code unit does not match the form of a UTF-16 start code unit, returns Utf16InvalidStartCodeUnit.\npub fn utf16CodeUnitSequenceLength(first_code_unit: u16) !u2 {\n    if (utf16IsHighSurrogate(first_code_unit)) return 2;\n    if (utf16IsLowSurrogate(first_code_unit)) return error.Utf16InvalidStartCodeUnit;\n    return 1;\n}\n\ntest utf16CodeUnitSequenceLength {\n    try testing.expectEqual(@as(u2, 1), try utf16CodeUnitSequenceLength('a'));\n    try testing.expectEqual(@as(u2, 1), try utf16CodeUnitSequenceLength(0xFFFF));\n    try testing.expectEqual(@as(u2, 2), try utf16CodeUnitSequenceLength(0xDBFF));\n    try testing.expectError(error.Utf16InvalidStartCodeUnit, utf16CodeUnitSequenceLength(0xDFFF));\n}\n\n/// Decodes the codepoint encoded in the given pair of UTF-16 code units.\n/// Asserts that `surrogate_pair.len >= 2` and that the first code unit is a high surrogate.\n/// If the second code unit is not a low surrogate, error.ExpectedSecondSurrogateHalf is returned.\npub fn utf16DecodeSurrogatePair(surrogate_pair: []const u16) !u21 {\n    assert(surrogate_pair.len >= 2);\n    assert(utf16IsHighSurrogate(surrogate_pair[0]));\n    const high_half: u21 = surrogate_pair[0];\n    const low_half = surrogate_pair[1];\n    if (!utf16IsLowSurrogate(low_half)) return error.ExpectedSecondSurrogateHalf;\n    return 0x10000 + ((high_half & 0x03ff) << 10) | (low_half & 0x03ff);\n}\n\npub const Utf16LeIterator = struct {\n    bytes: []const u8,\n    i: usize,\n\n    pub fn init(s: []const u16) Utf16LeIterator {\n        return Utf16LeIterator{\n            .bytes = mem.sliceAsBytes(s),\n            .i = 0,\n        };\n    }\n\n    pub const NextCodepointError = error{ DanglingSurrogateHalf, ExpectedSecondSurrogateHalf, UnexpectedSecondSurrogateHalf };\n\n    pub fn nextCodepoint(it: *Utf16LeIterator) NextCodepointError!?u21 {\n        assert(it.i <= it.bytes.len);\n        if (it.i == it.bytes.len) return null;\n        var code_units: [2]u16 = undefined;\n        code_units[0] = mem.readInt(u16, it.bytes[it.i..][0..2], .little);\n        it.i += 2;\n        if (utf16IsHighSurrogate(code_units[0])) {\n            // surrogate pair\n            if (it.i >= it.bytes.len) return error.DanglingSurrogateHalf;\n            code_units[1] = mem.readInt(u16, it.bytes[it.i..][0..2], .little);\n            const codepoint = try utf16DecodeSurrogatePair(&code_units);\n            it.i += 2;\n            return codepoint;\n        } else if (utf16IsLowSurrogate(code_units[0])) {\n            return error.UnexpectedSecondSurrogateHalf;\n        } else {\n            return code_units[0];\n        }\n    }\n};\n\n/// Returns the length of a supplied UTF-16 string literal in terms of unicode\n/// codepoints.\npub fn utf16CountCodepoints(utf16le: []const u16) !usize {\n    var len: usize = 0;\n    var it = Utf16LeIterator.init(utf16le);\n    while (try it.nextCodepoint()) |_| len += 1;\n    return len;\n}\n\nfn testUtf16CountCodepoints() !void {\n    try testing.expectEqual(\n        @as(usize, 1),\n        try utf16CountCodepoints(utf8ToUtf16LeStringLiteral(\"a\")),\n    );\n    try testing.expectEqual(\n        @as(usize, 10),\n        try utf16CountCodepoints(utf8ToUtf16LeStringLiteral(\"abcdefghij\")),\n    );\n    try testing.expectEqual(\n        @as(usize, 10),\n        try utf16CountCodepoints(utf8ToUtf16LeStringLiteral(\"\")),\n    );\n    try testing.expectEqual(\n        @as(usize, 5),\n        try utf16CountCodepoints(utf8ToUtf16LeStringLiteral(\"\")),\n    );\n}\n\ntest \"utf16 count codepoints\" {\n    try testUtf16CountCodepoints();\n    try comptime testUtf16CountCodepoints();\n}\n\ntest \"utf8 encode\" {\n    try comptime testUtf8Encode();\n    try testUtf8Encode();\n}\nfn testUtf8Encode() !void {\n    // A few taken from wikipedia a few taken elsewhere\n    var array: [4]u8 = undefined;\n    try testing.expect((try utf8Encode(try utf8Decode(\"\"), array[0..])) == 3);\n    try testing.expect(array[0] == 0b11100010);\n    try testing.expect(array[1] == 0b10000010);\n    try testing.expect(array[2] == 0b10101100);\n\n    try testing.expect((try utf8Encode(try utf8Decode(\"$\"), array[0..])) == 1);\n    try testing.expect(array[0] == 0b00100100);\n\n    try testing.expect((try utf8Encode(try utf8Decode(\"\"), array[0..])) == 2);\n    try testing.expect(array[0] == 0b11000010);\n    try testing.expect(array[1] == 0b10100010);\n\n    try testing.expect((try utf8Encode(try utf8Decode(\"\"), array[0..])) == 4);\n    try testing.expect(array[0] == 0b11110000);\n    try testing.expect(array[1] == 0b10010000);\n    try testing.expect(array[2] == 0b10001101);\n    try testing.expect(array[3] == 0b10001000);\n}\n\ntest \"utf8 encode comptime\" {\n    try testing.expectEqualSlices(u8, \"\", &utf8EncodeComptime(''));\n    try testing.expectEqualSlices(u8, \"$\", &utf8EncodeComptime('$'));\n    try testing.expectEqualSlices(u8, \"\", &utf8EncodeComptime(''));\n    try testing.expectEqualSlices(u8, \"\", &utf8EncodeComptime(''));\n}\n\ntest \"utf8 encode error\" {\n    try comptime testUtf8EncodeError();\n    try testUtf8EncodeError();\n}\nfn testUtf8EncodeError() !void {\n    var array: [4]u8 = undefined;\n    try testErrorEncode(0xd800, array[0..], error.Utf8CannotEncodeSurrogateHalf);\n    try testErrorEncode(0xdfff, array[0..], error.Utf8CannotEncodeSurrogateHalf);\n    try testErrorEncode(0x110000, array[0..], error.CodepointTooLarge);\n    try testErrorEncode(0x1fffff, array[0..], error.CodepointTooLarge);\n}\n\nfn testErrorEncode(codePoint: u21, array: []u8, expectedErr: anyerror) !void {\n    try testing.expectError(expectedErr, utf8Encode(codePoint, array));\n}\n\ntest \"utf8 iterator on ascii\" {\n    try comptime testUtf8IteratorOnAscii();\n    try testUtf8IteratorOnAscii();\n}\nfn testUtf8IteratorOnAscii() !void {\n    const s = Utf8View.initComptime(\"abc\");\n\n    var it1 = s.iterator();\n    try testing.expect(mem.eql(u8, \"a\", it1.nextCodepointSlice().?));\n    try testing.expect(mem.eql(u8, \"b\", it1.nextCodepointSlice().?));\n    try testing.expect(mem.eql(u8, \"c\", it1.nextCodepointSlice().?));\n    try testing.expect(it1.nextCodepointSlice() == null);\n\n    var it2 = s.iterator();\n    try testing.expect(it2.nextCodepoint().? == 'a');\n    try testing.expect(it2.nextCodepoint().? == 'b');\n    try testing.expect(it2.nextCodepoint().? == 'c');\n    try testing.expect(it2.nextCodepoint() == null);\n}\n\ntest \"utf8 view bad\" {\n    try comptime testUtf8ViewBad();\n    try testUtf8ViewBad();\n}\nfn testUtf8ViewBad() !void {\n    // Compile-time error.\n    // const s3 = Utf8View.initComptime(\"\\xfe\\xf2\");\n    try testing.expectError(error.InvalidUtf8, Utf8View.init(\"hel\\xadlo\"));\n}\n\ntest \"utf8 view ok\" {\n    try comptime testUtf8ViewOk();\n    try testUtf8ViewOk();\n}\nfn testUtf8ViewOk() !void {\n    const s = Utf8View.initComptime(\"\");\n\n    var it1 = s.iterator();\n    try testing.expect(mem.eql(u8, \"\", it1.nextCodepointSlice().?));\n    try testing.expect(mem.eql(u8, \"\", it1.nextCodepointSlice().?));\n    try testing.expect(mem.eql(u8, \"\", it1.nextCodepointSlice().?));\n    try testing.expect(it1.nextCodepointSlice() == null);\n\n    var it2 = s.iterator();\n    try testing.expect(it2.nextCodepoint().? == 0x6771);\n    try testing.expect(it2.nextCodepoint().? == 0x4eac);\n    try testing.expect(it2.nextCodepoint().? == 0x5e02);\n    try testing.expect(it2.nextCodepoint() == null);\n}\n\ntest \"validate slice\" {\n    try comptime testValidateSlice();\n    try testValidateSlice();\n\n    // We skip a variable (based on recommended vector size) chunks of\n    // ASCII characters. Let's make sure we're chunking correctly.\n    const str = [_]u8{'a'} ** 550 ++ \"\\xc0\";\n    for (0..str.len - 3) |i| {\n        try testing.expect(!utf8ValidateSlice(str[i..]));\n    }\n}\nfn testValidateSlice() !void {\n    try testing.expect(utf8ValidateSlice(\"abc\"));\n    try testing.expect(utf8ValidateSlice(\"abc\\xdf\\xbf\"));\n    try testing.expect(utf8ValidateSlice(\"\"));\n    try testing.expect(utf8ValidateSlice(\"a\"));\n    try testing.expect(utf8ValidateSlice(\"abc\"));\n    try testing.expect(utf8ValidateSlice(\"\"));\n    try testing.expect(utf8ValidateSlice(\"\"));\n    try testing.expect(utf8ValidateSlice(\"-\"));\n    try testing.expect(utf8ValidateSlice(\"\"));\n    try testing.expect(utf8ValidateSlice(\"a\\u{fffdb}\"));\n    try testing.expect(utf8ValidateSlice(\"\\xf4\\x8f\\xbf\\xbf\"));\n    try testing.expect(utf8ValidateSlice(\"abc\\xdf\\xbf\"));\n\n    try testing.expect(!utf8ValidateSlice(\"abc\\xc0\"));\n    try testing.expect(!utf8ValidateSlice(\"abc\\xc0abc\"));\n    try testing.expect(!utf8ValidateSlice(\"aa\\xe2\"));\n    try testing.expect(!utf8ValidateSlice(\"\\x42\\xfa\"));\n    try testing.expect(!utf8ValidateSlice(\"\\x42\\xfa\\x43\"));\n    try testing.expect(!utf8ValidateSlice(\"abc\\xc0\"));\n    try testing.expect(!utf8ValidateSlice(\"abc\\xc0abc\"));\n    try testing.expect(!utf8ValidateSlice(\"\\xf4\\x90\\x80\\x80\"));\n    try testing.expect(!utf8ValidateSlice(\"\\xf7\\xbf\\xbf\\xbf\"));\n    try testing.expect(!utf8ValidateSlice(\"\\xfb\\xbf\\xbf\\xbf\\xbf\"));\n    try testing.expect(!utf8ValidateSlice(\"\\xc0\\x80\"));\n    try testing.expect(!utf8ValidateSlice(\"\\xed\\xa0\\x80\"));\n    try testing.expect(!utf8ValidateSlice(\"\\xed\\xbf\\xbf\"));\n}\n\ntest \"valid utf8\" {\n    try comptime testValidUtf8();\n    try testValidUtf8();\n}\nfn testValidUtf8() !void {\n    try testValid(\"\\x00\", 0x0);\n    try testValid(\"\\x20\", 0x20);\n    try testValid(\"\\x7f\", 0x7f);\n    try testValid(\"\\xc2\\x80\", 0x80);\n    try testValid(\"\\xdf\\xbf\", 0x7ff);\n    try testValid(\"\\xe0\\xa0\\x80\", 0x800);\n    try testValid(\"\\xe1\\x80\\x80\", 0x1000);\n    try testValid(\"\\xef\\xbf\\xbf\", 0xffff);\n    try testValid(\"\\xf0\\x90\\x80\\x80\", 0x10000);\n    try testValid(\"\\xf1\\x80\\x80\\x80\", 0x40000);\n    try testValid(\"\\xf3\\xbf\\xbf\\xbf\", 0xfffff);\n    try testValid(\"\\xf4\\x8f\\xbf\\xbf\", 0x10ffff);\n}\n\ntest \"invalid utf8 continuation bytes\" {\n    try comptime testInvalidUtf8ContinuationBytes();\n    try testInvalidUtf8ContinuationBytes();\n}\nfn testInvalidUtf8ContinuationBytes() !void {\n    // unexpected continuation\n    try testError(\"\\x80\", error.Utf8InvalidStartByte);\n    try testError(\"\\xbf\", error.Utf8InvalidStartByte);\n    // too many leading 1's\n    try testError(\"\\xf8\", error.Utf8InvalidStartByte);\n    try testError(\"\\xff\", error.Utf8InvalidStartByte);\n    // expected continuation for 2 byte sequences\n    try testError(\"\\xc2\", error.UnexpectedEof);\n    try testError(\"\\xc2\\x00\", error.Utf8ExpectedContinuation);\n    try testError(\"\\xc2\\xc0\", error.Utf8ExpectedContinuation);\n    // expected continuation for 3 byte sequences\n    try testError(\"\\xe0\", error.UnexpectedEof);\n    try testError(\"\\xe0\\x00\", error.UnexpectedEof);\n    try testError(\"\\xe0\\xc0\", error.UnexpectedEof);\n    try testError(\"\\xe0\\xa0\", error.UnexpectedEof);\n    try testError(\"\\xe0\\xa0\\x00\", error.Utf8ExpectedContinuation);\n    try testError(\"\\xe0\\xa0\\xc0\", error.Utf8ExpectedContinuation);\n    // expected continuation for 4 byte sequences\n    try testError(\"\\xf0\", error.UnexpectedEof);\n    try testError(\"\\xf0\\x00\", error.UnexpectedEof);\n    try testError(\"\\xf0\\xc0\", error.UnexpectedEof);\n    try testError(\"\\xf0\\x90\\x00\", error.UnexpectedEof);\n    try testError(\"\\xf0\\x90\\xc0\", error.UnexpectedEof);\n    try testError(\"\\xf0\\x90\\x80\\x00\", error.Utf8ExpectedContinuation);\n    try testError(\"\\xf0\\x90\\x80\\xc0\", error.Utf8ExpectedContinuation);\n}\n\ntest \"overlong utf8 codepoint\" {\n    try comptime testOverlongUtf8Codepoint();\n    try testOverlongUtf8Codepoint();\n}\nfn testOverlongUtf8Codepoint() !void {\n    try testError(\"\\xc0\\x80\", error.Utf8OverlongEncoding);\n    try testError(\"\\xc1\\xbf\", error.Utf8OverlongEncoding);\n    try testError(\"\\xe0\\x80\\x80\", error.Utf8OverlongEncoding);\n    try testError(\"\\xe0\\x9f\\xbf\", error.Utf8OverlongEncoding);\n    try testError(\"\\xf0\\x80\\x80\\x80\", error.Utf8OverlongEncoding);\n    try testError(\"\\xf0\\x8f\\xbf\\xbf\", error.Utf8OverlongEncoding);\n}\n\ntest \"misc invalid utf8\" {\n    try comptime testMiscInvalidUtf8();\n    try testMiscInvalidUtf8();\n}\nfn testMiscInvalidUtf8() !void {\n    // codepoint out of bounds\n    try testError(\"\\xf4\\x90\\x80\\x80\", error.Utf8CodepointTooLarge);\n    try testError(\"\\xf7\\xbf\\xbf\\xbf\", error.Utf8CodepointTooLarge);\n    // surrogate halves\n    try testValid(\"\\xed\\x9f\\xbf\", 0xd7ff);\n    try testError(\"\\xed\\xa0\\x80\", error.Utf8EncodesSurrogateHalf);\n    try testError(\"\\xed\\xbf\\xbf\", error.Utf8EncodesSurrogateHalf);\n    try testValid(\"\\xee\\x80\\x80\", 0xe000);\n}\n\ntest \"utf8 iterator peeking\" {\n    try comptime testUtf8Peeking();\n    try testUtf8Peeking();\n}\n\nfn testUtf8Peeking() !void {\n    const s = Utf8View.initComptime(\"nol\");\n    var it = s.iterator();\n\n    try testing.expect(mem.eql(u8, \"n\", it.nextCodepointSlice().?));\n\n    try testing.expect(mem.eql(u8, \"o\", it.peek(1)));\n    try testing.expect(mem.eql(u8, \"o\", it.peek(2)));\n    try testing.expect(mem.eql(u8, \"ol\", it.peek(3)));\n    try testing.expect(mem.eql(u8, \"ol\", it.peek(4)));\n    try testing.expect(mem.eql(u8, \"ol\", it.peek(10)));\n\n    try testing.expect(mem.eql(u8, \"o\", it.nextCodepointSlice().?));\n    try testing.expect(mem.eql(u8, \"\", it.nextCodepointSlice().?));\n    try testing.expect(mem.eql(u8, \"l\", it.nextCodepointSlice().?));\n    try testing.expect(it.nextCodepointSlice() == null);\n\n    try testing.expect(mem.eql(u8, &[_]u8{}, it.peek(1)));\n}\n\nfn testError(bytes: []const u8, expected_err: anyerror) !void {\n    try testing.expectError(expected_err, testDecode(bytes));\n}\n\nfn testValid(bytes: []const u8, expected_codepoint: u21) !void {\n    try testing.expect((testDecode(bytes) catch unreachable) == expected_codepoint);\n}\n\nfn testDecode(bytes: []const u8) !u21 {\n    const length = try utf8ByteSequenceLength(bytes[0]);\n    if (bytes.len < length) return error.UnexpectedEof;\n    try testing.expect(bytes.len == length);\n    return utf8Decode(bytes);\n}\n\n/// Print the given `utf8` string, encoded as UTF-8 bytes.\n/// Ill-formed UTF-8 byte sequences are replaced by the replacement character (U+FFFD)\n/// according to \"U+FFFD Substitution of Maximal Subparts\" from Chapter 3 of\n/// the Unicode standard, and as specified by https://encoding.spec.whatwg.org/#utf-8-decoder\nfn formatUtf8(\n    utf8: []const u8,\n    comptime fmt: []const u8,\n    options: std.fmt.FormatOptions,\n    writer: anytype,\n) !void {\n    _ = fmt;\n    _ = options;\n    var buf: [300]u8 = undefined; // just an arbitrary size\n    var u8len: usize = 0;\n\n    // This implementation is based on this specification:\n    // https://encoding.spec.whatwg.org/#utf-8-decoder\n    var codepoint: u21 = 0;\n    var cont_bytes_seen: u3 = 0;\n    var cont_bytes_needed: u3 = 0;\n    var lower_boundary: u8 = 0x80;\n    var upper_boundary: u8 = 0xBF;\n\n    var i: usize = 0;\n    while (i < utf8.len) {\n        const byte = utf8[i];\n        if (cont_bytes_needed == 0) {\n            switch (byte) {\n                0x00...0x7F => {\n                    buf[u8len] = byte;\n                    u8len += 1;\n                },\n                0xC2...0xDF => {\n                    cont_bytes_needed = 1;\n                    codepoint = byte & 0b00011111;\n                },\n                0xE0...0xEF => {\n                    if (byte == 0xE0) lower_boundary = 0xA0;\n                    if (byte == 0xED) upper_boundary = 0x9F;\n                    cont_bytes_needed = 2;\n                    codepoint = byte & 0b00001111;\n                },\n                0xF0...0xF4 => {\n                    if (byte == 0xF0) lower_boundary = 0x90;\n                    if (byte == 0xF4) upper_boundary = 0x8F;\n                    cont_bytes_needed = 3;\n                    codepoint = byte & 0b00000111;\n                },\n                else => {\n                    u8len += utf8Encode(replacement_character, buf[u8len..]) catch unreachable;\n                },\n            }\n            // consume the byte\n            i += 1;\n        } else if (byte < lower_boundary or byte > upper_boundary) {\n            codepoint = 0;\n            cont_bytes_needed = 0;\n            cont_bytes_seen = 0;\n            lower_boundary = 0x80;\n            upper_boundary = 0xBF;\n            u8len += utf8Encode(replacement_character, buf[u8len..]) catch unreachable;\n            // do not consume the current byte, it should now be treated as a possible start byte\n        } else {\n            lower_boundary = 0x80;\n            upper_boundary = 0xBF;\n            codepoint <<= 6;\n            codepoint |= byte & 0b00111111;\n            cont_bytes_seen += 1;\n            // consume the byte\n            i += 1;\n\n            if (cont_bytes_seen == cont_bytes_needed) {\n                const codepoint_len = cont_bytes_seen + 1;\n                const codepoint_start_i = i - codepoint_len;\n                @memcpy(buf[u8len..][0..codepoint_len], utf8[codepoint_start_i..][0..codepoint_len]);\n                u8len += codepoint_len;\n\n                codepoint = 0;\n                cont_bytes_needed = 0;\n                cont_bytes_seen = 0;\n            }\n        }\n        // make sure there's always enough room for another maximum length UTF-8 codepoint\n        if (u8len + 4 > buf.len) {\n            try writer.writeAll(buf[0..u8len]);\n            u8len = 0;\n        }\n    }\n    if (cont_bytes_needed != 0) {\n        // we know there's enough room because we always flush\n        // if there's less than 4 bytes remaining in the buffer.\n        u8len += utf8Encode(replacement_character, buf[u8len..]) catch unreachable;\n    }\n    try writer.writeAll(buf[0..u8len]);\n}\n\n/// Return a Formatter for a (potentially ill-formed) UTF-8 string.\n/// Ill-formed UTF-8 byte sequences are replaced by the replacement character (U+FFFD)\n/// according to \"U+FFFD Substitution of Maximal Subparts\" from Chapter 3 of\n/// the Unicode standard, and as specified by https://encoding.spec.whatwg.org/#utf-8-decoder\npub fn fmtUtf8(utf8: []const u8) std.fmt.Formatter(formatUtf8) {\n    return .{ .data = utf8 };\n}\n\ntest fmtUtf8 {\n    const expectFmt = testing.expectFmt;\n    try expectFmt(\"\", \"{}\", .{fmtUtf8(\"\")});\n    try expectFmt(\"foo\", \"{}\", .{fmtUtf8(\"foo\")});\n    try expectFmt(\"\", \"{}\", .{fmtUtf8(\"\")});\n\n    // Table 3-8. U+FFFD for Non-Shortest Form Sequences\n    try expectFmt(\"A\", \"{}\", .{fmtUtf8(\"\\xC0\\xAF\\xE0\\x80\\xBF\\xF0\\x81\\x82A\")});\n\n    // Table 3-9. U+FFFD for Ill-Formed Sequences for Surrogates\n    try expectFmt(\"A\", \"{}\", .{fmtUtf8(\"\\xED\\xA0\\x80\\xED\\xBF\\xBF\\xED\\xAFA\")});\n\n    // Table 3-10. U+FFFD for Other Ill-Formed Sequences\n    try expectFmt(\"AB\", \"{}\", .{fmtUtf8(\"\\xF4\\x91\\x92\\x93\\xFFA\\x80\\xBFB\")});\n\n    // Table 3-11. U+FFFD for Truncated Sequences\n    try expectFmt(\"A\", \"{}\", .{fmtUtf8(\"\\xE1\\x80\\xE2\\xF0\\x91\\x92\\xF1\\xBFA\")});\n}\n\nfn utf16LeToUtf8ArrayListImpl(\n    result: *std.ArrayList(u8),\n    utf16le: []const u16,\n    comptime surrogates: Surrogates,\n) (switch (surrogates) {\n    .cannot_encode_surrogate_half => Utf16LeToUtf8AllocError,\n    .can_encode_surrogate_half => mem.Allocator.Error,\n})!void {\n    assert(result.unusedCapacitySlice().len >= utf16le.len);\n\n    var remaining = utf16le;\n    vectorized: {\n        const chunk_len = std.simd.suggestVectorLength(u16) orelse break :vectorized;\n        const Chunk = @Vector(chunk_len, u16);\n\n        // Fast path. Check for and encode ASCII characters at the start of the input.\n        while (remaining.len >= chunk_len) {\n            const chunk: Chunk = remaining[0..chunk_len].*;\n            const mask: Chunk = @splat(mem.nativeToLittle(u16, 0x7F));\n            if (@reduce(.Or, chunk | mask != mask)) {\n                // found a non ASCII code unit\n                break;\n            }\n            const ascii_chunk: @Vector(chunk_len, u8) = @truncate(mem.nativeToLittle(Chunk, chunk));\n            // We allocated enough space to encode every UTF-16 code unit\n            // as ASCII, so if the entire string is ASCII then we are\n            // guaranteed to have enough space allocated\n            result.addManyAsArrayAssumeCapacity(chunk_len).* = ascii_chunk;\n            remaining = remaining[chunk_len..];\n        }\n    }\n\n    switch (surrogates) {\n        .cannot_encode_surrogate_half => {\n            var it = Utf16LeIterator.init(remaining);\n            while (try it.nextCodepoint()) |codepoint| {\n                const utf8_len = utf8CodepointSequenceLength(codepoint) catch unreachable;\n                assert((utf8Encode(codepoint, try result.addManyAsSlice(utf8_len)) catch unreachable) == utf8_len);\n            }\n        },\n        .can_encode_surrogate_half => {\n            var it = Wtf16LeIterator.init(remaining);\n            while (it.nextCodepoint()) |codepoint| {\n                const utf8_len = utf8CodepointSequenceLength(codepoint) catch unreachable;\n                assert((wtf8Encode(codepoint, try result.addManyAsSlice(utf8_len)) catch unreachable) == utf8_len);\n            }\n        },\n    }\n}\n\npub const Utf16LeToUtf8AllocError = mem.Allocator.Error || Utf16LeToUtf8Error;\n\npub fn utf16LeToUtf8ArrayList(result: *std.ArrayList(u8), utf16le: []const u16) Utf16LeToUtf8AllocError!void {\n    try result.ensureUnusedCapacity(utf16le.len);\n    return utf16LeToUtf8ArrayListImpl(result, utf16le, .cannot_encode_surrogate_half);\n}\n\n/// Deprecated; renamed to utf16LeToUtf8Alloc\npub const utf16leToUtf8Alloc = utf16LeToUtf8Alloc;\n\n/// Caller must free returned memory.\npub fn utf16LeToUtf8Alloc(allocator: mem.Allocator, utf16le: []const u16) Utf16LeToUtf8AllocError![]u8 {\n    // optimistically guess that it will all be ascii.\n    var result = try std.ArrayList(u8).initCapacity(allocator, utf16le.len);\n    errdefer result.deinit();\n\n    try utf16LeToUtf8ArrayListImpl(&result, utf16le, .cannot_encode_surrogate_half);\n    return result.toOwnedSlice();\n}\n\n/// Deprecated; renamed to utf16LeToUtf8AllocZ\npub const utf16leToUtf8AllocZ = utf16LeToUtf8AllocZ;\n\n/// Caller must free returned memory.\npub fn utf16LeToUtf8AllocZ(allocator: mem.Allocator, utf16le: []const u16) Utf16LeToUtf8AllocError![:0]u8 {\n    // optimistically guess that it will all be ascii (and allocate space for the null terminator)\n    var result = try std.ArrayList(u8).initCapacity(allocator, utf16le.len + 1);\n    errdefer result.deinit();\n\n    try utf16LeToUtf8ArrayListImpl(&result, utf16le, .cannot_encode_surrogate_half);\n    return result.toOwnedSliceSentinel(0);\n}\n\npub const Utf16LeToUtf8Error = Utf16LeIterator.NextCodepointError;\n\n/// Asserts that the output buffer is big enough.\n/// Returns end byte index into utf8.\nfn utf16LeToUtf8Impl(utf8: []u8, utf16le: []const u16, comptime surrogates: Surrogates) (switch (surrogates) {\n    .cannot_encode_surrogate_half => Utf16LeToUtf8Error,\n    .can_encode_surrogate_half => error{},\n})!usize {\n    var dest_index: usize = 0;\n\n    var remaining = utf16le;\n    vectorized: {\n        const chunk_len = std.simd.suggestVectorLength(u16) orelse break :vectorized;\n        const Chunk = @Vector(chunk_len, u16);\n\n        // Fast path. Check for and encode ASCII characters at the start of the input.\n        while (remaining.len >= chunk_len) {\n            const chunk: Chunk = remaining[0..chunk_len].*;\n            const mask: Chunk = @splat(mem.nativeToLittle(u16, 0x7F));\n            if (@reduce(.Or, chunk | mask != mask)) {\n                // found a non ASCII code unit\n                break;\n            }\n            const ascii_chunk: @Vector(chunk_len, u8) = @truncate(mem.nativeToLittle(Chunk, chunk));\n            utf8[dest_index..][0..chunk_len].* = ascii_chunk;\n            dest_index += chunk_len;\n            remaining = remaining[chunk_len..];\n        }\n    }\n\n    switch (surrogates) {\n        .cannot_encode_surrogate_half => {\n            var it = Utf16LeIterator.init(remaining);\n            while (try it.nextCodepoint()) |codepoint| {\n                dest_index += utf8Encode(codepoint, utf8[dest_index..]) catch |err| switch (err) {\n                    // The maximum possible codepoint encoded by UTF-16 is U+10FFFF,\n                    // which is within the valid codepoint range.\n                    error.CodepointTooLarge => unreachable,\n                    // We know the codepoint was valid in UTF-16, meaning it is not\n                    // an unpaired surrogate codepoint.\n                    error.Utf8CannotEncodeSurrogateHalf => unreachable,\n                };\n            }\n        },\n        .can_encode_surrogate_half => {\n            var it = Wtf16LeIterator.init(remaining);\n            while (it.nextCodepoint()) |codepoint| {\n                dest_index += wtf8Encode(codepoint, utf8[dest_index..]) catch |err| switch (err) {\n                    // The maximum possible codepoint encoded by UTF-16 is U+10FFFF,\n                    // which is within the valid codepoint range.\n                    error.CodepointTooLarge => unreachable,\n                };\n            }\n        },\n    }\n    return dest_index;\n}\n\n/// Deprecated; renamed to utf16LeToUtf8\npub const utf16leToUtf8 = utf16LeToUtf8;\n\npub fn utf16LeToUtf8(utf8: []u8, utf16le: []const u16) Utf16LeToUtf8Error!usize {\n    return utf16LeToUtf8Impl(utf8, utf16le, .cannot_encode_surrogate_half);\n}\n\ntest utf16LeToUtf8 {\n    var utf16le: [2]u16 = undefined;\n    const utf16le_as_bytes = mem.sliceAsBytes(utf16le[0..]);\n\n    {\n        mem.writeInt(u16, utf16le_as_bytes[0..2], 'A', .little);\n        mem.writeInt(u16, utf16le_as_bytes[2..4], 'a', .little);\n        const utf8 = try utf16LeToUtf8Alloc(testing.allocator, &utf16le);\n        defer testing.allocator.free(utf8);\n        try testing.expect(mem.eql(u8, utf8, \"Aa\"));\n    }\n\n    {\n        mem.writeInt(u16, utf16le_as_bytes[0..2], 0x80, .little);\n        mem.writeInt(u16, utf16le_as_bytes[2..4], 0xffff, .little);\n        const utf8 = try utf16LeToUtf8Alloc(testing.allocator, &utf16le);\n        defer testing.allocator.free(utf8);\n        try testing.expect(mem.eql(u8, utf8, \"\\xc2\\x80\" ++ \"\\xef\\xbf\\xbf\"));\n    }\n\n    {\n        // the values just outside the surrogate half range\n        mem.writeInt(u16, utf16le_as_bytes[0..2], 0xd7ff, .little);\n        mem.writeInt(u16, utf16le_as_bytes[2..4], 0xe000, .little);\n        const utf8 = try utf16LeToUtf8Alloc(testing.allocator, &utf16le);\n        defer testing.allocator.free(utf8);\n        try testing.expect(mem.eql(u8, utf8, \"\\xed\\x9f\\xbf\" ++ \"\\xee\\x80\\x80\"));\n    }\n\n    {\n        // smallest surrogate pair\n        mem.writeInt(u16, utf16le_as_bytes[0..2], 0xd800, .little);\n        mem.writeInt(u16, utf16le_as_bytes[2..4], 0xdc00, .little);\n        const utf8 = try utf16LeToUtf8Alloc(testing.allocator, &utf16le);\n        defer testing.allocator.free(utf8);\n        try testing.expect(mem.eql(u8, utf8, \"\\xf0\\x90\\x80\\x80\"));\n    }\n\n    {\n        // largest surrogate pair\n        mem.writeInt(u16, utf16le_as_bytes[0..2], 0xdbff, .little);\n        mem.writeInt(u16, utf16le_as_bytes[2..4], 0xdfff, .little);\n        const utf8 = try utf16LeToUtf8Alloc(testing.allocator, &utf16le);\n        defer testing.allocator.free(utf8);\n        try testing.expect(mem.eql(u8, utf8, \"\\xf4\\x8f\\xbf\\xbf\"));\n    }\n\n    {\n        mem.writeInt(u16, utf16le_as_bytes[0..2], 0xdbff, .little);\n        mem.writeInt(u16, utf16le_as_bytes[2..4], 0xdc00, .little);\n        const utf8 = try utf16LeToUtf8Alloc(testing.allocator, &utf16le);\n        defer testing.allocator.free(utf8);\n        try testing.expect(mem.eql(u8, utf8, \"\\xf4\\x8f\\xb0\\x80\"));\n    }\n\n    {\n        mem.writeInt(u16, utf16le_as_bytes[0..2], 0xdcdc, .little);\n        mem.writeInt(u16, utf16le_as_bytes[2..4], 0xdcdc, .little);\n        const result = utf16LeToUtf8Alloc(testing.allocator, &utf16le);\n        try testing.expectError(error.UnexpectedSecondSurrogateHalf, result);\n    }\n}\n\nfn utf8ToUtf16LeArrayListImpl(result: *std.ArrayList(u16), utf8: []const u8, comptime surrogates: Surrogates) !void {\n    assert(result.unusedCapacitySlice().len >= utf8.len);\n\n    var remaining = utf8;\n    vectorized: {\n        const chunk_len = std.simd.suggestVectorLength(u16) orelse break :vectorized;\n        const Chunk = @Vector(chunk_len, u8);\n\n        // Fast path. Check for and encode ASCII characters at the start of the input.\n        while (remaining.len >= chunk_len) {\n            const chunk: Chunk = remaining[0..chunk_len].*;\n            const mask: Chunk = @splat(0x80);\n            if (@reduce(.Or, chunk & mask == mask)) {\n                // found a non ASCII code unit\n                break;\n            }\n            const utf16_chunk = mem.nativeToLittle(@Vector(chunk_len, u16), chunk);\n            result.addManyAsArrayAssumeCapacity(chunk_len).* = utf16_chunk;\n            remaining = remaining[chunk_len..];\n        }\n    }\n\n    const view = switch (surrogates) {\n        .cannot_encode_surrogate_half => try Utf8View.init(remaining),\n        .can_encode_surrogate_half => try Wtf8View.init(remaining),\n    };\n    var it = view.iterator();\n    while (it.nextCodepoint()) |codepoint| {\n        if (codepoint < 0x10000) {\n            try result.append(mem.nativeToLittle(u16, @intCast(codepoint)));\n        } else {\n            const high = @as(u16, @intCast((codepoint - 0x10000) >> 10)) + 0xD800;\n            const low = @as(u16, @intCast(codepoint & 0x3FF)) + 0xDC00;\n            try result.appendSlice(&.{ mem.nativeToLittle(u16, high), mem.nativeToLittle(u16, low) });\n        }\n    }\n}\n\npub fn utf8ToUtf16LeArrayList(result: *std.ArrayList(u16), utf8: []const u8) error{ InvalidUtf8, OutOfMemory }!void {\n    try result.ensureUnusedCapacity(utf8.len);\n    return utf8ToUtf16LeArrayListImpl(result, utf8, .cannot_encode_surrogate_half);\n}\n\npub fn utf8ToUtf16LeAlloc(allocator: mem.Allocator, utf8: []const u8) error{ InvalidUtf8, OutOfMemory }![]u16 {\n    // optimistically guess that it will not require surrogate pairs\n    var result = try std.ArrayList(u16).initCapacity(allocator, utf8.len);\n    errdefer result.deinit();\n\n    try utf8ToUtf16LeArrayListImpl(&result, utf8, .cannot_encode_surrogate_half);\n    return result.toOwnedSlice();\n}\n\n/// Deprecated; renamed to utf8ToUtf16LeAllocZ\npub const utf8ToUtf16LeWithNull = utf8ToUtf16LeAllocZ;\n\npub fn utf8ToUtf16LeAllocZ(allocator: mem.Allocator, utf8: []const u8) error{ InvalidUtf8, OutOfMemory }![:0]u16 {\n    // optimistically guess that it will not require surrogate pairs\n    var result = try std.ArrayList(u16).initCapacity(allocator, utf8.len + 1);\n    errdefer result.deinit();\n\n    try utf8ToUtf16LeArrayListImpl(&result, utf8, .cannot_encode_surrogate_half);\n    return result.toOwnedSliceSentinel(0);\n}\n\n/// Returns index of next character. If exact fit, returned index equals output slice length.\n/// Assumes there is enough space for the output.\npub fn utf8ToUtf16Le(utf16le: []u16, utf8: []const u8) error{InvalidUtf8}!usize {\n    return utf8ToUtf16LeImpl(utf16le, utf8, .cannot_encode_surrogate_half);\n}\n\npub fn utf8ToUtf16LeImpl(utf16le: []u16, utf8: []const u8, comptime surrogates: Surrogates) !usize {\n    var dest_index: usize = 0;\n\n    var remaining = utf8;\n    vectorized: {\n        const chunk_len = std.simd.suggestVectorLength(u16) orelse break :vectorized;\n        const Chunk = @Vector(chunk_len, u8);\n\n        // Fast path. Check for and encode ASCII characters at the start of the input.\n        while (remaining.len >= chunk_len) {\n            const chunk: Chunk = remaining[0..chunk_len].*;\n            const mask: Chunk = @splat(0x80);\n            if (@reduce(.Or, chunk & mask == mask)) {\n                // found a non ASCII code unit\n                break;\n            }\n            const utf16_chunk = mem.nativeToLittle(@Vector(chunk_len, u16), chunk);\n            utf16le[dest_index..][0..chunk_len].* = utf16_chunk;\n            dest_index += chunk_len;\n            remaining = remaining[chunk_len..];\n        }\n    }\n\n    const view = switch (surrogates) {\n        .cannot_encode_surrogate_half => try Utf8View.init(remaining),\n        .can_encode_surrogate_half => try Wtf8View.init(remaining),\n    };\n    var it = view.iterator();\n    while (it.nextCodepoint()) |codepoint| {\n        if (codepoint < 0x10000) {\n            utf16le[dest_index] = mem.nativeToLittle(u16, @intCast(codepoint));\n            dest_index += 1;\n        } else {\n            const high = @as(u16, @intCast((codepoint - 0x10000) >> 10)) + 0xD800;\n            const low = @as(u16, @intCast(codepoint & 0x3FF)) + 0xDC00;\n            utf16le[dest_index..][0..2].* = .{ mem.nativeToLittle(u16, high), mem.nativeToLittle(u16, low) };\n            dest_index += 2;\n        }\n    }\n    return dest_index;\n}\n\ntest utf8ToUtf16Le {\n    var utf16le: [128]u16 = undefined;\n    {\n        const length = try utf8ToUtf16Le(utf16le[0..], \"\");\n        try testing.expectEqualSlices(u8, \"\\x01\\xd8\\x37\\xdc\", mem.sliceAsBytes(utf16le[0..length]));\n    }\n    {\n        const length = try utf8ToUtf16Le(utf16le[0..], \"\\u{10FFFF}\");\n        try testing.expectEqualSlices(u8, \"\\xff\\xdb\\xff\\xdf\", mem.sliceAsBytes(utf16le[0..length]));\n    }\n    {\n        const result = utf8ToUtf16Le(utf16le[0..], \"\\xf4\\x90\\x80\\x80\");\n        try testing.expectError(error.InvalidUtf8, result);\n    }\n    {\n        const length = try utf8ToUtf16Le(utf16le[0..], \"This string has been designed to test the vectorized implementat\" ++\n            \"ion by beginning with one hundred twenty-seven ASCII characters\");\n        try testing.expectEqualSlices(u8, &.{\n            'T', 0, 'h', 0, 'i', 0, 's', 0, ' ', 0, 's', 0, 't', 0, 'r', 0, 'i', 0, 'n', 0, 'g', 0, ' ', 0, 'h', 0, 'a', 0, 's', 0, ' ',  0,\n            'b', 0, 'e', 0, 'e', 0, 'n', 0, ' ', 0, 'd', 0, 'e', 0, 's', 0, 'i', 0, 'g', 0, 'n', 0, 'e', 0, 'd', 0, ' ', 0, 't', 0, 'o',  0,\n            ' ', 0, 't', 0, 'e', 0, 's', 0, 't', 0, ' ', 0, 't', 0, 'h', 0, 'e', 0, ' ', 0, 'v', 0, 'e', 0, 'c', 0, 't', 0, 'o', 0, 'r',  0,\n            'i', 0, 'z', 0, 'e', 0, 'd', 0, ' ', 0, 'i', 0, 'm', 0, 'p', 0, 'l', 0, 'e', 0, 'm', 0, 'e', 0, 'n', 0, 't', 0, 'a', 0, 't',  0,\n            'i', 0, 'o', 0, 'n', 0, ' ', 0, 'b', 0, 'y', 0, ' ', 0, 'b', 0, 'e', 0, 'g', 0, 'i', 0, 'n', 0, 'n', 0, 'i', 0, 'n', 0, 'g',  0,\n            ' ', 0, 'w', 0, 'i', 0, 't', 0, 'h', 0, ' ', 0, 'o', 0, 'n', 0, 'e', 0, ' ', 0, 'h', 0, 'u', 0, 'n', 0, 'd', 0, 'r', 0, 'e',  0,\n            'd', 0, ' ', 0, 't', 0, 'w', 0, 'e', 0, 'n', 0, 't', 0, 'y', 0, '-', 0, 's', 0, 'e', 0, 'v', 0, 'e', 0, 'n', 0, ' ', 0, 'A',  0,\n            'S', 0, 'C', 0, 'I', 0, 'I', 0, ' ', 0, 'c', 0, 'h', 0, 'a', 0, 'r', 0, 'a', 0, 'c', 0, 't', 0, 'e', 0, 'r', 0, 's', 0, '', 0,\n        }, mem.sliceAsBytes(utf16le[0..length]));\n    }\n}\n\ntest utf8ToUtf16LeArrayList {\n    {\n        var list = std.ArrayList(u16).init(testing.allocator);\n        defer list.deinit();\n        try utf8ToUtf16LeArrayList(&list, \"\");\n        try testing.expectEqualSlices(u8, \"\\x01\\xd8\\x37\\xdc\", mem.sliceAsBytes(list.items));\n    }\n    {\n        var list = std.ArrayList(u16).init(testing.allocator);\n        defer list.deinit();\n        try utf8ToUtf16LeArrayList(&list, \"\\u{10FFFF}\");\n        try testing.expectEqualSlices(u8, \"\\xff\\xdb\\xff\\xdf\", mem.sliceAsBytes(list.items));\n    }\n    {\n        var list = std.ArrayList(u16).init(testing.allocator);\n        defer list.deinit();\n        const result = utf8ToUtf16LeArrayList(&list, \"\\xf4\\x90\\x80\\x80\");\n        try testing.expectError(error.InvalidUtf8, result);\n    }\n}\n\ntest utf8ToUtf16LeAlloc {\n    {\n        const utf16 = try utf8ToUtf16LeAlloc(testing.allocator, \"\");\n        defer testing.allocator.free(utf16);\n        try testing.expectEqualSlices(u8, \"\\x01\\xd8\\x37\\xdc\", mem.sliceAsBytes(utf16[0..]));\n    }\n    {\n        const utf16 = try utf8ToUtf16LeAlloc(testing.allocator, \"\\u{10FFFF}\");\n        defer testing.allocator.free(utf16);\n        try testing.expectEqualSlices(u8, \"\\xff\\xdb\\xff\\xdf\", mem.sliceAsBytes(utf16[0..]));\n    }\n    {\n        const result = utf8ToUtf16LeAlloc(testing.allocator, \"\\xf4\\x90\\x80\\x80\");\n        try testing.expectError(error.InvalidUtf8, result);\n    }\n}\n\ntest utf8ToUtf16LeAllocZ {\n    {\n        const utf16 = try utf8ToUtf16LeAllocZ(testing.allocator, \"\");\n        defer testing.allocator.free(utf16);\n        try testing.expectEqualSlices(u8, \"\\x01\\xd8\\x37\\xdc\", mem.sliceAsBytes(utf16));\n        try testing.expect(utf16[2] == 0);\n    }\n    {\n        const utf16 = try utf8ToUtf16LeAllocZ(testing.allocator, \"\\u{10FFFF}\");\n        defer testing.allocator.free(utf16);\n        try testing.expectEqualSlices(u8, \"\\xff\\xdb\\xff\\xdf\", mem.sliceAsBytes(utf16));\n        try testing.expect(utf16[2] == 0);\n    }\n    {\n        const result = utf8ToUtf16LeAllocZ(testing.allocator, \"\\xf4\\x90\\x80\\x80\");\n        try testing.expectError(error.InvalidUtf8, result);\n    }\n    {\n        const utf16 = try utf8ToUtf16LeWithNull(testing.allocator, \"This string has been designed to test the vectorized implementat\" ++\n            \"ion by beginning with one hundred twenty-seven ASCII characters\");\n        defer testing.allocator.free(utf16);\n        try testing.expectEqualSlices(u8, &.{\n            'T', 0, 'h', 0, 'i', 0, 's', 0, ' ', 0, 's', 0, 't', 0, 'r', 0, 'i', 0, 'n', 0, 'g', 0, ' ', 0, 'h', 0, 'a', 0, 's', 0, ' ',  0,\n            'b', 0, 'e', 0, 'e', 0, 'n', 0, ' ', 0, 'd', 0, 'e', 0, 's', 0, 'i', 0, 'g', 0, 'n', 0, 'e', 0, 'd', 0, ' ', 0, 't', 0, 'o',  0,\n            ' ', 0, 't', 0, 'e', 0, 's', 0, 't', 0, ' ', 0, 't', 0, 'h', 0, 'e', 0, ' ', 0, 'v', 0, 'e', 0, 'c', 0, 't', 0, 'o', 0, 'r',  0,\n            'i', 0, 'z', 0, 'e', 0, 'd', 0, ' ', 0, 'i', 0, 'm', 0, 'p', 0, 'l', 0, 'e', 0, 'm', 0, 'e', 0, 'n', 0, 't', 0, 'a', 0, 't',  0,\n            'i', 0, 'o', 0, 'n', 0, ' ', 0, 'b', 0, 'y', 0, ' ', 0, 'b', 0, 'e', 0, 'g', 0, 'i', 0, 'n', 0, 'n', 0, 'i', 0, 'n', 0, 'g',  0,\n            ' ', 0, 'w', 0, 'i', 0, 't', 0, 'h', 0, ' ', 0, 'o', 0, 'n', 0, 'e', 0, ' ', 0, 'h', 0, 'u', 0, 'n', 0, 'd', 0, 'r', 0, 'e',  0,\n            'd', 0, ' ', 0, 't', 0, 'w', 0, 'e', 0, 'n', 0, 't', 0, 'y', 0, '-', 0, 's', 0, 'e', 0, 'v', 0, 'e', 0, 'n', 0, ' ', 0, 'A',  0,\n            'S', 0, 'C', 0, 'I', 0, 'I', 0, ' ', 0, 'c', 0, 'h', 0, 'a', 0, 'r', 0, 'a', 0, 'c', 0, 't', 0, 'e', 0, 'r', 0, 's', 0, '', 0,\n        }, mem.sliceAsBytes(utf16));\n    }\n}\n\ntest \"ArrayList functions on a re-used list\" {\n    // utf8ToUtf16LeArrayList\n    {\n        var list = std.ArrayList(u16).init(testing.allocator);\n        defer list.deinit();\n\n        const init_slice = utf8ToUtf16LeStringLiteral(\"abcdefg\");\n        try list.ensureTotalCapacityPrecise(init_slice.len);\n        list.appendSliceAssumeCapacity(init_slice);\n\n        try utf8ToUtf16LeArrayList(&list, \"hijklmnopqrstuvwyxz\");\n\n        try testing.expectEqualSlices(u16, utf8ToUtf16LeStringLiteral(\"abcdefghijklmnopqrstuvwyxz\"), list.items);\n    }\n\n    // utf16LeToUtf8ArrayList\n    {\n        var list = std.ArrayList(u8).init(testing.allocator);\n        defer list.deinit();\n\n        const init_slice = \"abcdefg\";\n        try list.ensureTotalCapacityPrecise(init_slice.len);\n        list.appendSliceAssumeCapacity(init_slice);\n\n        try utf16LeToUtf8ArrayList(&list, utf8ToUtf16LeStringLiteral(\"hijklmnopqrstuvwyxz\"));\n\n        try testing.expectEqualStrings(\"abcdefghijklmnopqrstuvwyxz\", list.items);\n    }\n\n    // wtf8ToWtf16LeArrayList\n    {\n        var list = std.ArrayList(u16).init(testing.allocator);\n        defer list.deinit();\n\n        const init_slice = utf8ToUtf16LeStringLiteral(\"abcdefg\");\n        try list.ensureTotalCapacityPrecise(init_slice.len);\n        list.appendSliceAssumeCapacity(init_slice);\n\n        try wtf8ToWtf16LeArrayList(&list, \"hijklmnopqrstuvwyxz\");\n\n        try testing.expectEqualSlices(u16, utf8ToUtf16LeStringLiteral(\"abcdefghijklmnopqrstuvwyxz\"), list.items);\n    }\n\n    // wtf16LeToWtf8ArrayList\n    {\n        var list = std.ArrayList(u8).init(testing.allocator);\n        defer list.deinit();\n\n        const init_slice = \"abcdefg\";\n        try list.ensureTotalCapacityPrecise(init_slice.len);\n        list.appendSliceAssumeCapacity(init_slice);\n\n        try wtf16LeToWtf8ArrayList(&list, utf8ToUtf16LeStringLiteral(\"hijklmnopqrstuvwyxz\"));\n\n        try testing.expectEqualStrings(\"abcdefghijklmnopqrstuvwyxz\", list.items);\n    }\n}\n\n/// Converts a UTF-8 string literal into a UTF-16LE string literal.\npub fn utf8ToUtf16LeStringLiteral(comptime utf8: []const u8) *const [calcUtf16LeLen(utf8) catch |err| @compileError(err):0]u16 {\n    return comptime blk: {\n        const len: usize = calcUtf16LeLen(utf8) catch unreachable;\n        var utf16le: [len:0]u16 = [_:0]u16{0} ** len;\n        const utf16le_len = utf8ToUtf16Le(&utf16le, utf8[0..]) catch |err| @compileError(err);\n        assert(len == utf16le_len);\n        const final = utf16le;\n        break :blk &final;\n    };\n}\n\nconst CalcUtf16LeLenError = Utf8DecodeError || error{Utf8InvalidStartByte};\n\n/// Returns length in UTF-16 of UTF-8 slice as length of []u16.\n/// Length in []u8 is 2*len16.\npub fn calcUtf16LeLen(utf8: []const u8) CalcUtf16LeLenError!usize {\n    var src_i: usize = 0;\n    var dest_len: usize = 0;\n    while (src_i < utf8.len) {\n        const n = try utf8ByteSequenceLength(utf8[src_i]);\n        const next_src_i = src_i + n;\n        const codepoint = try utf8Decode(utf8[src_i..next_src_i]);\n        if (codepoint < 0x10000) {\n            dest_len += 1;\n        } else {\n            dest_len += 2;\n        }\n        src_i = next_src_i;\n    }\n    return dest_len;\n}\n\nfn testCalcUtf16LeLen() !void {\n    try testing.expectEqual(@as(usize, 1), try calcUtf16LeLen(\"a\"));\n    try testing.expectEqual(@as(usize, 10), try calcUtf16LeLen(\"abcdefghij\"));\n    try testing.expectEqual(@as(usize, 10), try calcUtf16LeLen(\"\"));\n    try testing.expectEqual(@as(usize, 5), try calcUtf16LeLen(\"\"));\n}\n\ntest \"calculate utf16 string length of given utf8 string in u16\" {\n    try testCalcUtf16LeLen();\n    try comptime testCalcUtf16LeLen();\n}\n\n/// Print the given `utf16le` string, encoded as UTF-8 bytes.\n/// Unpaired surrogates are replaced by the replacement character (U+FFFD).\nfn formatUtf16Le(\n    utf16le: []const u16,\n    comptime fmt: []const u8,\n    options: std.fmt.FormatOptions,\n    writer: anytype,\n) !void {\n    _ = fmt;\n    _ = options;\n    var buf: [300]u8 = undefined; // just an arbitrary size\n    var it = Utf16LeIterator.init(utf16le);\n    var u8len: usize = 0;\n    while (it.nextCodepoint() catch replacement_character) |codepoint| {\n        u8len += utf8Encode(codepoint, buf[u8len..]) catch\n            utf8Encode(replacement_character, buf[u8len..]) catch unreachable;\n        // make sure there's always enough room for another maximum length UTF-8 codepoint\n        if (u8len + 4 > buf.len) {\n            try writer.writeAll(buf[0..u8len]);\n            u8len = 0;\n        }\n    }\n    try writer.writeAll(buf[0..u8len]);\n}\n\n/// Deprecated; renamed to fmtUtf16Le\npub const fmtUtf16le = fmtUtf16Le;\n\n/// Return a Formatter for a (potentially ill-formed) UTF-16 LE string,\n/// which will be converted to UTF-8 during formatting.\n/// Unpaired surrogates are replaced by the replacement character (U+FFFD).\npub fn fmtUtf16Le(utf16le: []const u16) std.fmt.Formatter(formatUtf16Le) {\n    return .{ .data = utf16le };\n}\n\ntest fmtUtf16Le {\n    const expectFmt = testing.expectFmt;\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(utf8ToUtf16LeStringLiteral(\"\"))});\n    try expectFmt(\"foo\", \"{}\", .{fmtUtf16Le(utf8ToUtf16LeStringLiteral(\"foo\"))});\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(utf8ToUtf16LeStringLiteral(\"\"))});\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(&[_]u16{mem.readInt(u16, \"\\xff\\xd7\", native_endian)})});\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(&[_]u16{mem.readInt(u16, \"\\x00\\xd8\", native_endian)})});\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(&[_]u16{mem.readInt(u16, \"\\xff\\xdb\", native_endian)})});\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(&[_]u16{mem.readInt(u16, \"\\x00\\xdc\", native_endian)})});\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(&[_]u16{mem.readInt(u16, \"\\xff\\xdf\", native_endian)})});\n    try expectFmt(\"\", \"{}\", .{fmtUtf16Le(&[_]u16{mem.readInt(u16, \"\\x00\\xe0\", native_endian)})});\n}\n\ntest utf8ToUtf16LeStringLiteral {\n    {\n        const bytes = [_:0]u16{\n            mem.nativeToLittle(u16, 0x41),\n        };\n        const utf16 = utf8ToUtf16LeStringLiteral(\"A\");\n        try testing.expectEqualSlices(u16, &bytes, utf16);\n        try testing.expect(utf16[1] == 0);\n    }\n    {\n        const bytes = [_:0]u16{\n            mem.nativeToLittle(u16, 0xD801),\n            mem.nativeToLittle(u16, 0xDC37),\n        };\n        const utf16 = utf8ToUtf16LeStringLiteral(\"\");\n        try testing.expectEqualSlices(u16, &bytes, utf16);\n        try testing.expect(utf16[2] == 0);\n    }\n    {\n        const bytes = [_:0]u16{\n            mem.nativeToLittle(u16, 0x02FF),\n        };\n        const utf16 = utf8ToUtf16LeStringLiteral(\"\\u{02FF}\");\n        try testing.expectEqualSlices(u16, &bytes, utf16);\n        try testing.expect(utf16[1] == 0);\n    }\n    {\n        const bytes = [_:0]u16{\n            mem.nativeToLittle(u16, 0x7FF),\n        };\n        const utf16 = utf8ToUtf16LeStringLiteral(\"\\u{7FF}\");\n        try testing.expectEqualSlices(u16, &bytes, utf16);\n        try testing.expect(utf16[1] == 0);\n    }\n    {\n        const bytes = [_:0]u16{\n            mem.nativeToLittle(u16, 0x801),\n        };\n        const utf16 = utf8ToUtf16LeStringLiteral(\"\\u{801}\");\n        try testing.expectEqualSlices(u16, &bytes, utf16);\n        try testing.expect(utf16[1] == 0);\n    }\n    {\n        const bytes = [_:0]u16{\n            mem.nativeToLittle(u16, 0xDBFF),\n            mem.nativeToLittle(u16, 0xDFFF),\n        };\n        const utf16 = utf8ToUtf16LeStringLiteral(\"\\u{10FFFF}\");\n        try testing.expectEqualSlices(u16, &bytes, utf16);\n        try testing.expect(utf16[2] == 0);\n    }\n}\n\nfn testUtf8CountCodepoints() !void {\n    try testing.expectEqual(@as(usize, 10), try utf8CountCodepoints(\"abcdefghij\"));\n    try testing.expectEqual(@as(usize, 10), try utf8CountCodepoints(\"\"));\n    try testing.expectEqual(@as(usize, 5), try utf8CountCodepoints(\"\"));\n    // testing.expectError(error.Utf8EncodesSurrogateHalf, utf8CountCodepoints(\"\\xED\\xA0\\x80\"));\n}\n\ntest \"utf8 count codepoints\" {\n    try testUtf8CountCodepoints();\n    try comptime testUtf8CountCodepoints();\n}\n\nfn testUtf8ValidCodepoint() !void {\n    try testing.expect(utf8ValidCodepoint('e'));\n    try testing.expect(utf8ValidCodepoint(''));\n    try testing.expect(utf8ValidCodepoint(''));\n    try testing.expect(utf8ValidCodepoint(0xe000));\n    try testing.expect(utf8ValidCodepoint(0x10ffff));\n    try testing.expect(!utf8ValidCodepoint(0xd800));\n    try testing.expect(!utf8ValidCodepoint(0xdfff));\n    try testing.expect(!utf8ValidCodepoint(0x110000));\n}\n\ntest \"utf8 valid codepoint\" {\n    try testUtf8ValidCodepoint();\n    try comptime testUtf8ValidCodepoint();\n}\n\n/// Returns true if the codepoint is a surrogate (U+DC00 to U+DFFF)\npub fn isSurrogateCodepoint(c: u21) bool {\n    return switch (c) {\n        0xD800...0xDFFF => true,\n        else => false,\n    };\n}\n\n/// Encodes the given codepoint into a WTF-8 byte sequence.\n/// c: the codepoint.\n/// out: the out buffer to write to. Must have a len >= utf8CodepointSequenceLength(c).\n/// Errors: if c cannot be encoded in WTF-8.\n/// Returns: the number of bytes written to out.\npub fn wtf8Encode(c: u21, out: []u8) error{CodepointTooLarge}!u3 {\n    return utf8EncodeImpl(c, out, .can_encode_surrogate_half);\n}\n\nconst Wtf8DecodeError = Utf8Decode2Error || Utf8Decode3AllowSurrogateHalfError || Utf8Decode4Error;\n\npub fn wtf8Decode(bytes: []const u8) Wtf8DecodeError!u21 {\n    return switch (bytes.len) {\n        1 => @as(u21, bytes[0]),\n        2 => utf8Decode2(bytes),\n        3 => utf8Decode3AllowSurrogateHalf(bytes),\n        4 => utf8Decode4(bytes),\n        else => unreachable,\n    };\n}\n\n/// Returns true if the input consists entirely of WTF-8 codepoints\n/// (all the same restrictions as UTF-8, but allows surrogate codepoints\n/// U+D800 to U+DFFF).\n/// Does not check for well-formed WTF-8, meaning that this function\n/// does not check that all surrogate halves are unpaired.\npub fn wtf8ValidateSlice(input: []const u8) bool {\n    return utf8ValidateSliceImpl(input, .can_encode_surrogate_half);\n}\n\ntest \"validate WTF-8 slice\" {\n    try testValidateWtf8Slice();\n    try comptime testValidateWtf8Slice();\n\n    // We skip a variable (based on recommended vector size) chunks of\n    // ASCII characters. Let's make sure we're chunking correctly.\n    const str = [_]u8{'a'} ** 550 ++ \"\\xc0\";\n    for (0..str.len - 3) |i| {\n        try testing.expect(!wtf8ValidateSlice(str[i..]));\n    }\n}\nfn testValidateWtf8Slice() !void {\n    // These are valid/invalid under both UTF-8 and WTF-8 rules.\n    try testing.expect(wtf8ValidateSlice(\"abc\"));\n    try testing.expect(wtf8ValidateSlice(\"abc\\xdf\\xbf\"));\n    try testing.expect(wtf8ValidateSlice(\"\"));\n    try testing.expect(wtf8ValidateSlice(\"a\"));\n    try testing.expect(wtf8ValidateSlice(\"abc\"));\n    try testing.expect(wtf8ValidateSlice(\"\"));\n    try testing.expect(wtf8ValidateSlice(\"\"));\n    try testing.expect(wtf8ValidateSlice(\"-\"));\n    try testing.expect(wtf8ValidateSlice(\"\"));\n    try testing.expect(wtf8ValidateSlice(\"a\\u{fffdb}\"));\n    try testing.expect(wtf8ValidateSlice(\"\\xf4\\x8f\\xbf\\xbf\"));\n    try testing.expect(wtf8ValidateSlice(\"abc\\xdf\\xbf\"));\n\n    try testing.expect(!wtf8ValidateSlice(\"abc\\xc0\"));\n    try testing.expect(!wtf8ValidateSlice(\"abc\\xc0abc\"));\n    try testing.expect(!wtf8ValidateSlice(\"aa\\xe2\"));\n    try testing.expect(!wtf8ValidateSlice(\"\\x42\\xfa\"));\n    try testing.expect(!wtf8ValidateSlice(\"\\x42\\xfa\\x43\"));\n    try testing.expect(!wtf8ValidateSlice(\"abc\\xc0\"));\n    try testing.expect(!wtf8ValidateSlice(\"abc\\xc0abc\"));\n    try testing.expect(!wtf8ValidateSlice(\"\\xf4\\x90\\x80\\x80\"));\n    try testing.expect(!wtf8ValidateSlice(\"\\xf7\\xbf\\xbf\\xbf\"));\n    try testing.expect(!wtf8ValidateSlice(\"\\xfb\\xbf\\xbf\\xbf\\xbf\"));\n    try testing.expect(!wtf8ValidateSlice(\"\\xc0\\x80\"));\n\n    // But surrogate codepoints are only valid in WTF-8.\n    try testing.expect(wtf8ValidateSlice(\"\\xed\\xa0\\x80\"));\n    try testing.expect(wtf8ValidateSlice(\"\\xed\\xbf\\xbf\"));\n}\n\n/// Wtf8View iterates the code points of a WTF-8 encoded string,\n/// including surrogate halves.\n///\n/// ```\n/// var wtf8 = (try std.unicode.Wtf8View.init(\"hi there\")).iterator();\n/// while (wtf8.nextCodepointSlice()) |codepoint| {\n///   // note: codepoint could be a surrogate half which is invalid\n///   // UTF-8, avoid printing or otherwise sending/emitting this directly\n/// }\n/// ```\npub const Wtf8View = struct {\n    bytes: []const u8,\n\n    pub fn init(s: []const u8) error{InvalidWtf8}!Wtf8View {\n        if (!wtf8ValidateSlice(s)) {\n            return error.InvalidWtf8;\n        }\n\n        return initUnchecked(s);\n    }\n\n    pub fn initUnchecked(s: []const u8) Wtf8View {\n        return Wtf8View{ .bytes = s };\n    }\n\n    pub inline fn initComptime(comptime s: []const u8) Wtf8View {\n        return comptime if (init(s)) |r| r else |err| switch (err) {\n            error.InvalidWtf8 => {\n                @compileError(\"invalid wtf8\");\n            },\n        };\n    }\n\n    pub fn iterator(s: Wtf8View) Wtf8Iterator {\n        return Wtf8Iterator{\n            .bytes = s.bytes,\n            .i = 0,\n        };\n    }\n};\n\n/// Asserts that `bytes` is valid WTF-8\npub const Wtf8Iterator = struct {\n    bytes: []const u8,\n    i: usize,\n\n    pub fn nextCodepointSlice(it: *Wtf8Iterator) ?[]const u8 {\n        if (it.i >= it.bytes.len) {\n            return null;\n        }\n\n        const cp_len = utf8ByteSequenceLength(it.bytes[it.i]) catch unreachable;\n        it.i += cp_len;\n        return it.bytes[it.i - cp_len .. it.i];\n    }\n\n    pub fn nextCodepoint(it: *Wtf8Iterator) ?u21 {\n        const slice = it.nextCodepointSlice() orelse return null;\n        return wtf8Decode(slice) catch unreachable;\n    }\n\n    /// Look ahead at the next n codepoints without advancing the iterator.\n    /// If fewer than n codepoints are available, then return the remainder of the string.\n    pub fn peek(it: *Wtf8Iterator, n: usize) []const u8 {\n        const original_i = it.i;\n        defer it.i = original_i;\n\n        var end_ix = original_i;\n        var found: usize = 0;\n        while (found < n) : (found += 1) {\n            const next_codepoint = it.nextCodepointSlice() orelse return it.bytes[original_i..];\n            end_ix += next_codepoint.len;\n        }\n\n        return it.bytes[original_i..end_ix];\n    }\n};\n\npub fn wtf16LeToWtf8ArrayList(result: *std.ArrayList(u8), utf16le: []const u16) mem.Allocator.Error!void {\n    try result.ensureUnusedCapacity(utf16le.len);\n    return utf16LeToUtf8ArrayListImpl(result, utf16le, .can_encode_surrogate_half);\n}\n\n/// Caller must free returned memory.\npub fn wtf16LeToWtf8Alloc(allocator: mem.Allocator, wtf16le: []const u16) mem.Allocator.Error![]u8 {\n    // optimistically guess that it will all be ascii.\n    var result = try std.ArrayList(u8).initCapacity(allocator, wtf16le.len);\n    errdefer result.deinit();\n\n    try utf16LeToUtf8ArrayListImpl(&result, wtf16le, .can_encode_surrogate_half);\n    return result.toOwnedSlice();\n}\n\n/// Caller must free returned memory.\npub fn wtf16LeToWtf8AllocZ(allocator: mem.Allocator, wtf16le: []const u16) mem.Allocator.Error![:0]u8 {\n    // optimistically guess that it will all be ascii (and allocate space for the null terminator)\n    var result = try std.ArrayList(u8).initCapacity(allocator, wtf16le.len + 1);\n    errdefer result.deinit();\n\n    try utf16LeToUtf8ArrayListImpl(&result, wtf16le, .can_encode_surrogate_half);\n    return result.toOwnedSliceSentinel(0);\n}\n\npub fn wtf16LeToWtf8(wtf8: []u8, wtf16le: []const u16) usize {\n    return utf16LeToUtf8Impl(wtf8, wtf16le, .can_encode_surrogate_half) catch |err| switch (err) {};\n}\n\npub fn wtf8ToWtf16LeArrayList(result: *std.ArrayList(u16), wtf8: []const u8) error{ InvalidWtf8, OutOfMemory }!void {\n    try result.ensureUnusedCapacity(wtf8.len);\n    return utf8ToUtf16LeArrayListImpl(result, wtf8, .can_encode_surrogate_half);\n}\n\npub fn wtf8ToWtf16LeAlloc(allocator: mem.Allocator, wtf8: []const u8) error{ InvalidWtf8, OutOfMemory }![]u16 {\n    // optimistically guess that it will not require surrogate pairs\n    var result = try std.ArrayList(u16).initCapacity(allocator, wtf8.len);\n    errdefer result.deinit();\n\n    try utf8ToUtf16LeArrayListImpl(&result, wtf8, .can_encode_surrogate_half);\n    return result.toOwnedSlice();\n}\n\npub fn wtf8ToWtf16LeAllocZ(allocator: mem.Allocator, wtf8: []const u8) error{ InvalidWtf8, OutOfMemory }![:0]u16 {\n    // optimistically guess that it will not require surrogate pairs\n    var result = try std.ArrayList(u16).initCapacity(allocator, wtf8.len + 1);\n    errdefer result.deinit();\n\n    try utf8ToUtf16LeArrayListImpl(&result, wtf8, .can_encode_surrogate_half);\n    return result.toOwnedSliceSentinel(0);\n}\n\n/// Returns index of next character. If exact fit, returned index equals output slice length.\n/// Assumes there is enough space for the output.\npub fn wtf8ToWtf16Le(wtf16le: []u16, wtf8: []const u8) error{InvalidWtf8}!usize {\n    return utf8ToUtf16LeImpl(wtf16le, wtf8, .can_encode_surrogate_half);\n}\n\n/// Surrogate codepoints (U+D800 to U+DFFF) are replaced by the Unicode replacement\n/// character (U+FFFD).\n/// All surrogate codepoints and the replacement character are encoded as three\n/// bytes, meaning the input and output slices will always be the same length.\n/// In-place conversion is supported when `utf8` and `wtf8` refer to the same slice.\n/// Note: If `wtf8` is entirely composed of well-formed UTF-8, then no conversion is necessary.\n///       `utf8ValidateSlice` can be used to check if lossy conversion is worthwhile.\n/// If `wtf8` is not valid WTF-8, then `error.InvalidWtf8` is returned.\npub fn wtf8ToUtf8Lossy(utf8: []u8, wtf8: []const u8) error{InvalidWtf8}!void {\n    assert(utf8.len >= wtf8.len);\n\n    const in_place = utf8.ptr == wtf8.ptr;\n    const replacement_char_bytes = comptime blk: {\n        var buf: [3]u8 = undefined;\n        assert((utf8Encode(replacement_character, &buf) catch unreachable) == 3);\n        break :blk buf;\n    };\n\n    var dest_i: usize = 0;\n    const view = try Wtf8View.init(wtf8);\n    var it = view.iterator();\n    while (it.nextCodepointSlice()) |codepoint_slice| {\n        // All surrogate codepoints are encoded as 3 bytes\n        if (codepoint_slice.len == 3) {\n            const codepoint = wtf8Decode(codepoint_slice) catch unreachable;\n            if (isSurrogateCodepoint(codepoint)) {\n                @memcpy(utf8[dest_i..][0..replacement_char_bytes.len], &replacement_char_bytes);\n                dest_i += replacement_char_bytes.len;\n                continue;\n            }\n        }\n        if (!in_place) {\n            @memcpy(utf8[dest_i..][0..codepoint_slice.len], codepoint_slice);\n        }\n        dest_i += codepoint_slice.len;\n    }\n}\n\npub fn wtf8ToUtf8LossyAlloc(allocator: mem.Allocator, wtf8: []const u8) error{ InvalidWtf8, OutOfMemory }![]u8 {\n    const utf8 = try allocator.alloc(u8, wtf8.len);\n    errdefer allocator.free(utf8);\n\n    try wtf8ToUtf8Lossy(utf8, wtf8);\n\n    return utf8;\n}\n\npub fn wtf8ToUtf8LossyAllocZ(allocator: mem.Allocator, wtf8: []const u8) error{ InvalidWtf8, OutOfMemory }![:0]u8 {\n    const utf8 = try allocator.allocSentinel(u8, wtf8.len, 0);\n    errdefer allocator.free(utf8);\n\n    try wtf8ToUtf8Lossy(utf8, wtf8);\n\n    return utf8;\n}\n\ntest wtf8ToUtf8Lossy {\n    var buf: [32]u8 = undefined;\n\n    const invalid_utf8 = \"\\xff\";\n    try testing.expectError(error.InvalidWtf8, wtf8ToUtf8Lossy(&buf, invalid_utf8));\n\n    const ascii = \"abcd\";\n    try wtf8ToUtf8Lossy(&buf, ascii);\n    try testing.expectEqualStrings(\"abcd\", buf[0..ascii.len]);\n\n    const high_surrogate_half = \"ab\\xed\\xa0\\xbdcd\";\n    try wtf8ToUtf8Lossy(&buf, high_surrogate_half);\n    try testing.expectEqualStrings(\"ab\\u{FFFD}cd\", buf[0..high_surrogate_half.len]);\n\n    const low_surrogate_half = \"ab\\xed\\xb2\\xa9cd\";\n    try wtf8ToUtf8Lossy(&buf, low_surrogate_half);\n    try testing.expectEqualStrings(\"ab\\u{FFFD}cd\", buf[0..low_surrogate_half.len]);\n\n    // If the WTF-8 is not well-formed, each surrogate half is converted into a separate\n    // replacement character instead of being interpreted as a surrogate pair.\n    const encoded_surrogate_pair = \"ab\\xed\\xa0\\xbd\\xed\\xb2\\xa9cd\";\n    try wtf8ToUtf8Lossy(&buf, encoded_surrogate_pair);\n    try testing.expectEqualStrings(\"ab\\u{FFFD}\\u{FFFD}cd\", buf[0..encoded_surrogate_pair.len]);\n\n    // in place\n    @memcpy(buf[0..low_surrogate_half.len], low_surrogate_half);\n    const slice = buf[0..low_surrogate_half.len];\n    try wtf8ToUtf8Lossy(slice, slice);\n    try testing.expectEqualStrings(\"ab\\u{FFFD}cd\", slice);\n}\n\ntest wtf8ToUtf8LossyAlloc {\n    const invalid_utf8 = \"\\xff\";\n    try testing.expectError(error.InvalidWtf8, wtf8ToUtf8LossyAlloc(testing.allocator, invalid_utf8));\n\n    {\n        const ascii = \"abcd\";\n        const utf8 = try wtf8ToUtf8LossyAlloc(testing.allocator, ascii);\n        defer testing.allocator.free(utf8);\n        try testing.expectEqualStrings(\"abcd\", utf8);\n    }\n\n    {\n        const surrogate_half = \"ab\\xed\\xa0\\xbdcd\";\n        const utf8 = try wtf8ToUtf8LossyAlloc(testing.allocator, surrogate_half);\n        defer testing.allocator.free(utf8);\n        try testing.expectEqualStrings(\"ab\\u{FFFD}cd\", utf8);\n    }\n\n    {\n        // If the WTF-8 is not well-formed, each surrogate half is converted into a separate\n        // replacement character instead of being interpreted as a surrogate pair.\n        const encoded_surrogate_pair = \"ab\\xed\\xa0\\xbd\\xed\\xb2\\xa9cd\";\n        const utf8 = try wtf8ToUtf8LossyAlloc(testing.allocator, encoded_surrogate_pair);\n        defer testing.allocator.free(utf8);\n        try testing.expectEqualStrings(\"ab\\u{FFFD}\\u{FFFD}cd\", utf8);\n    }\n}\n\ntest wtf8ToUtf8LossyAllocZ {\n    const invalid_utf8 = \"\\xff\";\n    try testing.expectError(error.InvalidWtf8, wtf8ToUtf8LossyAllocZ(testing.allocator, invalid_utf8));\n\n    {\n        const ascii = \"abcd\";\n        const utf8 = try wtf8ToUtf8LossyAllocZ(testing.allocator, ascii);\n        defer testing.allocator.free(utf8);\n        try testing.expectEqualStrings(\"abcd\", utf8);\n    }\n\n    {\n        const surrogate_half = \"ab\\xed\\xa0\\xbdcd\";\n        const utf8 = try wtf8ToUtf8LossyAllocZ(testing.allocator, surrogate_half);\n        defer testing.allocator.free(utf8);\n        try testing.expectEqualStrings(\"ab\\u{FFFD}cd\", utf8);\n    }\n\n    {\n        // If the WTF-8 is not well-formed, each surrogate half is converted into a separate\n        // replacement character instead of being interpreted as a surrogate pair.\n        const encoded_surrogate_pair = \"ab\\xed\\xa0\\xbd\\xed\\xb2\\xa9cd\";\n        const utf8 = try wtf8ToUtf8LossyAllocZ(testing.allocator, encoded_surrogate_pair);\n        defer testing.allocator.free(utf8);\n        try testing.expectEqualStrings(\"ab\\u{FFFD}\\u{FFFD}cd\", utf8);\n    }\n}\n\npub const Wtf16LeIterator = struct {\n    bytes: []const u8,\n    i: usize,\n\n    pub fn init(s: []const u16) Wtf16LeIterator {\n        return Wtf16LeIterator{\n            .bytes = mem.sliceAsBytes(s),\n            .i = 0,\n        };\n    }\n\n    /// If the next codepoint is encoded by a surrogate pair, returns the\n    /// codepoint that the surrogate pair represents.\n    /// If the next codepoint is an unpaired surrogate, returns the codepoint\n    /// of the unpaired surrogate.\n    pub fn nextCodepoint(it: *Wtf16LeIterator) ?u21 {\n        assert(it.i <= it.bytes.len);\n        if (it.i == it.bytes.len) return null;\n        var code_units: [2]u16 = undefined;\n        code_units[0] = mem.readInt(u16, it.bytes[it.i..][0..2], .little);\n        it.i += 2;\n        surrogate_pair: {\n            if (utf16IsHighSurrogate(code_units[0])) {\n                if (it.i >= it.bytes.len) break :surrogate_pair;\n                code_units[1] = mem.readInt(u16, it.bytes[it.i..][0..2], .little);\n                const codepoint = utf16DecodeSurrogatePair(&code_units) catch break :surrogate_pair;\n                it.i += 2;\n                return codepoint;\n            }\n        }\n        return code_units[0];\n    }\n};\n\ntest \"non-well-formed WTF-8 does not roundtrip\" {\n    // This encodes the surrogate pair U+D83D U+DCA9.\n    // The well-formed version of this would be U+1F4A9 which is \\xF0\\x9F\\x92\\xA9.\n    const non_well_formed_wtf8 = \"\\xed\\xa0\\xbd\\xed\\xb2\\xa9\";\n\n    var wtf16_buf: [2]u16 = undefined;\n    const wtf16_len = try wtf8ToWtf16Le(&wtf16_buf, non_well_formed_wtf8);\n    const wtf16 = wtf16_buf[0..wtf16_len];\n\n    try testing.expectEqualSlices(u16, &[_]u16{\n        mem.nativeToLittle(u16, 0xD83D), // high surrogate\n        mem.nativeToLittle(u16, 0xDCA9), // low surrogate\n    }, wtf16);\n\n    var wtf8_buf: [4]u8 = undefined;\n    const wtf8_len = wtf16LeToWtf8(&wtf8_buf, wtf16);\n    const wtf8 = wtf8_buf[0..wtf8_len];\n\n    // Converting to WTF-16 and back results in well-formed WTF-8,\n    // but it does not match the input WTF-8\n    try testing.expectEqualSlices(u8, \"\\xf0\\x9f\\x92\\xa9\", wtf8);\n}\n\nfn testRoundtripWtf8(wtf8: []const u8) !void {\n    // Buffer\n    {\n        var wtf16_buf: [32]u16 = undefined;\n        const wtf16_len = try wtf8ToWtf16Le(&wtf16_buf, wtf8);\n        const wtf16 = wtf16_buf[0..wtf16_len];\n\n        var roundtripped_buf: [32]u8 = undefined;\n        const roundtripped_len = wtf16LeToWtf8(&roundtripped_buf, wtf16);\n        const roundtripped = roundtripped_buf[0..roundtripped_len];\n\n        try testing.expectEqualSlices(u8, wtf8, roundtripped);\n    }\n    // Alloc\n    {\n        const wtf16 = try wtf8ToWtf16LeAlloc(testing.allocator, wtf8);\n        defer testing.allocator.free(wtf16);\n\n        const roundtripped = try wtf16LeToWtf8Alloc(testing.allocator, wtf16);\n        defer testing.allocator.free(roundtripped);\n\n        try testing.expectEqualSlices(u8, wtf8, roundtripped);\n    }\n    // AllocZ\n    {\n        const wtf16 = try wtf8ToWtf16LeAllocZ(testing.allocator, wtf8);\n        defer testing.allocator.free(wtf16);\n\n        const roundtripped = try wtf16LeToWtf8AllocZ(testing.allocator, wtf16);\n        defer testing.allocator.free(roundtripped);\n\n        try testing.expectEqualSlices(u8, wtf8, roundtripped);\n    }\n}\n\ntest \"well-formed WTF-8 roundtrips\" {\n    try testRoundtripWtf8(\"\\xed\\x9f\\xbf\"); // not a surrogate half\n    try testRoundtripWtf8(\"\\xed\\xa0\\xbd\"); // high surrogate\n    try testRoundtripWtf8(\"\\xed\\xb2\\xa9\"); // low surrogate\n    try testRoundtripWtf8(\"\\xed\\xa0\\xbd \\xed\\xb2\\xa9\"); // <high surrogate><space><low surrogate>\n    try testRoundtripWtf8(\"\\xed\\xa0\\x80\\xed\\xaf\\xbf\"); // <high surrogate><high surrogate>\n    try testRoundtripWtf8(\"\\xed\\xa0\\x80\\xee\\x80\\x80\"); // <high surrogate><not surrogate>\n    try testRoundtripWtf8(\"\\xed\\x9f\\xbf\\xed\\xb0\\x80\"); // <not surrogate><low surrogate>\n    try testRoundtripWtf8(\"a\\xed\\xb0\\x80\"); // <not surrogate><low surrogate>\n    try testRoundtripWtf8(\"\\xf0\\x9f\\x92\\xa9\"); // U+1F4A9, encoded as a surrogate pair in WTF-16\n}\n\nfn testRoundtripWtf16(wtf16le: []const u16) !void {\n    // Buffer\n    {\n        var wtf8_buf: [32]u8 = undefined;\n        const wtf8_len = wtf16LeToWtf8(&wtf8_buf, wtf16le);\n        const wtf8 = wtf8_buf[0..wtf8_len];\n\n        var roundtripped_buf: [32]u16 = undefined;\n        const roundtripped_len = try wtf8ToWtf16Le(&roundtripped_buf, wtf8);\n        const roundtripped = roundtripped_buf[0..roundtripped_len];\n\n        try testing.expectEqualSlices(u16, wtf16le, roundtripped);\n    }\n    // Alloc\n    {\n        const wtf8 = try wtf16LeToWtf8Alloc(testing.allocator, wtf16le);\n        defer testing.allocator.free(wtf8);\n\n        const roundtripped = try wtf8ToWtf16LeAlloc(testing.allocator, wtf8);\n        defer testing.allocator.free(roundtripped);\n\n        try testing.expectEqualSlices(u16, wtf16le, roundtripped);\n    }\n    // AllocZ\n    {\n        const wtf8 = try wtf16LeToWtf8AllocZ(testing.allocator, wtf16le);\n        defer testing.allocator.free(wtf8);\n\n        const roundtripped = try wtf8ToWtf16LeAllocZ(testing.allocator, wtf8);\n        defer testing.allocator.free(roundtripped);\n\n        try testing.expectEqualSlices(u16, wtf16le, roundtripped);\n    }\n}\n\ntest \"well-formed WTF-16 roundtrips\" {\n    try testRoundtripWtf16(&[_]u16{\n        mem.nativeToLittle(u16, 0xD83D), // high surrogate\n        mem.nativeToLittle(u16, 0xDCA9), // low surrogate\n    });\n    try testRoundtripWtf16(&[_]u16{\n        mem.nativeToLittle(u16, 0xD83D), // high surrogate\n        mem.nativeToLittle(u16, ' '), // not surrogate\n        mem.nativeToLittle(u16, 0xDCA9), // low surrogate\n    });\n    try testRoundtripWtf16(&[_]u16{\n        mem.nativeToLittle(u16, 0xD800), // high surrogate\n        mem.nativeToLittle(u16, 0xDBFF), // high surrogate\n    });\n    try testRoundtripWtf16(&[_]u16{\n        mem.nativeToLittle(u16, 0xD800), // high surrogate\n        mem.nativeToLittle(u16, 0xE000), // not surrogate\n    });\n    try testRoundtripWtf16(&[_]u16{\n        mem.nativeToLittle(u16, 0xD7FF), // not surrogate\n        mem.nativeToLittle(u16, 0xDC00), // low surrogate\n    });\n    try testRoundtripWtf16(&[_]u16{\n        mem.nativeToLittle(u16, 0x61), // not surrogate\n        mem.nativeToLittle(u16, 0xDC00), // low surrogate\n    });\n    try testRoundtripWtf16(&[_]u16{\n        mem.nativeToLittle(u16, 0xDC00), // low surrogate\n    });\n}\n"
  ],
  "mappings": "2ZAYA,6FCLA,wBACS,sBCuFmB,qHAAA,eAAA,QAAsB,4BAAA,gBAC9C,6BAEyB,uHAAA,GAEC,4BFvFd,qBAAA,GGyFhB,0CAE6B,cAAgC,oHAAA,OAAhC,kDAAA,OAAT,OAChB,oDAAA,GC+vBJ,8BAAkE,kBAE1C,kBAAyD,8DAAzD,2CAAA,GC/0BxB,uCA0BI,WACA,WACA,WAG8B,aAEE,8BAC5B,OAAuC,6BAAjC,wEAAA,OACN,cAE4B,8BAC5B,cACA,WAAM,wEAAA,OAEsB,8BAC5B,cACA,WAAM,wEAAA,OAEsB,gCAE5B,WAAA,WAGoB,uCAEoB,0GAAA,OAAnB,gCAAA,0CAEzB,OAA+D,6BAAA,oBAAA,GAAA,YAAA,OAArC,WAAA,QAAA,GAAA,wCAAA,OAC1B,cAIA,OAAuE,6BAAA,oBAAA,GAAA,YAAA,OAArC,WAAA,QAAA,GAAA,wCAAA,OAEX,4BAEJ,OACE,0BA4ErB,gBA3E6C,yBAIhC,mCAAA,GFqHjB,mDAA4I,cAMpI,MACA,WACA,4CAGJ,cAA8B,kBA8GV,OAKY,cAnHgB,eA5IpD,qBACI,cAAwB,cAAK,OAAL,uBA2IwB,+CAAA,GAAoC,oDAAA,kBAEpE,0BAAA,oBAAA,GAAA,gBAAA,mBAAA,oBAAA,GAAA,gBAAA,oBAAA,UACmB,WAAA,QAAA,GAAA,wCAAnC,qDAAA,GCqrBJ,8BAAkD,OAMlD,kBACU,WAAW,oBAAsB,yCACnC,OAAE,OAAyB,WAAH,oCAAA,kBAAA,GAAA,GAAA,YAAA,8BAE5B,OAAE,kBAAO,sEAAA,OAPS,oBAAA,GEhftB,mCAAW,qEAIP,0BACA,qBAIgC,yCAAA,oBAAA,GAAA,2BAAA,IAAJ,gDAAhB,6CAAA,oBAAA,2BAAA,yBAAA,wCAEO,gDAAA,oBAAA,GAAA,iBAAA,2EAAA,oBAAA,GAAA,4CAAA,+CACX,aAAA,yBAHI,wBAMK,+CAAA,GCmrHrB,8BAA+D,cACjC,UAApB,YACoC,wEAAb,wEAAT,YAApB,sBAAA,EHz3GJ,8BAAmG,qBAiCnF,GAAA,MDxpBhB,+CAAoE,OAChE,cAAoC,cAmExC,kBASwC,cAAkC,kHAAA,OAAlC,6BAAA,OAAT,cACjB,0BAAA,oBAAA,GAAA,gBAAA,mBAAA,oBAAA,GAAA,oBAAV,0CA7EoC,IAApC,8DAAA,oEAAA,2EAAA,GC6uBJ,8BAA2D,cAEnC,mFAAA,GCv0BxB,8BAAkC,OACF,SAAA,GAAA,wCAAA,WAAA,QAAA,GAAA,wCAAA,OAGS,mCAAA,GGCzC,gCAAoF,0FAIpB,mCAAA,oBAAA,GAAA,4CAA5B,8BAChC,mDACqC,6GAAA,eAA0B,oCAAA,YACxC,cAAY,wEAAA,QAC/B,6CAE8B,mBAAA,kBAqB9B,GArB8B,GAAA,gBAAA,yCACtB,mBAC2D,gCAE3D,GAF2D,wCAAb,wEAAzB,SAAA,GAAA,wCAAA,WAAA,QAAA,GAAA,wCAAA,QAChB,mBAAA,oBAAA,GAAA,gBAAA,4CACL,GAGwB,sBAAA,yBAAA,GAAA,kBAAA,mDACd,oCACgB,0BACtB,SAOM,0BAAA,uBAPK,kCAAA,GAOL,GAAA,kBAAA,iCAAoB,0FAAA,cAC9B,GAJU,0BAAA,yBAAA,GAAA,kBAAA,iCAAe,0FAAA,eAIzB,cAGR,6BA8DR,eACuB,yFAAyC,qBA7DtB,eACN,YAAhC,4BAAA,GCkoCJ,8CAAsE,WAKzB,kBACV,0DAC3B,qCACA,uDAEU,yBAAA,oBAAA,GAAA,wCAAA,KAAd,oDAAA,EC/sCJ,8BAAmC,OA0BU,cAApB,6BAAA,GFwGzB,8BAAiC,OACe,qBACT,qFAAA,OACZ,iBAEO,mBAAA,oBAAA,GAAA,gBAAA,wCAC1B,iBACiE,gCAEjE,GAFiE,wCAAnB,wEAAzB,SAAA,GAAA,wCAAA,WAAA,QAAA,GAAA,wCAAA,OACZ,mBAAA,oBAAA,GAAA,gBAAA,wCACT,uBAG6C,aAC7C,qCAAkB,2BACJ,mBAAA,oBAAA,GAAA,4CAAsB,qFAAxC,sBAAA,GCyiCJ,kCAA8H,OAGpH,+BAGoF,wEAAA,WAAb,0FAAA,IAA/B,qCAAA,oBAAA,GAAA,4CAAA,eAAlB,OAAA,oBAAA,GAAA,wCAAA,gBAA5B,sBAAA,GA8DJ,8BAAmD,WAGzC,eACgD,WAAI,0FAAA,IAAnC,qCAAA,oBAAA,GAAA,wCAAvB,sBAAA,GHl2BJ,mCAAW,qEAIP,0BACA,qBAIgC,yCAAA,oBAAA,GAAA,2BAAA,IAAJ,gDAAhB,6CAAA,oBAAA,2BAAA,yBAAA,wCAEO,gDAAA,oBAAA,GAAA,iBAAA,2EAAA,oBAAA,GAAA,4CAAA,+CACX,aAAA,yBAHI,wBAMK,+CAAA,GGuyBrB,+BAA0D,6DACjC,6GAAA,eAAA,QAAiB,4BAAA,IAAtC,uBAAA,GD1oCJ,uCAAO,wGAKyD,mCAAA,oBAAA,GAAA,4CAA5B,8BACI,wEAAA,4BACpC,mDACqD,kBACpB,cAAsB,wEAAA,QACnD,+CAC+C,2GAuCvD,cACuB,gCAxCgC,eAA8B,oCAwC9D,wCAAyC,eArCd,YACU,kBAmC5D,cACuB,wEAAyC,eAnCd,YACI,iHAAA,kBAAmC,0CAAA,eACjF,kDAP6E,cAC7E,iDAAA,GAeR,wCAAO,mCAGyD,mCAAA,oBAAA,GAAA,4CAA5B,6BACA,wEAAA,uBACW,iBACpB,cAAY,wEAAA,OACtB,OACT,qDACmD,gCAc3D,aACuB,gCAfoC,wCAAb,wEAAjB,OAAA,GAAA,wCAeN,wCAAyC,eAXlB,WACM,qBACL,qFAAA,WACsB,wEAAvB,wEAAjB,SAAA,GAAA,wCAAA,WAAA,QAAA,GAAA,wCAAA,OACM,iBACT,0BAAA,yBAAA,GAAA,kBAAA,kDACT,0BAAA,yBAAA,GAAA,kBAAA,4CAVY,cAAA,SAAA,GAAA,gDAAA,OACP,0BAAA,yBAAA,GAAA,kBAAA,kDACT,0BAAA,yBAAA,GAAA,kBAAA,0CAQI,yBAAA,GCmoCjB,sCAAmD,kBAGzC,eACgD,gBAAI,uGAAA,IAAnC,qCAAA,oBAAA,GAAA,wCAAvB,sBAAA,GL3ZJ,8BAAmE,cAE3C,mFAAA,GO43BxB,mDAAuF,cACjD,+FACjB,sDCp5CrB,sBACY,sBAC6B,OAAd,yCDk5CA,IAAjB,cAAN,qCAAA,oBAAA,SAAA,wBAEY,YADa,iFAGJ,uCAArB,oGAAA,GJwgFJ,8BAAgE,OAC5D,mBAAA,oBAA8C,iBAAA,SAAA,IAA9C,sBAAA,GDr2HJ,8BAA6B,kBACrB,6BAAK,wCAAA,oBAAA,GCi1Hb,8BAAgE,cAClC,UAApB,YAIoB,wEAAA,kBAA1B,sBAAA,GJjiIJ,8CAA2J,cAC5H,iGAAA,cAAuB,mDAAA,WAClD,cAAmC,8CAAnC,8DAAA,mCAAA,0CAAA,EDvLJ,8BAAqC,OACjC,oBAAA,GSotDJ,mDAAuF,cACjD,+FACjB,sDCp5CrB,sBACY,sBAC6B,OAAd,yCDk5CA,IAAjB,cAAN,qCAAA,oBAAA,SAAA,wBAEY,YADa,iFAGJ,uCAArB,oGAAA,GL30CJ,mCAAW,qEAIP,0BACA,qBAIgC,yCAAA,oBAAA,GAAA,2BAAA,IAAJ,gDAAhB,6CAAA,oBAAA,2BAAA,yBAAA,wCAEO,gDAAA,oBAAA,GAAA,iBAAA,2EAAA,oBAAA,GAAA,4CAAA,+CACX,aAAA,yBAHI,wBAMK,+CAAA,EO3UrB,8BAAoF,cAChF,6CAAA,EA1EJ,8BAA0C,OAC9B,2BAAA,GD8TZ,8CAA0F,qBAClD,WAAA,QAAA,GAAA,wCAAA,OACd,sCAAd,8DAAA,mCAAA,0CAAA,GDpRZ,kCAuCY,cAAmB,uFAAnB,mCA2DJ,OAGc,qGAAd,+BAcA,0BAAA,GEjGR,sCACY,0CAA0B,OAAR,iCAAA,oBAAA,GAAA,gBAAA,eAAA,oBAAA,GAAA,YAAA,mBAAA,oBAAA,GAAA,gBAAlB,kCAAA,GRWZ,kCAA6D,OAC7B,aAAsB,OAAV,OA0C5C,OACI,YA1CA,OAAc,cAAS,OAAT,WACc,OAwChC,OACI,YAxCsB,4BACH,cAAT,+CAAA,GF2Ld,uCAAmD,cAEjB,wCACF,OACxB,MAAgB,sBACE,cAED,0BAAA,oBAAA,GAAA,gBAAA,mBAAA,oBAAA,GAAA,gBAAA,oBAAA,UACrB,cAAY,cAAc,0BAAA,oBAAA,GAAA,gBAAA,mBAAA,oBAAA,GAAA,gBAAA,QAzN9B,oCACI,cAAuB,cAAK,OAAL,2BAwN8B,qBAAA,GImtHzD,sCAA2E,cAQ9D,UOv4HiD,GPu4HlB,WAAA,SAAA,0BAAiB,2CAIjC,OAAgB,0BAAA,oBAAA,GAAA,gBAAA,mBAAA,oBAAA,GAAA,gBAAxC,kCAAA,GEh7FJ,8BAAuC,OAC7B,+BACa,wEAAA,0BAAnB,sBAAA,GAjkBJ,0CAA6D,cAEzD,0EACM,0DAAU,mDACP,OAAT,oDAAA,GNxVJ,mDAA4I,cAMpI,MACA,WACA,4CAGJ,cAA8B,kBA8GV,OAKY,cAnHgB,eA5IpD,qBACI,cAAwB,cAAK,OAAL,uBA2IwB,+CAAA,GAAoC,oDAAA,kBAEpE,0BAAA,oBAAA,GAAA,gBAAA,mBAAA,oBAAA,GAAA,gBAAA,oBAAA,UAChB,qDAAA,GQhJJ,sCAuCY,cAAmB,uFAAnB,+BA2DJ,WAGc,4FAAd,+BA9DI,0BAAmB,sFAAnB,+BA2DJ,WAGc,4FAAd,+BAcA,0BAAA,GA0iDR,mDAAuF,cACjD,+FACjB,sDCp5CrB,sBACY,sBAC6B,OAAd,yCDk5CA,IAAjB,cAAN,qCAAA,oBAAA,SAAA,wBAEY,YADa,iFAGJ,uCAArB,oGAAA,GIvuDJ,0CAA6D,cACzD,WACO,WAAc,uCACjB,OAAS,cAAc,mCAAM,oCAAA,kBAAvB,GAAuB,GAAA,YAAA,sBAAA,oBAAA,GAAA,YAAA,eAAA,oBAAA,GAAA,YAAA,QAAN,4GAAA,OAAd,+BAAA,OAAH,wEAAA,OAAA,EAAA,EAAA,0BAAA,GJ6cd,0CAA6B,yBAEzB,0BGipBJ,sBH1foB,YACA,cAAsB,2CAAtB,uDAAA,GAAA,uBAAA,+BAGgB,8CAAhB,uDAAA,uBAAA,8BAAA,GIjnBpB,kDAA2D,cACvD,cAAmB,OAAK,OAAL,kCAAnB,8DAAA,mCAAA,0CAAA,GJk+BJ,+EAAQ,qBACO,iGAAA,cAEkC,2FAiCzC,eAAmB,uFAjCsB,cAAe,cAiCxD,gCAAA,GAjCwD,WACpC,uCAA6B,gCAAA,WAAA,6CAAA,WAE7C,YACA,cAAsB,+BAAtB,uDAAA,GAAA,wBAAA,wCAEJ,WACgD,0DAAR,yCAAlB,4CAAA,8BAAA,cACP,kCAAA,kBAAA,mDAAA,GAAA,kBADO,qDKr6BC,uBL06BW,oCAJnB,0BAAA,yBAAA,GAAA,kBAAA,0BAAA,yBAAA,GAAA,kBAAA,2CADO,4BAOP,aAAP,wDAAA,gDAEA,gBAAmB,+GAAnB,qCACA,gBAA2B,mHAA3B,qCAAA,GAG6B,2BACE,uFAAK,uBACpC,gBAA2B,oHAA3B,qCACA,gBAAmB,+GAAnB,qCACA,iBAA2B,oHAA3B,qCAAA,GAGA,iBAA2B,mHAA3B,qCACA,iBAAmB,+GAAnB,uCAKR,iCAAA,GEt9BR,sDAAsE,qBACjD,UAAW,4BACZ,OAAY,aAAO,iCAAM,mDAEd,aAAkB,OAAN,wEAAiB,uBAChD,OAAY,OAAY,OAAO,2CAAA,oBAAA,GAAA,YAAA,eAAA,oBAAA,GAAA,YAAA,sBAAa,iCAAA,oBAAA,GAAA,gBAAA,eAAA,oBAAA,GAAA,YAAA,mBAAA,oBAAA,GAAA,gBAAA,uBAAA,oBAAA,GAAA,wCAAA,mDAAA,oBAAA,GAAA,wCAAA,kBAC5C,OAAI,yBAAK,wEAAA,OAEL,MAAQ,mDAEZ,oDAAA,GFyZZ,8BAA6B,kBAEzB,0BGipBJ,sBA7BA,cHnmB8B,gBAAlB,uDAAA,uBAAA,8BAAA,GA0MZ,8BAAQ,OAI2C,gBAArB,uDAAA,uBAAA,8BAAA,GA7mB9B,sCAuCY,cAAmB,uFAAnB,+BA2DJ,WAGc,4FAAd,+BA9DI,0BAAmB,sFAAnB,+BA2DJ,WAGc,4FAAd,+BAcA,0BAAA,GKGR,uDAAiD,cAC7C,WAKA,WACO,WAAK,mCAAM,GAkBN,GAhBD,aAAE,wEAAQ,yCACQ,qBAAc,+CAAA,kBADX,GACW,GAAA,YTi8C/C,6BACI,kBSl8C2C,WAC/B,sBAAA,GACJ,WAAI,wEAAA,OAHkB,WAAE,wEAAA,OAAA,GAEpB,CAIJ,OAAK,yCAC+B,OAAE,eAAA,kBASlC,GATkC,GAAA,YAAA,cAAF,yFAAA,OAA1B,mDAAA,kBACN,OAAE,wEAAO,iCAAM,wDAEX,gCAEsB,qBAAO,kEAAA,uBAF7B,GAE6B,GAAA,aAAA,qBAAA,yBAAA,GAAA,aAAA,YAAP,sHAAA,QAAd,2DAGhB,aAAE,oGAAA,QACF,aAAI,wFAAA,SAAA,EAAA,EAIZ,sEAAA,GA7LJ,sCAAkG,qDACzE,yCAArB,8DAAA,mCAAA,0CAAA,GDCJ,0CAA+E,qBAC3E,WACO,gDACH,cAAiB,sFADF,GACf,+BADa,WAAE,sEAAA,OAAA,EAAA,EAAA,0BAAA,GJ8pBvB,8BAAQ,OAIkB,OAoCN,4BAAhB,uDAAA,uBAAA,8BAAA,GK1tBJ,8BAAkD,OAE/B,kGAAA,eAAA,iGAAA,eAAA,iGAAA,eAAA,iGAAA,eAAA,aAAA,IAAf,8DAAA,mCAAA,0CAAA,GA0EJ,8CAAyD,kBACtC,yCAKH,wCAJW,mBAAA,kBAAA,GAAA,gBACH,mDACA,mDACA,mDAHG,oDAIX,IALZ,8DAAA,mCAAA,0CAAA,GAaJ,kDAA2D,cAC3C,mBAAN,QACM,mBAAA,oBAAA,GAAA,gBAAA,sDAAN,QACgB,mBAAA,oBAAA,GAAA,gBAAA,oCAEb,mBAAA,oBAAA,GAAA,gBAAA,wEAAgC,mDACzC,oCAAA,oBAAA,GAAA,4CAAA,8CACA,4BAAc,mBAAA,oBAAA,GAAA,gBAAA,gEAEV,0DAAc,mDAElB,gHAAA,GAMJ,kDAA2D,cACR,2FAAA,OAAjC,kDAAA,2DAEV,OAAA,2BAAA,2BAAA,SAAA,sBAAqC,uDAEzC,gFAAA,GA8BJ,8DAA2D,cAC3C,mBAAN,QACM,mBAAA,oBAAA,GAAA,gBAAA,sDAAN,QACgB,mBAAA,oBAAA,GAAA,gBAAA,oCAEb,mBAAA,oBAAA,GAAA,gBAAA,wEAAgC,mDACzC,oCAAA,oBAAA,GAAA,4CAAA,8CACA,4BAAc,mBAAA,oBAAA,GAAA,gBAAA,gEAEL,mBAAA,oBAAA,GAAA,gBAAA,wEAAgC,mDACzC,oCAAA,sBAAA,GAAA,qDAAA,0DACA,oCAAc,0BAAA,yBAAA,GAAA,kBAAA,kFAEL,0BAAA,yBAAA,GAAA,kBAAA,8FAAgC,2DACzC,8CAAA,yBAAA,GAAA,qDAAA,2DACA,oCAAc,0BAAA,yBAAA,GAAA,kBAAA,kFAEV,4EAAiB,2DACjB,kFAAkB,2DAEtB,0IAAA,GAzIJ,wCAA0E,qDACxB,mGAAA,OAA/B,mDAAA,cACL,OAAJ,YACE,0DAwBI,wCAnBH,cAAG,iCAAA,kBAAA,GAAA,gBAEJ,cAAG,iCAAA,kBAAA,GAAA,gBAIqE,4BACpE,oDAAA,GAOJ,cAAG,iCAAA,oBAAA,GAAA,gBAAA,WAAuC,sBAAA,oBAAA,GAAA,6CAAA,0BAAzB,OAAA,oBAAA,GAAA,wCAAA,OACjB,cAAG,iCAAA,oBAAA,GAAA,oBAAA,cAAwC,kBAAA,oBAAA,GAAA,4CAAA,wBAA1B,OAAA,sBAAA,GAAA,gDAAA,OACjB,cAAG,2CAAA,yBAAA,GAAA,wBAAA,kBAAwC,6BAAA,yBAAA,GAAA,qDAAA,gCAA1B,UAAA,yBAAA,GAAA,gDAAA,SACjB,cAAG,2CAAA,yBAAA,GAAA,wBAAA,8CAAc,UAAA,yBAAA,GAAA,gDAAA,kBARjB,cAAG,2CAAA,yBAAA,GAAA,mBAAA,cAAuC,6BAAA,yBAAA,GAAA,sDAAA,kCAAzB,UAAA,yBAAA,GAAA,gDAAA,SACjB,cAAG,2CAAA,yBAAA,GAAA,wBAAA,kBAAwC,wBAAA,yBAAA,GAAA,qDAAA,gCAA1B,UAAA,yBAAA,GAAA,gDAAA,SACjB,cAAG,2CAAA,yBAAA,GAAA,wBAAA,8CAAc,UAAA,yBAAA,GAAA,gDAAA,kBATd,aAAuC,6BAAA,yBAAA,GAAA,sDAAA,kCAAzB,UAAA,yBAAA,GAAA,gDAAA,SACjB,cAAG,2CAAA,yBAAA,GAAA,wBAAA,8CAAc,UAAA,yBAAA,GAAA,gDAAA,kBAHb,aAAc,yBAAA,yBAAA,GAAA,gDAAA,oBAqB1B,uEAAA,GL0jCJ,oCAAQ,4CACE,eAEgB,WAStB,OAGA,YAEA,6FAEA,OACsB,WAElB,6DAAA,GAWkC,GAV3B,mDACH,WAAM,gCADc,GACd,wCAAA,OACN,OAAY,oDAAA,oBAAA,GAAA,gBAAkB,OAAuB,YAAvB,wCAFd,OAAI,mBAAA,EAkBhB,EAJJ,SAAgB,YAAA,SAAA,GAAA,wCAAA,cAChB,WAAM,wEAAA,OACN,OAAG,mBAAA,oBAAA,GAAA,gBAAA,sBAA8B,oBAAA,oBAAA,GAAA,wCAAT,mBACxB,OAAE,YAAA,SAAA,GAAA,wCAAA,cACE,eAAA,GAAA,GAAA,CAAA,GAbJ,gEACA,aAAM,2CAGN,aAAM,2CAHA,gDAAA,QACN,QAAG,2BAAA,uBAAA,GAAA,mBAEG,gDAAA,QACN,QAAY,wEAAA,yBAAA,GAAA,mBAAkB,6DAH3B,sCAAwB,4BAAA,yBAAA,GAAA,sDAAV,oHAAA,iBA6BT,QAAI,yDAAA,yBAAA,GAAA,mBAAA,0CAAA,yBAAA,GAAA,mBAAA,2BAAA,yBAAA,GAAA,mBAAA,gCAAJ,qBAAhB,wEAAA,6BAAA,oCAAA,GAUJ,8BAAmC,OAKuB,wEAAO,8CAAA,oBAAA,GAAA,iBAJ7D,kCAAA,GAkhBJ,8BAA6C,yBAC1B,oHACI,kDAAA,+FAAA,wCAAA,WACU,mDACjB,wCADiB,YAAA,UAAA,SAAgD,0FAAA,SAAxD,6FAAA,SACT,IAHZ,sBAAA,GKllDJ,sDAA+F,cAC/E,mBAAN,QACM,mBAAA,oBAAA,GAAA,gBAAA,sDAAN,QACgB,mBAAA,oBAAA,GAAA,gBAAA,oCAEb,mBAAA,oBAAA,GAAA,gBAAA,wEAAgC,mDACzC,oCAAA,oBAAA,GAAA,4CAAA,8CACA,4BAAc,mBAAA,oBAAA,GAAA,gBAAA,gEAEL,mBAAA,oBAAA,GAAA,gBAAA,wEAAgC,mDACzC,oCAAA,sBAAA,GAAA,qDAAA,0DACA,oCAAc,0BAAA,yBAAA,GAAA,kBAAA,kFAEV,2EAAe,2DAEnB,0IAAA,GAjJJ,8BAA+C,4CACvC,yBAAU,kDACV,qCAAW,kDACX,sCAAa,kDACb,uCAAc,2CAClB,kDAAA,GA+hDJ,8BAAyC,8CACtB,4DAAA,WAAA,SAAA,IAAf,sBAAA"
}